<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 205]
- [cs.MM](#cs.MM) [Total: 3]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.LG](#cs.LG) [Total: 164]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos](https://arxiv.org/abs/2512.12060)
*Tejas Panambur,Ishan Rajendrakumar Dave,Chongjian Ge,Ersin Yumer,Xue Bai*

Main category: cs.CV

TL;DR: CreativeVR是一个针对AI生成视频和真实视频中严重结构/时序伪影的修复框架，通过单一精度控制旋钮在精确修复与结构/运动校正间平滑权衡，在AIGC伪影修复上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有T2V扩散模型常产生扭曲的面部、手部、背景和时序不一致运动等严重结构伪影，类似问题也出现在低质量真实视频中。传统视频修复方法主要针对模糊和下采样等合成退化，而扩散先验修复器通常针对光度噪声训练，难以在感知质量与保真度间取得平衡。

Method: 提出基于深度适配器的扩散先验引导视频修复框架，核心创新是训练时使用的时序一致性退化模块，该模块应用精心设计的变换来产生真实的结构失效。方法暴露单一精度控制旋钮，可调节模型对输入的遵循程度。

Result: 在严重伪影视频上达到SOTA结果，在标准视频修复基准上具有竞争力，在单张80GB A100上以约13FPS处理720p视频。提出AIGC54基准用于评估AIGC伪影修复。

Conclusion: CreativeVR为AI生成视频和严重退化真实视频提供有效的修复解决方案，通过单一控制实现精确修复与创造性校正的平衡，在AIGC伪影修复领域取得突破。

Abstract: Modern text-to-video (T2V) diffusion models can synthesize visually compelling clips, yet they remain brittle at fine-scale structure: even state-of-the-art generators often produce distorted faces and hands, warped backgrounds, and temporally inconsistent motion. Such severe structural artifacts also appear in very low-quality real-world videos. Classical video restoration and super-resolution (VR/VSR) methods, in contrast, are tuned for synthetic degradations such as blur and downsampling and tend to stabilize these artifacts rather than repair them, while diffusion-prior restorers are usually trained on photometric noise and offer little control over the trade-off between perceptual quality and fidelity.
  We introduce CreativeVR, a diffusion-prior-guided video restoration framework for AI-generated (AIGC) and real videos with severe structural and temporal artifacts. Our deep-adapter-based method exposes a single precision knob that controls how strongly the model follows the input, smoothly trading off between precise restoration on standard degradations and stronger structure- and motion-corrective behavior on challenging content. Our key novelty is a temporally coherent degradation module used during training, which applies carefully designed transformations that produce realistic structural failures.
  To evaluate AIGC-artifact restoration, we propose the AIGC54 benchmark with FIQA, semantic and perceptual metrics, and multi-aspect scoring. CreativeVR achieves state-of-the-art results on videos with severe artifacts and performs competitively on standard video restoration benchmarks, while running at practical throughput (about 13 FPS at 720p on a single 80-GB A100). Project page: https://daveishan.github.io/creativevr-webpage/.

</details>


### [2] [Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2512.11865)
*Ju-Young Kim,Ji-Hong Park,Myeongjun Kim,Gun-Woo Kim*

Main category: cs.CV

TL;DR: 提出基于OpenVLA-OFT框架的可解释对抗鲁棒视觉-语言-动作模型，通过Evidence-3模块检测光度扰动并生成自然语言解释，提升智能农业系统在对抗攻击下的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 智能农业中依赖RGB相机感知和机械臂控制的系统容易受到色调、光照、噪声等光度扰动的对抗攻击，导致系统故障，需要提高系统的对抗鲁棒性和可解释性。

Method: 基于OpenVLA-OFT框架构建可解释对抗鲁棒视觉-语言-动作模型，集成Evidence-3模块检测光度扰动并生成自然语言解释，说明扰动原因和影响。

Result: 实验表明，相比基线模型，当前动作L1损失降低21.7%，下一动作L1损失降低18.4%，在对抗条件下提高了动作预测准确性和可解释性。

Conclusion: 提出的模型有效提升了智能农业系统在对抗攻击下的鲁棒性和可解释性，为光度扰动环境下的可靠操作提供了解决方案。

Abstract: Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.

</details>


### [3] [Temporal-Anchor3DLane: Enhanced 3D Lane Detection with Multi-Task Losses and LSTM Fusion](https://arxiv.org/abs/2512.11869)
*D. Shainu Suhas,G. Rahul,K. Muni*

Main category: cs.CV

TL;DR: Temporal-Anchor3DLane通过改进损失函数、加入轻量级时序融合模块和训练优化，显著提升了单目3D车道线检测的精度和时序稳定性。


<details>
  <summary>Details</summary>
Motivation: 单目3D车道线检测面临深度模糊、遮挡和帧间时序不稳定等挑战。虽然Anchor3DLane等基于锚点的方法在多摄像头环视中表现良好，但仍存在回归异常值敏感、全局曲线几何监督弱、多损失项平衡困难以及时序连续性利用有限等问题。

Method: 提出了Temporal-Anchor3DLane框架，包含三个关键改进：(1) 多任务损失改进：包括Balanced L1回归、Chamfer点集距离和基于不确定性的损失加权，以及分类和可见性的focal和Dice组件；(2) 轻量级时序LSTM融合模块：跨帧聚合每个锚点的特征，替代较重的Transformer式时序融合；(3) ESCOP风格训练优化：将曲线级监督与时序一致性相结合。

Result: 在OpenLane数据集上，Temporal-Anchor3DLane将F1分数提升了+6.2，并产生了更平滑的时序轨迹。结果表明，小的架构和损失改进显著增强了3D车道线检测的鲁棒性，无需额外传感器或扩大规模。

Conclusion: 通过精心设计的损失函数改进、轻量级时序融合和训练优化，Temporal-Anchor3DLane显著提升了单目3D车道线检测的性能，证明了在不增加额外传感器或计算复杂度的情况下，通过系统性的改进可以获得显著的性能提升。

Abstract: Monocular 3D lane detection remains challenging due to depth ambiguity, occlusion, and temporal instability across frames. Anchor-based approaches such as Anchor3DLane have demonstrated strong performance by regressing continuous 3D lane curves from multi-camera surround views. However, the baseline model still exhibits (i) sensitivity to regression outliers, (ii) weak supervision of global curve geometry, (iii) difficulty in balancing multiple loss terms, and (iv) limited exploitation of temporal continuity. We propose Temporal-Anchor3DLane, an enhanced 3D lane detection framework that extends Anchor3DLane with three key contributions: (1) a set of multi-task loss improvements, including Balanced L1 regression, Chamfer point-set distance, and uncertainty-based loss weighting, together with focal and Dice components for classification and visibility; (2) a lightweight Temporal LSTM Fusion module that aggregates per-anchor features across frames, replacing a heavier Transformer-style temporal fusion; and (3) ESCOP-style training refinements that couple curve-level supervision with temporal consistency. On OpenLane, Temporal-Anchor3DLane improves F1 by +6.2 and yields smoother temporal trajectories, showing that small architectural and loss refinements significantly enhance 3D lane robustness without extra sensors or scaling.

</details>


### [4] [Schrodinger Audio-Visual Editor: Object-Level Audiovisual Removal](https://arxiv.org/abs/2512.12875)
*Weihan Xu,Kan Jen Cheng,Koichi Saito,Muhammad Jehanzeb Mirza,Tingle Li,Yisi Liu,Alexander H. Liu,Liming Wang,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji,Gopala Anumanchipalli,Paul Pu Liang*

Main category: cs.CV

TL;DR: SAVE模型通过Schrodinger Bridge实现音频和视频的联合编辑，在SAVEBench数据集上训练，能同时编辑音频和视频内容并保持对齐。


<details>
  <summary>Details</summary>
Motivation: 音频和视觉内容的联合编辑对于精确可控的内容创作至关重要，但面临配对数据稀缺和模态异质性的挑战。

Method: 提出SAVEBench配对音频-视觉数据集，并训练SAVE模型——基于流匹配的端到端模型，使用Schrodinger Bridge学习从源到目标音频-视觉混合的直接传输。

Result: SAVE模型能够移除音频和视觉中的目标对象同时保留其余内容，在时间同步性和音频-视觉语义对应方面优于音频编辑器和视频编辑器的组合方法。

Conclusion: 提出的SAVE模型通过联合编辑框架有效解决了音频-视觉内容编辑的挑战，在保持内容对齐方面表现出色。

Abstract: Joint editing of audio and visual content is crucial for precise and controllable content creation. This new task poses challenges due to the limitations of paired audio-visual data before and after targeted edits, and the heterogeneity across modalities. To address the data and modeling challenges in joint audio-visual editing, we introduce SAVEBench, a paired audiovisual dataset with text and mask conditions to enable object-grounded source-to-target learning. With SAVEBench, we train the Schrodinger Audio-Visual Editor (SAVE), an end-to-end flow-matching model that edits audio and video in parallel while keeping them aligned throughout processing. SAVE incorporates a Schrodinger Bridge that learns a direct transport from source to target audiovisual mixtures. Our evaluation demonstrates that the proposed SAVE model is able to remove the target objects in audio and visual content while preserving the remaining content, with stronger temporal synchronization and audiovisual semantic correspondence compared with pairwise combinations of an audio editor and a video editor.

</details>


### [5] [Automated Plant Disease and Pest Detection System Using Hybrid Lightweight CNN-MobileViT Models for Diagnosis of Indigenous Crops](https://arxiv.org/abs/2512.11871)
*Tekleab G. Gebremedhin,Hailom S. Asegede,Bruh W. Tesheme,Tadesse B. Gebremichael,Kalayu G. Redae*

Main category: cs.CV

TL;DR: 研究人员为埃塞俄比亚提格雷地区开发了一个离线作物病害检测系统，专注于本地仙人掌无花果病害，使用轻量级模型在移动设备上实现高效诊断。


<details>
  <summary>Details</summary>
Motivation: 提格雷地区80%以上人口依赖农业，但基础设施中断限制了专业作物病害诊断的获取。需要为冲突后边缘环境开发离线可用的诊断工具。

Method: 创建了包含3,587张田间图像的本地仙人掌无花果数据集，评估了三种移动高效架构：自定义轻量级CNN、EfficientNet-Lite1和CNN-Transformer混合模型MobileViT-XS。

Result: EfficientNet-Lite1达到90.7%测试准确率，轻量级CNN达到89.5%且部署最优（42ms推理延迟，4.8MB模型大小），MobileViT-XS达到97.3%平均交叉验证准确率，显示全局推理优于局部纹理分析。

Conclusion: 成功开发了兼容ARM的模型，部署在提格雷尼亚语和阿姆哈拉语本地化的Flutter应用中，支持在Cortex-A53设备上完全离线推理，增强了粮食安全关键诊断的包容性。

Abstract: Agriculture supports over 80% of the population in the Tigray region of Ethiopia, where infrastructural disruptions limit access to expert crop disease diagnosis. We present an offline-first detection system centered on a newly curated indigenous cactus-fig (Opuntia ficus-indica) dataset consisting of 3,587 field images across three core symptom classes. Given deployment constraints in post-conflict edge environments, we benchmark three mobile-efficient architectures: a custom lightweight CNN, EfficientNet-Lite1, and the CNN-Transformer hybrid MobileViT-XS. While the broader system contains independent modules for potato, apple, and corn, this study isolates cactus-fig model performance to evaluate attention sensitivity and inductive bias transfer on indigenous morphology alone. Results establish a clear Pareto trade-off: EfficientNet-Lite1 achieves 90.7% test accuracy, the lightweight CNN reaches 89.5% with the most favorable deployment profile (42 ms inference latency, 4.8 MB model size), and MobileViT-XS delivers 97.3% mean cross-validation accuracy, demonstrating that MHSA-based global reasoning disambiguates pest clusters from two dimensional fungal lesions more reliably than local texture CNN kernels. The ARM compatible models are deployed in a Tigrigna and Amharic localized Flutter application supporting fully offline inference on Cortex-A53 class devices, strengthening inclusivity for food security critical diagnostics.

</details>


### [6] [Pseudo-Label Refinement for Robust Wheat Head Segmentation via Two-Stage Hybrid Training](https://arxiv.org/abs/2512.11874)
*Jiahao Jiang,Zhangrui Yang,Xuanhan Wang,Jingkuan Song*

Main category: cs.CV

TL;DR: 提出用于小麦全语义分割竞赛的自训练框架，结合两阶段混合训练策略与数据增强，使用SegFormer-MiT-B4模型，通过师生迭代循环提升精度，在开发与测试集上取得竞争性表现


<details>
  <summary>Details</summary>
Motivation: 解决Global Wheat Full Semantic Segmentation Competition中的小麦语义分割问题，需要高效利用有限数据并提升模型精度

Method: 系统化自训练框架：1) 两阶段混合训练策略；2) 广泛数据增强；3) SegFormer-MiT-B4核心模型；4) 迭代式师生循环逐步优化模型

Result: 在Development和Testing Phase数据集上均取得竞争性性能表现

Conclusion: 提出的自训练框架能有效提升小麦语义分割精度，通过系统化训练策略和数据利用最大化实现竞争性结果

Abstract: This extended abstract details our solution for the Global Wheat Full Semantic Segmentation Competition. We developed a systematic self-training framework. This framework combines a two-stage hybrid training strategy with extensive data augmentation. Our core model is SegFormer with a Mix Transformer (MiT-B4) backbone. We employ an iterative teacher-student loop. This loop progressively refines model accuracy. It also maximizes data utilization. Our method achieved competitive performance. This was evident on both the Development and Testing Phase datasets.

</details>


### [7] [Generalization vs. Specialization: Evaluating Segment Anything Model (SAM3) Zero-Shot Segmentation Against Fine-Tuned YOLO Detectors](https://arxiv.org/abs/2512.11884)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.CV

TL;DR: SAM3零样本分割与YOLO11微调模型在密集苹果实例分割任务上的对比：YOLO在检测完整性上表现更好，但SAM3在边界稳定性上优势明显（12倍）


<details>
  <summary>Details</summary>
Motivation: 比较两种实例分割范式：专门化微调模型（YOLO11）与通用基础模型（SAM3）在密集场景下的性能差异，为实际应用提供选择依据

Method: 在MinneApple数据集（670张果园图像，28,179个苹果实例）上评估SAM3零样本模式与三种YOLO11变体（nano、medium、large）的微调模型，分析不同IoU阈值下的性能表现

Result: 在IoU=0.15时，YOLO模型F1分数为68.9%-72.2%，SAM3为59.8%；但YOLO在IoU变化时性能下降48-50点，SAM3仅下降4点，边界稳定性是YOLO的12倍

Conclusion: YOLO在检测完整性方面更优，适合需要高召回率的任务；SAM3在边界精度和稳定性方面显著优势，适合需要精确分割的任务。选择取决于具体应用需求

Abstract: Deep learning has advanced two fundamentally different paradigms for instance segmentation: specialized models optimized through task-specific fine-tuning and generalist foundation models capable of zero-shot segmentation. This work presents a comprehensive comparison between SAM3 (Segment Anything Model, also called SAMv3) operating in zero-shot mode and three variants of Ultralytics YOLO11 (nano, medium, and large) fine-tuned for instance segmentation. The evaluation is conducted on the MinneApple dataset, a dense benchmark comprising 670 orchard images with 28,179 annotated apple instances, enabling rigorous validation of model behavior under high object density and occlusion. Our analysis shows IoU choices can inflate performance gaps by up to 30%. At the appropriate IoU = 0.15 threshold, YOLO models achieve 68.9%, 72.2%, and 71.9% F1, while SAM3 reaches 59.8% in pure zero-shot mode. However, YOLO exhibits steep degradation 48-50 points across IoU ranges whereas SAM3 drops only 4 points, revealing 12 times superior boundary stability of SAM3. This highlights the strength of SAMv3 in mask precision versus specialization in detection completeness of YOLO11. We provide open-source code, evaluation pipelines, and methodological recommendations, contributing to a deeper understanding of when specialized fine-tuned models or generalist foundation models are preferable for dense instance segmentation tasks. This project repository is available on GitHub as https://github.com/Applied-AI-Research-Lab/Segment-Anything-Model-SAM3-Zero-Shot-Segmentation-Against-Fine-Tuned-YOLO-Detectors

</details>


### [8] [mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description](https://arxiv.org/abs/2512.11894)
*Mahathir Monjur,Shahriar Nirjon*

Main category: cs.CV

TL;DR: mmWeaver：基于隐式神经表示（INR）和超网络的环境感知毫米波信号生成框架，实现高效、真实的信号合成与数据增强


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达应用（如活动识别和姿态估计）需要多样化的环境特定信号数据集，但毫米波信号复杂、稀疏、高维，物理仿真计算成本高昂，需要高效的信号生成方法

Method: 使用隐式神经表示（INR）将毫米波信号建模为连续函数，结合超网络根据环境上下文（从RGB-D图像提取）和人体运动特征（通过MotionGPT从文本生成姿态）动态生成INR参数，实现多分辨率I/Q信号合成

Result: 实现高达49倍的压缩比，复杂SSIM达0.88，PSNR达35 dB，活动识别准确率提升7%，人体姿态估计误差降低15%，比基于仿真的方法快6-35倍

Conclusion: mmWeaver通过结合语义和几何先验，实现了高效、真实的环境感知毫米波信号生成，为毫米波雷达应用提供了强大的数据增强工具

Abstract: Realistic signal generation and dataset augmentation are essential for advancing mmWave radar applications such as activity recognition and pose estimation, which rely heavily on diverse, and environment-specific signal datasets. However, mmWave signals are inherently complex, sparse, and high-dimensional, making physical simulation computationally expensive. This paper presents mmWeaver, a novel framework that synthesizes realistic, environment-specific complex mmWave signals by modeling them as continuous functions using Implicit Neural Representations (INRs), achieving up to 49-fold compression. mmWeaver incorporates hypernetworks that dynamically generate INR parameters based on environmental context (extracted from RGB-D images) and human motion features (derived from text-to-pose generation via MotionGPT), enabling efficient and adaptive signal synthesis. By conditioning on these semantic and geometric priors, mmWeaver generates diverse I/Q signals at multiple resolutions, preserving phase information critical for downstream tasks such as point cloud estimation and activity classification. Extensive experiments show that mmWeaver achieves a complex SSIM of 0.88 and a PSNR of 35 dB, outperforming existing methods in signal realism while improving activity recognition accuracy by up to 7% and reducing human pose estimation error by up to 15%, all while operating 6-35 times faster than simulation-based approaches.

</details>


### [9] [Hot Hém: Sài Gòn Giũa Cái Nóng Hông Còng Bàng -- Saigon in Unequal Heat](https://arxiv.org/abs/2512.11896)
*Tessa Vu*

Main category: cs.CV

TL;DR: Hot Hém是一个GeoAI工作流，结合街景图像、语义分割和遥感数据，预测胡志明市行人热暴露，实现热感知路径规划


<details>
  <summary>Details</summary>
Motivation: 热带高密度城市中行人热暴露是重要的健康风险，但标准路径规划算法通常忽略微观尺度的热变化

Method: 结合Google街景图像、语义图像分割和遥感数据，训练两个XGBoost模型预测地表温度，并在OSMnx生成的行人网络节点上部署

Result: 开发了Hot Hém工作流，能够估计胡志明市行人热暴露，实现热感知路径规划，识别温度异常高的城市走廊

Conclusion: 该模型为识别城市热暴露热点区域提供了基础，有助于理解基础设施尺度上某些走廊温度异常高的原因

Abstract: Pedestrian heat exposure is a critical health risk in dense tropical cities, yet standard routing algorithms often ignore micro-scale thermal variation. Hot Hém is a GeoAI workflow that estimates and operationalizes pedestrian heat exposure in Hô Chí Minh City (HCMC), Vi\d{e}t Nam, colloquially known as Sài Gòn. This spatial data science pipeline combines Google Street View (GSV) imagery, semantic image segmentation, and remote sensing. Two XGBoost models are trained to predict land surface temperature (LST) using a GSV training dataset in selected administrative wards, known as phŏng, and are deployed in a patchwork manner across all OSMnx-derived pedestrian network nodes to enable heat-aware routing. This is a model that, when deployed, can provide a foundation for pinpointing where and further understanding why certain city corridors may experience disproportionately higher temperatures at an infrastructural scale.

</details>


### [10] [Microscopic Vehicle Trajectory Datasets from UAV-collected Video for Heterogeneous, Area-Based Urban Traffic](https://arxiv.org/abs/2512.11898)
*Yawar Ali,K. Ramachandra Rao,Ashish Bhaskar,Niladri Chatterjee*

Main category: cs.CV

TL;DR: 该论文提供了使用无人机在异质、区域型城市交通条件下收集的开放微观车辆轨迹数据集，解决了传统路边视频采集的遮挡和视角限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统路边视频采集在密集混合交通中因遮挡、视角有限和车辆不规则运动而效果不佳，需要更好的数据采集方法来研究复杂城市交通环境。

Method: 使用无人机从俯视角度采集交通数据，通过Data from Sky平台提取，在印度国家首都区的六个路段收集，包含时间戳位置、速度、加速度和车辆分类信息。

Result: 创建了包含丰富时空动态的开放数据集，分辨率30帧/秒，验证了手动计数、空间平均速度和探测轨迹，揭示了车道保持偏好、速度分布和横向操纵等行为模式。

Conclusion: 这些开放数据集为全球研究社区提供了独特资源，支持模拟建模、安全评估和行为研究，有助于开发更准确代表复杂城市交通环境的模型。

Abstract: This paper offers openly available microscopic vehicle trajectory (MVT) datasets collected using unmanned aerial vehicles (UAVs) in heterogeneous, area-based urban traffic conditions. Traditional roadside video collection often fails in dense mixed traffic due to occlusion, limited viewing angles, and irregular vehicle movements. UAV-based recording provides a top-down perspective that reduces these issues and captures rich spatial and temporal dynamics. The datasets described here were extracted using the Data from Sky (DFS) platform and validated against manual counts, space mean speeds, and probe trajectories in earlier work. Each dataset contains time-stamped vehicle positions, speeds, longitudinal and lateral accelerations, and vehicle classifications at a resolution of 30 frames per second. Data were collected at six mid-block locations in the national capital region of India, covering diverse traffic compositions and density levels. Exploratory analyses highlight key behavioural patterns, including lane-keeping preferences, speed distributions, and lateral manoeuvres typical of heterogeneous and area-based traffic settings. These datasets are intended as a resource for the global research community to support simulation modelling, safety assessment, and behavioural studies under area-based traffic conditions. By making these empirical datasets openly available, this work offers researchers a unique opportunity to develop, test, and validate models that more accurately represent complex urban traffic environments.

</details>


### [11] [Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models](https://arxiv.org/abs/2512.11899)
*Futa Waseda,Shojiro Yamabe,Daiki Shiono,Kento Sasaki,Tsubasa Takahashi*

Main category: cs.CV

TL;DR: 该论文提出了RIO-VQA任务和RIO-Bench基准，用于评估大型视觉语言模型在需要选择性读取或忽略图像中文本时的能力，解决了现有评估方法过度鼓励忽略文本的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型容易受到排版攻击，而现有的评估和防御方法主要关注物体识别，隐含地鼓励忽略文本来实现鲁棒性。然而，现实场景通常需要同时对物体和文本进行联合推理（如识别行人的同时读取交通标志）。

Method: 提出了Read-or-Ignore VQA（RIO-VQA）任务，形式化了视觉问答中文本的选择性使用。开发了RIO-Bench基准数据集和评估协议，为每个真实图像提供相同场景的反事实（读取/忽略），仅改变文本内容和问题类型。

Result: 使用RIO-Bench评估显示，强大的LVLMs和现有防御方法无法平衡排版鲁棒性和文本读取能力。RIO-Bench还支持一种新的数据驱动防御方法，学习自适应选择性文本使用。

Conclusion: 这项工作揭示了现有评估范围与现实需求之间的根本错位，为构建可靠的LVLMs提供了原则性路径。RIO-Bench为开发既能抵抗攻击又能有效利用文本的模型提供了标准化评估框架。

Abstract: Large vision-language models (LVLMs) are vulnerable to typographic attacks, where misleading text within an image overrides visual understanding. Existing evaluation protocols and defenses, largely focused on object recognition, implicitly encourage ignoring text to achieve robustness; however, real-world scenarios often require joint reasoning over both objects and text (e.g., recognizing pedestrians while reading traffic signs). To address this, we introduce a novel task, Read-or-Ignore VQA (RIO-VQA), which formalizes selective text use in visual question answering (VQA): models must decide, from context, when to read text and when to ignore it. For evaluation, we present the Read-or-Ignore Benchmark (RIO-Bench), a standardized dataset and protocol that, for each real image, provides same-scene counterfactuals (read / ignore) by varying only the textual content and question type. Using RIO-Bench, we show that strong LVLMs and existing defenses fail to balance typographic robustness and text-reading capability, highlighting the need for improved approaches. Finally, RIO-Bench enables a novel data-driven defense that learns adaptive selective text use, moving beyond prior non-adaptive, text-ignoring defenses. Overall, this work reveals a fundamental misalignment between the existing evaluation scope and real-world requirements, providing a principled path toward reliable LVLMs. Our Project Page is at https://turingmotors.github.io/rio-vqa/.

</details>


### [12] [CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities](https://arxiv.org/abs/2512.11901)
*Santosh Patapati*

Main category: cs.CV

TL;DR: CLARGA是一个通用的多模态融合架构，通过注意力加权图和多头图注意力网络实现任意模态的高效融合，具有亚二次复杂度，支持缺失模态，并在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法通常针对特定模态设计，缺乏通用性。需要一种能够处理任意数量和类型模态的统一框架，同时具备高效性和对缺失模态的鲁棒性。

Method: CLARGA为每个样本构建注意力加权图，通过多头图注意力网络在模态特征间传递信息。使用可学习掩码处理缺失模态输入，采用监督任务损失和对比InfoNCE损失的混合目标进行训练。

Result: 在金融、人机交互、多媒体分类和情感计算等7个数据集上，CLARGA均优于基线、SOTA模型和消融实验，展示了在缺失输入下的鲁棒性和在特定任务上的优异表现。

Conclusion: CLARGA是一个通用、高效、鲁棒的多模态融合架构，可轻松集成到各种机器学习模型中，实现跨多种任务的有效表示学习。

Abstract: We introduce CLARGA, a general-purpose multimodal fusion architecture for multimodal representation learning that works with any number and type of modalities without changing the underlying framework. Given a supervised dataset, CLARGA can be applied to virtually any machine learning task to fuse different multimodal representations for processing by downstream layers. On a sample-by-sample basis, CLARGA learns how modalities should inform one another by building an attention weighted graph over their features and passing messages along this graph with a multi-head Graph Attention Network. Not only does this make CLARGA highly adaptive, as it constructs unique graphs for different samples, it makes for efficient fusion with sub-quadratic complexity as the number of modalities grows. Through a learnable mask, it can also adapt to missing modality inputs. The model is trained with a hybrid objective that combines a supervised task loss with contrastive InfoNCE loss, improving cross-modal consistency and robustness to noisy inputs. We demonstrate CLARGA's effectiveness in diverse multimodal representation learning tasks across 7 datasets spanning finance, human-computer interaction, general multimedia classification, and affective computing. It consistently outperforms baselines, state-of-the-art models, and ablations. Additional experiments also demonstrate its robustness to missing inputs and ability to excel on niche tasks. Overall, CLARGA can be easily plugged into machine learning models for effective and efficient learning of representations across a wide variety of tasks.

</details>


### [13] [Smartphone monitoring of smiling as a behavioral proxy of well-being in everyday life](https://arxiv.org/abs/2512.11905)
*Ming-Zher Poh,Shun Liao,Marco Andreetto,Daniel McDuff,Jonathan Wang,Paolo Di Achille,Jiang Wu,Yun Liu,Lawrence Cai,Eric Teasley,Mark Malhotra,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

TL;DR: 通过智能手机被动捕捉的自然微笑可作为主观幸福感的客观行为指标，与全国调查数据高度相关


<details>
  <summary>Details</summary>
Motivation: 传统的主观幸福感测量方法依赖自我报告，存在回忆偏差和参与者负担重的问题，缺乏对日常生活中幸福感表达的理解

Method: 分析233名参与者一周内被动记录的405,448个视频片段，使用深度学习模型量化微笑强度，研究昼夜和每日模式

Result: 微笑强度的每日模式与全国幸福感调查数据高度相关(r=0.92)，昼夜节律与日重建方法结果高度一致(r=0.80)。较高的每日平均微笑强度与更多体力活动和更大光照暴露显著相关

Conclusion: 被动智能手机传感可作为研究情感行为动态的强大、生态有效的方法，为在人群规模上理解这种行为打开了大门

Abstract: Subjective well-being is a cornerstone of individual and societal health, yet its scientific measurement has traditionally relied on self-report methods prone to recall bias and high participant burden. This has left a gap in our understanding of well-being as it is expressed in everyday life. We hypothesized that candid smiles captured during natural smartphone interactions could serve as a scalable, objective behavioral correlate of positive affect. To test this, we analyzed 405,448 video clips passively recorded from 233 consented participants over one week. Using a deep learning model to quantify smile intensity, we identified distinct diurnal and daily patterns. Daily patterns of smile intensity across the week showed strong correlation with national survey data on happiness (r=0.92), and diurnal rhythms documented close correspondence with established results from the day reconstruction method (r=0.80). Higher daily mean smile intensity was significantly associated with more physical activity (Beta coefficient = 0.043, 95% CI [0.001, 0.085]) and greater light exposure (Beta coefficient = 0.038, [0.013, 0.063]), whereas no significant effects were found for smartphone use. These findings suggest that passive smartphone sensing could serve as a powerful, ecologically valid methodology for studying the dynamics of affective behavior and open the door to understanding this behavior at a population scale.

</details>


### [14] [MPath: Multimodal Pathology Report Generation from Whole Slide Images](https://arxiv.org/abs/2512.11906)
*Noorul Wahab,Nasir Rajpoot*

Main category: cs.CV

TL;DR: MPath是一个轻量级多模态框架，使用视觉前缀提示机制将WSI特征注入预训练的生物医学语言模型，用于病理报告自动生成，在RED 2025挑战赛中排名第4。


<details>
  <summary>Details</summary>
Motivation: 从全切片图像自动生成诊断病理报告是计算病理学的新方向，但由于组织形态变异大和病理叙述结构复杂，将高分辨率组织模式转化为临床连贯文本仍然困难。

Method: MPath采用轻量级多模态框架，通过学习的视觉前缀提示机制，将WSI特征（使用CONCH+Titan基础模型提取）注入冻结的预训练生物医学语言模型BioBART，避免端到端视觉语言预训练。

Result: 在RED 2025 Grand Challenge数据集上开发评估，在Test Phase 2中排名第4，尽管提交机会有限，展示了基于提示的多模态条件化策略的潜力。

Conclusion: 基于提示的多模态条件化是病理报告生成的可扩展和可解释策略，MPath框架通过轻量级设计有效结合WSI视觉特征和生物医学语言模型。

Abstract: Automated generation of diagnostic pathology reports directly from whole slide images (WSIs) is an emerging direction in computational pathology. Translating high-resolution tissue patterns into clinically coherent text remains difficult due to large morphological variability and the complex structure of pathology narratives. We introduce MPath, a lightweight multimodal framework that conditions a pretrained biomedical language model (BioBART) on WSI-derived visual embeddings through a learned visual-prefix prompting mechanism. Instead of end-to-end vision-language pretraining, MPath leverages foundation-model WSI features (CONCH + Titan) and injects them into BioBART via a compact projection module, keeping the language backbone frozen for stability and data efficiency. MPath was developed and evaluated on the RED 2025 Grand Challenge dataset and ranked 4th in Test Phase 2, despite limited submission opportunities. The results highlight the potential of prompt-based multimodal conditioning as a scalable and interpretable strategy for pathology report generation.

</details>


### [15] [FloraForge: LLM-Assisted Procedural Generation of Editable and Analysis-Ready 3D Plant Geometric Models For Agricultural Applications](https://arxiv.org/abs/2512.11925)
*Mozhgan Hadadi,Talukder Z. Jubery,Patrick S. Schnable,Arti Singh,Bedrich Benes,Adarsh Krishnamurthy,Baskar Ganapathysubramanian*

Main category: cs.CV

TL;DR: FloraForge：一个LLM辅助框架，让领域专家通过自然语言交互生成参数化3D植物模型，无需编程专业知识


<details>
  <summary>Details</summary>
Motivation: 当前3D植物建模方法存在局限性：基于学习的方法需要大量物种特定训练数据且缺乏可编辑性；程序化建模需要专业几何建模知识和复杂规则理解，领域科学家难以使用

Method: 利用LLM辅助协同设计，通过迭代自然语言植物精炼（PR）生成Python脚本，创建参数化植物几何作为分层B样条曲面表示，具有植物学约束、显式控制点和参数变形函数

Result: 在玉米、大豆和绿豆上演示了框架，通过手动精炼植物描述符（PD）将程序化模型拟合到经验点云数据，生成用于可视化的三角网格和用于定量分析的带参数元数据的三角网格

Conclusion: 该框架独特地结合了LLM辅助模板创建、支持表型分析和渲染的数学连续表示，以及通过PD的直接参数控制，为植物科学民主化复杂几何建模同时保持数学严谨性

Abstract: Accurate 3D plant models are crucial for computational phenotyping and physics-based simulation; however, current approaches face significant limitations. Learning-based reconstruction methods require extensive species-specific training data and lack editability. Procedural modeling offers parametric control but demands specialized expertise in geometric modeling and an in-depth understanding of complex procedural rules, making it inaccessible to domain scientists. We present FloraForge, an LLM-assisted framework that enables domain experts to generate biologically accurate, fully parametric 3D plant models through iterative natural language Plant Refinements (PR), minimizing programming expertise. Our framework leverages LLM-enabled co-design to refine Python scripts that generate parameterized plant geometries as hierarchical B-spline surface representations with botanical constraints with explicit control points and parametric deformation functions. This representation can be easily tessellated into polygonal meshes with arbitrary precision, ensuring compatibility with functional structural plant analysis workflows such as light simulation, computational fluid dynamics, and finite element analysis. We demonstrate the framework on maize, soybean, and mung bean, fitting procedural models to empirical point cloud data through manual refinement of the Plant Descriptor (PD), human-readable files. The pipeline generates dual outputs: triangular meshes for visualization and triangular meshes with additional parametric metadata for quantitative analysis. This approach uniquely combines LLM-assisted template creation, mathematically continuous representations enabling both phenotyping and rendering, and direct parametric control through PD. The framework democratizes sophisticated geometric modeling for plant science while maintaining mathematical rigor.

</details>


### [16] [TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder](https://arxiv.org/abs/2512.11926)
*Qinghao Meng,Chenming Wu,Liangjun Zhang,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出TransBridge框架，通过联合补全与检测网络，利用transformer融合特征，解决稀疏点云区域3D目标检测难题，在nuScenes和Waymo数据集上显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的3D目标检测对感知移动物体和障碍物至关重要，但远距离区域由于LiDAR点云稀疏导致检测困难。现有方法通过点云稠密化解决稀疏性问题，但需要保持计算成本不变的同时提升稀疏区域检测特征。

Method: 提出TransBridge框架：1) 基于transformer的上采样模块融合检测和补全网络特征；2) 动态-静态重建模块生成稠密LiDAR数据作为补全网络真值；3) 利用transformer机制建立通道和空间关系，生成高分辨率特征图用于补全。

Result: 在nuScenes和Waymo数据集上的实验表明，该框架能持续改进端到端3D目标检测，mAP提升0.7-1.5点，展示良好泛化能力。对于两阶段检测框架，mAP提升最高达5.78点。

Conclusion: TransBridge框架通过联合补全和检测网络，有效解决稀疏点云区域检测问题，在保持成本不变的同时显著提升3D目标检测性能，具有实际应用价值。

Abstract: 3D object detection is essential in autonomous driving, providing vital information about moving objects and obstacles. Detecting objects in distant regions with only a few LiDAR points is still a challenge, and numerous strategies have been developed to address point cloud sparsity through densification.This paper presents a joint completion and detection framework that improves the detection feature in sparse areas while maintaining costs unchanged. Specifically, we propose TransBridge, a novel transformer-based up-sampling block that fuses the features from the detection and completion networks.The detection network can benefit from acquiring implicit completion features derived from the completion network. Additionally, we design the Dynamic-Static Reconstruction (DSRecon) module to produce dense LiDAR data for the completion network, meeting the requirement for dense point cloud ground truth.Furthermore, we employ the transformer mechanism to establish connections between channels and spatial relations, resulting in a high-resolution feature map used for completion purposes.Extensive experiments on the nuScenes and Waymo datasets demonstrate the effectiveness of the proposed framework.The results show that our framework consistently improves end-to-end 3D object detection, with the mean average precision (mAP) ranging from 0.7 to 1.5 across multiple methods, indicating its generalization ability. For the two-stage detection framework, it also boosts the mAP up to 5.78 points.

</details>


### [17] [MONET -- Virtual Cell Painting of Brightfield Images and Time Lapses Using Reference Consistent Diffusion](https://arxiv.org/abs/2512.11928)
*Alexander Peysakhovich,William Berman,Joseph Rufo,Felix Wong,Maxwell Z. Wilson*

Main category: cs.CV

TL;DR: 使用扩散模型从明场图像预测细胞染色图像，解决传统细胞染色技术劳动密集和无法研究细胞动态的问题


<details>
  <summary>Details</summary>
Motivation: 传统细胞染色技术存在两个主要问题：1) 劳动密集型，需要大量人工操作；2) 需要化学固定，无法研究细胞动态过程

Method: 训练名为MONET的扩散模型，使用大规模数据集从明场图像预测细胞染色通道。采用一致性架构生成延时视频，并支持上下文学习以部分适应分布外的细胞系和成像协议

Result: 模型质量随规模扩大而提升，能够生成细胞动态的延时视频（尽管缺乏相应的训练数据），并展示出一定的分布外适应能力

Conclusion: 虚拟细胞染色不是要完全取代物理细胞染色，而是作为补充工具，为生物学研究提供新的工作流程

Abstract: Cell painting is a popular technique for creating human-interpretable, high-contrast images of cell morphology. There are two major issues with cell paint: (1) it is labor-intensive and (2) it requires chemical fixation, making the study of cell dynamics impossible. We train a diffusion model (Morphological Observation Neural Enhancement Tool, or MONET) on a large dataset to predict cell paint channels from brightfield images. We show that model quality improves with scale. The model uses a consistency architecture to generate time-lapse videos, despite the impossibility of obtaining cell paint video training data. In addition, we show that this architecture enables a form of in-context learning, allowing the model to partially transfer to out-of-distribution cell lines and imaging protocols. Virtual cell painting is not intended to replace physical cell painting completely, but to act as a complementary tool enabling novel workflows in biological research.

</details>


### [18] [Contextual Peano Scan and Fast Image Segmentation Using Hidden and Evidential Markov Chains](https://arxiv.org/abs/2512.11939)
*Clément Fernandes,Wojciech Pieczynski*

Main category: cs.CV

TL;DR: 提出HEMC-CPS模型，结合上下文Peano扫描和证据隐马尔可夫链，用于无监督图像分割，比传统方法更快且能处理复杂图像。


<details>
  <summary>Details</summary>
Motivation: 传统隐马尔可夫场（HMFs）图像分割方法计算量大，而基于Peano扫描的隐马尔可夫链（HMCs）方法更快但仍有改进空间。上下文Peano扫描（CPS）和证据隐马尔可夫链（HEMCs）各自展现了优势，因此研究将两者结合以进一步提升分割性能。

Method: 提出HEMC-CPS模型，同时结合上下文Peano扫描和证据隐马尔可夫链。采用贝叶斯最大后验概率（MPM）分割，使用随机期望最大化（SEM）方法进行无监督参数估计。

Result: 在合成图像和真实图像上验证了HEMC-CPS模型的有效性。该模型不仅适用于图像分割，还能处理更复杂的图像（如三维或多传感器多分辨率图像）以及任何空间相关数据。

Conclusion: HEMC-CPS模型结合了上下文Peano扫描和证据隐马尔可夫链的优势，在无监督图像分割中表现出色，具有处理复杂图像和空间相关数据的潜力。

Abstract: Transforming bi-dimensional sets of image pixels into mono-dimensional sequences with a Peano scan (PS) is an established technique enabling the use of hidden Markov chains (HMCs) for unsupervised image segmentation. Related Bayesian segmentation methods can compete with hidden Markov fields (HMFs)-based ones and are much faster. PS has recently been extended to the contextual PS, and some initial experiments have shown the value of the associated HMC model, denoted as HMC-CPS, in image segmentation. Moreover, HMCs have been extended to hidden evidential Markov chains (HEMCs), which are capable of improving HMC-based Bayesian segmentation. In this study, we introduce a new HEMC-CPS model by simultaneously considering contextual PS and evidential HMC. We show its effectiveness for Bayesian maximum posterior mode (MPM) segmentation using synthetic and real images. Segmentation is performed in an unsupervised manner, with parameters being estimated using the stochastic expectation--maximization (SEM) method. The new HEMC-CPS model presents potential for the modeling and segmentation of more complex images, such as three-dimensional or multi-sensor multi-resolution images. Finally, the HMC-CPS and HEMC-CPS models are not limited to image segmentation and could be used for any kind of spatially correlated data.

</details>


### [19] [DynaPURLS: Dynamic Refinement of Part-aware Representations for Skeleton-based Zero-Shot Action Recognition](https://arxiv.org/abs/2512.11941)
*Jingmin Zhu,Anqi Zhu,James Bailey,Jun Liu,Hossein Rahmani,Mohammed Bennamoun,Farid Boussaid,Qiuhong Ke*

Main category: cs.CV

TL;DR: DynaPURLS：一个用于零样本骨架动作识别的统一框架，通过动态细粒度视觉-语义对齐和推理时自适应优化，显著提升未见类别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有零样本骨架动作识别方法主要依赖骨架特征与静态、类别级语义的对齐，这种粗粒度对齐无法有效桥接可见与未见类别之间的域偏移，阻碍了细粒度视觉知识的迁移。

Method: 1) 使用大语言模型生成包含全局运动和局部身体部位动态的分层文本描述；2) 自适应分区模块通过语义分组骨架关节生成细粒度视觉表示；3) 动态优化模块在推理时通过轻量可学习投影将文本特征适配到输入视觉流；4) 置信感知、类别平衡的记忆库稳定优化过程，减少噪声伪标签的错误传播。

Result: 在NTU RGB+D 60/120和PKU-MMD三个大规模基准数据集上的广泛实验表明，DynaPURLS显著优于现有方法，创造了新的最先进记录。

Conclusion: DynaPURLS通过建立鲁棒的多尺度视觉-语义对应关系并在推理时动态优化，有效解决了零样本骨架动作识别中的域偏移问题，实现了对未见类别的更好泛化。

Abstract: Zero-shot skeleton-based action recognition (ZS-SAR) is fundamentally constrained by prevailing approaches that rely on aligning skeleton features with static, class-level semantics. This coarse-grained alignment fails to bridge the domain shift between seen and unseen classes, thereby impeding the effective transfer of fine-grained visual knowledge. To address these limitations, we introduce \textbf{DynaPURLS}, a unified framework that establishes robust, multi-scale visual-semantic correspondences and dynamically refines them at inference time to enhance generalization. Our framework leverages a large language model to generate hierarchical textual descriptions that encompass both global movements and local body-part dynamics. Concurrently, an adaptive partitioning module produces fine-grained visual representations by semantically grouping skeleton joints. To fortify this fine-grained alignment against the train-test domain shift, DynaPURLS incorporates a dynamic refinement module. During inference, this module adapts textual features to the incoming visual stream via a lightweight learnable projection. This refinement process is stabilized by a confidence-aware, class-balanced memory bank, which mitigates error propagation from noisy pseudo-labels. Extensive experiments on three large-scale benchmark datasets, including NTU RGB+D 60/120 and PKU-MMD, demonstrate that DynaPURLS significantly outperforms prior art, setting new state-of-the-art records. The source code is made publicly available at https://github.com/Alchemist0754/DynaPURLS

</details>


### [20] [A Comparative Analysis of Semiconductor Wafer Map Defect Detection with Image Transformer](https://arxiv.org/abs/2512.11977)
*Sushmita Nath*

Main category: cs.CV

TL;DR: 本研究探索了在数据受限条件下使用DeiT（数据高效图像变换器）进行晶圆图缺陷分类，相比传统CNN模型（VGG-19、Xception、Squeeze-Net）在准确率、F1分数和训练收敛速度方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 半导体晶圆缺陷检测对预测性维护至关重要，但传统CNN模型在数据有限且不平衡的场景下性能下降。需要探索在数据约束条件下更有效的分类方法。

Method: 采用数据高效图像变换器（DeiT）模型进行半导体晶圆图缺陷分类，并在数据受限条件下与VGG-19、Xception、Squeeze-Net等CNN模型以及混合模型进行对比实验。

Result: DeiT模型达到90.83%的最高分类准确率，显著优于VGG-19(65%)、SqueezeNet(82%)、Xception(66%)和混合模型(67%)。同时获得90.78%的F1分数，训练收敛更快，对少数缺陷类别的检测更具鲁棒性。

Conclusion: 基于变换器的DeiT模型在半导体晶圆缺陷检测中展现出优越性能，特别是在数据受限条件下，为半导体制造过程中的预测性维护策略提供了有力支持。

Abstract: Predictive maintenance is an important sector in modern industries which improves fault detection and cost reduction processes. By using machine learning algorithms in the whole process, the defects detection process can be implemented smoothly. Semiconductor is a sensitive maintenance field that requires predictability in work. While convolutional neural networks (CNNs) such as VGG-19, Xception and Squeeze-Net have demonstrated solid performance in image classification for semiconductor wafer industry, their effectiveness often declines in scenarios with limited and imbalanced data. This study investigates the use of the Data-Efficient Image Transformer (DeiT) for classifying wafer map defects under data-constrained conditions. Experimental results reveal that the DeiT model achieves highest classification accuracy of 90.83%, outperforming CNN models such as VGG-19(65%), SqueezeNet(82%), Xception(66%) and Hybrid(67%). DeiT also demonstrated superior F1-score (90.78%) and faster training convergence, with enhanced robustness in detecting minority defect classes. These findings highlight the potential of transformer-based models like DeiT in semiconductor wafer defect detection and support predictive maintenance strategies within semiconductor fabrication processes.

</details>


### [21] [CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction](https://arxiv.org/abs/2512.11988)
*Xianghui Xie,Bowen Wen,Yan Chang,Hesam Rabeti,Jiefeng Li,Ye Yuan,Gerard Pons-Moll,Stan Birchfield*

Main category: cs.CV

TL;DR: CARI4D：首个从单目RGB视频重建4D人-物交互的类别无关方法，通过姿态假设选择、渲染-比较优化和接触推理实现空间、时间一致的度量尺度重建。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB视图推断4D人-物交互极具挑战性，因为存在未知物体和人体信息、深度模糊、遮挡和复杂运动等问题。现有方法通常需要真实物体模板或局限于有限物体类别，限制了实际应用。

Method: 提出姿态假设选择算法，鲁棒地整合基础模型的个体预测；通过学习的渲染-比较范式联合优化，确保空间、时间和像素对齐；最后通过接触推理进行细化，满足物理约束。

Result: 在分布内数据集上重建误差降低38%，在未见数据集上降低36%，超越了现有方法。模型能泛化到训练类别之外，可零样本应用于真实网络视频。

Conclusion: CARI4D是首个从单目RGB视频实现类别无关、空间时间一致的4D人-物交互重建的方法，在泛化性和准确性方面显著优于先前工作，具有实际应用价值。

Abstract: Accurate capture of human-object interaction from ubiquitous sensors like RGB cameras is important for applications in human understanding, gaming, and robot learning. However, inferring 4D interactions from a single RGB view is highly challenging due to the unknown object and human information, depth ambiguity, occlusion, and complex motion, which hinder consistent 3D and temporal reconstruction. Previous methods simplify the setup by assuming ground truth object template or constraining to a limited set of object categories. We present CARI4D, the first category-agnostic method that reconstructs spatially and temporarily consistent 4D human-object interaction at metric scale from monocular RGB videos. To this end, we propose a pose hypothesis selection algorithm that robustly integrates the individual predictions from foundation models, jointly refine them through a learned render-and-compare paradigm to ensure spatial, temporal and pixel alignment, and finally reasoning about intricate contacts for further refinement satisfying physical constraints. Experiments show that our method outperforms prior art by 38% on in-distribution dataset and 36% on unseen dataset in terms of reconstruction error. Our model generalizes beyond the training categories and thus can be applied zero-shot to in-the-wild internet videos. Our code and pretrained models will be publicly released.

</details>


### [22] [V-REX: Benchmarking Exploratory Visual Reasoning via Chain-of-Questions](https://arxiv.org/abs/2512.11995)
*Chenrui Fan,Yijun Liang,Shweta Bhardwaj,Kwesi Cobbina,Ming Li,Tianyi Zhou*

Main category: cs.CV

TL;DR: V-REX是一个评估视觉语言模型多步探索推理能力的评测套件，包含挑战性视觉推理任务和评估协议，将多步探索推理分解为问题链，评估模型的规划能力和执行能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理复杂开放任务时存在困难，这些任务通常需要在视觉空间中进行多轮探索和推理。虽然这种视觉思维路径能提供逐步探索验证和更好的答案解释，但由于中间步骤的探索空间巨大，难以评估。

Method: 开发V-REX评估套件，包含跨领域的挑战性视觉推理任务。将多步探索推理转化为问题链(CoQ)，解耦为两个能力：(1)规划能力：分解开放任务并选择探索性问题链；(2)执行能力：按顺序回答策划好的问题链以收集信息推导最终答案。通过为每个步骤策划有限的问题和答案选项，实现可靠量化和细粒度中间步骤分析。

Result: 通过评估最先进的专有和开源视觉语言模型，揭示了：一致的扩展趋势、规划能力和执行能力之间的显著差异，以及多步探索推理方面仍有巨大改进空间。

Conclusion: V-REX填补了视觉语言模型在复杂开放任务评估方面的空白，提供了可靠的多步探索推理评估框架，揭示了当前模型的局限性并为未来改进指明了方向。

Abstract: While many vision-language models (VLMs) are developed to answer well-defined, straightforward questions with highly specified targets, as in most benchmarks, they often struggle in practice with complex open-ended tasks, which usually require multiple rounds of exploration and reasoning in the visual space. Such visual thinking paths not only provide step-by-step exploration and verification as an AI detective but also produce better interpretations of the final answers. However, these paths are challenging to evaluate due to the large exploration space of intermediate steps. To bridge the gap, we develop an evaluation suite, ``Visual Reasoning with multi-step EXploration (V-REX)'', which is composed of a benchmark of challenging visual reasoning tasks requiring native multi-step exploration and an evaluation protocol. V-REX covers rich application scenarios across diverse domains. V-REX casts the multi-step exploratory reasoning into a Chain-of-Questions (CoQ) and disentangles VLMs' capability to (1) Planning: breaking down an open-ended task by selecting a chain of exploratory questions; and (2) Following: answering curated CoQ sequentially to collect information for deriving the final answer. By curating finite options of questions and answers per step, V-REX achieves a reliable quantitative and fine-grained analysis of the intermediate steps. By assessing SOTA proprietary and open-sourced VLMs, we reveal consistent scaling trends, significant differences between planning and following abilities, and substantial room for improvement in multi-step exploratory reasoning.

</details>


### [23] [Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus](https://arxiv.org/abs/2512.12012)
*Antonio Guillen-Perez*

Main category: cs.CV

TL;DR: Semantic-Drive是一个本地优先的神经符号框架，用于从自动驾驶车辆日志中挖掘语义数据，通过两阶段感知和推理VLM识别罕见的安全关键事件，在消费级硬件上实现高召回率和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆开发受限于"长尾"训练数据的稀缺性。虽然车队收集了大量视频日志，但识别罕见的安全关键事件（如乱穿马路、施工绕行）仍然是手动且成本高昂的过程。现有解决方案要么依赖粗粒度的元数据搜索（缺乏精度），要么使用基于云的视觉语言模型（侵犯隐私且昂贵）。

Method: 提出一个本地优先的神经符号框架，将感知解耦为两个阶段：(1) 符号接地：通过实时开放词汇检测器（YOLOE）锚定注意力；(2) 认知分析：通过推理VLM进行法医场景分析。为缓解幻觉问题，实施了"系统2"推理时对齐策略，采用多模型"法官-侦察员"共识机制。

Result: 在nuScenes数据集上基于Waymo Open Dataset（WOD-E2E）分类法进行基准测试，Semantic-Drive实现了0.966的召回率（CLIP为0.475），与单一模型相比将风险评估误差降低了40%。系统完全在消费级硬件（NVIDIA RTX 3090）上运行。

Conclusion: Semantic-Drive提供了一个隐私保护的本地替代方案，能够高效地从自动驾驶车辆日志中挖掘语义数据，识别罕见的安全关键事件，解决了现有云解决方案的隐私和成本问题。

Abstract: The development of robust Autonomous Vehicles (AVs) is bottlenecked by the scarcity of "Long-Tail" training data. While fleets collect petabytes of video logs, identifying rare safety-critical events (e.g., erratic jaywalking, construction diversions) remains a manual, cost-prohibitive process. Existing solutions rely on coarse metadata search, which lacks precision, or cloud-based VLMs, which are privacy-invasive and expensive. We introduce Semantic-Drive, a local-first, neuro-symbolic framework for semantic data mining. Our approach decouples perception into two stages: (1) Symbolic Grounding via a real-time open-vocabulary detector (YOLOE) to anchor attention, and (2) Cognitive Analysis via a Reasoning VLM that performs forensic scene analysis. To mitigate hallucination, we implement a "System 2" inference-time alignment strategy, utilizing a multi-model "Judge-Scout" consensus mechanism. Benchmarked on the nuScenes dataset against the Waymo Open Dataset (WOD-E2E) taxonomy, Semantic-Drive achieves a Recall of 0.966 (vs. 0.475 for CLIP) and reduces Risk Assessment Error by 40\% compared to single models. The system runs entirely on consumer hardware (NVIDIA RTX 3090), offering a privacy-preserving alternative to the cloud.

</details>


### [24] [Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition](https://arxiv.org/abs/2512.12013)
*Senhao Gao,Junqing Zhang,Luoyu Mei,Shuai Wang,Xuyu Wang*

Main category: cs.CV

TL;DR: 提出基于离散动态图神经网络(DDGNN)的毫米波雷达点云人体活动识别方法，通过星形图表示解决点云稀疏和变尺寸问题，在资源受限平台上实现高效识别。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达点云用于人体活动识别面临稀疏性和变尺寸问题，现有基于视觉系统的预处理算法不适用于雷达系统，需要专门的方法来提取准确的空间-时间特征。

Method: 设计星形图表示手动添加的静态中心点与动态毫米波雷达点之间的高维相对关系，采用离散动态图神经网络(DDGNN)学习变尺寸星形图中的特征。

Result: 在真实世界HAR数据集上优于其他基线方法，达到94.27%的整体分类准确率，接近基于骨架视觉数据的97.25%最优性能，在树莓派4上验证了资源受限平台的有效性。

Conclusion: 提出的DDGNN方法有效解决了毫米波雷达点云的稀疏性和变尺寸问题，无需重采样或帧聚合器，在资源受限平台上实现了高效的人体活动识别。

Abstract: Human activity recognition (HAR) requires extracting accurate spatial-temporal features with human movements. A mmWave radar point cloud-based HAR system suffers from sparsity and variable-size problems due to the physical features of the mmWave signal. Existing works usually borrow the preprocessing algorithms for the vision-based systems with dense point clouds, which may not be optimal for mmWave radar systems. In this work, we proposed a graph representation with a discrete dynamic graph neural network (DDGNN) to explore the spatial-temporal representation of human movement-related features. Specifically, we designed a star graph to describe the high-dimensional relative relationship between a manually added static center point and the dynamic mmWave radar points in the same and consecutive frames. We then adopted DDGNN to learn the features residing in the star graph with variable sizes. Experimental results demonstrated that our approach outperformed other baseline methods using real-world HAR datasets. Our system achieved an overall classification accuracy of 94.27\%, which gets the near-optimal performance with a vision-based skeleton data accuracy of 97.25\%. We also conducted an inference test on Raspberry Pi~4 to demonstrate its effectiveness on resource-constraint platforms. \sh{ We provided a comprehensive ablation study for variable DDGNN structures to validate our model design. Our system also outperformed three recent radar-specific methods without requiring resampling or frame aggregators.

</details>


### [25] [Adaptive federated learning for ship detection across diverse satellite imagery sources](https://arxiv.org/abs/2512.12053)
*Tran-Vu La,Minh-Tan Pham,Yu Li,Patrick Matgen,Marco Chini*

Main category: cs.CV

TL;DR: 该研究探索了联邦学习在船舶检测中的应用，评估了四种FL算法，发现FL模型相比本地训练显著提升检测精度，接近使用全部数据的全局训练效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决卫星船舶检测中的数据隐私问题，特别是商业卫星图像和敏感船舶标注数据的保护需求，避免数据共享或集中收集。

Method: 采用联邦学习框架，评估了FedAvg、FedProx、FedOpt和FedMedian四种FL算法，使用YOLOv8作为基础检测模型，并与本地训练基线进行比较。

Result: FL模型相比小规模本地数据集训练显著提高了检测精度，性能接近使用所有数据集的全局训练，同时强调了FL配置参数（通信轮数、本地训练周期）对优化精度和计算效率的重要性。

Conclusion: 联邦学习为卫星船舶检测提供了有效的隐私保护解决方案，能够在不共享数据的情况下实现接近全局训练的性能，但需要仔细选择FL配置参数以获得最佳效果。

Abstract: We investigate the application of Federated Learning (FL) for ship detection across diverse satellite datasets, offering a privacy-preserving solution that eliminates the need for data sharing or centralized collection. This approach is particularly advantageous for handling commercial satellite imagery or sensitive ship annotations. Four FL models including FedAvg, FedProx, FedOpt, and FedMedian, are evaluated and compared to a local training baseline, where the YOLOv8 ship detection model is independently trained on each dataset without sharing learned parameters. The results reveal that FL models substantially improve detection accuracy over training on smaller local datasets and achieve performance levels close to global training that uses all datasets during the training. Furthermore, the study underscores the importance of selecting appropriate FL configurations, such as the number of communication rounds and local training epochs, to optimize detection precision while maintaining computational efficiency.

</details>


### [26] [Enhancing deep learning performance on burned area delineation from SPOT-6/7 imagery for emergency management](https://arxiv.org/abs/2512.12056)
*Maria Rodriguez,Minh-Tan Pham,Martin Sudmanns,Quentin Poterek,Oscar Narvaez*

Main category: cs.CV

TL;DR: 本研究提出一种监督式语义分割工作流，用于提升野火后烧毁区域（BA）制图的性能和效率，基于SPOT-6/7高分辨率影像，通过实验比较U-Net和SegFormer模型，并探索了土地覆盖数据辅助任务和测试时增强技术。


<details>
  <summary>Details</summary>
Motivation: 当前烧毁区域制图方法主要依赖计算机视觉模型处理灾后遥感影像，但往往忽视了其在时间紧迫的应急管理场景中的适用性。需要开发既能保证性能又能提高效率的烧毁区域快速制图方法。

Method: 提出监督式语义分割工作流，针对SPOT-6/7高分辨率影像。实验比较U-Net和SegFormer模型，评估指标包括Dice分数、IoU和推理时间。引入土地覆盖数据作为辅助任务增强模型鲁棒性，并测试了测试时增强技术。

Result: U-Net和SegFormer在有限训练数据下表现相似，但SegFormer需要更多计算资源，不利于应急使用。加入土地覆盖辅助任务可提升模型鲁棒性而不增加推理时间。测试时增强能改善制图性能但会增加推理时间，可通过混合精度等优化方法缓解。

Conclusion: 对于应急管理场景下的烧毁区域快速制图，U-Net是更实用的选择，因其在性能相当的情况下资源需求更低。辅助任务和优化技术可进一步提升模型性能与效率的平衡。

Abstract: After a wildfire, delineating burned areas (BAs) is crucial for quantifying damages and supporting ecosystem recovery. Current BA mapping approaches rely on computer vision models trained on post-event remote sensing imagery, but often overlook their applicability to time-constrained emergency management scenarios. This study introduces a supervised semantic segmentation workflow aimed at boosting both the performance and efficiency of BA delineation. It targets SPOT-6/7 imagery due to its very high resolution and on-demand availability. Experiments are evaluated based on Dice score, Intersection over Union, and inference time. The results show that U-Net and SegFormer models perform similarly with limited training data. However, SegFormer requires more resources, challenging its practical use in emergencies. Incorporating land cover data as an auxiliary task enhances model robustness without increasing inference time. Lastly, Test-Time Augmentation improves BA delineation performance but raises inference time, which can be mitigated with optimization methods like Mixed Precision.

</details>


### [27] [BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models](https://arxiv.org/abs/2512.12080)
*Ryan Po,Eric Ryan Chan,Changan Chen,Gordon Wetzstein*

Main category: cs.CV

TL;DR: BAgger是一种自监督训练方案，通过构建模型自身生成轨迹的纠正路径，解决自回归视频模型中的曝光偏差问题，提高长期生成稳定性。


<details>
  <summary>Details</summary>
Motivation: 自回归视频模型在通过下一帧预测进行世界建模时存在曝光偏差问题：训练时使用干净上下文，而推理时使用自生成帧，导致误差累积和质量随时间漂移。

Method: 提出Backwards Aggregation (BAgger)自监督方案，从模型自身生成轨迹中构建纠正路径，教导模型从错误中恢复。使用标准分数匹配或流匹配目标训练，避免依赖大型教师模型和长时间链的反向传播。

Result: 在因果扩散变换器上实现BAgger，在文本到视频、视频扩展和多提示生成任务中评估，观察到更稳定的长期运动和更好的视觉一致性，减少了漂移现象。

Conclusion: BAgger通过自监督纠正轨迹训练，有效解决了自回归视频模型的曝光偏差问题，提高了长期生成的质量和稳定性，无需依赖传统蒸馏方法。

Abstract: Autoregressive video models are promising for world modeling via next-frame prediction, but they suffer from exposure bias: a mismatch between training on clean contexts and inference on self-generated frames, causing errors to compound and quality to drift over time. We introduce Backwards Aggregation (BAgger), a self-supervised scheme that constructs corrective trajectories from the model's own rollouts, teaching it to recover from its mistakes. Unlike prior approaches that rely on few-step distillation and distribution-matching losses, which can hurt quality and diversity, BAgger trains with standard score or flow matching objectives, avoiding large teachers and long-chain backpropagation through time. We instantiate BAgger on causal diffusion transformers and evaluate on text-to-video, video extension, and multi-prompt generation, observing more stable long-horizon motion and better visual consistency with reduced drift.

</details>


### [28] [RePack: Representation Packing of Vision Foundation Model Features Enhances Diffusion Transformer](https://arxiv.org/abs/2512.12083)
*Guanfang Dong,Luke Schultz,Negar Hassanpour,Chao Gao*

Main category: cs.CV

TL;DR: RePack框架通过将高维视觉基础模型特征压缩到低维流形，解决了信息过载问题，显著加速了扩散变换器的收敛并提升了图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉基础模型的高维特征虽然能增强潜在扩散模型，但会导致信息过载问题，特别是当VFM特征尺寸超过原始图像解码需求时，影响模型效率和性能。

Method: 提出RePack框架，将高维VFM表示投影到低维流形上，转化为更紧凑、解码器友好的表示，过滤非语义噪声同时保留核心结构信息。

Result: 在DiT-XL/2上仅用64个epoch就达到FID 3.66，比现有方法快35%收敛，显著优于直接注入原始VFM特征的方法。

Conclusion: RePack成功提取了VFM表示的核心语义，同时避免了高维度的副作用，为有效利用预训练视觉基础模型特征提供了简单而有效的解决方案。

Abstract: The superior representation capability of pre-trained vision foundation models (VFMs) has been harnessed for enhancing latent diffusion models (LDMs). These approaches inject the rich semantics from high-dimensional VFM representations (e.g., DINOv3) into LDMs at different phases, resulting in accelerated learning and better generation performance. However, the high-dimensionality of VFM representations may also lead to Information Overload, particularly when the VFM features exceed the size of the original image for decoding. To address this issue while preserving the utility of VFM features, we propose RePack (Representation Packing), a simple yet effective framework for improving Diffusion Transformers (DiTs). RePack transforms the VFM representation into a more compact, decoder-friendly representation by projecting onto low-dimensional manifolds. We find that RePack can effectively filter out non-semantic noise while preserving the core structural information needed for high-fidelity reconstruction. Experimental results show that RePack significantly accelerates DiT convergence and outperforms recent methods that directly inject raw VFM features into the decoder for image reconstruction. On DiT-XL/2, RePack achieves an FID of 3.66 in only 64 epochs, which is 35% faster than the state-of-the-art method. This demonstrates that RePack successfully extracts the core semantics of VFM representations while bypassing their high-dimensionality side effects.

</details>


### [29] [VEGAS: Mitigating Hallucinations in Large Vision-Language Models via Vision-Encoder Attention Guided Adaptive Steering](https://arxiv.org/abs/2512.12089)
*Zihu Wang,Boxun Xu,Yuxuan Xia,Peng Li*

Main category: cs.CV

TL;DR: VEGAS：通过将视觉编码器的注意力图注入语言模型中间层来减少LVLM幻觉的推理时方法


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）虽然能联合推理视觉和文本输入，但经常产生与视觉证据事实不一致的幻觉输出。现有方法未能有效回答：什么形式的视觉注意力能在解码过程中有效抑制幻觉？

Method: 提出VEGAS方法：1）发现视觉编码器自身的注意力图比LVLM的最终视觉注意力图更集中；2）分析发现视觉-文本冲突在语言模型中间层达到峰值；3）在推理时将视觉编码器的注意力图注入语言模型的中间层，自适应地引导未能聚焦关键图像对象的token

Result: 在多个基准测试上的广泛实验表明，VEGAS在减少幻觉方面始终达到最先进的性能

Conclusion: 视觉编码器的注意力图是抑制LVLM幻觉的有效形式，通过将其注入语言模型中间层可以显著减少幻觉，VEGAS提供了一种简单而有效的推理时解决方案

Abstract: Large vision-language models (LVLMs) exhibit impressive ability to jointly reason over visual and textual inputs. However, they often produce outputs that are linguistically fluent but factually inconsistent with the visual evidence, i.e., they hallucinate. Despite growing efforts to mitigate such hallucinations, a key question remains: what form of visual attention can effectively suppress hallucinations during decoding? In this work, we provide a simple answer: the vision encoder's own attention map. We show that LVLMs tend to hallucinate when their final visual-attention maps fail to concentrate on key image objects, whereas the vision encoder's more concentrated attention maps substantially reduce hallucinations. To further investigate the cause, we analyze vision-text conflicts during decoding and find that these conflicts peak in the language model's middle layers. Injecting the vision encoder's attention maps into these layers effectively suppresses hallucinations. Building on these insights, we introduce VEGAS, a simple yet effective inference-time method that integrates the vision encoder's attention maps into the language model's mid-layers and adaptively steers tokens which fail to concentrate on key image objects. Extensive experiments across multiple benchmarks demonstrate that VEGAS consistently achieves state-of-the-art performance in reducing hallucinations.

</details>


### [30] [SPDMark: Selective Parameter Displacement for Robust Video Watermarking](https://arxiv.org/abs/2512.12090)
*Samar Fares,Nurbek Tastan,Karthik Nandakumar*

Main category: cs.CV

TL;DR: SPDMark是一种基于选择性参数位移的视频生成水印框架，通过修改生成模型参数嵌入水印，具有不可感知性、鲁棒性和计算效率


<details>
  <summary>Details</summary>
Motivation: 高质量视频生成模型的出现增加了对鲁棒水印方案的需求，现有方法无法同时实现不可感知性、鲁棒性和计算效率

Method: 基于选择性参数位移，使用低秩适应实现层间基位移，联合训练基位移和水印提取器，通过加密哈希函数生成帧特定水印消息，使用最大二分匹配恢复帧顺序

Result: 在文本到视频和图像到视频生成模型上评估，SPDMark能够生成不可感知的水印，具有高准确度的恢复能力，并对各种常见视频修改具有鲁棒性

Conclusion: SPDMark为视频生成水印提供了一种有效框架，能够同时满足不可感知性、鲁棒性和计算效率的要求

Abstract: The advent of high-quality video generation models has amplified the need for robust watermarking schemes that can be used to reliably detect and track the provenance of generated videos. Existing video watermarking methods based on both post-hoc and in-generation approaches fail to simultaneously achieve imperceptibility, robustness, and computational efficiency. This work introduces a novel framework for in-generation video watermarking called SPDMark (pronounced `SpeedMark') based on selective parameter displacement of a video diffusion model. Watermarks are embedded into the generated videos by modifying a subset of parameters in the generative model. To make the problem tractable, the displacement is modeled as an additive composition of layer-wise basis shifts, where the final composition is indexed by the watermarking key. For parameter efficiency, this work specifically leverages low-rank adaptation (LoRA) to implement the basis shifts. During the training phase, the basis shifts and the watermark extractor are jointly learned by minimizing a combination of message recovery, perceptual similarity, and temporal consistency losses. To detect and localize temporal modifications in the watermarked videos, we use a cryptographic hashing function to derive frame-specific watermark messages from the given base watermarking key. During watermark extraction, maximum bipartite matching is applied to recover the correct frame order, even from temporally tampered videos. Evaluations on both text-to-video and image-to-video generation models demonstrate the ability of SPDMark to generate imperceptible watermarks that can be recovered with high accuracy and also establish its robustness against a variety of common video modifications.

</details>


### [31] [AI-Augmented Pollen Recognition in Optical and Holographic Microscopy for Veterinary Imaging](https://arxiv.org/abs/2512.12101)
*Swarn S. Warshaneyan,Maksims Ivanovs,Blaž Cugmas,Inese Bērziņa,Laura Goldberga,Mindaugas Tamosiunas,Roberts Kadiķis*

Main category: cs.CV

TL;DR: 该研究探索了在传统光学和数字同轴全息显微镜(DIHM)图像上实现全自动花粉识别，使用YOLOv8s进行目标检测和MobileNetV3L进行分类，发现DIHM图像识别性能显著低于光学图像，通过WGAN-SN生成合成DIHM图像进行数据增强可将检测性能提升至15.4%。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在未重建的全息图像中视觉识别花粉的挑战，这些图像存在散斑噪声、孪生像伪影以及与明场图像外观的显著差异，旨在推动全自动DIHM工作流程在兽医成像中的应用。

Method: 研究方法包括：1) 使用YOLOv8s进行目标检测和MobileNetV3L进行分类；2) 在自动标注的光学和仿射对齐的DIHM图像双模态数据集上训练；3) 使用带谱归一化的Wasserstein GAN(WGAN-SN)生成合成DIHM图像；4) 将真实和合成数据以1.0:1.5的比例混合用于数据增强。

Result: 在光学数据上，检测mAP50达到91.3%，分类准确率达到97%；在DIHM数据上，检测mAP50仅为8.15%，分类准确率为50%。通过扩大DIHM图像中花粉的边界框，检测mAP50提升至13.3%，分类准确率提升至54%。使用GAN增强后，DIHM图像的目标检测性能提升至15.4%，FID得分为58.246。

Conclusion: 研究表明，基于GAN的数据增强可以缩小光学和DIHM图像识别性能之间的差距，为全自动DIHM工作流程在兽医成像中的应用迈出了重要一步，尽管性能提升幅度有限，但具有实际意义。

Abstract: We present a comprehensive study on fully automated pollen recognition across both conventional optical and digital in-line holographic microscopy (DIHM) images of sample slides. Visually recognizing pollen in unreconstructed holographic images remains challenging due to speckle noise, twin-image artifacts and substantial divergence from bright-field appearances. We establish the performance baseline by training YOLOv8s for object detection and MobileNetV3L for classification on a dual-modality dataset of automatically annotated optical and affinely aligned DIHM images. On optical data, detection mAP50 reaches 91.3% and classification accuracy reaches 97%, whereas on DIHM data, we achieve only 8.15% for detection mAP50 and 50% for classification accuracy. Expanding the bounding boxes of pollens in DIHM images over those acquired in aligned optical images achieves 13.3% for detection mAP50 and 54% for classification accuracy. To improve object detection in DIHM images, we employ a Wasserstein GAN with spectral normalization (WGAN-SN) to create synthetic DIHM images, yielding an FID score of 58.246. Mixing real-world and synthetic data at the 1.0 : 1.5 ratio for DIHM images improves object detection up to 15.4%. These results demonstrate that GAN-based augmentation can reduce the performance divide, bringing fully automated DIHM workflows for veterinary imaging a small but important step closer to practice.

</details>


### [32] [EchoVLM: Measurement-Grounded Multimodal Learning for Echocardiography](https://arxiv.org/abs/2512.12107)
*Yuheng Li,Yue Zhang,Abdoul Aziz Amadou,Yuxiang Lai,Jike Zhong,Tiziano Passerini,Dorin Comaniciu,Puneet Sharma*

Main category: cs.CV

TL;DR: 提出了EchoGround-MIMIC数据集和EchoVLM模型，用于多模态超声心动图分析，在多种临床任务中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 超声心动图是心脏病学中最广泛使用的成像方式，但其解释仍然劳动密集且本质上是多模态的，需要视图识别、定量测量、定性评估和基于指南的推理。现有的视觉语言模型在超声心动图领域潜力有限，缺乏大规模临床基础的数据集和测量推理能力。

Method: 1) 引入EchoGround-MIMIC数据集，包含19,065个图像-文本对，具有标准化视图、结构化测量、测量基础描述和指南疾病标签；2) 提出EchoVLM模型，包含两个新的预训练目标：视图感知对比损失和否定感知对比损失。

Result: 在36个任务的5类临床应用中，EchoVLM达到最先进性能：零样本疾病分类AUC为86.5%，视图分类准确率为95.1%。模型展示了可迁移的视觉表示能力。

Conclusion: 临床基础的多模态预训练产生可迁移的视觉表示，EchoVLM可作为端到端超声心动图解释的基础模型。将发布数据集和代码以促进可重复性和进一步研究。

Abstract: Echocardiography is the most widely used imaging modality in cardiology, yet its interpretation remains labor-intensive and inherently multimodal, requiring view recognition, quantitative measurements, qualitative assessments, and guideline-based reasoning. While recent vision-language models (VLMs) have achieved broad success in natural images and certain medical domains, their potential in echocardiography has been limited by the lack of large-scale, clinically grounded image-text datasets and the absence of measurement-based reasoning central to echo interpretation. We introduce EchoGround-MIMIC, the first measurement-grounded multimodal echocardiography dataset, comprising 19,065 image-text pairs from 1,572 patients with standardized views, structured measurements, measurement-grounded captions, and guideline-derived disease labels. Building on this resource, we propose EchoVLM, a vision-language model that incorporates two novel pretraining objectives: (i) a view-informed contrastive loss that encodes the view-dependent structure of echocardiographic imaging, and (ii) a negation-aware contrastive loss that distinguishes clinically critical negative from positive findings. Across five types of clinical applications with 36 tasks spanning multimodal disease classification, image-text retrieval, view classification, chamber segmentation, and landmark detection, EchoVLM achieves state-of-the-art performance (86.5% AUC in zero-shot disease classification and 95.1% accuracy in view classification). We demonstrate that clinically grounded multimodal pretraining yields transferable visual representations and establish EchoVLM as a foundation model for end-to-end echocardiography interpretation. We will release EchoGround-MIMIC and the data curation code, enabling reproducibility and further research in multimodal echocardiography interpretation.

</details>


### [33] [A Novel Patch-Based TDA Approach for Computed Tomography](https://arxiv.org/abs/2512.12108)
*Dashti A. Ali,Aras T. Asaad,Jacob J. Peoples,Mohammad Hamghalam,Alex Robins,Mane Piliposyan,Richard K. G. Do,Natalie Gangai,Yun S. Chun,Ahmad Bashir Barekzai,Jayasree Chakraborty,Hala Khasawneh,Camila Vilela,Natally Horvat,João Miranda,Alice C. Wei,Amber L. Simpson*

Main category: cs.CV

TL;DR: 提出一种针对3D CT图像的基于patch的持久同调构建方法，相比传统3D立方体复形方法在分类性能和计算效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统3D立方体复形方法在构建CT图像的持久同调时，可能无法获得最佳性能，且在高分辨率图像上计算复杂度高。需要一种更高效、性能更好的方法。

Method: 提出一种新颖的基于patch的持久同调构建方法，专门针对体积医学成像数据（特别是CT模态）设计。该方法将图像分割成patch进行处理。

Result: 在多个3D CT数据集上的实验表明，patch-based方法在准确率、AUC、灵敏度、特异性和F1分数上分别平均提升10.38%、6.94%、2.06%、11.58%和8.51%，同时在时间效率上也有优势。

Conclusion: 基于patch的TDA方法在CT图像分析中优于传统立方体复形方法，提供了更好的分类性能和计算效率，并发布了方便的Python包Patch-TDA来促进该方法的应用。

Abstract: The development of machine learning (ML) models based on computed tomography (CT) imaging modality has been a major focus of recent research in the medical imaging domain. Incorporating robust feature engineering approach can highly improve the performance of these models. Topological data analysis (TDA), a recent development based on the mathematical field of algebraic topology, mainly focuses on the data from a topological perspective, extracting deeper insight and higher dimensional structures from the data. Persistent homology (PH), a fundamental tool in the area of TDA, can extract topological features such as connected components, cycles and voids from the data. A popular approach to construct PH from 3D CT images is to utilize the 3D cubical complex filtration, a method adapted for grid-structured data. However, this approach may not always yield the best performance and can suffer from computational complexity with higher resolution CT images. This study introduces a novel patch-based PH construction approach tailored for volumetric medical imaging data, in particular CT modality. A wide range of experiments has been conducted on several datasets of 3D CT images to comprehensively analyze the performance of the proposed method with various parameters and benchmark it against the 3D cubical complex algorithm. Our results highlight the dominance of the patch-based TDA approach in terms of both classification performance and time-efficiency. The proposed approach outperformed the cubical complex method, achieving average improvement of 10.38%, 6.94%, 2.06%, 11.58%, and 8.51% in accuracy, AUC, sensitivity, specificity, and F1 score, respectively, across all datasets. Finally, we provide a convenient python package, Patch-TDA, to facilitate the utilization of the proposed approach.

</details>


### [34] [A Benchmark Dataset for Spatially Aligned Road Damage Assessment in Small Uncrewed Aerial Systems Disaster Imagery](https://arxiv.org/abs/2512.12128)
*Thomas Manzini,Priyankari Perali,Raisa Karnik,Robin R. Murphy*

Main category: cs.CV

TL;DR: 本文提出了最大的道路损坏评估和道路对齐基准数据集CRASAR-U-DRIODs，包含10次联邦宣布灾难后的sUAS图像，提供了18个基线模型，并解决了先前数据集规模小、分辨率低、缺乏操作验证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有灾后道路损坏评估数据集要么规模小，要么依赖低分辨率图像无法检测应急管理者感兴趣的现象，且现有机器学习系统缺乏操作验证。实践中还观察到道路线错位问题，导致模型性能下降和错误标注。

Method: 标注了657.25公里道路，采用10类标注方案；在2024年飓风Debby和Helene的应急响应中训练和部署了18个机器学习模型；提供了9,184个道路线调整以解决空间对齐问题。

Result: 当模型部署到真实世界错位的道路线时，模型性能平均下降5.596% Macro IoU；如果不考虑空间对齐，约8%（11公里）的道路不良状况会被错误标注，约9%（59公里）的道路线会偏离实际道路。

Conclusion: 道路空间对齐是影响灾后道路损坏评估准确性的关键因素，ML、CV和机器人社区需要解决这一差距，以实现更有效和知情的灾难决策。

Abstract: This paper presents the largest known benchmark dataset for road damage assessment and road alignment, and provides 18 baseline models trained on the CRASAR-U-DRIODs dataset's post-disaster small uncrewed aerial systems (sUAS) imagery from 10 federally declared disasters, addressing three challenges within prior post-disaster road damage assessment datasets. While prior disaster road damage assessment datasets exist, there is no current state of practice, as prior public datasets have either been small-scale or reliant on low-resolution imagery insufficient for detecting phenomena of interest to emergency managers. Further, while machine learning (ML) systems have been developed for this task previously, none are known to have been operationally validated. These limitations are overcome in this work through the labeling of 657.25km of roads according to a 10-class labeling schema, followed by training and deploying ML models during the operational response to Hurricanes Debby and Helene in 2024. Motivated by observed road line misalignment in practice, 9,184 road line adjustments were provided for spatial alignment of a priori road lines, as it was found that when the 18 baseline models are deployed against real-world misaligned road lines, model performance degraded on average by 5.596\% Macro IoU. If spatial alignment is not considered, approximately 8\% (11km) of adverse conditions on road lines will be labeled incorrectly, with approximately 9\% (59km) of road lines misaligned off the actual road. These dynamics are gaps that should be addressed by the ML, CV, and robotics communities to enable more effective and informed decision-making during disasters.

</details>


### [35] [MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater](https://arxiv.org/abs/2512.12142)
*Björn Lütjens,Patrick Alexander,Raf Antwerpen,Til Widmann,Guido Cervone,Marco Tedesco*

Main category: cs.CV

TL;DR: 开发深度学习模型融合遥感观测和物理模型数据，生成格陵兰冰盖每日100米分辨率的地表融水分布图，比现有方法精度提高10个百分点以上。


<details>
  <summary>Details</summary>
Motivation: 格陵兰冰盖加速融化，但相关过程难以测量。现有融水分布图在时间和空间分辨率上存在权衡，无法同时实现高时空分辨率，限制了对其融化过程的理解。

Method: 开发深度学习模型，融合区域气候模型(RCM)、合成孔径雷达(SAR)、被动微波(PMW)和数字高程模型(DEM)数据，对Helheim冰川2017-2023年数据进行时空降尺度处理，生成每日100米分辨率的融水分布图。

Result: 深度学习融合方法准确率达到95%，比仅使用区域气候模型的方法(83%)和仅使用被动微波观测的方法(72%)分别提高12和23个百分点。同时发布了MeltwaterBench基准数据集用于方法比较。

Conclusion: 深度学习融合多源数据的方法能显著提高地表融水分布图的时空分辨率和精度，为理解格陵兰冰盖融化过程提供更好的观测工具。同时提供了公开数据集和代码促进相关研究。

Abstract: The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolution by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as "ground truth", we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a gridded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at $\href{https://github.com/blutjens/hrmelt}{github.com/blutjens/hrmelt}$.

</details>


### [36] [Open Horizons: Evaluating Deep Models in the Wild](https://arxiv.org/abs/2512.12146)
*Ayush Vaibhav Bhatti,Deniz Karakay,Debottama Das,Nilotpal Rajbongshi,Yuito Sugimoto*

Main category: cs.CV

TL;DR: 该研究在CIFAR-10上统一评估开放集识别(OSR)和少样本类增量学习(FSCIL)。OSR测试显示CLIP ViT-B/16在已知/未知类别分离上表现最佳，Energy评分函数最稳定；FSCIL评估中ConCM在10-shot场景达到84.7%准确率，所有方法在超过5-shot后性能饱和。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署需要模型既能识别已知类别，又能在出现新类别时保持可靠。研究旨在通过统一实验评估开放集识别和少样本类增量学习，探索不同架构和评分机制对未知样本检测的影响，以及原型方法如何缓解增量学习中的灾难性遗忘。

Method: 1. OSR部分：比较ResNet-50、ConvNeXt-Tiny和CLIP ViT-B/16三种预训练冻结视觉编码器，使用线性探测和四种后验评分函数(MSP、Energy、Mahalanobis、kNN)；2. FSCIL部分：在部分冻结的ResNet-50上比较SPPR、OrCo和ConCM三种方法，评估1-shot、5-shot和10-shot场景。

Result: 1. OSR：CLIP在所有指标(AUROC、AUPR、FPR@95、OSCR)上对已知/未知样本分离能力最强，Energy评分函数在不同骨干网络中表现最稳定；2. FSCIL：ConCM在10-shot设置中达到84.7%准确率且混淆矩阵最清晰，所有方法在超过5-shot后性能饱和，原型方法能有效缓解灾难性遗忘。

Conclusion: 研究揭示了骨干架构和评分机制对未知检测的影响，以及原型方法在增量适应中的优势。CLIP在开放集识别中表现优异，而少样本类增量学习方法在超过5-shot后性能饱和，为实际部署提供了重要参考。

Abstract: Open-world deployment requires models to recognize both known categories and remain reliable when novel classes appear. We present a unified experimental study spanning open-set recognition (OSR) and few-shot class-incremental learning (FSCIL) on CIFAR-10. For OSR, we compare three pretrained frozen visual encoders: ResNet-50, ConvNeXt-Tiny and CLIP ViT-B/16,using a linear probe and four post-hoc scoring functions, namely MSP, Energy, Mahalanobis and kNN. Across metrics,such as, AUROC, AUPR, FPR@95, and OSCR, CLIP consistently yields the strongest separability between known and unknown samples, with Energy providing the most stable performance across backbones. For FSCIL, we compare modified SPPR, OrCo, and ConCM using partially frozen ResNet-50 across 1-, 5-, and 10-shot scenarios. ConCM achieves 84.7% accuracy in the 10-shot setting with the cleanest confusion matrix, while all methods show saturation beyond 5 shots. Our controlled evaluation reveals how the backbone architecture and scoring mechanisms affect unknown detection and how prototype-based methods mitigate catastrophic forgetting during incremental adaptation.

</details>


### [37] [Audio-Visual Camera Pose Estimationn with Passive Scene Sounds and In-the-Wild Video](https://arxiv.org/abs/2512.12165)
*Daniel Adebi,Sagnik Majumder,Kristen Grauman*

Main category: cs.CV

TL;DR: 提出首个利用音频辅助相对相机姿态估计的方法，通过整合到达方向谱和双耳嵌入到视觉模型中，在真实视频中实现性能提升和视觉退化时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 相机运动理解是具身感知和3D场景理解的基础问题。现有视觉方法在运动模糊、遮挡等视觉退化条件下表现不佳，而被动场景声音提供了互补线索。

Method: 提出简单有效的音频-视觉框架，将到达方向(DOA)谱和双耳化嵌入整合到最先进的纯视觉姿态估计模型中，利用音频提供额外空间信息。

Result: 在两个大型数据集上相比强视觉基线获得一致性能提升，在视觉信息受损时表现出鲁棒性，首次成功利用音频进行真实视频的相对相机姿态估计。

Conclusion: 日常音频信号为经典空间挑战提供了意外但有前景的补充信息，音频-视觉融合在相机姿态估计中具有重要价值。

Abstract: Understanding camera motion is a fundamental problem in embodied perception and 3D scene understanding. While visual methods have advanced rapidly, they often struggle under visually degraded conditions such as motion blur or occlusions. In this work, we show that passive scene sounds provide complementary cues for relative camera pose estimation for in-the-wild videos. We introduce a simple but effective audio-visual framework that integrates direction-ofarrival (DOA) spectra and binauralized embeddings into a state-of-the-art vision-only pose estimation model. Our results on two large datasets show consistent gains over strong visual baselines, plus robustness when the visual information is corrupted. To our knowledge, this represents the first work to successfully leverage audio for relative camera pose estimation in real-world videos, and it establishes incidental, everyday audio as an unexpected but promising signal for a classic spatial challenge. Project: http://vision.cs.utexas.edu/projects/av_camera_pose.

</details>


### [38] [SMRABooth: Subject and Motion Representation Alignment for Customized Video Generation](https://arxiv.org/abs/2512.12193)
*Xuancheng Xu,Yaning Li,Sisi You,Bing-Kun Bao*

Main category: cs.CV

TL;DR: SMRABooth：通过自监督编码器和光流编码器提供对象级主体和运动表示，结合LoRA微调实现主体外观和运动模式的双重定制化视频生成


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时保证主体外观相似性和运动模式一致性，缺乏对主体和运动的对象级指导

Method: 1) 使用自监督编码器提取主体表示指导主体对齐；2) 使用光流编码器提取运动表示捕获对象级运动轨迹；3) 提出主体-运动关联解耦策略，在位置和时间上稀疏注入LoRAs

Result: 实验表明SMRABooth在主体和运动定制方面表现优异，能保持主体外观和运动模式的一致性

Conclusion: SMRABooth通过对象级表示和LoRA微调，有效解决了定制化视频生成中主体外观保持和运动一致性的问题

Abstract: Customized video generation aims to produce videos that faithfully preserve the subject's appearance from reference images while maintaining temporally consistent motion from reference videos. Existing methods struggle to ensure both subject appearance similarity and motion pattern consistency due to the lack of object-level guidance for subject and motion. To address this, we propose SMRABooth, which leverages the self-supervised encoder and optical flow encoder to provide object-level subject and motion representations. These representations are aligned with the model during the LoRA fine-tuning process. Our approach is structured in three core stages: (1) We exploit subject representations via a self-supervised encoder to guide subject alignment, enabling the model to capture overall structure of subject and enhance high-level semantic consistency. (2) We utilize motion representations from an optical flow encoder to capture structurally coherent and object-level motion trajectories independent of appearance. (3) We propose a subject-motion association decoupling strategy that applies sparse LoRAs injection across both locations and timing, effectively reducing interference between subject and motion LoRAs. Extensive experiments show that SMRABooth excels in subject and motion customization, maintaining consistent subject appearance and motion patterns, proving its effectiveness in controllable text-to-video generation.

</details>


### [39] [Thermal RGB Fusion for Micro-UAV Wildfire Perimeter Tracking with Minimal Comms](https://arxiv.org/abs/2512.12199)
*Ercan Erkalkan,Vedat Topuz,Ayça Ak*

Main category: cs.CV

TL;DR: 提出一种用于微型无人机编队的轻量级周界跟踪方法，在带宽受限的野火环境中通过热成像和RGB图像融合实现边界检测，采用简化算法降低计算负载，在嵌入式平台上实现低延迟跟踪。


<details>
  <summary>Details</summary>
Motivation: 针对野火环境中微型无人机编队执行紧急侦察任务时面临的带宽限制问题，需要一种轻量级的周界跟踪方法，能够在GPS信号退化的情况下保持轨迹稳定性，同时降低计算和通信需求。

Method: 结合热成像和RGB图像处理：热图像通过自适应阈值和形态学细化生成粗略热点区域掩码；RGB图像提供边缘线索并通过基于梯度的滤波抑制纹理相关的误检测。采用规则级合并策略选择边界候选，使用Ramer-Douglas-Peucker算法简化边界。系统包含周期性信标和惯性反馈回路以维持GPS退化时的轨迹稳定性。

Result: 小规模模拟显示，与纯边缘跟踪基线相比，平均路径长度和边界抖动均有所减少，同时通过交集合并分析保持环境覆盖率。在嵌入式SoC平台上实现低于50ms的延迟，电池消耗和计算利用率证实可在标准微型平台上实现10-15m/s的前向运动。

Conclusion: 该方法实现了快速现场部署，仅需鲁棒传感和最小化通信，适用于紧急侦察应用，为带宽受限环境下的微型无人机编队周界跟踪提供了可行的轻量级解决方案。

Abstract: This study introduces a lightweight perimeter tracking method designed for micro UAV teams operating over wildfire environments under limited bandwidth conditions. Thermal image frames generate coarse hot region masks through adaptive thresholding and morphological refinement, while RGB frames contribute edge cues and suppress texture related false detections using gradient based filtering. A rule level merging strategy selects boundary candidates and simplifies them via the Ramer Douglas Peucker algorithm. The system incorporates periodic beacons and an inertial feedback loop that maintains trajectory stability in the presence of GPS degradation. The guidance loop targets sub 50 ms latency on embedded System on Chip (SoC) platforms by constraining per frame pixel operations and precomputing gradient tables. Small scale simulations demonstrate reductions in average path length and boundary jitter compared to a pure edge tracking baseline, while maintaining environmental coverage measured through intersection merge analysis. Battery consumption and computational utilization confirm the feasibility of achieving 10, 15 m/s forward motion on standard micro platforms. This approach enables rapid deployment in the field, requiring robust sensing and minimal communications for emergency reconnaissance applications.

</details>


### [40] [A Multi-Year Urban Streetlight Imagery Dataset for Visual Monitoring and Spatio-Temporal Drift Detection](https://arxiv.org/abs/2512.12205)
*Peizheng Li,Ioannis Mavromatis,Ajith Sahadevan,Tim Farnham,Adnan Aijaz,Aftab Khan*

Main category: cs.CV

TL;DR: 提出了一个大规模、长期的英国布里斯托尔城市路灯视觉数据集，包含22个固定角度摄像头在2021-2025年间每小时采集的52.6万张图像，涵盖不同光照、天气和季节条件，附带丰富元数据，用于研究视觉漂移、异常检测和智能城市MLOps策略。


<details>
  <summary>Details</summary>
Motivation: 为研究智能城市部署中的视觉漂移、异常检测和MLOps策略提供真实世界的数据基准。现有数据集往往缺乏长期、大规模、多条件的城市环境视觉数据，难以评估模型在长期部署中的稳定性。

Method: 使用22个固定角度摄像头在布里斯托尔部署，每小时采集图像，持续4年。提供基于卷积变分自编码器（CNN-VAEs）的自监督框架，为每个摄像头节点和昼夜图像集单独训练模型。定义两种漂移度量：相对质心漂移（捕获潜在空间偏离）和相对重建误差（测量图像域退化）。

Result: 创建了包含超过526,000张图像的大规模数据集，每张图像附带时间戳、GPS坐标和设备标识符等元数据。数据集公开提供JPEG和CSV格式，支持可重复性和下游应用，如路灯监控、天气推断和城市场景理解。

Conclusion: 该数据集为评估长期模型稳定性、漂移感知学习和部署就绪的视觉系统提供了现实、细粒度的基准。通过公开数据集和自监督框架，促进了智能城市视觉系统的二次分析和研究。

Abstract: We present a large-scale, longitudinal visual dataset of urban streetlights captured by 22 fixed-angle cameras deployed across Bristol, U.K., from 2021 to 2025. The dataset contains over 526,000 images, collected hourly under diverse lighting, weather, and seasonal conditions. Each image is accompanied by rich metadata, including timestamps, GPS coordinates, and device identifiers. This unique real-world dataset enables detailed investigation of visual drift, anomaly detection, and MLOps strategies in smart city deployments. To promtoe seconardary analysis, we additionally provide a self-supervised framework based on convolutional variational autoencoders (CNN-VAEs). Models are trained separately for each camera node and for day/night image sets. We define two per-sample drift metrics: relative centroid drift, capturing latent space deviation from a baseline quarter, and relative reconstruction error, measuring normalized image-domain degradation. This dataset provides a realistic, fine-grained benchmark for evaluating long-term model stability, drift-aware learning, and deployment-ready vision systems. The images and structured metadata are publicly released in JPEG and CSV formats, supporting reproducibility and downstream applications such as streetlight monitoring, weather inference, and urban scene understanding. The dataset can be found at https://doi.org/10.5281/zenodo.17781192 and https://doi.org/10.5281/zenodo.17859120.

</details>


### [41] [ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB](https://arxiv.org/abs/2512.12206)
*Jeongjun Park,Sunwook Hwang,Hyeonho Noh,Jin Mo Yang,Hyun Jong Yang,Saewoong Bahk*

Main category: cs.CV

TL;DR: 提出ALERT数据集和ISA-ViT框架，解决UWB雷达驾驶分心检测中数据集缺乏和ViT输入尺寸不匹配问题，实现22.68%准确率提升。


<details>
  <summary>Details</summary>
Motivation: 驾驶分心是全球致命事故的主要原因。现有UWB雷达DAR面临两大挑战：缺乏大规模真实世界UWB数据集，以及固定输入尺寸的ViT难以适应UWB雷达数据的非标准维度。

Method: 1) 发布ALERT数据集：包含10,220个真实驾驶条件下七种分心驾驶活动的雷达样本；2) 提出ISA-ViT框架：通过调整补丁配置和利用预训练位置嵌入向量，在满足ViT输入要求的同时保留雷达特定信息（多普勒频移和相位特征）；3) 域融合策略：结合距离域和频域特征提升分类性能。

Result: ISA-ViT在UWB-based DAR任务上相比现有ViT方法实现了22.68%的准确率提升。ALERT数据集和ISA-ViT框架为开发更鲁棒、可扩展的驾驶分心检测系统提供了基础。

Conclusion: 通过公开ALERT数据集和详细说明输入尺寸无关策略，这项工作促进了更鲁棒、可扩展的驾驶分心检测系统的开发，为实际部署提供了重要基础。

Abstract: Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.
  This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.
  Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.

</details>


### [42] [A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction](https://arxiv.org/abs/2512.12208)
*Indranil Bhattacharjee,Vartika Narayani Srinet,Anirudha Bhattacharjee,Braj Bhushan,Bishakh Bhattacharya*

Main category: cs.CV

TL;DR: 提出一种用于自闭症儿童情感识别的深度学习管道，结合CNN和GCN处理面部表情数据，在机器人交互场景中表现良好


<details>
  <summary>Details</summary>
Motivation: 理解自闭症儿童在社交互动中的情感反应是发展心理学和人机交互领域的重要挑战，目前缺乏针对自闭症儿童的大规模情感分析数据集和专门方法

Method: 使用混合模型：微调的ResNet-50 CNN + 三层GCN，处理视觉和几何特征（来自MediaPipe FaceMesh关键点），采用加权集成模型（DeepFace和FER）进行概率标注，通过KL散度优化融合嵌入

Result: 该方法在建模微妙情感反应方面表现稳健，有效捕捉神经多样性儿童的微表情线索，为临床和治疗性人机交互中的情感分析提供了重要基础

Conclusion: 这是印度首个针对自闭症的大规模真实世界数据集和情感分析管道，为未来个性化辅助技术奠定了重要基础，填补了自闭症特定HRI研究的空白

Abstract: Understanding emotional responses in children with Autism Spectrum Disorder (ASD) during social interaction remains a critical challenge in both developmental psychology and human-robot interaction. This study presents a novel deep learning pipeline for emotion recognition in autistic children in response to a name-calling event by a humanoid robot (NAO), under controlled experimental settings. The dataset comprises of around 50,000 facial frames extracted from video recordings of 15 children with ASD. A hybrid model combining a fine-tuned ResNet-50-based Convolutional Neural Network (CNN) and a three-layer Graph Convolutional Network (GCN) trained on both visual and geometric features extracted from MediaPipe FaceMesh landmarks. Emotions were probabilistically labeled using a weighted ensemble of two models: DeepFace's and FER, each contributing to soft-label generation across seven emotion classes. Final classification leveraged a fused embedding optimized via Kullback-Leibler divergence. The proposed method demonstrates robust performance in modeling subtle affective responses and offers significant promise for affective profiling of ASD children in clinical and therapeutic human-robot interaction contexts, as the pipeline effectively captures micro emotional cues in neurodivergent children, addressing a major gap in autism-specific HRI research. This work represents the first such large-scale, real-world dataset and pipeline from India on autism-focused emotion analysis using social robotics, contributing an essential foundation for future personalized assistive technologies.

</details>


### [43] [CineLOG: A Training Free Approach for Cinematic Long Video Generation](https://arxiv.org/abs/2512.12209)
*Zahra Dehghanian,Morteza Abolghasemi,Hamid Beigy,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: CineLOG是一个包含5000个高质量视频片段的数据集，带有详细的场景描述、相机指令和类型标签，用于解决可控视频合成的数据不平衡问题，并提出了一个四阶段生成管道和轨迹引导过渡模块。


<details>
  <summary>Details</summary>
Motivation: 当前视频合成模型在精细控制方面存在局限，特别是对于相机轨迹和电影类型等电影属性，现有数据集存在数据不平衡、标签噪声和模拟到现实的差距问题。

Method: 提出了CineLOG数据集构建管道，将复杂的文本到视频生成任务解耦为四个更简单的阶段，并引入了轨迹引导过渡模块来生成平滑的时空插值，实现连贯的多镜头序列。

Result: 人类评估显示，该管道在遵循特定相机和剧本指令方面显著优于现有的端到端文本到视频模型，同时保持专业的视觉质量。

Conclusion: CineLOG数据集和提出的管道为可控视频合成提供了高质量、平衡的数据资源和有效的生成方法，解决了现有方法的局限性。

Abstract: Controllable video synthesis is a central challenge in computer vision, yet current models struggle with fine grained control beyond textual prompts, particularly for cinematic attributes like camera trajectory and genre. Existing datasets often suffer from severe data imbalance, noisy labels, or a significant simulation to real gap. To address this, we introduce CineLOG, a new dataset of 5,000 high quality, balanced, and uncut video clips. Each entry is annotated with a detailed scene description, explicit camera instructions based on a standard cinematic taxonomy, and genre label, ensuring balanced coverage across 17 diverse camera movements and 15 film genres. We also present our novel pipeline designed to create this dataset, which decouples the complex text to video (T2V) generation task into four easier stages with more mature technology. To enable coherent, multi shot sequences, we introduce a novel Trajectory Guided Transition Module that generates smooth spatio-temporal interpolation. Extensive human evaluations show that our pipeline significantly outperforms SOTA end to end T2V models in adhering to specific camera and screenplay instructions, while maintaining professional visual quality. All codes and data are available at https://cine-log.pages.dev.

</details>


### [44] [Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking](https://arxiv.org/abs/2512.12218)
*Rheeya Uppaal,Phu Mon Htut,Min Bai,Nikolaos Pappas,Zheng Qi*

Main category: cs.CV

TL;DR: 提出评估视觉语言模型推理链视觉忠实性的框架，以及无需训练的自我反思方法来检测和修复不忠实的感知步骤


<details>
  <summary>Details</summary>
Motivation: 现有推理增强视觉语言模型存在新失败模式：模型可能通过视觉不忠实的中间步骤得到正确答案，或推理忠实但最终预测失败。仅评估最终答案准确率无法区分这些行为。

Method: 提出无训练和参考的框架，将推理链分解为感知与推理步骤，使用现成VLM评估步骤级忠实性；基于此提出轻量级自我反思程序，检测并局部重新生成不忠实的感知步骤

Result: 在多个推理训练VLM和感知密集型基准测试中，该方法降低了不忠实感知率，同时保持了最终答案准确率，提高了多模态推理的可靠性

Conclusion: 视觉推理链的忠实性应作为独立评估维度，提出的框架和方法能有效提高多模态推理的可靠性，无需额外训练即可改善模型行为

Abstract: Reasoning-augmented vision language models (VLMs) generate explicit chains of thought that promise greater capability and transparency but also introduce new failure modes: models may reach correct answers via visually unfaithful intermediate steps, or reason faithfully yet fail on the final prediction. Standard evaluations that only measure final-answer accuracy cannot distinguish these behaviors. We introduce the visual faithfulness of reasoning chains as a distinct evaluation dimension, focusing on whether the perception steps of a reasoning chain are grounded in the image. We propose a training- and reference-free framework that decomposes chains into perception versus reasoning steps and uses off-the-shelf VLM judges for step-level faithfulness, additionally verifying this approach through a human meta-evaluation. Building on this metric, we present a lightweight self-reflection procedure that detects and locally regenerates unfaithful perception steps without any training. Across multiple reasoning-trained VLMs and perception-heavy benchmarks, our method reduces Unfaithful Perception Rate while preserving final-answer accuracy, improving the reliability of multimodal reasoning.

</details>


### [45] [Fine-Grained Zero-Shot Learning with Attribute-Centric Representations](https://arxiv.org/abs/2512.12219)
*Zhi Chen,Jingcai Guo,Taotao Cai,Yuxiang Cai*

Main category: cs.CV

TL;DR: 提出ACR框架解决细粒度零样本学习中的属性纠缠问题，通过专家混合机制实现属性解耦表示，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度零样本学习需要区分细微视觉差异，但传统模型将颜色、形状、纹理等不同属性纠缠在单一视觉嵌入中，导致关键差异被掩盖。现有后处理方法不足，因为它们处理的是已经混合的表示。

Method: 提出属性中心表示(ACR)框架，包含两个专家混合组件：1) 补丁专家混合(MoPE)，通过双级路由机制将图像补丁有条件地分配到专门专家；2) 属性专家混合(MoAE)，将专家精炼特征投影到稀疏、部分感知的属性映射中。

Result: 在CUB、AwA2和SUN等零样本学习基准数据集上取得了一致的state-of-the-art结果。

Conclusion: 通过在表示学习中强制属性解耦，ACR框架有效解决了属性纠缠问题，提升了细粒度零样本学习的性能。

Abstract: Recognizing unseen fine-grained categories demands a model that can distinguish subtle visual differences. This is typically achieved by transferring visual-attribute relationships from seen classes to unseen classes. The core challenge is attribute entanglement, where conventional models collapse distinct attributes like color, shape, and texture into a single visual embedding. This causes interference that masks these critical distinctions. The post-hoc solutions of previous work are insufficient, as they operate on representations that are already mixed. We propose a zero-shot learning framework that learns AttributeCentric Representations (ACR) to tackle this problem by imposing attribute disentanglement during representation learning. ACR is achieved with two mixture-of-experts components, including Mixture of Patch Experts (MoPE) and Mixture of Attribute Experts (MoAE). First, MoPE is inserted into the transformer using a dual-level routing mechanism to conditionally dispatch image patches to specialized experts. This ensures coherent attribute families are processed by dedicated experts. Finally, the MoAE head projects these expert-refined features into sparse, partaware attribute maps for robust zero-shot classification. On zero-shot learning benchmark datasets CUB, AwA2, and SUN, our ACR achieves consistent state-of-the-art results.

</details>


### [46] [ProImage-Bench: Rubric-Based Evaluation for Professional Image Generation](https://arxiv.org/abs/2512.12220)
*Minheng Ni,Zhengyuan Yang,Yaowen Zhang,Linjie Li,Chung-Ching Lin,Kevin Lin,Zhendong Wang,Xiaofei Wang,Shujie Liu,Lei Zhang,Wangmeng Zuo,Lijuan Wang*

Main category: cs.CV

TL;DR: 研究者提出ProImage-Bench基准，用于评估专业图像生成模型在科学插图生成中的精确性，发现现有模型在科学保真度方面存在显著差距，并展示如何利用评估反馈提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型在生成视觉上合理的图像方面表现良好，但在生成信息密集、科学精确的专业插图方面存在不足。需要建立一个能够量化评估模型在科学保真度方面表现的基准。

Method: 构建ProImage-Bench基准，包含654个来自真实教科书和技术报告的图表，创建详细的图像指令和分层评估标准（6,076个标准和44,131个二进制检查）。使用大型多模态模型从周围文本和参考图中推导评估标准，并通过自动化LMM评估器进行评分。

Result: 测试多个代表性文本到图像模型，发现即使在开放领域表现良好的最佳基础模型，在ProImage-Bench上也只能达到0.791的评估标准准确率和0.553的标准分数，显示在细粒度科学保真度方面存在显著差距。通过将失败的检查反馈给编辑模型进行迭代优化，可以将强生成器的评估标准准确率从0.653提升到0.865，标准分数从0.388提升到0.697。

Conclusion: ProImage-Bench既为专业图像生成提供了严格的诊断工具，也为改进符合规范的科学插图生成提供了可扩展的监督信号，有助于推动模型在科学精确性方面的发展。

Abstract: We study professional image generation, where a model must synthesize information-dense, scientifically precise illustrations from technical descriptions rather than merely produce visually plausible pictures. To quantify the progress, we introduce ProImage-Bench, a rubric-based benchmark that targets biology schematics, engineering/patent drawings, and general scientific diagrams. For 654 figures collected from real textbooks and technical reports, we construct detailed image instructions and a hierarchy of rubrics that decompose correctness into 6,076 criteria and 44,131 binary checks. Rubrics are derived from surrounding text and reference figures using large multimodal models, and are evaluated by an automated LMM-based judge with a principled penalty scheme that aggregates sub-question outcomes into interpretable criterion scores. We benchmark several representative text-to-image models on ProImage-Bench and find that, despite strong open-domain performance, the best base model reaches only 0.791 rubric accuracy and 0.553 criterion score overall, revealing substantial gaps in fine-grained scientific fidelity. Finally, we show that the same rubrics provide actionable supervision: feeding failed checks back into an editing model for iterative refinement boosts a strong generator from 0.653 to 0.865 in rubric accuracy and from 0.388 to 0.697 in criterion score. ProImage-Bench thus offers both a rigorous diagnostic for professional image generation and a scalable signal for improving specification-faithful scientific illustrations.

</details>


### [47] [Comparison of different segmentation algorithms on brain volume and fractal dimension in infant brain MRIs](https://arxiv.org/abs/2512.12222)
*Nathalie Alexander,Arnaud Gucciardi,Umberto Michelucci*

Main category: cs.CV

TL;DR: 比较SynthSeg和SamSeg两种婴儿脑MRI分割方法，发现SynthSeg在分割质量和体积估计上更优，但分割准确性仍影响分形维数分析


<details>
  <summary>Details</summary>
Motivation: 婴儿脑MRI分割因髓鞘化过程中的组织对比度低而具有挑战性，需要评估不同分割方法对体积和分形维数估计的影响

Method: 使用BOB数据集（71个扫描，1-9个月），比较SynthSeg和SamSeg与专家标注的差异，评估指标包括Dice系数、IoU、Hausdorff距离和归一化互信息

Result: SynthSeg在所有质量指标上优于SamSeg（主要区域平均Dice>0.8），体积估计更接近手动参考；SamSeg系统性地高估脑室和全脑体积；分割准确性随年龄增长而提高；分形维数分析显示分割相关变异超过大多数发育队列报告的组间差异

Conclusion: SynthSeg是儿科MRI最可靠的体积和分形维数分析方法，但由于分割相关的不确定性，对小的形态学差异应谨慎解释

Abstract: Accurate segmentation of infant brain MRI is essential for quantifying developmental changes in structure and complexity. However, ongoing myelination and reduced tissue contrast make automated segmentation particularly challenging. This study systematically compared segmentation accuracy and its impact on volumetric and fractal dimension (FD) estimates in infant brain MRI using the Baby Open Brains (BOB) dataset (71 scans, 1-9 months). Two methods, SynthSeg and SamSeg, were evaluated against expert annotations using Dice, Intersection over Union, 95th-percentile Hausdorff distance, and Normalised Mutual Information. SynthSeg outperformed SamSeg across all quality metrics (mean Dice > 0.8 for major regions) and provided volumetric estimates closely matching the manual reference (mean +4% [-28% - 71%]). SamSeg systematically overestimated ventricular and whole-brain volumes (mean +76% [-12% - 190%]). Segmentation accuracy improved with age, consistent with increasing tissue contrast during myelination. Fractal dimension a(FD) nalyses revealed significant regional differences between SynthSeg and expert segmentations, and Bland-Altman limits of agreement indicated that segmentation-related FD variability exceeded most group differences reported in developmental cohorts. Volume and FD deviations were positively correlated across structures, indicating that segmentation bias directly affects FD estimation. Overall, SynthSeg provided the most reliable volumetric and FD results for paediatric MRI, yet small morphological differences in volume and FD should be interpreted with caution due to segmentation-related uncertainty.

</details>


### [48] [Ultra-Low Bitrate Perceptual Image Compression with Shallow Encoder](https://arxiv.org/abs/2512.12229)
*Tianyu Zhang,Dong Liu,Chang Wen Chen*

Main category: cs.CV

TL;DR: 提出AEIC框架，使用浅层编码器结合一步扩散解码器，在超低比特率下实现高效编码和高保真重建


<details>
  <summary>Details</summary>
Motivation: 现有超低比特率图像压缩方法依赖大型预训练编码器，不适合在边缘设备等弱发送端部署，需要探索浅层编码器的可行性

Method: 提出非对称极端图像压缩(AEIC)框架：使用浅层编码器，结合一步扩散解码器保持重建质量；设计双边特征蒸馏方案，将知识从中等编码器迁移到浅层编码器变体

Result: AEIC在超低比特率下优于现有方法的率失真感知性能，编码效率达35.8 FPS（1080P输入），解码速度与现有方法相当

Conclusion: AEIC框架成功实现了编码简单性和解码质量的双重目标，为边缘设备上的超低比特率图像压缩提供了实用解决方案

Abstract: Ultra-low bitrate image compression (below 0.05 bits per pixel) is increasingly critical for bandwidth-constrained and computation-limited encoding scenarios such as edge devices. Existing frameworks typically rely on large pretrained encoders (e.g., VAEs or tokenizer-based models) and perform transform coding within their generative latent space. While these approaches achieve impressive perceptual fidelity, their reliance on heavy encoder networks makes them unsuitable for deployment on weak sender devices. In this work, we explore the feasibility of applying shallow encoders for ultra-low bitrate compression and propose a novel Asymmetric Extreme Image Compression (AEIC) framework that pursues simultaneously encoding simplicity and decoding quality. Specifically, AEIC employs moderate or even shallow encoder networks, while leveraging an one-step diffusion decoder to maintain high-fidelity and high-realism reconstructions under extreme bitrates. To further enhance the efficiency of shallow encoders, we design a dual-side feature distillation scheme that transfers knowledge from AEIC with moderate encoders to its shallow encoder variants. Experiments demonstrate that AEIC not only outperforms existing methods on rate-distortion-perception performance at ultra-low bitrates, but also delivers exceptional encoding efficiency for 35.8 FPS on 1080P input images, while maintaining competitive decoding speed compared to existing methods.

</details>


### [49] [Moment and Highlight Detection via MLLM Frame Segmentation](https://arxiv.org/abs/2512.12246)
*I Putu Andika Bagas Jiwanta,Ayu Purwarianti*

Main category: cs.CV

TL;DR: 提出一种基于LLM的视频时刻检测与高光检测方法，通过让LLM输出"0"/"1"字符序列来表示帧级前景/背景概率，结合分割损失和语言建模损失进行训练


<details>
  <summary>Details</summary>
Motivation: 现有基于生成式多模态大语言模型的方法只能输出文本时间戳，无法提供帧级预测的直接梯度。虽然强化学习方法试图解决此问题，但本文提出更直接的方法

Method: 将固定数量的视频帧输入LLM，通过提示让LLM输出连续的"0"和/或"1"字符序列（每个字符对应一帧）。"0"代表背景概率，"1"代表前景概率。训练时结合分割损失和因果语言建模损失

Result: 在QVHighlights数据集上，仅采样25帧（少于同类方法一半）就实现了56.74 HIT@1的高光检测性能，时刻检索达到35.28 MAP，超过基线

Conclusion: 通过让LLM输出"0"/"1"字符序列，既能利用LLM的语言能力，又能获得帧级分割概率。分割损失提供了稳定的补充学习信号，即使因果语言建模损失趋于平稳时仍有效

Abstract: Detecting video moments and highlights from natural-language queries have been unified by transformer-based methods. Other works use generative Multimodal LLM (MLLM) to predict moments and/or highlights as text timestamps, utilizing its reasoning capability. While effective, text-based generation cannot provide direct gradients for frame-level predictions because the model only emits language tokens. Although recent Reinforcement Learning (RL) methods attempt to address the issue, we propose a novel approach by applying segmentation objectives directly on the LLM's output tokens. The LLM is fed with a fixed number of frames alongside a prompt that enforces it to output a sequence of continuous "0" and/or "1" characters, with one character per frame. The "0"/"1" characters benefit from the LLM's inherent language capability while also acting as background and foreground probabilities, respectively. Training employs segmentation losses on the probabilities alongside a normal causal LM loss. At inference, beam search generates sequence and logits, acting as moments and saliency scores, respectively. Despite sampling only 25 frames -- less than half of comparable methods -- our method achieved strong highlight detection (56.74 HIT@1) on QVHighlights. Additionally, our efficient method scores above the baseline (35.28 MAP) for moment retrieval. Empirically, segmentation losses provide a stable complementary learning signal even when the causal LM loss plateaus.

</details>


### [50] [MetaTPT: Meta Test-time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2512.12268)
*Yuqing Lei,Yingjun Du,Yawen Huang,Xiantong Zhen,Ling Shao*

Main category: cs.CV

TL;DR: MetaTPT：一种元学习框架，通过自监督辅助任务动态学习参数化增强，指导测试时提示调优，提升视觉语言模型在域偏移下的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有测试时提示调优方法使用固定增强策略，在更具挑战性的域偏移场景中表现不佳。需要更灵活、更具表达性的增强方法来捕捉目标域的关键特征。

Method: 提出元测试时提示调优框架，采用双循环优化：内循环学习自监督任务生成信息丰富的视图，外循环通过强制这些视图间的一致性进行提示调优。动态学习参数化增强，将增强学习与提示调优耦合。

Result: 在域泛化和跨数据集基准测试中取得了最先进的性能，显著提升了视觉语言模型在域偏移下的测试时适应能力。

Conclusion: MetaTPT通过元学习自监督辅助任务，动态生成参数化增强，有效提升了测试时提示调优在域偏移场景中的表现，为视觉语言模型的域适应提供了新思路。

Abstract: Vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization but remain sensitive to domain shifts at test time. Test-time prompt tuning (TPT) mitigates this issue by adapting prompts with fixed augmentations, which may falter in more challenging settings. In this work, we propose Meta Test-Time Prompt Tuning (MetaTPT), a meta-learning framework that learns a self-supervised auxiliary task to guide test-time prompt tuning. The auxiliary task dynamically learns parameterized augmentations for each sample, enabling more expressive transformations that capture essential features in target domains. MetaTPT adopts a dual-loop optimization paradigm: an inner loop learns a self-supervised task that generates informative views, while the outer loop performs prompt tuning by enforcing consistency across these views. By coupling augmentation learning with prompt tuning, MetaTPT improves test-time adaptation under domain shifts. Extensive experiments demonstrate that MetaTPT achieves state-of-the-art performance on domain generalization and cross-dataset benchmarks.

</details>


### [51] [Feature Aggregation for Efficient Continual Learning of Complex Facial Expressions](https://arxiv.org/abs/2512.12277)
*Thibault Geoffroy,Myriam Maumy,Lionel Prevost*

Main category: cs.CV

TL;DR: 提出一个用于持续学习场景下的混合面部表情识别框架，结合深度卷积特征和面部动作单元，使用贝叶斯高斯混合模型来减轻灾难性遗忘，在CFEE数据集上验证了从基础表情到复合表情的渐进学习能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在日常生活中的普及，识别和适应人类情感对于有效的人机交互至关重要。面部表情识别是推断情感状态的主要渠道，但情感的动态性和文化细微差别要求模型能够持续学习而不遗忘先前知识。

Method: 提出混合框架，整合两种互补模态：深度卷积特征和面部动作单元（源自面部动作编码系统）。通过贝叶斯高斯混合模型对组合表示进行建模，提供轻量级概率解决方案，避免重新训练同时保持强判别能力。

Result: 在Compound Facial Expression of Emotion数据集上验证，模型能够先学习基础表情，然后渐进识别复合表情。实验显示提高了准确性、增强了知识保留能力、减少了遗忘。

Conclusion: 该框架有助于开发情感智能AI系统，可应用于教育、医疗保健和自适应用户界面等领域。

Abstract: As artificial intelligence (AI) systems become increasingly embedded in our daily life, the ability to recognize and adapt to human emotions is essential for effective human-computer interaction. Facial expression recognition (FER) provides a primary channel for inferring affective states, but the dynamic and culturally nuanced nature of emotions requires models that can learn continuously without forgetting prior knowledge. In this work, we propose a hybrid framework for FER in a continual learning setting that mitigates catastrophic forgetting. Our approach integrates two complementary modalities: deep convolutional features and facial Action Units (AUs) derived from the Facial Action Coding System (FACS). The combined representation is modelled through Bayesian Gaussian Mixture Models (BGMMs), which provide a lightweight, probabilistic solution that avoids retraining while offering strong discriminative power. Using the Compound Facial Expression of Emotion (CFEE) dataset, we show that our model can first learn basic expressions and then progressively recognize compound expressions. Experiments demonstrate improved accuracy, stronger knowledge retention, and reduced forgetting. This framework contributes to the development of emotionally intelligent AI systems with applications in education, healthcare, and adaptive user interfaces.

</details>


### [52] [Cognitive-YOLO: LLM-Driven Architecture Synthesis from First Principles of Data for Object Detection](https://arxiv.org/abs/2512.12281)
*Jiahao Zhao*

Main category: cs.CV

TL;DR: Cognitive-YOLO：基于LLM的数据驱动架构生成框架，通过分析数据集特征直接合成目标检测网络，无需传统NAS的昂贵搜索过程。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测架构设计耗时耗力，NAS计算成本过高，现有LLM方法多作为迭代优化器而非从数据整体理解直接生成架构。需要一种能从数据集内在特征直接生成高性能架构的方法。

Method: 三阶段框架：1) 分析模块提取数据集元特征（目标尺度分布、场景密度等）；2) LLM基于特征推理，结合RAG检索的最先进组件，用NADL结构化描述语言合成架构；3) 编译器将描述实例化为可部署模型。

Result: 在五个多样化目标检测数据集上验证，Cognitive-YOLO生成的架构始终优于基线模型，实现高度竞争性能，并在性能-参数权衡方面表现更优。消融研究证明LLM的数据驱动推理是性能提升的主要因素。

Conclusion: 数据驱动的"第一性原理"理解比单纯检索SOTA组件对生成优越架构更为关键，Cognitive-YOLO为LLM驱动的架构设计提供了新范式。

Abstract: Designing high-performance object detection architectures is a complex task, where traditional manual design is time-consuming and labor-intensive, and Neural Architecture Search (NAS) is computationally prohibitive. While recent approaches using Large Language Models (LLMs) show promise, they often function as iterative optimizers within a search loop, rather than generating architectures directly from a holistic understanding of the data. To address this gap, we propose Cognitive-YOLO, a novel framework for LLM-driven architecture synthesis that generates network configurations directly from the intrinsic characteristics of the dataset. Our method consists of three stages: first, an analysis module extracts key meta-features (e.g., object scale distribution and scene density) from the target dataset; second, the LLM reasons upon these features, augmented with state-of-the-art components retrieved via Retrieval-Augmented Generation (RAG), to synthesize the architecture into a structured Neural Architecture Description Language (NADL); finally, a compiler instantiates this description into a deployable model. Extensive experiments on five diverse object detection datasets demonstrate that our proposed Cognitive-YOLO consistently generates superior architectures, achieving highly competitive performance and demonstrating a superior performance-per-parameter trade-off compared to strong baseline models across multiple benchmarks. Crucially, our ablation studies prove that the LLM's data-driven reasoning is the primary driver of performance, demonstrating that a deep understanding of data "first principles" is more critical for achieving a superior architecture than simply retrieving SOTA components.

</details>


### [53] [RealDrag: The First Dragging Benchmark with Real Target Image](https://arxiv.org/abs/2512.12287)
*Ahmad Zafarani,Zahra Dehghanian,Mohammadreza Davoodi,Mohsen Shadroo,MohammadAmin Fazli,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: RealDrag是首个包含真实目标图像的基于点拖动图像编辑基准，包含400+人工标注样本和4个新指标，用于系统评估17个SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于拖动的图像编辑模型评估不可靠，缺乏标准化基准和指标，没有包含真实目标图像的数据集，导致方法间难以客观比较。

Method: 构建RealDrag基准数据集，包含400+人工标注样本（来自多样化视频源），提供源/目标图像、控制点/目标点、可编辑区域掩码和描述性标注；提出4个新指标：语义距离(SeD)、外部掩码保持分数(OMPS)、内部补丁保持分数(IPPS)和方向相似性(DiS)。

Result: 使用该基准对17个SOTA模型进行首次大规模系统分析，揭示了当前方法间的明确权衡，建立了稳健、可复现的基线。

Conclusion: RealDrag为基于点拖动的图像编辑提供了首个包含真实目标图像的标准化基准和评估工具，将指导未来研究发展。

Abstract: The evaluation of drag based image editing models is unreliable due to a lack of standardized benchmarks and metrics. This ambiguity stems from inconsistent evaluation protocols and, critically, the absence of datasets containing ground truth target images, making objective comparisons between competing methods difficult. To address this, we introduce \textbf{RealDrag}, the first comprehensive benchmark for point based image editing that includes paired ground truth target images. Our dataset contains over 400 human annotated samples from diverse video sources, providing source/target images, handle/target points, editable region masks, and descriptive captions for both the image and the editing action.
  We also propose four novel, task specific metrics: Semantical Distance (SeD), Outer Mask Preserving Score (OMPS), Inner Patch Preserving Score (IPPS), and Directional Similarity (DiS). These metrics are designed to quantify pixel level matching fidelity, check preservation of non edited (out of mask) regions, and measure semantic alignment with the desired task. Using this benchmark, we conduct the first large scale systematic analysis of the field, evaluating 17 SOTA models. Our results reveal clear trade offs among current approaches and establish a robust, reproducible baseline to guide future research. Our dataset and evaluation toolkit will be made publicly available.

</details>


### [54] [GrowTAS: Progressive Expansion from Small to Large Subnets for Efficient ViT Architecture Search](https://arxiv.org/abs/2512.12296)
*Hyunju Lee,Youngmin Oh,Jeimin Jeon,Donghyeon Baek,Bumsub Ham*

Main category: cs.CV

TL;DR: 提出GrowTAS渐进式训练框架，从训练小型子网络开始逐步加入大型子网络，减少权重共享带来的干扰，提升Transformer架构搜索性能


<details>
  <summary>Details</summary>
Motivation: 现有Transformer架构搜索方法使用超网络共享权重，导致小型子网络性能严重下降。研究发现训练良好的小型子网络可以作为训练大型子网络的良好基础

Method: 提出GrowTAS渐进式训练框架：1) 从训练小型子网络开始；2) 逐步加入大型子网络；3) 减少干扰并稳定训练过程。还提出GrowTAS+，仅微调部分权重以进一步提升大型子网络性能

Result: 在ImageNet和多个迁移学习基准（CIFAR-10/100、Flowers、CARS、INAT-19）上的广泛实验表明，该方法优于当前TAS方法

Conclusion: GrowTAS通过渐进式训练框架有效解决了超网络中权重共享导致的干扰问题，显著提升了Transformer架构搜索的性能

Abstract: Transformer architecture search (TAS) aims to automatically discover efficient vision transformers (ViTs), reducing the need for manual design. Existing TAS methods typically train an over-parameterized network (i.e., a supernet) that encompasses all candidate architectures (i.e., subnets). However, all subnets share the same set of weights, which leads to interference that degrades the smaller subnets severely. We have found that well-trained small subnets can serve as a good foundation for training larger ones. Motivated by this, we propose a progressive training framework, dubbed GrowTAS, that begins with training small subnets and incorporate larger ones gradually. This enables reducing the interference and stabilizing a training process. We also introduce GrowTAS+ that fine-tunes a subset of weights only to further enhance the performance of large subnets. Extensive experiments on ImageNet and several transfer learning benchmarks, including CIFAR-10/100, Flowers, CARS, and INAT-19, demonstrate the effectiveness of our approach over current TAS methods

</details>


### [55] [From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving](https://arxiv.org/abs/2512.12302)
*Huan Zheng,Yucheng Zhou,Tianyi Yan,Jiayi Su,Hongjun Chen,Dubing Chen,Wencheng Han,Runzhou Tao,Zhongying Qiu,Jianfei Yang,Jianbing Shen*

Main category: cs.CV

TL;DR: 论文提出了Intention-Drive基准测试，用于评估自动驾驶系统从高级人类意图到具体驾驶动作的转化能力，揭示了现有模型在意图理解方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统仅能执行低级转向指令，而真正智能的自动驾驶需要从"命令执行者"转变为"意图实现者"，但目前缺乏标准化基准来衡量和推动这一复杂任务的进展。

Method: 引入Intention-Drive基准测试，包含两个核心贡献：(1) 包含复杂场景和对应自然语言意图的新数据集；(2) 基于意图成功率(ISR)的新评估协议，超越几何精度评估语义目标实现。

Result: 通过对一系列基线模型在Intention-Drive上的广泛评估，揭示了显著的性能缺陷，表明基线模型难以达到这一高级任务所需的全面场景和意图理解能力。

Conclusion: Intention-Drive填补了自动驾驶意图理解评估的关键空白，为从命令跟随到意图实现的范式转变提供了标准化基准，揭示了当前系统的局限性并指明了未来研究方向。

Abstract: Current end-to-end autonomous driving systems operate at a level of intelligence akin to following simple steering commands. However, achieving genuinely intelligent autonomy requires a paradigm shift: moving from merely executing low-level instructions to understanding and fulfilling high-level, abstract human intentions. This leap from a command-follower to an intention-fulfiller, as illustrated in our conceptual framework, is hindered by a fundamental challenge: the absence of a standardized benchmark to measure and drive progress on this complex task. To address this critical gap, we introduce Intention-Drive, the first comprehensive benchmark designed to evaluate the ability to translate high-level human intent into safe and precise driving actions. Intention-Drive features two core contributions: (1) a new dataset of complex scenarios paired with corresponding natural language intentions, and (2) a novel evaluation protocol centered on the Intent Success Rate (ISR), which assesses the semantic fulfillment of the human's goal beyond simple geometric accuracy. Through an extensive evaluation of a spectrum of baseline models on Intention-Drive, we reveal a significant performance deficit, showing that the baseline model struggle to achieve the comprehensive scene and intention understanding required for this advanced task.

</details>


### [56] [OMUDA: Omni-level Masking for Unsupervised Domain Adaptation in Semantic Segmentation](https://arxiv.org/abs/2512.12303)
*Yang Ou,Xiongwei Zhao,Xinye Yang,Yihan Wang,Yicheng Di,Rong Yuan,Xieyuanli Chen,Xu Zhu*

Main category: cs.CV

TL;DR: OMUDA提出了一种用于无监督域自适应语义分割的层次化掩码框架，通过上下文感知、特征蒸馏和类别解耦三种掩码策略，在多个基准上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有UDA方法在跨域语义分割中面临三个主要挑战：跨域上下文模糊性、不一致的特征表示和类别级伪标签噪声，导致难以有效弥合域间差距。

Method: 提出OMUDA框架，包含三种层次化掩码策略：1)上下文感知掩码(CAM)区分前景背景平衡全局上下文与局部细节；2)特征蒸馏掩码(FDM)通过预训练模型知识迁移增强鲁棒特征学习；3)类别解耦掩码(CDM)通过显式建模类别不确定性减轻噪声伪标签影响。

Result: 在SYNTHIA->Cityscapes和GTA5->Cityscapes等跨域语义分割基准上验证了有效性，可无缝集成到现有UDA方法中，平均提升7%，达到SOTA性能。

Conclusion: OMUDA通过层次化掩码范式在上下文、表示和类别三个层面减少域偏移，为跨域语义分割提供了超越现有方法的统一解决方案。

Abstract: Unsupervised domain adaptation (UDA) enables semantic segmentation models to generalize from a labeled source domain to an unlabeled target domain. However, existing UDA methods still struggle to bridge the domain gap due to cross-domain contextual ambiguity, inconsistent feature representations, and class-wise pseudo-label noise. To address these challenges, we propose Omni-level Masking for Unsupervised Domain Adaptation (OMUDA), a unified framework that introduces hierarchical masking strategies across distinct representation levels. Specifically, OMUDA comprises: 1) a Context-Aware Masking (CAM) strategy that adaptively distinguishes foreground from background to balance global context and local details; 2) a Feature Distillation Masking (FDM) strategy that enhances robust and consistent feature learning through knowledge transfer from pre-trained models; and 3) a Class Decoupling Masking (CDM) strategy that mitigates the impact of noisy pseudo-labels by explicitly modeling class-wise uncertainty. This hierarchical masking paradigm effectively reduces the domain shift at the contextual, representational, and categorical levels, providing a unified solution beyond existing approaches. Extensive experiments on multiple challenging cross-domain semantic segmentation benchmarks validate the effectiveness of OMUDA. Notably, on the SYNTHIA->Cityscapes and GTA5->Cityscapes tasks, OMUDA can be seamlessly integrated into existing UDA methods and consistently achieving state-of-the-art results with an average improvement of 7%.

</details>


### [57] [MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding](https://arxiv.org/abs/2512.12307)
*Benjamin Beilharz,Thomas S. A. Wallis*

Main category: cs.CV

TL;DR: MRD方法通过可微分渲染生成物理上不同但模型激活相同的3D场景，用于探究视觉模型对底层3D场景属性的隐式理解。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在视觉任务上表现出色，但其表示和决策过程难以解释。虽然视觉模型通常在2D输入上训练，但人们假设它们能发展出对底层3D场景的隐式理解。需要一种方法来探究模型对生成性3D场景属性的理解程度。

Method: 提出MRD（可微分渲染的元相似体），使用基于物理的可微分渲染技术，寻找物理上不同但产生相同模型激活的3D场景参数。通过保持某些场景属性（如材质、光照）不变，专门探究模型对其他属性（如形状）的敏感性。

Result: 作为原理验证，评估了多个模型在恢复场景几何形状和双向反射分布函数（材质）参数方面的能力。结果显示目标场景和优化场景之间的模型激活高度相似，但视觉结果各不相同。重建结果有助于定性地研究模型对哪些物理场景属性敏感或不敏感。

Conclusion: MRD方法通过将重建结果锚定在物理场景描述中，为理解和解释视觉模型的内部表示提供了新途径。该方法有望推进对计算机视觉和人类视觉的理解，通过分析物理场景参数如何驱动模型响应的变化。

Abstract: While deep learning methods have achieved impressive success in many vision benchmarks, it remains difficult to understand and explain the representations and decisions of these models. Though vision models are typically trained on 2D inputs, they are often assumed to develop an implicit representation of the underlying 3D scene (for example, showing tolerance to partial occlusion, or the ability to reason about relative depth). Here, we introduce MRD (metamers rendered differentiably), an approach that uses physically based differentiable rendering to probe vision models' implicit understanding of generative 3D scene properties, by finding 3D scene parameters that are physically different but produce the same model activation (i.e. are model metamers). Unlike previous pixel-based methods for evaluating model representations, these reconstruction results are always grounded in physical scene descriptions. This means we can, for example, probe a model's sensitivity to object shape while holding material and lighting constant. As a proof-of-principle, we assess multiple models in their ability to recover scene parameters of geometry (shape) and bidirectional reflectance distribution function (material). The results show high similarity in model activation between target and optimized scenes, with varying visual results. Qualitatively, these reconstructions help investigate the physical scene attributes to which models are sensitive or invariant. MRD holds promise for advancing our understanding of both computer and human vision by enabling analysis of how physical scene parameters drive changes in model responses.

</details>


### [58] [WeDetect: Fast Open-Vocabulary Object Detection as Retrieval](https://arxiv.org/abs/2512.12309)
*Shenghao Fu,Yukun Su,Fengyun Rao,Jing Lyu,Xiaohua Xie,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: WeDetect是一个基于检索范式的开放词汇目标检测模型家族，包含三个组件：基础检测器、通用提议生成器和LMM分类器，在15个基准上达到SOTA性能，同时保持高效推理。


<details>
  <summary>Details</summary>
Motivation: 探索无跨模态融合层的检索式开放词汇目标检测方法的潜力，这种非融合方法通过将识别视为检索问题（在共享嵌入空间中匹配区域和文本查询），在推理效率和多功能性方面具有独特优势。

Method: 提出WeDetect模型家族：1) WeDetect基础检测器：双塔架构的实时检测器；2) WeDetect-Uni：基于WeDetect的通用提议生成器，冻结检测器仅微调objectness提示；3) WeDetect-Ref：基于LMM的对象分类器，处理复杂指代表达式，从WeDetect-Uni提取的提议列表中检索目标对象。

Result: WeDetect在15个基准测试中达到最先进性能，非融合模型超越其他融合模型，建立了强大的开放词汇基础；支持快速回溯历史数据中的对象检索；能够处理复杂指代表达式理解，同时保持高推理效率。

Conclusion: WeDetect模型家族在统一的检索框架下整合了检测、提议生成、对象检索和指代表达式理解，证明了检索范式在开放词汇目标检测中的优越性，特别是在效率和多功能性方面。

Abstract: Open-vocabulary object detection aims to detect arbitrary classes via text prompts. Methods without cross-modal fusion layers (non-fusion) offer faster inference by treating recognition as a retrieval problem, \ie, matching regions to text queries in a shared embedding space. In this work, we fully explore this retrieval philosophy and demonstrate its unique advantages in efficiency and versatility through a model family named WeDetect: (1) State-of-the-art performance. WeDetect is a real-time detector with a dual-tower architecture. We show that, with well-curated data and full training, the non-fusion WeDetect surpasses other fusion models and establishes a strong open-vocabulary foundation. (2) Fast backtrack of historical data. WeDetect-Uni is a universal proposal generator based on WeDetect. We freeze the entire detector and only finetune an objectness prompt to retrieve generic object proposals across categories. Importantly, the proposal embeddings are class-specific and enable a new application, object retrieval, supporting retrieval objects in historical data. (3) Integration with LMMs for referring expression comprehension (REC). We further propose WeDetect-Ref, an LMM-based object classifier to handle complex referring expressions, which retrieves target objects from the proposal list extracted by WeDetect-Uni. It discards next-token prediction and classifies objects in a single forward pass. Together, the WeDetect family unifies detection, proposal generation, object retrieval, and REC under a coherent retrieval framework, achieving state-of-the-art performance across 15 benchmarks with high inference efficiency.

</details>


### [59] [Unified Control for Inference-Time Guidance of Denoising Diffusion Models](https://arxiv.org/abs/2512.12339)
*Maurya Goyal,Anuj Singh,Hadi Jamali-Rad*

Main category: cs.CV

TL;DR: UniCoDe提出了一种统一的算法，将采样方法和梯度引导方法结合，通过集成局部梯度信号来提高扩散模型与下游目标的对齐效率。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型与下游目标对齐的方法主要分为采样方法和梯度引导方法，两者各有优缺点。采样方法需要探索多个候选输出，效率较低；梯度引导方法虽然直接但依赖可微的奖励近似。需要一种能结合两者优势的统一框架。

Method: UniCoDe是一个通用算法，将采样和梯度引导统一到一个框架中。它在采样过程中集成局部梯度信号，解决了复杂奖励采样方法的效率问题，同时保持了与扩散无条件先验的良好平衡。

Result: 实验结果表明，UniCoDe在一系列任务中与最先进的基线方法保持竞争力，实现了更高效的采样，并在奖励对齐和与扩散先验的偏离之间提供了更好的权衡。

Conclusion: UniCoDe成功地将采样和梯度引导两种范式统一起来，为扩散模型与下游目标的对齐提供了更高效、更平衡的解决方案，代码已开源。

Abstract: Aligning diffusion model outputs with downstream objectives is essential for improving task-specific performance. Broadly, inference-time training-free approaches for aligning diffusion models can be categorized into two main strategies: sampling-based methods, which explore multiple candidate outputs and select those with higher reward signals, and gradient-guided methods, which use differentiable reward approximations to directly steer the generation process. In this work, we propose a universal algorithm, UniCoDe, which brings together the strengths of sampling and gradient-based guidance into a unified framework. UniCoDe integrates local gradient signals during sampling, thereby addressing the sampling inefficiency inherent in complex reward-based sampling approaches. By cohesively combining these two paradigms, UniCoDe enables more efficient sampling while offering better trade-offs between reward alignment and divergence from the diffusion unconditional prior. Empirical results demonstrate that UniCoDe remains competitive with state-of-the-art baselines across a range of tasks. The code is available at https://github.com/maurya-goyal10/UniCoDe

</details>


### [60] [TCLeaf-Net: a transformer-convolution framework with global-local attention for robust in-field lesion-level plant leaf disease detection](https://arxiv.org/abs/2512.12357)
*Zishen Song,Yongjian Zhu,Dong Wang,Hongzhan Liu,Lingyu Jiang,Yongxing Duan,Zehua Zhang,Sihan Li,Jiarui Li*

Main category: cs.CV

TL;DR: 提出TCLeaf-Net用于田间叶片病害检测，结合Transformer和CNN处理复杂背景，发布Daylily-Leaf数据集，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 田间叶片病害检测面临复杂背景干扰、领域偏移和病变级别数据集有限等挑战，需要开发鲁棒且高效的检测模型。

Method: 提出TCLeaf-Net混合检测器：1) TCM模块结合全局上下文和局部卷积抑制非叶片区域；2) RSFRS块保留精细空间细节；3) DFPN块处理病变尺度变化和特征偏移。

Result: 在Daylily-Leaf田间数据集上，mAP@50提升5.4个百分点至78.2%，计算量减少7.5 GFLOPs，GPU内存使用降低8.7%，在多个植物病害数据集上表现优异。

Conclusion: TCLeaf-Net通过Transformer-CNN混合架构有效解决田间叶片病害检测的三大挑战，在精度、效率和泛化性方面均优于现有方法。

Abstract: Timely and accurate detection of foliar diseases is vital for safeguarding crop growth and reducing yield losses. Yet, in real-field conditions, cluttered backgrounds, domain shifts, and limited lesion-level datasets hinder robust modeling. To address these challenges, we release Daylily-Leaf, a paired lesion-level dataset comprising 1,746 RGB images and 7,839 lesions captured under both ideal and in-field conditions, and propose TCLeaf-Net, a transformer-convolution hybrid detector optimized for real-field use. TCLeaf-Net is designed to tackle three major challenges. To mitigate interference from complex backgrounds, the transformer-convolution module (TCM) couples global context with locality-preserving convolution to suppress non-leaf regions. To reduce information loss during downsampling, the raw-scale feature recalling and sampling (RSFRS) block combines bilinear resampling and convolution to preserve fine spatial detail. To handle variations in lesion scale and feature shifts, the deformable alignment block with FPN (DFPN) employs offset-based alignment and multi-receptive-field perception to strengthen multi-scale fusion. Experimental results show that on the in-field split of the Daylily-Leaf dataset, TCLeaf-Net improves mAP@50 by 5.4 percentage points over the baseline model, reaching 78.2\%, while reducing computation by 7.5 GFLOPs and GPU memory usage by 8.7\%. Moreover, the model outperforms recent YOLO and RT-DETR series in both precision and recall, and demonstrates strong performance on the PlantDoc, Tomato-Leaf, and Rice-Leaf datasets, validating its robustness and generalizability to other plant disease detection scenarios.

</details>


### [61] [VideoARM: Agentic Reasoning over Hierarchical Memory for Long-Form Video Understanding](https://arxiv.org/abs/2512.12360)
*Yufei Yin,Qianke Meng,Minghao Chen,Jiajun Ding,Zhenwei Shao,Zhou Yu*

Main category: cs.CV

TL;DR: VideoARM：一种用于长视频理解的代理式分层记忆推理范式，通过自适应实时推理和记忆构建，显著减少token消耗并提升性能。


<details>
  <summary>Details</summary>
Motivation: 长视频理解面临扩展时间结构和密集多模态线索的挑战。现有方法依赖手工推理流程或消耗大量token的视频预处理，需要更高效的自适应解决方案。

Method: 提出VideoARM代理式分层记忆推理范式：1）控制器执行观察-思考-行动-记忆的自适应循环，以粗到细方式解释视频；2）分层多模态记忆持续捕获和更新多级线索，为控制器提供精确上下文信息。

Result: 在主流基准测试中，VideoARM超越了当前最先进的DVD方法，同时在长视频处理中显著减少了token消耗。

Conclusion: VideoARM通过自适应代理推理和分层记忆构建，为长视频理解提供了一种高效且性能优越的解决方案，解决了现有方法的token消耗和静态预处理限制。

Abstract: Long-form video understanding remains challenging due to the extended temporal structure and dense multimodal cues. Despite recent progress, many existing approaches still rely on hand-crafted reasoning pipelines or employ token-consuming video preprocessing to guide MLLMs in autonomous reasoning. To overcome these limitations, we introduce VideoARM, an Agentic Reasoning-over-hierarchical-Memory paradigm for long-form video understanding. Instead of static, exhaustive preprocessing, VideoARM performs adaptive, on-the-fly agentic reasoning and memory construction. Specifically, VideoARM performs an adaptive and continuous loop of observing, thinking, acting, and memorizing, where a controller autonomously invokes tools to interpret the video in a coarse-to-fine manner, thereby substantially reducing token consumption. In parallel, a hierarchical multimodal memory continuously captures and updates multi-level clues throughout the operation of the agent, providing precise contextual information to support the controller in decision-making. Experiments on prevalent benchmarks demonstrate that VideoARM outperforms the state-of-the-art method, DVD, while significantly reducing token consumption for long-form videos.

</details>


### [62] [STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative](https://arxiv.org/abs/2512.12372)
*Peixuan Zhang,Zijian Jia,Kaiqi Liu,Shuchen Weng,Si Li,Boxin Shi*

Main category: cs.CV

TL;DR: STAGE提出了一种基于故事板的多镜头视频生成工作流，通过预测结构化的故事板、使用多镜头记忆包确保实体一致性、双编码策略保证镜头内连贯性，以及两阶段训练学习镜头间过渡，显著提升了叙事控制和跨镜头一致性。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在视频合成方面取得了显著进展，但在创建连贯的多镜头叙事方面仍面临挑战。基于关键帧的方法虽然提供了细粒度控制和更高效率，但往往难以保持跨镜头一致性并捕捉电影语言。

Method: 1. 提出STAGE工作流，将多镜头视频生成任务重新定义为故事板锚定生成；2. 使用STEP2预测每个镜头的起始-结束帧对组成的结构化故事板；3. 引入多镜头记忆包确保长距离实体一致性；4. 采用双编码策略保证镜头内连贯性；5. 设计两阶段训练方案学习电影化的镜头间过渡；6. 贡献大规模ConStoryBoard数据集，包含高质量电影片段和细粒度标注。

Result: 大量实验表明，STAGE在结构化叙事控制和跨镜头连贯性方面实现了优越性能，显著提升了多镜头视频生成的质量和一致性。

Conclusion: STAGE通过故事板锚定的生成方法，有效解决了多镜头视频生成中的跨镜头一致性和叙事控制问题，为创建连贯的电影化叙事提供了新的解决方案。

Abstract: While recent advancements in generative models have achieved remarkable visual fidelity in video synthesis, creating coherent multi-shot narratives remains a significant challenge. To address this, keyframe-based approaches have emerged as a promising alternative to computationally intensive end-to-end methods, offering the advantages of fine-grained control and greater efficiency. However, these methods often fail to maintain cross-shot consistency and capture cinematic language. In this paper, we introduce STAGE, a SToryboard-Anchored GEneration workflow to reformulate the keyframe-based multi-shot video generation task. Instead of using sparse keyframes, we propose STEP2 to predict a structural storyboard composed of start-end frame pairs for each shot. We introduce the multi-shot memory pack to ensure long-range entity consistency, the dual-encoding strategy for intra-shot coherence, and the two-stage training scheme to learn cinematic inter-shot transition. We also contribute the large-scale ConStoryBoard dataset, including high-quality movie clips with fine-grained annotations for story progression, cinematic attributes, and human preferences. Extensive experiments demonstrate that STAGE achieves superior performance in structured narrative control and cross-shot coherence.

</details>


### [63] [V-Warper: Appearance-Consistent Video Diffusion Personalization via Value Warping](https://arxiv.org/abs/2512.12375)
*Hyunkoo Lee,Wooseok Jang,Jini Yang,Taehwan Kim,Sangoh Kim,Sangwon Jung,Seungryong Kim*

Main category: cs.CV

TL;DR: V-Warper：无需训练的视频个性化框架，通过粗到细的外观适配提升身份保真度


<details>
  <summary>Details</summary>
Motivation: 现有视频个性化方法需要大量视频微调或大规模视频数据集，计算成本高且难以扩展，同时难以保持跨帧的细粒度外观一致性。

Method: 1. 轻量级粗粒度外观适配阶段：仅使用少量参考图像，通过图像专用LoRA和主题嵌入适配编码全局主题身份
2. 推理时细粒度外观注入阶段：通过计算RoPE-free中层查询-键特征的语义对应关系，引导外观丰富的值表示到生成过程的语义对齐区域，使用掩码确保空间可靠性

Result: V-Warper显著提升外观保真度，同时保持提示对齐和运动动态，无需大规模视频微调即可高效实现这些改进

Conclusion: V-Warper提供了一种无需训练的视频个性化框架，通过粗到细的外观适配策略有效解决了现有方法在计算成本和细粒度一致性方面的限制。

Abstract: Video personalization aims to generate videos that faithfully reflect a user-provided subject while following a text prompt. However, existing approaches often rely on heavy video-based finetuning or large-scale video datasets, which impose substantial computational cost and are difficult to scale. Furthermore, they still struggle to maintain fine-grained appearance consistency across frames. To address these limitations, we introduce V-Warper, a training-free coarse-to-fine personalization framework for transformer-based video diffusion models. The framework enhances fine-grained identity fidelity without requiring any additional video training. (1) A lightweight coarse appearance adaptation stage leverages only a small set of reference images, which are already required for the task. This step encodes global subject identity through image-only LoRA and subject-embedding adaptation. (2) A inference-time fine appearance injection stage refines visual fidelity by computing semantic correspondences from RoPE-free mid-layer query--key features. These correspondences guide the warping of appearance-rich value representations into semantically aligned regions of the generation process, with masking ensuring spatial reliability. V-Warper significantly improves appearance fidelity while preserving prompt alignment and motion dynamics, and it achieves these gains efficiently without large-scale video finetuning.

</details>


### [64] [M4Human: A Large-Scale Multimodal mmWave Radar Benchmark for Human Mesh Reconstruction](https://arxiv.org/abs/2512.12378)
*Junqiao Fan,Yunjiao Zhou,Yizhuo Yang,Xinyuan Cui,Jiarui Zhang,Lihua Xie,Jianfei Yang,Chris Xiaoxuan Lu,Fangqiang Ding*

Main category: cs.CV

TL;DR: M4Human是一个大规模多模态基准数据集，包含66.1万帧高分辨率毫米波雷达、RGB和深度数据，用于隐私保护的人体网格重建研究。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的人体网格重建方法受限于遮挡、光照变化和隐私问题，而现有的雷达数据集存在标注稀疏、规模有限、动作简单等问题，需要更全面的基准来推动隐私保护的人体感知研究。

Method: 构建了当前最大规模的多模态数据集M4Human，包含原始雷达张量和处理后雷达点云两种数据格式，覆盖20名受试者的50种多样化动作，并提供高质量的动作捕捉标注（3D网格和全局轨迹）。

Result: 建立了雷达张量和雷达点云两种模态的基准，以及多模态融合（RGB-D）的基准，展示了M4Human在雷达人体建模中的重要性，同时揭示了在快速、无约束运动下的持续挑战。

Conclusion: M4Human数据集将推动隐私保护的人体网格重建研究，为雷达和多模态人体感知提供重要基准，数据集和代码将在论文发表后开源。

Abstract: Human mesh reconstruction (HMR) provides direct insights into body-environment interaction, which enables various immersive applications. While existing large-scale HMR datasets rely heavily on line-of-sight RGB input, vision-based sensing is limited by occlusion, lighting variation, and privacy concerns. To overcome these limitations, recent efforts have explored radio-frequency (RF) mmWave radar for privacy-preserving indoor human sensing. However, current radar datasets are constrained by sparse skeleton labels, limited scale, and simple in-place actions. To advance the HMR research community, we introduce M4Human, the current largest-scale (661K-frame) ($9\times$ prior largest) multimodal benchmark, featuring high-resolution mmWave radar, RGB, and depth data. M4Human provides both raw radar tensors (RT) and processed radar point clouds (RPC) to enable research across different levels of RF signal granularity. M4Human includes high-quality motion capture (MoCap) annotations with 3D meshes and global trajectories, and spans 20 subjects and 50 diverse actions, including in-place, sit-in-place, and free-space sports or rehabilitation movements. We establish benchmarks on both RT and RPC modalities, as well as multimodal fusion with RGB-D modalities. Extensive results highlight the significance of M4Human for radar-based human modeling while revealing persistent challenges under fast, unconstrained motion. The dataset and code will be released after the paper publication.

</details>


### [65] [Speedrunning ImageNet Diffusion](https://arxiv.org/abs/2512.12386)
*Swayam Bhanded*

Main category: cs.CV

TL;DR: SR-DiT框架通过整合多种技术（token路由、架构改进、训练优化）在表示对齐基础上，仅用140M参数模型在400K迭代下达到SOTA性能，媲美更大模型效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器训练效率提升技术大多孤立研究，缺乏对多种技术组合协同效应的探索，需要系统整合不同方法以最大化性能提升。

Method: 提出SR-DiT框架，系统整合token路由、架构改进和训练修改，构建在表示对齐基础上，通过大量消融实验确定最有效的技术组合。

Result: 在ImageNet-256上达到FID 3.49和KDD 0.319，仅用140M参数模型在400K迭代下（无需分类器引导），性能媲美685M参数模型，是该模型尺寸下的SOTA结果。

Conclusion: 系统整合多种技术能显著提升扩散变换器效率，框架可作为未来研究的计算友好基线，同时揭示了技术组合间的协同效应和兼容性问题。

Abstract: Recent advances have significantly improved the training efficiency of diffusion transformers. However, these techniques have largely been studied in isolation, leaving unexplored the potential synergies from combining multiple approaches. We present SR-DiT (Speedrun Diffusion Transformer), a framework that systematically integrates token routing, architectural improvements, and training modifications on top of representation alignment. Our approach achieves FID 3.49 and KDD 0.319 on ImageNet-256 using only a 140M parameter model at 400K iterations without classifier-free guidance - comparable to results from 685M parameter models trained significantly longer. To our knowledge, this is a state-of the-art result at this model size. Through extensive ablation studies, we identify which technique combinations are most effective and document both synergies and incompatibilities. We release our framework as a computationally accessible baseline for future research.

</details>


### [66] [ArtGen: Conditional Generative Modeling of Articulated Objects in Arbitrary Part-Level States](https://arxiv.org/abs/2512.12395)
*Haowen Wang,Xiaoping Yuan,Fugang Zhang,Rui Jian,Yuanwei Zhu,Xiuquan Qiao,Yakun Huang*

Main category: cs.CV

TL;DR: ArtGen是一个基于条件扩散的框架，能够从单视图图像或文本描述生成具有准确几何和连贯运动学的铰接式3D物体，通过跨状态蒙特卡洛采样和思维链推理解决结构-运动纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型通常依赖闭合状态的单视图输入，导致几何形状和关节动力学纠缠，产生模糊或不现实的运动学结构。铰接式资产生成对机器人、数字孪生和具身智能至关重要。

Method: 1. 使用跨状态蒙特卡洛采样显式强制执行全局运动学一致性；2. 集成思维链推理模块推断结构先验（部件语义、关节类型、连接性）；3. 采用稀疏专家扩散变换器处理多样化运动学交互；4. 使用局部-全局注意力增强的组合式3D-VAE潜在先验。

Result: 在PartNet-Mobility基准测试上的大量实验表明，ArtGen显著优于最先进的方法。

Conclusion: ArtGen通过解耦结构-运动纠缠，能够从单视图输入生成具有准确几何和连贯运动学的铰接式3D物体，为机器人、数字孪生和具身智能应用提供了有效解决方案。

Abstract: Generating articulated assets is crucial for robotics, digital twins, and embodied intelligence. Existing generative models often rely on single-view inputs representing closed states, resulting in ambiguous or unrealistic kinematic structures due to the entanglement between geometric shape and joint dynamics. To address these challenges, we introduce ArtGen, a conditional diffusion-based framework capable of generating articulated 3D objects with accurate geometry and coherent kinematics from single-view images or text descriptions at arbitrary part-level states. Specifically, ArtGen employs cross-state Monte Carlo sampling to explicitly enforce global kinematic consistency, reducing structural-motion entanglement. Additionally, we integrate a Chain-of-Thought reasoning module to infer robust structural priors, such as part semantics, joint types, and connectivity, guiding a sparse-expert Diffusion Transformer to specialize in diverse kinematic interactions. Furthermore, a compositional 3D-VAE latent prior enhanced with local-global attention effectively captures fine-grained geometry and global part-level relationships. Extensive experiments on the PartNet-Mobility benchmark demonstrate that ArtGen significantly outperforms state-of-the-art methods.

</details>


### [67] [A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams](https://arxiv.org/abs/2512.12410)
*Khalfalla Awedat,Mohamed Abidalrekab,Mohammad El-Yabroudi*

Main category: cs.CV

TL;DR: 基于图注意力网络的LiDAR垂直光束丢失重建方法，仅使用单帧点云数据恢复缺失的垂直通道，无需相机图像或时序信息。


<details>
  <summary>Details</summary>
Motivation: LiDAR传感器因硬件老化、灰尘、雪、雾或强反射等原因导致垂直光束丢失，这会移除点云中的整个垂直切片，严重影响自动驾驶车辆的3D感知能力。

Method: 将LiDAR扫描表示为非结构化空间图：点作为节点，边连接邻近点并保持原始光束索引顺序。使用多层图注意力网络学习局部几何邻域的自适应注意力权重，直接回归缺失位置的高程(z)值。

Result: 在1,065个KITTI原始序列上使用模拟通道丢失进行训练和评估，平均高度RMSE为11.67厘米，87.98%的重建点落在10厘米误差阈值内。单GPU推理每帧14.65秒，重建质量对不同邻域大小k保持稳定。

Conclusion: 纯图注意力模型仅基于原始点云几何就能有效恢复现实传感器退化情况下的丢失垂直光束，证明了该方法在LiDAR数据修复中的有效性。

Abstract: Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.

</details>


### [68] [ViInfographicVQA: A Benchmark for Single and Multi-image Visual Question Answering on Vietnamese Infographics](https://arxiv.org/abs/2512.12424)
*Tue-Thu Van-Dinh,Hoang-Duy Tran,Truong-Binh Duong,Mai-Hanh Pham,Binh-Nam Le-Nguyen,Quoc-Thai Nguyen*

Main category: cs.CV

TL;DR: ViInfographicVQA是首个越南语信息图表视觉问答基准，包含6747个真实信息图表和20409个问题-答案对，评估模型在数据丰富、布局复杂的视觉内容上的阅读理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有VQA基准主要针对场景文本或自然图像，缺乏对信息图表这种结合文本、图表、图标和设计元素的复杂视觉内容的评估。越南语作为低资源语言，尤其缺乏此类评估基准。

Method: 构建包含6747个真实世界信息图表和20409个人工验证问题-答案对的数据集，涵盖经济、医疗、教育等多个领域。设计两种评估设置：单图像任务（传统VQA）和多图像任务（跨图像推理）。

Result: 评估多种最新视觉语言模型，发现显著性能差距。多图像任务中涉及跨图像整合和非跨度推理的问题错误最严重，揭示了当前多模态模型在低资源环境下的局限性。

Conclusion: ViInfographicVQA为越南语信息图表VQA提供了基准结果，揭示了当前模型在布局感知和跨图像推理方面的不足，鼓励未来研究关注这些方向。

Abstract: Infographic Visual Question Answering (InfographicVQA) evaluates a model's ability to read and reason over data-rich, layout-heavy visuals that combine text, charts, icons, and design elements. Compared with scene-text or natural-image VQA, infographics require stronger integration of OCR, layout understanding, and numerical and semantic reasoning. We introduce ViInfographicVQA, the first benchmark for Vietnamese InfographicVQA, comprising over 6747 real-world infographics and 20409 human-verified question-answer pairs across economics, healthcare, education, and more. The benchmark includes two evaluation settings. The Single-image task follows the traditional setup in which each question is answered using a single infographic. The Multi-image task requires synthesizing evidence across multiple semantically related infographics and is, to our knowledge, the first Vietnamese evaluation of cross-image reasoning in VQA. We evaluate a range of recent vision-language models on this benchmark, revealing substantial performance disparities, with the most significant errors occurring on Multi-image questions that involve cross-image integration and non-span reasoning. ViInfographicVQA contributes benchmark results for Vietnamese InfographicVQA and sheds light on the limitations of current multimodal models in low-resource contexts, encouraging future exploration of layout-aware and cross-image reasoning methods.

</details>


### [69] [BokehDepth: Enhancing Monocular Depth Estimation through Bokeh Generation](https://arxiv.org/abs/2512.12425)
*Hangwei Zhang,Armando Teles Fortes,Tianyi Wei,Xingang Pan*

Main category: cs.CV

TL;DR: BokehDepth：两阶段框架，将散景合成与深度预测解耦，利用散焦作为无监督的几何线索，提升散景渲染质量和单目深度估计精度


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用散景与单目深度估计之间的紧密联系。高质量散景渲染依赖噪声深度图导致可见伪影，而单目深度模型在弱纹理、远距离和几何模糊区域表现不佳，这些区域恰恰是散焦线索最有信息量的地方。

Method: 两阶段框架：第一阶段使用基于预训练图像编辑骨干的物理引导可控散景生成器，从单张清晰输入生成无深度散景堆栈；第二阶段通过轻量级散焦感知聚合模块，将散焦维度特征融合到现有单目深度编码器中，暴露稳定的深度敏感变化。

Result: 在挑战性基准测试中，BokehDepth相比基于深度图的散景基线提升了视觉保真度，并持续提升了强单目深度基础模型的度量精度和鲁棒性。

Conclusion: BokehDepth通过解耦散景合成与深度预测，将散焦作为无监督几何线索，有效解决了现有方法的局限性，实现了散景渲染质量和深度估计精度的双重提升。

Abstract: Bokeh and monocular depth estimation are tightly coupled through the same lens imaging geometry, yet current methods exploit this connection in incomplete ways. High-quality bokeh rendering pipelines typically depend on noisy depth maps, which amplify estimation errors into visible artifacts, while modern monocular metric depth models still struggle on weakly textured, distant and geometrically ambiguous regions where defocus cues are most informative. We introduce BokehDepth, a two-stage framework that decouples bokeh synthesis from depth prediction and treats defocus as an auxiliary supervision-free geometric cue. In Stage-1, a physically guided controllable bokeh generator, built on a powerful pretrained image editing backbone, produces depth-free bokeh stacks with calibrated bokeh strength from a single sharp input. In Stage-2, a lightweight defocus-aware aggregation module plugs into existing monocular depth encoders, fuses features along the defocus dimension, and exposes stable depth-sensitive variations while leaving downstream decoder unchanged. Across challenging benchmarks, BokehDepth improves visual fidelity over depth-map-based bokeh baselines and consistently boosts the metric accuracy and robustness of strong monocular depth foundation models.

</details>


### [70] [Endless World: Real-Time 3D-Aware Long Video Generation](https://arxiv.org/abs/2512.12430)
*Ke Zhang,Yiqun Mei,Jiacong Xu,Vishal M. Patel*

Main category: cs.CV

TL;DR: Endless World是一个实时无限3D一致视频生成框架，通过条件自回归训练和全局3D感知注意力实现长视频序列的稳定生成。


<details>
  <summary>Details</summary>
Motivation: 解决长视频序列生成中保持3D结构稳定性的挑战，特别是在流式场景下，现有方法难以产生连贯、稳定的长视频。

Method: 1. 条件自回归训练策略：对齐新生成内容与现有视频帧，保持长程依赖且计算高效；2. 全局3D感知注意力：提供跨时间连续几何指导；3. 3D注入机制：确保物理合理性和几何一致性。

Result: 在单GPU上实现实时推理，无需额外训练开销，生成长、稳定、视觉连贯的视频，在视觉保真度和空间一致性方面达到或超越现有方法。

Conclusion: Endless World成功解决了长视频生成的3D一致性问题，为无限视频生成提供了有效的实时解决方案，在流式场景中具有重要应用价值。

Abstract: Producing long, coherent video sequences with stable 3D structure remains a major challenge, particularly in streaming scenarios. Motivated by this, we introduce Endless World, a real-time framework for infinite, 3D-consistent video generation.To support infinite video generation, we introduce a conditional autoregressive training strategy that aligns newly generated content with existing video frames. This design preserves long-range dependencies while remaining computationally efficient, enabling real-time inference on a single GPU without additional training overhead.Moreover, our Endless World integrates global 3D-aware attention to provide continuous geometric guidance across time. Our 3D injection mechanism enforces physical plausibility and geometric consistency throughout extended sequences, addressing key challenges in long-horizon and dynamic scene synthesis.Extensive experiments demonstrate that Endless World produces long, stable, and visually coherent videos, achieving competitive or superior performance to existing methods in both visual fidelity and spatial consistency. Our project has been available on https://bwgzk-keke.github.io/EndlessWorld/.

</details>


### [71] [From Particles to Fields: Reframing Photon Mapping with Continuous Gaussian Photon Fields](https://arxiv.org/abs/2512.12459)
*Jiachen Tao,Benjamin Planche,Van Nguyen Nguyen,Junyi Wu,Yuchun Liu,Haoxuan Wang,Zhongpai Gao,Gengyu Zhang,Meng Zheng,Feiran Wang,Anwesa Choudhuri,Zhenghao Zhao,Weitai Kang,Terrence Chen,Yan Yan,Ziyan Wu*

Main category: cs.CV

TL;DR: 提出Gaussian Photon Field (GPF)，将光子映射重构为连续可重用的辐射函数，通过3D高斯基元编码光子分布，实现多视角渲染加速


<details>
  <summary>Details</summary>
Motivation: 光子映射能准确模拟复杂全局光照效果（如焦散、镜面-漫反射交互），但在渲染同一场景的多个视角时，每个视角都需要独立的光子追踪和随机核估计，导致大量冗余计算，计算效率低下

Method: 引入高斯光子场(GPF)，将光子分布编码为由位置、旋转、尺度和光谱参数化的各向异性3D高斯基元。从第一次SPPM迭代的物理追踪光子初始化，通过多视角最终辐射监督进行优化，将基于光子的光传输提炼为连续场

Result: 在具有复杂光传输的场景（如焦散和镜面-漫反射交互）上进行广泛实验，证明GPF在保持光子级精度的同时，将计算量减少数个数量级

Conclusion: GPF统一了基于光子渲染的物理严谨性与神经场景表示的高效性，实现了可微分辐射评估而无需重复光子追踪或迭代优化

Abstract: Accurately modeling light transport is essential for realistic image synthesis. Photon mapping provides physically grounded estimates of complex global illumination effects such as caustics and specular-diffuse interactions, yet its per-view radiance estimation remains computationally inefficient when rendering multiple views of the same scene. The inefficiency arises from independent photon tracing and stochastic kernel estimation at each viewpoint, leading to inevitable redundant computation. To accelerate multi-view rendering, we reformulate photon mapping as a continuous and reusable radiance function. Specifically, we introduce the Gaussian Photon Field (GPF), a learnable representation that encodes photon distributions as anisotropic 3D Gaussian primitives parameterized by position, rotation, scale, and spectrum. GPF is initialized from physically traced photons in the first SPPM iteration and optimized using multi-view supervision of final radiance, distilling photon-based light transport into a continuous field. Once trained, the field enables differentiable radiance evaluation along camera rays without repeated photon tracing or iterative refinement. Extensive experiments on scenes with complex light transport, such as caustics and specular-diffuse interactions, demonstrate that GPF attains photon-level accuracy while reducing computation by orders of magnitude, unifying the physical rigor of photon-based rendering with the efficiency of neural scene representations.

</details>


### [72] [More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models](https://arxiv.org/abs/2512.12487)
*Hoang Anh Just,Yifei Fan,Handong Zhao,Jiuxiang Gu,Ruiyi Zhang,Simon Jenni,Kushal Kafle,Ruoxi Jia,Jing Shi*

Main category: cs.CV

TL;DR: PeRL-VL提出了一种解耦框架，分别改进视觉感知和文本推理，通过VLM描述奖励和纯文本推理SFT提升多模态模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR训练的多模态模型存在两个主要问题：1) 视觉提取不准确（遗漏细节或产生幻觉）2) 思维链逻辑不一致。这是因为可验证信号只监督最终答案，无法有效指导中间过程。

Method: PeRL-VL采用解耦框架：1) 感知方面：引入基于VLM的描述奖励，对模型自生成的图像描述进行忠实性和充分性评分 2) 推理方面：在逻辑丰富的思维链数据上添加纯文本推理SFT阶段，独立于视觉增强逻辑一致性。

Result: 在多样化多模态基准测试中，PeRL-VL将平均Pass@1准确率从63.3%（基础Qwen2.5-VL-7B）提升到68.8%，优于标准RLVR、纯文本推理SFT和GPT-4o的多模态蒸馏方法。

Conclusion: PeRL-VL通过解耦感知和推理学习，有效解决了多模态模型中视觉提取不准确和逻辑不一致的问题，显著提升了多模态推理性能。

Abstract: Reinforcement learning from verifiable rewards (RLVR) has recently been extended from text-only LLMs to vision-language models (VLMs) to elicit long-chain multimodal reasoning. However, RLVR-trained VLMs still exhibit two persistent failure modes: inaccurate visual extraction (missing or hallucinating details) and logically inconsistent chains-of-thought, largely because verifiable signals supervise only the final answer. We propose PeRL-VL (Perception and Reasoning Learning for Vision-Language Models), a decoupled framework that separately improves visual perception and textual reasoning on top of RLVR. For perception, PeRL-VL introduces a VLM-based description reward that scores the model's self-generated image descriptions for faithfulness and sufficiency. For reasoning, PeRL-VL adds a text-only Reasoning SFT stage on logic-rich chain-of-thought data, enhancing coherence and logical consistency independently of vision. Across diverse multimodal benchmarks, PeRL-VL improves average Pass@1 accuracy from 63.3% (base Qwen2.5-VL-7B) to 68.8%, outperforming standard RLVR, text-only reasoning SFT, and naive multimodal distillation from GPT-4o.

</details>


### [73] [Adaptive Detector-Verifier Framework for Zero-Shot Polyp Detection in Open-World Settings](https://arxiv.org/abs/2512.12492)
*Shengkai Xu,Hsiang Lun Kao,Tianxiang Xu,Honghui Zhang,Junqiao Wang,Runmeng Ding,Guanyu Liu,Tianyu Shi,Zhenyu Yu,Guofeng Pan,Ziqian Bi,Yuqi Ouyang*

Main category: cs.CV

TL;DR: 提出AdaptiveDetector两阶段检测-验证框架，通过YOLOv11检测器和VLM验证器，结合自适应阈值调整和成本敏感强化学习，在恶劣内窥镜条件下显著提升息肉检测召回率。


<details>
  <summary>Details</summary>
Motivation: 现有息肉检测器在干净数据集上训练，但在真实内窥镜环境中（光照变化、运动模糊、遮挡等）性能下降，存在实验室条件与临床实践之间的领域差距。

Method: 提出两阶段检测-验证框架：1) YOLOv11检测器在VLM指导下自适应调整每帧置信度阈值；2) VLM验证器使用Group Relative Policy Optimization (GRPO)进行微调，采用非对称成本敏感奖励函数，特别设计来减少漏检。

Result: 在合成退化的CVC-ClinicDB和Kvasir-SEG图像上进行零样本评估，相比单独YOLO，召回率提升14-22个百分点，精度保持在基线0.7点以下至1.7点以上范围内。

Conclusion: 自适应阈值调整和成本敏感强化学习的结合实现了临床对齐的开放世界息肉检测，显著减少假阴性，降低漏检癌前息肉风险，改善患者预后。

Abstract: Polyp detectors trained on clean datasets often underperform in real-world endoscopy, where illumination changes, motion blur, and occlusions degrade image quality. Existing approaches struggle with the domain gap between controlled laboratory conditions and clinical practice, where adverse imaging conditions are prevalent. In this work, we propose AdaptiveDetector, a novel two-stage detector-verifier framework comprising a YOLOv11 detector with a vision-language model (VLM) verifier. The detector adaptively adjusts per-frame confidence thresholds under VLM guidance, while the verifier is fine-tuned with Group Relative Policy Optimization (GRPO) using an asymmetric, cost-sensitive reward function specifically designed to discourage missed detections -- a critical clinical requirement. To enable realistic assessment under challenging conditions, we construct a comprehensive synthetic testbed by systematically degrading clean datasets with adverse conditions commonly encountered in clinical practice, providing a rigorous benchmark for zero-shot evaluation. Extensive zero-shot evaluation on synthetically degraded CVC-ClinicDB and Kvasir-SEG images demonstrates that our approach improves recall by 14 to 22 percentage points over YOLO alone, while precision remains within 0.7 points below to 1.7 points above the baseline. This combination of adaptive thresholding and cost-sensitive reinforcement learning achieves clinically aligned, open-world polyp detection with substantially fewer false negatives, thereby reducing the risk of missed precancerous polyps and improving patient outcomes.

</details>


### [74] [Advancing Cache-Based Few-Shot Classification via Patch-Driven Relational Gated Graph Attention](https://arxiv.org/abs/2512.12498)
*Tasweer Ahmad,Arindam Sikdar,Sandip Pradhan,Ardhendu Behera*

Main category: cs.CV

TL;DR: 提出基于图注意力网络的补丁关系细化方法，提升少样本图像分类性能，保持零样本推理效率


<details>
  <summary>Details</summary>
Motivation: 现有基于缓存的适配方法（如Tip-Adapter）仍继承CLIP的全局表示倾向，在少样本和域偏移场景下不够判别性，需要更精细的补丁级关系建模

Method: 提出补丁驱动的关系细化：1）使用关系门控图注意力网络构建补丁图，进行边缘感知注意力强调信息性补丁交互；2）可学习的多聚合池化生成紧凑任务判别表示；3）仅在训练时使用图细化，推理时保持标准缓存查找效率

Result: 在11个基准测试上持续超越最先进的CLIP适配器和基于缓存的方法，同时保持零样本效率；引入新的受伤士兵数据集验证战场应用价值

Conclusion: 通过补丁级关系建模显著提升少样本分类性能，为时间关键的战场伤员识别等应用提供有效解决方案

Abstract: Few-shot image classification remains difficult under limited supervision and visual domain shift. Recent cache-based adaptation approaches (e.g., Tip-Adapter) address this challenge to some extent by learning lightweight residual adapters over frozen features, yet they still inherit CLIP's tendency to encode global, general-purpose representations that are not optimally discriminative to adapt the generalist to the specialist's domain in low-data regimes. We address this limitation with a novel patch-driven relational refinement that learns cache adapter weights from intra-image patch dependencies rather than treating an image embedding as a monolithic vector. Specifically, we introduce a relational gated graph attention network that constructs a patch graph and performs edge-aware attention to emphasize informative inter-patch interactions, producing context-enriched patch embeddings. A learnable multi-aggregation pooling then composes these into compact, task-discriminative representations that better align cache keys with the target few-shot classes. Crucially, the proposed graph refinement is used only during training to distil relational structure into the cache, incurring no additional inference cost beyond standard cache lookup. Final predictions are obtained by a residual fusion of cache similarity scores with CLIP zero-shot logits. Extensive evaluations on 11 benchmarks show consistent gains over state-of-the-art CLIP adapter and cache-based baselines while preserving zero-shot efficiency. We further validate battlefield relevance by introducing an Injured vs. Uninjured Soldier dataset for casualty recognition. It is motivated by the operational need to support triage decisions within the "platinum minutes" and the broader "golden hour" window in time-critical UAV-driven search-and-rescue and combat casualty care.

</details>


### [75] [Generative Spatiotemporal Data Augmentation](https://arxiv.org/abs/2512.12508)
*Jinfan Zhou,Lixin Luo,Sungmin Eum,Heesung Kwon,Jeong Joon Park*

Main category: cs.CV

TL;DR: 利用视频基础模型进行时空数据增强，通过视频扩散模型生成真实的3D空间和时间变化，在低数据场景下提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法主要基于简单的几何变换或外观扰动，无法有效模拟真实的3D空间和时间变化。在无人机图像等标注稀缺的低数据场景中，需要更有效的增强方法来扩展数据分布

Method: 使用现成的视频扩散模型从给定图像数据集生成真实的3D空间和时间变化，创建合成视频片段作为补充训练数据。提供实用指南包括：选择适当的时空生成设置、将标注转移到合成帧、处理新暴露区域的标注缺失问题

Result: 在COCO子集和无人机捕获数据集上的实验表明，时空增强能够沿着传统和先前生成方法未能充分代表的维度扩展数据分布，在数据稀缺情况下有效提升模型性能

Conclusion: 时空数据增强通过视频基础模型生成真实的3D变化，为低数据场景提供了有效的性能提升手段，特别是在无人机图像等标注稀缺的应用中具有重要价值

Abstract: We explore spatiotemporal data augmentation using video foundation models to diversify both camera viewpoints and scene dynamics. Unlike existing approaches based on simple geometric transforms or appearance perturbations, our method leverages off-the-shelf video diffusion models to generate realistic 3D spatial and temporal variations from a given image dataset. Incorporating these synthesized video clips as supplemental training data yields consistent performance gains in low-data settings, such as UAV-captured imagery where annotations are scarce. Beyond empirical improvements, we provide practical guidelines for (i) choosing an appropriate spatiotemporal generative setup, (ii) transferring annotations to synthetic frames, and (iii) addressing disocclusion - regions newly revealed and unlabeled in generated views. Experiments on COCO subsets and UAV-captured datasets show that, when applied judiciously, spatiotemporal augmentation broadens the data distribution along axes underrepresented by traditional and prior generative methods, offering an effective lever for improving model performance in data-scarce regimes.

</details>


### [76] [Animus3D: Text-driven 3D Animation via Motion Score Distillation](https://arxiv.org/abs/2512.12534)
*Qi Sun,Can Wang,Jiaxiang Shang,Wensen Feng,Jing Liao*

Main category: cs.CV

TL;DR: Animus3D：基于文本驱动的3D动画框架，通过Motion Score Distillation（MSD）替代传统SDS，结合LoRA增强的视频扩散模型和时空正则化，为静态3D资产生成高质量运动场


<details>
  <summary>Details</summary>
Motivation: 现有方法主要使用vanilla Score Distillation Sampling（SDS）从预训练文本到视频扩散模型中蒸馏运动，导致动画运动幅度小或明显抖动，需要更好的运动生成方法

Method: 提出Motion Score Distillation（MSD）替代SDS，使用LoRA增强的视频扩散模型定义静态源分布，结合基于反转的噪声估计技术保持外观一致性，加入时空正则化减少几何失真，并设计运动细化模块提升时间分辨率和细节

Result: 实验表明Animus3D能成功为各种文本提示的静态3D资产生成动画，相比现有基线方法产生更显著、更详细的运动，同时保持高视觉完整性

Conclusion: Animus3D通过创新的MSD方法和时空正则化技术，有效解决了文本驱动3D动画中的运动幅度不足和抖动问题，为静态3D资产生成高质量动画

Abstract: We present Animus3D, a text-driven 3D animation framework that generates motion field given a static 3D asset and text prompt. Previous methods mostly leverage the vanilla Score Distillation Sampling (SDS) objective to distill motion from pretrained text-to-video diffusion, leading to animations with minimal movement or noticeable jitter. To address this, our approach introduces a novel SDS alternative, Motion Score Distillation (MSD). Specifically, we introduce a LoRA-enhanced video diffusion model that defines a static source distribution rather than pure noise as in SDS, while another inversion-based noise estimation technique ensures appearance preservation when guiding motion. To further improve motion fidelity, we incorporate explicit temporal and spatial regularization terms that mitigate geometric distortions across time and space. Additionally, we propose a motion refinement module to upscale the temporal resolution and enhance fine-grained details, overcoming the fixed-resolution constraints of the underlying video model. Extensive experiments demonstrate that Animus3D successfully animates static 3D assets from diverse text prompts, generating significantly more substantial and detailed motion than state-of-the-art baselines while maintaining high visual integrity. Code will be released at https://qiisun.github.io/animus3d_page.

</details>


### [77] [Anatomy Guided Coronary Artery Segmentation from CCTA Using Spatial Frequency Joint Modeling](https://arxiv.org/abs/2512.12539)
*Huan Huang,Michele Esposito,Chen Zhao*

Main category: cs.CV

TL;DR: 提出一种结合心肌解剖先验、结构感知特征编码和三维小波变换的冠状动脉分割框架，在复杂几何条件下实现稳定分割


<details>
  <summary>Details</summary>
Motivation: 冠状动脉CT血管成像的准确分割对定量分析和临床决策至关重要，但由于血管细小、分支复杂、边界模糊和心肌干扰等因素，可靠分割仍然具有挑战性

Method: 整合心肌解剖先验、结构感知特征编码和三维小波-逆小波变换，编码阶段加入心肌先验和残差注意力特征增强，使用小波变换进行下采样和上采样实现联合空间频率建模，解码阶段通过多尺度特征融合模块整合语义和几何信息

Result: 在公开ImageCAS数据集上，Dice系数0.8082，敏感性0.7946，精确率0.8471，HD95为9.77mm，优于多个主流分割模型，消融研究证实各组件互补贡献

Conclusion: 该方法在复杂几何条件下实现更稳定一致的冠状动脉分割，为后续冠状动脉结构分析任务提供可靠分割结果

Abstract: Accurate coronary artery segmentation from coronary computed tomography angiography is essential for quantitative coronary analysis and clinical decision support. Nevertheless, reliable segmentation remains challenging because of small vessel calibers, complex branching, blurred boundaries, and myocardial interference. We propose a coronary artery segmentation framework that integrates myocardial anatomical priors, structure aware feature encoding, and three dimensional wavelet inverse wavelet transformations. Myocardial priors and residual attention based feature enhancement are incorporated during encoding to strengthen coronary structure representation. Wavelet inverse wavelet based downsampling and upsampling enable joint spatial frequency modeling and preserve multi scale structural consistency, while a multi scale feature fusion module integrates semantic and geometric information in the decoding stage. The model is trained and evaluated on the public ImageCAS dataset using a 3D overlapping patch based strategy with a 7:1:2 split for training, validation, and testing. Experimental results demonstrate that the proposed method achieves a Dice coefficient of 0.8082, Sensitivity of 0.7946, Precision of 0.8471, and an HD95 of 9.77 mm, outperforming several mainstream segmentation models. Ablation studies further confirm the complementary contributions of individual components. The proposed method enables more stable and consistent coronary artery segmentation under complex geometric conditions, providing reliable segmentation results for subsequent coronary structure analysis tasks.

</details>


### [78] [Supervised Contrastive Frame Aggregation for Video Representation Learning](https://arxiv.org/abs/2512.12549)
*Shaif Chowdhury,Mushfika Rahman,Greg Hamerly*

Main category: cs.CV

TL;DR: 提出一种监督对比学习框架用于视频表征学习，通过将视频帧空间排列成单张图像，利用预训练CNN骨干网络，避免复杂视频Transformer的计算开销，在分类准确率和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频表征学习方法通常依赖复杂的视频Transformer模型，计算开销大。需要一种能利用预训练CNN骨干网络、计算高效且能捕捉视频全局时序上下文的方法。

Method: 提出监督对比帧聚合方法：1) 视频到图像聚合策略，将多个视频帧空间排列成单张输入图像；2) 监督对比学习目标，比较模型生成的成对投影，同标签视频投影为正对，其他为负对；3) 通过不同时序帧采样创建同一视频的多个自然视图，无需数据增强即可获得多样正样本。

Result: 在Penn Action数据集上达到76%分类准确率（ViViT为43%），在HMDB51数据集上达到48%准确率（ViViT为37%）。方法在监督和自监督设置下都能学习有效视频表征，支持分类和字幕生成等任务，且计算资源需求更少。

Conclusion: 提出的监督对比帧聚合方法通过视频到图像聚合策略和对比学习目标，有效学习视频表征，在分类准确率和计算效率上优于现有方法，为视频理解任务提供了高效解决方案。

Abstract: We propose a supervised contrastive learning framework for video representation learning that leverages temporally global context. We introduce a video to image aggregation strategy that spatially arranges multiple frames from each video into a single input image. This design enables the use of pre trained convolutional neural network backbones such as ResNet50 and avoids the computational overhead of complex video transformer models. We then design a contrastive learning objective that directly compares pairwise projections generated by the model. Positive pairs are defined as projections from videos sharing the same label while all other projections are treated as negatives. Multiple natural views of the same video are created using different temporal frame samplings from the same underlying video. Rather than relying on data augmentation these frame level variations produce diverse positive samples with global context and reduce overfitting. Experiments on the Penn Action and HMDB51 datasets demonstrate that the proposed method outperforms existing approaches in classification accuracy while requiring fewer computational resources. The proposed Supervised Contrastive Frame Aggregation method learns effective video representations in both supervised and self supervised settings and supports video based tasks such as classification and captioning. The method achieves seventy six percent classification accuracy on Penn Action compared to forty three percent achieved by ViVIT and forty eight percent accuracy on HMDB51 compared to thirty seven percent achieved by ViVIT.

</details>


### [79] [StreamingAssistant: Efficient Visual Token Pruning for Accelerating Online Video Understanding](https://arxiv.org/abs/2512.12560)
*Xinqi Jin,Hanxun Yu,Bohan Yu,Kebin Liu,Jian Liu,Keda Tao,Yixuan Pei,Huan Wang,Fan Dang,Jiangchuan Liu,Weiqiang Wang*

Main category: cs.CV

TL;DR: 提出MSSAVT冗余度量与掩码剪枝策略，减少视频理解中MLLMs的token数量，降低计算开销同时提升精度


<details>
  <summary>Details</summary>
Motivation: 在线视频理解应用广泛，但MLLMs处理大量视频帧时面临GPU内存占用高、计算延迟大的挑战，需要减少上下文长度同时保留关键信息

Method: 提出MSSAVT冗余度量（考虑token相似性和空间位置），设计掩码剪枝策略避免双向依赖，结合现有时间冗余剪枝方法消除时间冗余

Result: 在多个在线和离线视频理解基准测试中，方法显著提升精度（最高4%），剪枝延迟可忽略（小于1ms）

Conclusion: 提出的token剪枝方法能有效减少MLLMs在视频理解中的计算负担，同时保持甚至提升性能，为实际应用提供可行方案

Abstract: Online video understanding is essential for applications like public surveillance and AI glasses. However, applying Multimodal Large Language Models (MLLMs) to this domain is challenging due to the large number of video frames, resulting in high GPU memory usage and computational latency. To address these challenges, we propose token pruning as a means to reduce context length while retaining critical information. Specifically, we introduce a novel redundancy metric, Maximum Similarity to Spatially Adjacent Video Tokens (MSSAVT), which accounts for both token similarity and spatial position. To mitigate the bidirectional dependency between pruning and redundancy, we further design a masked pruning strategy that ensures only mutually unadjacent tokens are pruned. We also integrate an existing temporal redundancy-based pruning method to eliminate temporal redundancy of the video modality. Experimental results on multiple online and offline video understanding benchmarks demonstrate that our method significantly improves the accuracy (i.e., by 4\% at most) while incurring a negligible pruning latency (i.e., less than 1ms). Our full implementation will be made publicly available.

</details>


### [80] [From Tokens to Photons: Test-Time Physical Prompting for Vison-Language Models](https://arxiv.org/abs/2512.12571)
*Boyeong Im,Wooseok Lee,Yoojin Kwon,Hyung-Sin Kim*

Main category: cs.CV

TL;DR: MVP提出了一种将测试时适应从数字领域扩展到物理传感器控制的方法，通过相机曝光三角作为物理提示，在推理时选择最佳传感器设置并聚合预测，显著提升视觉语言模型在物理环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 将视觉语言模型从网络图像扩展到传感器介导的物理环境，传统方法主要关注后捕获的数字提示，而忽略了测量时的物理控制对模型鲁棒性的潜在提升。

Method: MVP是一个前向推理框架，将相机曝光三角（ISO、快门速度、光圈）作为物理提示。在推理时：1）获取每个场景的物理视图库；2）使用源亲和性分数选择top-k传感器设置；3）在轻量级数字增强下评估每个保留视图；4）过滤最低熵的增强视图子集；5）使用零温度softmax（硬投票）聚合预测。无需梯度或模型修改。

Result: 在ImageNet-ES和ImageNet-ES-Diverse数据集上，MVP比单次自动曝光捕获的数字TTA方法提升高达25.6个百分点，比结合传统传感器控制与TTA的流程额外提升3.4个百分点。即使在减少参数候选集以降低捕获延迟的情况下，MVP仍然有效。

Conclusion: 除了后捕获提示外，测量时控制——选择和组合真实的物理视图——能显著提升视觉语言模型的鲁棒性。MVP框架简单、易于校准，无需梯度或模型修改，具有实际应用价值。

Abstract: To extend the application of vision-language models (VLMs) from web images to sensor-mediated physical environments, we propose Multi-View Physical-prompt for Test-Time Adaptation (MVP), a forward-only framework that moves test-time adaptation (TTA) from tokens to photons by treating the camera exposure triangle--ISO, shutter speed, and aperture--as physical prompts. At inference, MVP acquires a library of physical views per scene, selects the top-k sensor settings using a source-affinity score, evaluates each retained view under lightweight digital augmentations, filters the lowest-entropy subset of augmented views, and aggregates predictions with Zero-temperature softmax (i.e., hard voting). This selection-then-vote design is simple, calibration-friendly, and requires no gradients or model modifications. On ImageNet-ES and ImageNet-ES-Diverse, MVP consistently outperforms digital-only TTA on single Auto-Exposure captures, by up to 25.6 percentage points (pp), and delivers up to 3.4 pp additional gains over pipelines that combine conventional sensor control with TTA. MVP remains effective under reduced parameter candidate sets that lower capture latency, demonstrating practicality. These results support the main claim that, beyond post-capture prompting, measurement-time control--selecting and combining real physical views--substantially improves robustness for VLMs.

</details>


### [81] [StegaVAR: Privacy-Preserving Video Action Recognition via Steganographic Domain Analysis](https://arxiv.org/abs/2512.12586)
*Lixin Chen,Chaomeng Chen,Jiale Zhou,Zhijian Wu,Xun Lin*

Main category: cs.CV

TL;DR: StegaVAR：首个在隐写域直接执行视频动作识别的隐私保护框架，将动作视频嵌入普通封面视频，同时保持时空信息完整和传输隐蔽性


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护方法存在两个主要问题：(1) 隐蔽性低，产生视觉扭曲的视频在传输时容易吸引攻击者注意；(2) 时空破坏，降低VAR所需的必要时空特征。需要一种既能保护隐私又不影响动作识别性能的方法

Method: 提出StegaVAR框架，将动作视频嵌入普通封面视频，首次在隐写域直接执行VAR。提出两个关键技术：STeP（秘密时空促进）在训练时使用秘密视频指导隐写域的时空特征提取；CroDA（跨波段差异注意力）通过捕捉跨波段语义差异来抑制封面干扰

Result: 实验表明StegaVAR在广泛使用的数据集上实现了优越的视频动作识别和隐私保护性能。该框架对多种隐写模型都有效

Conclusion: StegaVAR成功解决了隐私保护视频动作识别中的隐蔽性和时空特征保持问题，为隐私敏感的VAR应用提供了有效解决方案

Abstract: Despite the rapid progress of deep learning in video action recognition (VAR) in recent years, privacy leakage in videos remains a critical concern. Current state-of-the-art privacy-preserving methods often rely on anonymization. These methods suffer from (1) low concealment, where producing visually distorted videos that attract attackers' attention during transmission, and (2) spatiotemporal disruption, where degrading essential spatiotemporal features for accurate VAR. To address these issues, we propose StegaVAR, a novel framework that embeds action videos into ordinary cover videos and directly performs VAR in the steganographic domain for the first time. Throughout both data transmission and action analysis, the spatiotemporal information of hidden secret video remains complete, while the natural appearance of cover videos ensures the concealment of transmission. Considering the difficulty of steganographic domain analysis, we propose Secret Spatio-Temporal Promotion (STeP) and Cross-Band Difference Attention (CroDA) for analysis within the steganographic domain. STeP uses the secret video to guide spatiotemporal feature extraction in the steganographic domain during training. CroDA suppresses cover interference by capturing cross-band semantic differences. Experiments demonstrate that StegaVAR achieves superior VAR and privacy-preserving performance on widely used datasets. Moreover, our framework is effective for multiple steganographic models.

</details>


### [82] [Automatic Wire-Harness Color Sequence Detector](https://arxiv.org/abs/2512.12590)
*Indiwara Nanayakkara,Dehan Jayawickrama,Mervyn Parakrama B. Ekanayake*

Main category: cs.CV

TL;DR: 本文提出了一种半自动机器视觉系统，用于线束检测，通过5个工业CMOS相机和HSV/RGB颜色分类器，实现了100%检测精度和44%时间节省。


<details>
  <summary>Details</summary>
Motivation: 在现代电子制造服务（EMS）行业中，线束检测过程仍然是劳动密集型且容易出错的过程，需要自动化解决方案来提高效率和准确性。

Method: 系统采用5个工业标准CMOS相机集成到模块化机械框架中，使用基于HSV和RGB颜色域值比较的颜色序列分类器。用户可以使用至少5个参考样本训练系统，训练文件可存储并重复用于类似线束类型。

Result: 系统在GPV Lanka Pvt. Ltd.部署，实现了100%的检测精度，相比手动方法减少了44%的检测时间。系统还包含用户管理、可调照明、会话数据存储和安全登录等附加功能。

Conclusion: 该半自动机器视觉系统为线束检测提供了可靠高效的解决方案，在实际应用中表现出色，能够显著提高检测效率和准确性。

Abstract: Wire harness inspection process remains a labor-intensive process prone to errors in the modern Electronics Manufacturing Services (EMS) industry. This paper introduces a semiautomated machine vision system capable of verifying correct wire positioning, correctness of the connector polarity and correctness of color sequences for both linear and circular wire harness configurations. Five industrial standard CMOS cameras are integrated into a modularized mechanical framework in the physical structure of the solution and a HSV and RGB color domain value comparison based color sequence classifier is used in the operation. For each harness batch, a user can train the system using at least five reference samples; the trained file is stored and reused for similar harness types. The Solution is deployed at GPV Lanka Pvt. Ltd. (Fig. 2) and the system achieved 100% detection accuracy and reduced inspection time by 44% compared to manual methods. Additional features include user management, adjustable lighting, session data storage, and secure login. Results of this product usage in the real world situation demonstrate that this approach delivers reliable and efficient inspection capabilities.

</details>


### [83] [Vision-Enhanced Large Language Models for High-Resolution Image Synthesis and Multimodal Data Interpretation](https://arxiv.org/abs/2512.12595)
*Karthikeya KV*

Main category: cs.CV

TL;DR: 提出一个结合视觉增强LLM与先进Transformer架构的框架，通过整流流机制和双向标记化策略，实现高质量图像合成和多模态数据理解，在图像分辨率和计算效率上显著优于扩散方法。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率图像合成和多模态数据解释中的挑战，通过整合视觉增强的大型语言模型与先进Transformer架构，提升生成质量和计算效率。

Method: 采用整流流机制连接噪声与数据，使用双向标记化策略融合文本、图像和视频输入，嵌入时空特征，结合混合文本-图像序列建模，并优化噪声感知学习算法。

Result: 在基准数据集上评估显示，图像分辨率清晰度提高25%，计算需求减少20%相比扩散方法，模型展现出强大的可扩展性和适应性。

Conclusion: 该框架通过视觉中心的大型语言模型重新定义了计算机视觉和多模态人工智能的能力，在自主系统、创意内容生成和高级视频分析等领域具有应用潜力。

Abstract: This research introduces a transformative framework for integrating Vision-Enhanced Large Language Models (LLMs) with advanced transformer-based architectures to tackle challenges in high-resolution image synthesis and multimodal data interpretation. The proposed model incorporates a rectified flow mechanism that connects noise and data with linear paths, enabling efficient and high-quality generation. A bidirectional tokenization strategy is employed to seamlessly merge inputs from text, image, and video modalities, fostering a unified understanding across diverse data types. By embedding spatial-temporal features and leveraging a hybrid text-image sequence modeling approach, the framework achieves unparalleled fidelity in synthesized images and coherent multimodal representations. The architecture is optimized with a noise-aware learning algorithm, addressing discrepancies in noisy data distributions and improving generative performance under varying input conditions. Rigorous evaluations on benchmark datasets demonstrate a 25% increase in image resolution clarity and a 20% reduction in computational requirements compared to diffusion-based methods. Furthermore, the model exhibits robust scalability and adaptability, showcasing its potential in applications like autonomous systems, creative content generation, and advanced video analysis. This work underscores the role of vision-centric LLMs in redefining capabilities in computer vision and multimodal artificial intelligence.

</details>


### [84] [Content-Aware Ad Banner Layout Generation with Two-Stage Chain-of-Thought in Vision Language Models](https://arxiv.org/abs/2512.12596)
*Kei Yoshitake,Kento Hosono,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.CV

TL;DR: 提出一种基于视觉语言模型（VLM）的广告布局生成方法，通过分析背景图像内容来智能放置文本和Logo，相比传统显著性映射方法能生成更高质量的广告布局。


<details>
  <summary>Details</summary>
Motivation: 传统广告布局技术主要依赖显著性映射来检测背景图像中的显著区域，但这种方法往往无法充分考虑图像的详细构图和语义内容，导致布局质量有限。

Method: 采用两阶段流水线：1）VLM分析图像识别物体类型和空间关系，生成基于文本的"放置计划"；2）将该计划渲染为HTML格式的最终布局代码。

Result: 通过定量和定性实验验证，该方法相比现有方法能生成明显更高质量的广告布局，证明考虑背景图像内容的重要性。

Conclusion: 利用VLM理解图像语义内容的方法能有效提升广告布局生成质量，为图像广告设计提供了更智能的解决方案。

Abstract: In this paper, we propose a method for generating layouts for image-based advertisements by leveraging a Vision-Language Model (VLM). Conventional advertisement layout techniques have predominantly relied on saliency mapping to detect salient regions within a background image, but such approaches often fail to fully account for the image's detailed composition and semantic content. To overcome this limitation, our method harnesses a VLM to recognize the products and other elements depicted in the background and to inform the placement of text and logos. The proposed layout-generation pipeline consists of two steps. In the first step, the VLM analyzes the image to identify object types and their spatial relationships, then produces a text-based "placement plan" based on this analysis. In the second step, that plan is rendered into the final layout by generating HTML-format code. We validated the effectiveness of our approach through evaluation experiments, conducting both quantitative and qualitative comparisons against existing methods. The results demonstrate that by explicitly considering the background image's content, our method produces noticeably higher-quality advertisement layouts.

</details>


### [85] [Geometry-Aware Scene-Consistent Image Generation](https://arxiv.org/abs/2512.12598)
*Cong Xie,Che Wang,Yan Zhang,Zheng Pan,Han Zou,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: 提出一种几何感知的场景一致性图像生成方法，通过场景一致性数据构建和几何引导注意力损失，在保持参考场景物理环境的同时，根据文本条件生成符合空间关系的新实体。


<details>
  <summary>Details</summary>
Motivation: 现有方法在场景一致性图像生成中存在平衡问题：要么高度保真地复制场景但对文本提示响应差，要么优先满足提示但牺牲场景一致性。需要解决这种权衡，实现既保持场景物理环境又正确生成符合空间关系实体的图像生成。

Method: 1) 场景一致性数据构建管道，生成多样化的几何基础训练对；2) 新颖的几何引导注意力损失，利用跨视图线索来正则化模型的空间推理能力。

Result: 在场景一致性基准测试中，该方法在场景对齐和文本-图像一致性方面优于现有最先进基线，自动指标和人类偏好研究均显示更好效果。能生成几何连贯、构图多样且忠实于文本指令和底层场景结构的图像。

Conclusion: 该方法成功解决了场景一致性图像生成中的平衡问题，通过几何感知方法实现了更好的场景保持和提示响应，为几何感知的场景一致图像生成提供了有效解决方案。

Abstract: We study geometry-aware scene-consistent image generation: given a reference scene image and a text condition specifying an entity to be generated in the scene and its spatial relation to the scene, the goal is to synthesize an output image that preserves the same physical environment as the reference scene while correctly generating the entity according to the spatial relation described in the text. Existing methods struggle to balance scene preservation with prompt adherence: they either replicate the scene with high fidelity but poor responsiveness to the prompt, or prioritize prompt compliance at the expense of scene consistency. To resolve this trade-off, we introduce two key contributions: (i) a scene-consistent data construction pipeline that generates diverse, geometrically-grounded training pairs, and (ii) a novel geometry-guided attention loss that leverages cross-view cues to regularize the model's spatial reasoning. Experiments on our scene-consistent benchmark show that our approach achieves better scene alignment and text-image consistency than state-of-the-art baselines, according to both automatic metrics and human preference studies. Our method produces geometrically coherent images with diverse compositions that remain faithful to the textual instructions and the underlying scene structure.

</details>


### [86] [No Cache Left Idle: Accelerating diffusion model via Extreme-slimming Caching](https://arxiv.org/abs/2512.12604)
*Tingyan Wen,Haoyu Li,Yihuang Chen,Xing Zhou,Lifei Zhu,Xueqian Wang*

Main category: cs.CV

TL;DR: X-Slim是一种无需训练的缓存加速框架，通过三层次（时间步、结构块、空间标记）冗余利用和双阈值控制器，在保持生成质量的同时显著加速扩散模型推理。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成质量优异，但计算开销随步数、模型深度和序列长度线性增长。现有缓存方法存在权衡：激进的时间步重用加速明显但容易损害保真度，而块级或标记级重用安全但加速有限。需要一种统一的框架来同时利用不同层次的冗余。

Method: 提出X-Slim框架：1）统一利用时间步、结构块和空间标记三个层次的缓存冗余；2）引入双阈值控制器，将缓存过程分为"推送-抛光"两阶段：先推送时间步重用至预警线，再切换到轻量级块级和标记级刷新来抛光剩余冗余，最后在临界线处触发完整推理重置累积误差；3）使用上下文感知指标决定何时何地缓存。

Result: 在多种任务上显著推进了速度-质量前沿：在FLUX.1-dev上延迟降低4.97倍，在HunyuanVideo上降低3.52倍，感知损失最小；在DiT-XL/2上达到3.13倍加速，且FID比先前方法改善2.42。

Conclusion: X-Slim是首个统一利用时间步、结构和空间冗余的缓存加速框架，通过创新的双阈值控制器实现了训练免费的高效加速，在保持生成质量的同时大幅降低扩散模型推理延迟。

Abstract: Diffusion models achieve remarkable generative quality, but computational overhead scales with step count, model depth, and sequence length. Feature caching is effective since adjacent timesteps yield highly similar features. However, an inherent trade-off remains: aggressive timestep reuse offers large speedups but can easily cross the critical line, hurting fidelity, while block- or token-level reuse is safer but yields limited computational savings. We present X-Slim (eXtreme-Slimming Caching), a training-free, cache-based accelerator that, to our knowledge, is the first unified framework to exploit cacheable redundancy across timesteps, structure (blocks), and space (tokens). Rather than simply mixing levels, X-Slim introduces a dual-threshold controller that turns caching into a push-then-polish process: it first pushes reuse at the timestep level up to an early-warning line, then switches to lightweight block- and token-level refresh to polish the remaining redundancy, and triggers full inference once the critical line is crossed to reset accumulated error. At each level, context-aware indicators decide when and where to cache. Across diverse tasks, X-Slim advances the speed-quality frontier. On FLUX.1-dev and HunyuanVideo, it reduces latency by up to 4.97x and 3.52x with minimal perceptual loss. On DiT-XL/2, it reaches 3.13x acceleration and improves FID by 2.42 over prior methods.

</details>


### [87] [Patch-wise Retrieval: A Bag of Practical Techniques for Instance-level Matching](https://arxiv.org/abs/2512.12610)
*Wonseok Choi,Sohwi Lim,Nam Hyeon-Woo,Moon Ye-Bin,Dong-Ju Jeong,Jinyoung Hwang,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: Patchify是一个无需微调的patch-wise图像检索框架，通过将数据库图像分割成结构化patch并与查询描述符进行局部特征匹配，实现了高性能、可扩展和可解释的实例级图像检索。


<details>
  <summary>Details</summary>
Motivation: 实例级图像检索面临尺寸、位置和外观变化的挑战，现有方法在准确性、可扩展性和可解释性方面存在不足，需要一种既能保持高性能又能提供空间定位信息的解决方案。

Method: 提出Patchify框架：1）将数据库图像分割成少量结构化patch；2）使用局部特征与全局查询描述符进行匹配；3）引入LocScore评估指标，量化检索区域与目标对象的对齐程度；4）应用Product Quantization进行高效大规模检索。

Result: 在多个基准测试、骨干网络和区域选择策略上的实验表明，Patchify优于全局方法，并能补充最先进的reranking流程。使用信息丰富的特征进行压缩能显著提升性能。

Conclusion: Patchify提供了一个简单有效的patch-wise检索框架，在保持高性能的同时提供了可解释性和空间定位能力。LocScore作为诊断工具有助于理解和改进检索行为，而Product Quantization的集成使系统适用于大规模应用。

Abstract: Instance-level image retrieval aims to find images containing the same object as a given query, despite variations in size, position, or appearance. To address this challenging task, we propose Patchify, a simple yet effective patch-wise retrieval framework that offers high performance, scalability, and interpretability without requiring fine-tuning. Patchify divides each database image into a small number of structured patches and performs retrieval by comparing these local features with a global query descriptor, enabling accurate and spatially grounded matching. To assess not just retrieval accuracy but also spatial correctness, we introduce LocScore, a localization-aware metric that quantifies whether the retrieved region aligns with the target object. This makes LocScore a valuable diagnostic tool for understanding and improving retrieval behavior. We conduct extensive experiments across multiple benchmarks, backbones, and region selection strategies, showing that Patchify outperforms global methods and complements state-of-the-art reranking pipelines. Furthermore, we apply Product Quantization for efficient large-scale retrieval and highlight the importance of using informative features during compression, which significantly boosts performance. Project website: https://wons20k.github.io/PatchwiseRetrieval/

</details>


### [88] [D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation](https://arxiv.org/abs/2512.12622)
*Zihan Wang,Seungjun Lee,Guangzhao Dai,Gim Hee Lee*

Main category: cs.CV

TL;DR: D3D-VLP模型通过动态3D思维链和协同学习策略，统一了规划、定位、导航和问答，在多个3D视觉语言导航基准上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两难困境：端到端模型缺乏可解释性和显式3D推理能力，而模块化系统忽略了跨组件间的相互依赖和协同效应。需要一种既能保持可解释性又能实现跨组件协同的方法。

Method: 提出动态3D视觉语言规划模型(D3D-VLP)，包含两个关键创新：1) 动态3D思维链(3D CoT)，将规划、定位、导航和问答统一在单个3D-VLM和CoT流水线中；2) 碎片化监督协同学习(SLFS)策略，使用掩码自回归损失从大量部分标注的混合数据中学习，让不同CoT组件相互增强和隐式监督。

Result: 在多个基准测试中取得最先进结果：视觉语言导航(R2R-CE, REVERIE-CE, NavRAG-CE)、目标导航(HM3D-OVON)、任务导向顺序定位和导航(SG3D)。真实世界移动操作实验进一步验证了有效性。

Conclusion: D3D-VLP成功解决了端到端模型缺乏可解释性和模块化系统忽略协同的问题，通过统一的3D思维链和协同学习策略，实现了更好的性能和可解释性，为具身智能提供了有效解决方案。

Abstract: Embodied agents face a critical dilemma that end-to-end models lack interpretability and explicit 3D reasoning, while modular systems ignore cross-component interdependencies and synergies. To bridge this gap, we propose the Dynamic 3D Vision-Language-Planning Model (D3D-VLP). Our model introduces two key innovations: 1) A Dynamic 3D Chain-of-Thought (3D CoT) that unifies planning, grounding, navigation, and question answering within a single 3D-VLM and CoT pipeline; 2) A Synergistic Learning from Fragmented Supervision (SLFS) strategy, which uses a masked autoregressive loss to learn from massive and partially-annotated hybrid data. This allows different CoT components to mutually reinforce and implicitly supervise each other. To this end, we construct a large-scale dataset with 10M hybrid samples from 5K real scans and 20K synthetic scenes that are compatible with online learning methods such as RL and DAgger. Our D3D-VLP achieves state-of-the-art results on multiple benchmarks, including Vision-and-Language Navigation (R2R-CE, REVERIE-CE, NavRAG-CE), Object-goal Navigation (HM3D-OVON), and Task-oriented Sequential Grounding and Navigation (SG3D). Real-world mobile manipulation experiments further validate the effectiveness.

</details>


### [89] [Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space](https://arxiv.org/abs/2512.12623)
*Chengzhi Liu,Yuzhe Yang,Yue Fan,Qingyue Wei,Sheng Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: DMLR提出动态多模态潜在推理框架，通过置信度引导的潜在策略梯度优化和动态视觉注入策略，实现视觉与文本的动态交错推理，显著提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型虽然通过思维链机制增强了跨模态理解，但仍依赖显式的逐步推理，存在感知-推理交互不稳定和计算开销大的问题。受人类认知中推理与感知动态交错进行的启发，需要更自然高效的多模态推理方法。

Method: 提出DMLR框架：1）使用置信度引导的潜在策略梯度优化来精炼潜在思考标记以进行深度推理；2）引入动态视觉注入策略，在每个潜在思考标记处检索最相关的视觉特征并更新最佳视觉补丁集，然后将更新后的补丁注入潜在思考标记中，实现动态视觉-文本交错。

Result: 在七个多模态推理基准测试和各种模型架构上的实验表明，DMLR显著提高了推理和感知性能，同时保持了较高的推理效率。

Conclusion: DMLR通过动态多模态潜在推理框架，实现了更自然高效的视觉-文本交错推理，解决了现有方法在推理稳定性、计算效率和感知-推理交互方面的问题，为多模态推理提供了新的思路。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced cross-modal understanding and reasoning by incorporating Chain-of-Thought (CoT) reasoning in the semantic space. Building upon this, recent studies extend the CoT mechanism to the visual modality, enabling models to integrate visual information during reasoning through external tools or explicit image generation. However, these methods remain dependent on explicit step-by-step reasoning, unstable perception-reasoning interaction and notable computational overhead. Inspired by human cognition, we posit that thinking unfolds not linearly but through the dynamic interleaving of reasoning and perception within the mind. Motivated by this perspective, we propose DMLR, a test-time Dynamic Multimodal Latent Reasoning framework that employs confidence-guided latent policy gradient optimization to refine latent think tokens for in-depth reasoning. Furthermore, a Dynamic Visual Injection Strategy is introduced, which retrieves the most relevant visual features at each latent think token and updates the set of best visual patches. The updated patches are then injected into latent think token to achieve dynamic visual-textual interleaving. Experiments across seven multimodal reasoning benchmarks and various model architectures demonstrate that DMLR significantly improves reasoning and perception performance while maintaining high inference efficiency.

</details>


### [90] [DiG: Differential Grounding for Enhancing Fine-Grained Perception in Multimodal Large Language Model](https://arxiv.org/abs/2512.12633)
*Zhou Tao,Shida Wang,Yongxiang Hua,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: DiG提出了一种通过识别相似图像对之间的所有差异来训练MLLMs进行细粒度视觉感知的新代理任务框架，无需预先知道差异数量，显著提升了模型的细粒度视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉语言任务上表现优异，但在细粒度视觉感知和精确空间推理方面仍存在局限，需要一种可扩展的方法来提升模型的精细视觉理解能力。

Method: 提出了DiG（差分接地）代理任务框架，通过自动化的3D渲染数据生成管道创建可控差异的图像对，采用课程学习从单差异逐步增加到多差异，让模型学习识别和定位所有差异而不依赖先验知识。

Result: DiG显著提升了模型在各种视觉感知基准测试上的性能，学习到的细粒度感知技能能有效迁移到标准下游任务，包括RefCOCO、RefCOCO+、RefCOCOg等基准测试。

Conclusion: 差分接地是一种可扩展且稳健的方法，能够有效提升多模态大语言模型的细粒度视觉推理能力，为视觉感知研究提供了新的训练范式。

Abstract: Multimodal Large Language Models have achieved impressive performance on a variety of vision-language tasks, yet their fine-grained visual perception and precise spatial reasoning remain limited. In this work, we introduce DiG (Differential Grounding), a novel proxy task framework where MLLMs learn fine-grained perception by identifying and localizing all differences between similar image pairs without prior knowledge of their number. To support scalable training, we develop an automated 3D rendering-based data generation pipeline that produces high-quality paired images with fully controllable discrepancies. To address the sparsity of difference signals, we further employ curriculum learning that progressively increases complexity from single to multiple differences, enabling stable optimization. Extensive experiments demonstrate that DiG significantly improves model performance across a variety of visual perception benchmarks and that the learned fine-grained perception skills transfer effectively to standard downstream tasks, including RefCOCO, RefCOCO+, RefCOCOg, and general multimodal perception benchmarks. Our results highlight differential grounding as a scalable and robust approach for advancing fine-grained visual reasoning in MLLMs.

</details>


### [91] [Cross-modal Fundus Image Registration under Large FoV Disparity](https://arxiv.org/abs/2512.12657)
*Hongyang Li,Junyi Tao,Qijie Wei,Ningzhi Yang,Meng Wang,Weihong Yu,Xirong Li*

Main category: cs.CV

TL;DR: CARe方法通过裁剪和对齐操作解决大视场差异的跨模态眼底图像配准问题，在60对OCTA-wfCFP图像对上验证有效


<details>
  <summary>Details</summary>
Motivation: 现有跨模态眼底图像配准方法假设小视场差异，无法处理大视场差异的挑战性场景

Method: 提出CARe方法：1) 裁剪操作利用视网膜生理结构从目标图像裁剪子图像，使其视场与源图像大致对齐；2) 对齐模块采用双拟合策略，结合RANSAC算法和多项式坐标拟合改进空间变换

Result: 在新开发的60对OCTA-wfCFP测试集上验证了CARe方法的可行性

Conclusion: CARe是一种简单有效的跨模态眼底图像配准方法，能够处理大视场差异的挑战性场景

Abstract: Previous work on cross-modal fundus image registration (CMFIR) assumes small cross-modal Field-of-View (FoV) disparity. By contrast, this paper is targeted at a more challenging scenario with large FoV disparity, to which directly applying current methods fails. We propose Crop and Alignment for cross-modal fundus image Registration(CARe), a very simple yet effective method. Specifically, given an OCTA with smaller FoV as a source image and a wide-field color fundus photograph (wfCFP) as a target image, our Crop operation exploits the physiological structure of the retina to crop from the target image a sub-image with its FoV roughly aligned with that of the source. This operation allows us to re-purpose the previous small-FoV-disparity oriented methods for subsequent image registration. Moreover, we improve spatial transformation by a double-fitting based Alignment module that utilizes the classical RANSAC algorithm and polynomial-based coordinate fitting in a sequential manner. Extensive experiments on a newly developed test set of 60 OCTA-wfCFP pairs verify the viability of CARe for CMFIR.

</details>


### [92] [CogDoc: Towards Unified thinking in Documents](https://arxiv.org/abs/2512.12658)
*Qixin Xu,Haozhe Wang,Che Liu,Fangzhen Lin,Wenhu Chen*

Main category: cs.CV

TL;DR: CogDoc提出了一种模仿人类认知过程的粗到细思维框架，通过"快速阅读"和"专注思考"两阶段解决文档推理中的可扩展性与保真度权衡问题，采用直接强化学习策略，7B模型在视觉丰富文档基准上超越了GPT-4o等更大模型。


<details>
  <summary>Details</summary>
Motivation: 当前文档推理范式面临可扩展性（处理长上下文文档）与保真度（捕捉细粒度多模态细节）之间的基本权衡，需要一种能够同时兼顾两者的解决方案。

Method: 提出CogDoc统一粗到细思维框架，模仿人类认知过程：1）低分辨率"快速阅读"阶段用于可扩展信息定位；2）高分辨率"专注思考"阶段用于深度推理。采用直接强化学习策略而非SFT初始化的RL，避免"策略冲突"。

Result: 7B参数模型在其参数类别中达到最先进性能，在具有挑战性的视觉丰富文档基准上显著超越了GPT-4o等更大的专有模型。直接RL方法优于SFT初始化的RL。

Conclusion: CogDoc框架通过模仿人类认知的粗到细思维过程，有效解决了文档推理中的可扩展性与保真度权衡问题，直接强化学习策略避免了策略冲突，使较小模型能够超越更大模型在复杂文档任务上的表现。

Abstract: Current document reasoning paradigms are constrained by a fundamental trade-off between scalability (processing long-context documents) and fidelity (capturing fine-grained, multimodal details). To bridge this gap, we propose CogDoc, a unified coarse-to-fine thinking framework that mimics human cognitive processes: a low-resolution "Fast Reading" phase for scalable information localization,followed by a high-resolution "Focused Thinking" phase for deep reasoning. We conduct a rigorous investigation into post-training strategies for the unified thinking framework, demonstrating that a Direct Reinforcement Learning (RL) approach outperforms RL with Supervised Fine-Tuning (SFT) initialization. Specifically, we find that direct RL avoids the "policy conflict" observed in SFT. Empirically, our 7B model achieves state-of-the-art performance within its parameter class, notably surpassing significantly larger proprietary models (e.g., GPT-4o) on challenging, visually rich document benchmarks.

</details>


### [93] [Anatomy-Guided Representation Learning Using a Transformer-Based Network for Thyroid Nodule Segmentation in Ultrasound Images](https://arxiv.org/abs/2512.12662)
*Muhammad Umar Farooq,Abd Ur Rehman,Azka Rehman,Muhammad Usman,Dong-Kyu Chae,Junaid Qadir*

Main category: cs.CV

TL;DR: SSMT-Net：一种半监督多任务Transformer网络，用于甲状腺结节超声图像分割，通过利用未标记数据和联合优化结节分割、腺体分割及结节大小估计来提升性能。


<details>
  <summary>Details</summary>
Motivation: 甲状腺结节超声图像分割面临边界模糊、尺寸变化大、标注数据稀缺等挑战，现有深度学习模型难以有效整合甲状腺腺体上下文信息，且泛化能力有限。

Method: 提出SSMT-Net，包含两个阶段：1）无监督阶段利用未标记数据增强Transformer编码器的特征提取能力；2）有监督阶段联合优化结节分割、腺体分割和结节大小估计三个任务，整合局部和全局上下文特征。

Result: 在TN3K和DDTI数据集上的广泛评估表明，SSMT-Net在准确性和鲁棒性方面优于现有最先进方法。

Conclusion: SSMT-Net通过半监督学习和多任务学习有效解决了甲状腺结节分割的挑战，展现出在实际临床应用中的潜力。

Abstract: Accurate thyroid nodule segmentation in ultrasound images is critical for diagnosis and treatment planning. However, ambiguous boundaries between nodules and surrounding tissues, size variations, and the scarcity of annotated ultrasound data pose significant challenges for automated segmentation. Existing deep learning models struggle to incorporate contextual information from the thyroid gland and generalize effectively across diverse cases. To address these challenges, we propose SSMT-Net, a Semi-Supervised Multi-Task Transformer-based Network that leverages unlabeled data to enhance Transformer-centric encoder feature extraction capability in an initial unsupervised phase. In the supervised phase, the model jointly optimizes nodule segmentation, gland segmentation, and nodule size estimation, integrating both local and global contextual features. Extensive evaluations on the TN3K and DDTI datasets demonstrate that SSMT-Net outperforms state-of-the-art methods, with higher accuracy and robustness, indicating its potential for real-world clinical applications.

</details>


### [94] [InteracTalker: Prompt-Based Human-Object Interaction with Co-Speech Gesture Generation](https://arxiv.org/abs/2512.12664)
*Sreehari Rajan,Kunal Bhosikar,Charu Sharma*

Main category: cs.CV

TL;DR: InteracTalker：一个统一语音手势生成与物体交互的框架，通过多阶段训练学习统一嵌入空间，采用自适应融合策略处理异质条件信号，在两项任务上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法分别处理语音驱动手势和物体交互，缺乏集成数据集，限制了真实世界应用。需要能够同时响应语音和物理对象的自然人体运动生成方法。

Method: 1) 构建丰富的人-物交互数据集；2) 多阶段训练学习统一的运动、语音和提示嵌入空间；3) 使用广义运动适应模块进行独立训练；4) 提出自适应融合策略动态重加权异质条件信号。

Result: 在语音手势生成和物体交互合成任务上均优于现有方法，特别是优于专注于手势的扩散方法，生成具有增强真实感、灵活性和控制性的物体感知全身运动。

Conclusion: InteracTalker成功统一了先前分离的任务，通过集成框架实现了高度真实、物体感知的全身运动生成，解决了异质条件信号不平衡问题。

Abstract: Generating realistic human motions that naturally respond to both spoken language and physical objects is crucial for interactive digital experiences. Current methods, however, address speech-driven gestures or object interactions independently, limiting real-world applicability due to a lack of integrated, comprehensive datasets. To overcome this, we introduce InteracTalker, a novel framework that seamlessly integrates prompt-based object-aware interactions with co-speech gesture generation. We achieve this by employing a multi-stage training process to learn a unified motion, speech, and prompt embedding space. To support this, we curate a rich human-object interaction dataset, formed by augmenting an existing text-to-motion dataset with detailed object interaction annotations. Our framework utilizes a Generalized Motion Adaptation Module that enables independent training, adapting to the corresponding motion condition, which is then dynamically combined during inference. To address the imbalance between heterogeneous conditioning signals, we propose an adaptive fusion strategy, which dynamically reweights the conditioning signals during diffusion sampling. InteracTalker successfully unifies these previously separate tasks, outperforming prior methods in both co-speech gesture generation and object-interaction synthesis, outperforming gesture-focused diffusion methods, yielding highly realistic, object-aware full-body motions with enhanced realism, flexibility, and control.

</details>


### [95] [Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning](https://arxiv.org/abs/2512.12667)
*Haiyang Zheng,Nan Pu,Wenjing Li,Teng Long,Nicu Sebe,Zhun Zhong*

Main category: cs.CV

TL;DR: 提出CAL框架解决开放世界深度伪造溯源问题，通过置信度感知非对称学习和动态原型剪枝，无需已知未知伪造类型数量先验假设，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放世界深度伪造溯源方法存在两个关键局限：1) 置信度偏斜导致对新型伪造的伪标签不可靠，造成训练偏差；2) 不现实地假设未知伪造类型数量已知。需要更鲁棒的方法来处理现实世界中的混合已知和未知伪造类型。

Method: 提出置信度感知非对称学习框架，包含两个核心组件：置信度感知一致性正则化（CCR）和非对称置信度增强（ACR）。CCR通过基于归一化置信度动态缩放样本损失，逐步将训练重点从高置信度样本转移到低置信度样本。ACR通过选择性学习高置信度样本，分别校准已知和新型类别的置信度。此外，引入动态原型剪枝策略，以粗到细的方式自动估计新型伪造类型数量。

Result: 在标准开放世界深度伪造溯源基准和新扩展的包含高级操作的基准上，CAL始终优于先前方法，在已知和新型伪造溯源上都达到了新的最先进性能。

Conclusion: CAL框架有效解决了开放世界深度伪造溯源中的置信度偏斜和先验假设问题，通过置信度感知学习和动态类型估计，显著提升了模型在现实场景中的可扩展性和性能。

Abstract: The proliferation of synthetic facial imagery has intensified the need for robust Open-World DeepFake Attribution (OW-DFA), which aims to attribute both known and unknown forgeries using labeled data for known types and unlabeled data containing a mixture of known and novel types. However, existing OW-DFA methods face two critical limitations: 1) A confidence skew that leads to unreliable pseudo-labels for novel forgeries, resulting in biased training. 2) An unrealistic assumption that the number of unknown forgery types is known *a priori*. To address these challenges, we propose a Confidence-Aware Asymmetric Learning (CAL) framework, which adaptively balances model confidence across known and novel forgery types. CAL mainly consists of two components: Confidence-Aware Consistency Regularization (CCR) and Asymmetric Confidence Reinforcement (ACR). CCR mitigates pseudo-label bias by dynamically scaling sample losses based on normalized confidence, gradually shifting the training focus from high- to low-confidence samples. ACR complements this by separately calibrating confidence for known and novel classes through selective learning on high-confidence samples, guided by their confidence gap. Together, CCR and ACR form a mutually reinforcing loop that significantly improves the model's OW-DFA performance. Moreover, we introduce a Dynamic Prototype Pruning (DPP) strategy that automatically estimates the number of novel forgery types in a coarse-to-fine manner, removing the need for unrealistic prior assumptions and enhancing the scalability of our methods to real-world OW-DFA scenarios. Extensive experiments on the standard OW-DFA benchmark and a newly extended benchmark incorporating advanced manipulations demonstrate that CAL consistently outperforms previous methods, achieving new state-of-the-art performance on both known and novel forgery attribution.

</details>


### [96] [Progressive Conditioned Scale-Shift Recalibration of Self-Attention for Online Test-time Adaptation](https://arxiv.org/abs/2512.12673)
*Yushun Tang,Ziqiong Liu,Jiyuan Jia,Yi Zhang,Zhihai He*

Main category: cs.CV

TL;DR: 提出PCSR方法，通过渐进式条件缩放-平移重校准来在线适应Transformer模型到新领域，显著提升测试时域适应性能


<details>
  <summary>Details</summary>
Motivation: 发现Transformer模型在应用到新目标域时，其自注意力模块的Query、Key和Value特征会发生显著变化，导致性能大幅下降，需要解决这一重要问题

Method: 提出渐进式条件缩放-平移重校准(PCSR)方法：1) 将在线模型适应视为渐进域偏移分离过程；2) 在每个Transformer层学习域分离网络提取域偏移特征；3) 使用因子生成网络预测缩放和平移参数；4) 这些轻量级网络在推理时在线适应

Result: 在基准数据集上，PCSR方法显著提升了在线测试时域适应性能，在ImageNet-C数据集上分类准确率最高提升3.9%

Conclusion: 通过渐进式条件缩放-平移重校准Transformer自注意力模块，能够有效应对域偏移问题，显著提升在线测试时适应性能

Abstract: Online test-time adaptation aims to dynamically adjust a network model in real-time based on sequential input samples during the inference stage. In this work, we find that, when applying a transformer network model to a new target domain, the Query, Key, and Value features of its self-attention module often change significantly from those in the source domain, leading to substantial performance degradation of the transformer model. To address this important issue, we propose to develop a new approach to progressively recalibrate the self-attention at each layer using a local linear transform parameterized by conditioned scale and shift factors. We consider the online model adaptation from the source domain to the target domain as a progressive domain shift separation process. At each transformer network layer, we learn a Domain Separation Network to extract the domain shift feature, which is used to predict the scale and shift parameters for self-attention recalibration using a Factor Generator Network. These two lightweight networks are adapted online during inference. Experimental results on benchmark datasets demonstrate that the proposed progressive conditioned scale-shift recalibration (PCSR) method is able to significantly improve the online test-time domain adaptation performance by a large margin of up to 3.9\% in classification accuracy on the ImageNet-C dataset.

</details>


### [97] [Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling](https://arxiv.org/abs/2512.12675)
*Yuran Wang,Bohan Zeng,Chengzhuo Tong,Wenxuan Liu,Yang Shi,Xiaochen Ma,Hao Liang,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: Scone是一个统一的理解-生成方法，整合了多主体组合和区分能力，通过两阶段训练方案和语义对齐提升生成质量，并提出了SconeEval评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有主体驱动图像生成方法从单主体发展到多主体组合，但忽视了区分能力——当输入包含多个候选主体时识别并生成正确主体的能力。这一限制影响了在复杂真实视觉场景中的有效性。

Method: 提出Scone统一理解-生成方法，让理解专家作为语义桥梁，传递语义信息并指导生成专家在最小化干扰的同时保持主体身份。采用两阶段训练方案：先学习组合，然后通过语义对齐和基于注意力的掩码增强区分能力。

Result: 实验表明，Scone在两个基准测试中的组合和区分任务上优于现有开源模型。同时提出了SconeEval评估基准，用于评估不同场景下的组合和区分能力。

Conclusion: Scone通过整合组合和区分能力，提升了主体驱动图像生成在复杂真实场景中的有效性，为多主体图像生成提供了更全面的解决方案。

Abstract: Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone.

</details>


### [98] [$β$-CLIP: Text-Conditioned Contrastive Learning for Multi-Granular Vision-Language Alignment](https://arxiv.org/abs/2512.12678)
*Fatimah Zohra,Chen Zhao,Hani Itani,Bernard Ghanem*

Main category: cs.CV

TL;DR: β-CLIP通过多粒度文本条件对比学习框架，实现从完整描述到句子、短语的层次化视觉-语言对齐，显著提升细粒度任务性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在全局视觉-文本对齐方面表现良好，但在细粒度任务上表现不佳，即使使用详细描述进行微调。需要一种能够实现多层次语义对齐的方法。

Method: 提出β-CLIP框架：1) 多粒度文本条件对比学习，从完整描述到句子、短语的层次化对齐；2) 使用交叉注意力动态池化图像块生成上下文视觉嵌入；3) 引入β-上下文对比对齐损失(β-CAL)，参数化严格查询匹配与宽松图像内上下文之间的权衡。

Result: 在Urban1K上达到T2I 91.8%和I2T 92.3%的R@1，在FG-OVD(Hard)上达到30.9%，在没有使用困难负样本的方法中达到最先进水平。

Conclusion: β-CLIP建立了密集视觉-语言对应的鲁棒自适应基线，显著改善了细粒度对齐能力，为多粒度语义对齐提供了有效框架。

Abstract: CLIP achieves strong zero-shot image-text retrieval by aligning global vision and text representations, yet it falls behind on fine-grained tasks even when fine-tuned on long, detailed captions. In this work, we propose $β$-CLIP, a multi-granular text-conditioned contrastive learning framework designed to achieve hierarchical alignment between multiple textual granularities-from full captions to sentences and phrases-and their corresponding visual regions. For each level of granularity, $β$-CLIP utilizes cross-attention to dynamically pool image patches, producing contextualized visual embeddings. To address the semantic overlap inherent in this hierarchy, we introduce the $β$-Contextualized Contrastive Alignment Loss ($β$-CAL). This objective parameterizes the trade-off between strict query-specific matching and relaxed intra-image contextualization, supporting both soft Cross-Entropy and hard Binary Cross-Entropy formulations. Through extensive experiments, we demonstrate that $β$-CLIP significantly improves dense alignment: achieving 91.8% T2I 92.3% I2T at R@1 on Urban1K and 30.9% on FG-OVD (Hard), setting state-of-the-art among methods trained without hard negatives. $β$-CLIP establishes a robust, adaptive baseline for dense vision-language correspondence. The code and models are released at https://github.com/fzohra/B-CLIP.

</details>


### [99] [Efficient Vision-Language Reasoning via Adaptive Token Pruning](https://arxiv.org/abs/2512.12701)
*Xue Li,Xiaonan Song,Henry Hu*

Main category: cs.CV

TL;DR: ATP通过动态剪枝视觉语言模型中的非关键token，在保持精度的同时显著提升推理效率


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型计算成本高，对所有token进行统一处理效率低下，需要一种自适应机制来减少冗余计算

Method: 提出自适应token剪枝(ATP)，结合ViT CLS注意力（模态内显著性）和CLIP文本-图像相似度（模态间相关性）计算混合重要性分数，保留top-K token给LLM处理

Result: 在VQAv2、GQA和COCO等基准测试中，ATP减少约40%的推理FLOPs，实现约1.5倍的端到端延迟加速，精度损失小于1%

Conclusion: ATP证明资源受限的推理和模型可靠性不是相互竞争的目标，自适应剪枝不仅能提升效率，还能抑制虚假相关性，提高模型鲁棒性

Abstract: Real-world deployment of Vision-Language Models (VLMs) is hindered by high computational demands, as existing architectures inefficiently process all tokens uniformly. We introduce Adaptive Token Pruning (ATP), a dynamic inference mechanism that retains only the most informative tokens based on contextual relevance. ATP operates at the vision-language interface, assigning a hybrid importance score combining ViT CLS attention (intra-modal saliency) and CLIP text-image similarity (inter-modal relevance) to keep top-K tokens for the LLM. Unlike static compression, ATP adapts to each input without modifying the backbone. Proposed as a lightweight gating module, ATP is compatible with popular backbones like BLIP-2, LLaVA, and Flamingo. Preliminary evaluations across VQAv2, GQA, and COCO indicate that ATP reduces inference FLOPs by around 40% and achieves roughly 1.5x speedups in end-to-end latency with negligible accuracy loss (less than 1%). Qualitative analyses suggest ATP preserves visual grounding and enhances interpretability. Beyond efficiency, we investigate robustness under corruptions; observations suggest adaptive pruning suppresses spurious correlations, improving stability. These findings imply that resource-constrained inference and model reliability are not competing objectives. Finally, we discuss ATP's role in efficient multimodal edge computing pipelines.

</details>


### [100] [Robust Motion Generation using Part-level Reliable Data from Videos](https://arxiv.org/abs/2512.12703)
*Boyuan Li,Sipeng Zheng,Bin Cao,Ruihua Song,Zongqing Lu*

Main category: cs.CV

TL;DR: 提出RoPar方法，利用视频中可信的身体部位数据增强运动生成，通过部位感知掩码自回归模型处理部分可见或遮挡的人体运动数据


<details>
  <summary>Details</summary>
Motivation: 从大规模网络视频中提取人体运动可以解决角色动画数据稀缺问题，但许多视频帧中人体部分不可见（离屏或遮挡）。丢弃这些数据会限制规模和多样性，而保留则会损害数据质量和模型性能

Method: 1) 将人体分解为五个部位，检测视频帧中清晰可见的"可信"部位；2) 通过部位感知变分自编码器将可信部位编码为潜在标记；3) 提出鲁棒的部位级掩码生成模型预测被掩码的可信部位，同时忽略噪声部位

Result: 在干净和噪声数据集上均优于基线方法，在运动质量、语义一致性和多样性方面表现更好。同时贡献了包含约20万真实世界运动序列的新基准K700-M

Conclusion: 提出的RoPar方法通过利用视频中可信的身体部位数据，有效解决了部分可见人体运动数据的生成问题，在真实世界场景中表现出色

Abstract: Extracting human motion from large-scale web videos offers a scalable solution to the data scarcity issue in character animation. However, some human parts in many video frames cannot be seen due to off-screen captures or occlusions. It brings a dilemma: discarding the data missing any part limits scale and diversity, while retaining it compromises data quality and model performance.
  To address this problem, we propose leveraging credible part-level data extracted from videos to enhance motion generation via a robust part-aware masked autoregression model. First, we decompose a human body into five parts and detect the parts clearly seen in a video frame as "credible". Second, the credible parts are encoded into latent tokens by our proposed part-aware variational autoencoder. Third, we propose a robust part-level masked generation model to predict masked credible parts, while ignoring those noisy parts.
  In addition, we contribute K700-M, a challenging new benchmark comprising approximately 200k real-world motion sequences, for evaluation. Experimental results indicate that our method successfully outperforms baselines on both clean and noisy datasets in terms of motion quality, semantic consistency and diversity. Project page: https://boyuaner.github.io/ropar-main/

</details>


### [101] [Spinal Line Detection for Posture Evaluation through Train-ing-free 3D Human Body Reconstruction with 2D Depth Images](https://arxiv.org/abs/2512.12718)
*Sehyun Kim,Hye Jun Lee,Jiwoo Lee,Changgyun Kim,Taemin Lee*

Main category: cs.CV

TL;DR: 提出一种基于四方向深度图像融合的3D人体姿态分析系统，通过全局与精细配准的分层匹配恢复3D人体模型并自动估计脊柱中心线，无需训练数据或复杂神经网络模型。


<details>
  <summary>Details</summary>
Motivation: 现有多图像人体恢复方法需要昂贵设备和复杂流程，而单图像方法因遮挡和视角限制难以准确估计脊柱中心线等内部结构，需要一种能弥补多图像方法缺点并解决单图像方法局限性的方案。

Method: 1) 集成四个方向的深度图像恢复3D人体模型；2) 采用全局与精细配准的分层匹配处理噪声和遮挡；3) 应用自适应顶点缩减保持网格分辨率和形状可靠性；4) 使用细节层次集成确保脊柱角度估计的准确性和稳定性。

Result: 实现了不依赖训练数据或复杂神经网络模型的高精度3D脊柱配准估计，验证表明匹配质量得到改善。

Conclusion: 提出的3D人体姿态分析系统能有效恢复3D人体模型并自动估计脊柱中心线，解决了现有方法的局限性，实现了高精度脊柱角度估计。

Abstract: The spinal angle is an important indicator of body balance. It is important to restore the 3D shape of the human body and estimate the spine center line. Existing mul-ti-image-based body restoration methods require expensive equipment and complex pro-cedures, and single image-based body restoration methods have limitations in that it is difficult to accurately estimate the internal structure such as the spine center line due to occlusion and viewpoint limitation. This study proposes a method to compensate for the shortcomings of the multi-image-based method and to solve the limitations of the sin-gle-image method. We propose a 3D body posture analysis system that integrates depth images from four directions to restore a 3D human model and automatically estimate the spine center line. Through hierarchical matching of global and fine registration, restora-tion to noise and occlusion is performed. Also, the Adaptive Vertex Reduction is applied to maintain the resolution and shape reliability of the mesh, and the accuracy and stabil-ity of spinal angle estimation are simultaneously secured by using the Level of Detail en-semble. The proposed method achieves high-precision 3D spine registration estimation without relying on training data or complex neural network models, and the verification confirms the improvement of matching quality.

</details>


### [102] [GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation](https://arxiv.org/abs/2512.12751)
*Zhenya Yang,Zhe Liu,Yuxiang Lu,Liping Hou,Chenxuan Miao,Siyi Peng,Bailan Feng,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: GenieDrive：基于4D占据的物理感知驾驶世界模型，通过VAE压缩占据到三平面表示，结合互控注意力机制，实现高质量、物理一致的驾驶视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用单一扩散模型直接将驾驶动作映射到视频，学习困难且输出物理不一致。需要物理感知的驾驶世界模型来支持驾驶规划、OOD数据合成和闭环评估。

Method: 1) 首先生成包含丰富物理信息的4D占据（3D结构+动态）；2) 提出VAE将高分辨率占据编码为三平面表示，减少58%潜在尺寸；3) 引入互控注意力(MCA)精确建模控制对占据演化的影响；4) 端到端联合训练VAE和预测模块；5) 在视频生成中使用归一化多视角注意力，以4D占据为指导生成多视角视频。

Result: 1) 预测mIoU提升7.2%，推理速度41 FPS，仅需3.47M参数；2) 视频质量显著提升，FVD降低20.7%；3) 实现高度可控、多视角一致、物理感知的驾驶视频生成。

Conclusion: GenieDrive通过4D占据作为物理感知基础，结合高效的压缩表示和注意力机制，成功解决了现有驾驶世界模型学习困难和物理不一致的问题，实现了高质量的物理感知驾驶视频生成。

Abstract: Physics-aware driving world model is essential for drive planning, out-of-distribution data synthesis, and closed-loop evaluation. However, existing methods often rely on a single diffusion model to directly map driving actions to videos, which makes learning difficult and leads to physically inconsistent outputs. To overcome these challenges, we propose GenieDrive, a novel framework designed for physics-aware driving video generation. Our approach starts by generating 4D occupancy, which serves as a physics-informed foundation for subsequent video generation. 4D occupancy contains rich physical information, including high-resolution 3D structures and dynamics. To facilitate effective compression of such high-resolution occupancy, we propose a VAE that encodes occupancy into a latent tri-plane representation, reducing the latent size to only 58% of that used in previous methods. We further introduce Mutual Control Attention (MCA) to accurately model the influence of control on occupancy evolution, and we jointly train the VAE and the subsequent prediction module in an end-to-end manner to maximize forecasting accuracy. Together, these designs yield a 7.2% improvement in forecasting mIoU at an inference speed of 41 FPS, while using only 3.47 M parameters. Additionally, a Normalized Multi-View Attention is introduced in the video generation model to generate multi-view driving videos with guidance from our 4D occupancy, significantly improving video quality with a 20.7% reduction in FVD. Experiments demonstrate that GenieDrive enables highly controllable, multi-view consistent, and physics-aware driving video generation.

</details>


### [103] [FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning](https://arxiv.org/abs/2512.12756)
*Yue Jiang,Dingkang Yang,Minghao Han,Jinghang Han,Zizhi Chen,Yizhou Liu,Mingcheng Li,Peng Zhai,Lihua Zhang*

Main category: cs.CV

TL;DR: FysicsWorld是一个统一的全模态基准测试，支持图像、视频、音频和文本之间的双向输入输出，包含16个主要任务和3268个样本，用于评估多模态大语言模型在理解、生成和推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态基准测试存在局限性：模态覆盖不完整、交互仅限于文本中心输出、模态间相互依赖和互补性弱。需要建立一个更全面的评估框架来推动全模态架构的发展。

Method: 提出FysicsWorld基准测试，包含16个主要任务和3268个精选样本，从40多个高质量来源聚合而来。采用跨模态互补性筛选（CMCS）策略，构建系统化的数据构造框架，生成用于口语交互和融合依赖跨模态推理的全模态数据。

Result: 对30多个最先进的基线模型（包括MLLMs、模态特定模型、统一理解-生成模型和全模态语言模型）进行全面评估，揭示了模型在理解、生成和推理方面的性能差异和局限性。

Conclusion: FysicsWorld为评估和推进下一代全模态架构建立了统一的基础和强大的基线，填补了当前基准测试的空白，支持全面的任意到任意模态评估。

Abstract: Despite rapid progress in multimodal large language models (MLLMs) and emerging omni-modal architectures, current benchmarks remain limited in scope and integration, suffering from incomplete modality coverage, restricted interaction to text-centric outputs, and weak interdependence and complementarity among modalities. To bridge these gaps, we introduce FysicsWorld, the first unified full-modality benchmark that supports bidirectional input-output across image, video, audio, and text, enabling comprehensive any-to-any evaluation across understanding, generation, and reasoning. FysicsWorld encompasses 16 primary tasks and 3,268 curated samples, aggregated from over 40 high-quality sources and covering a rich set of open-domain categories with diverse question types. We also propose the Cross-Modal Complementarity Screening (CMCS) strategy integrated in a systematic data construction framework that produces omni-modal data for spoken interaction and fusion-dependent cross-modal reasoning. Through a comprehensive evaluation of over 30 state-of-the-art baselines, spanning MLLMs, modality-specific models, unified understanding-generation models, and omni-modal language models, FysicsWorld exposes the performance disparities and limitations across models in understanding, generation, and reasoning. Our benchmark establishes a unified foundation and strong baselines for evaluating and advancing next-generation full-modality architectures.

</details>


### [104] [CoRe3D: Collaborative Reasoning as a Foundation for 3D Intelligence](https://arxiv.org/abs/2512.12768)
*Tianjiao Yu,Xinzhuo Li,Yifan Shen,Yuanzhe Liu,Ismini Lourentzou*

Main category: cs.CV

TL;DR: CoRe3D提出一个统一的3D理解和生成推理框架，通过语义和空间抽象联合操作，使语言推断的高层意图直接指导低级3D内容形成。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型的进展表明显式推理机制对提升模型可靠性、可解释性和跨模态对齐至关重要。虽然这类推理中心方法在语言和视觉任务中有效，但在3D领域扩展仍不足。

Method: 采用空间基础推理表示，将3D潜在空间分解为局部化区域，使模型能以组合和程序化方式推理几何。通过紧密耦合语义链式思维推理与结构化空间推理。

Result: CoRe3D生成的3D输出表现出强大的局部一致性和与语言描述的高度对齐。

Conclusion: 该框架为3D理解和生成任务提供了有效的推理机制，填补了当前3D领域推理方法的空白。

Abstract: Recent advances in large multimodal models suggest that explicit reasoning mechanisms play a critical role in improving model reliability, interpretability, and cross-modal alignment. While such reasoning-centric approaches have been proven effective in language and vision tasks, their extension to 3D remains underdeveloped. CoRe3D introduces a unified 3D understanding and generation reasoning framework that jointly operates over semantic and spatial abstractions, enabling high-level intent inferred from language to directly guide low-level 3D content formation. Central to this design is a spatially grounded reasoning representation that decomposes 3D latent space into localized regions, allowing the model to reason over geometry in a compositional and procedural manner. By tightly coupling semantic chain-of-thought inference with structured spatial reasoning, CoRe3D produces 3D outputs that exhibit strong local consistency and faithful alignment with linguistic descriptions.

</details>


### [105] [Fast 2DGS: Efficient Image Representation with Deep Gaussian Prior](https://arxiv.org/abs/2512.12774)
*Hao Wang,Ashish Bastola,Chaoyi Zhou,Wenhui Zhu,Xiwen Chen,Xuanzhao Dong,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: Fast-2DGS提出了一种轻量级框架，通过深度高斯先验和属性回归网络实现高效的高斯图像表示，在单次前向传播中即可获得高质量重建，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型能够产生高保真视觉内容，对高效、可解释和可编辑的图像表示需求日益增长。现有的2D高斯泼溅方法需要后优化，收敛速度慢（>10秒），而基于学习网络的方法又增加了计算和架构复杂性。

Method: 提出Fast-2DGS框架：1）深度高斯先验：作为条件网络捕获不同复杂度下高斯基元的空间分布；2）属性回归网络：预测密集的高斯属性。这种解耦架构在单次前向传播中实现高质量重建，仅需最小微调。

Result: 实验表明该方法在单次前向传播中即可实现高质量重建，显著降低计算成本而不影响视觉质量，使2DGS更接近工业级部署。

Conclusion: Fast-2DGS通过轻量级框架解决了现有2D高斯泼溅方法的效率问题，实现了高质量重建与低计算成本的平衡，为工业应用提供了可行方案。

Abstract: As generative models become increasingly capable of producing high-fidelity visual content, the demand for efficient, interpretable, and editable image representations has grown substantially. Recent advances in 2D Gaussian Splatting (2DGS) have emerged as a promising solution, offering explicit control, high interpretability, and real-time rendering capabilities (>1000 FPS). However, high-quality 2DGS typically requires post-optimization. Existing methods adopt random or heuristics (e.g., gradient maps), which are often insensitive to image complexity and lead to slow convergence (>10s). More recent approaches introduce learnable networks to predict initial Gaussian configurations, but at the cost of increased computational and architectural complexity. To bridge this gap, we present Fast-2DGS, a lightweight framework for efficient Gaussian image representation. Specifically, we introduce Deep Gaussian Prior, implemented as a conditional network to capture the spatial distribution of Gaussian primitives under different complexities. In addition, we propose an attribute regression network to predict dense Gaussian properties. Experiments demonstrate that this disentangled architecture achieves high-quality reconstruction in a single forward pass, followed by minimal fine-tuning. More importantly, our approach significantly reduces computational cost without compromising visual quality, bringing 2DGS closer to industry-ready deployment.

</details>


### [106] [L-STEC: Learned Video Compression with Long-term Spatio-Temporal Enhanced Context](https://arxiv.org/abs/2512.12790)
*Tiange Zhang,Zhimeng Huang,Xiandong Meng,Kai Zhang,Zhipin Deng,Siwei Ma*

Main category: cs.CV

TL;DR: L-STEC方法通过长时依赖建模和像素域空间上下文融合，显著提升神经视频压缩性能，相比DCVC-TCM节省37.01%码率（PSNR）和31.65%（MS-SSIM），超越VTM-17.0和DCVC-FM达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有神经视频压缩方法仅依赖前一帧特征预测时域上下文，存在两个关键问题：1) 短参考窗口无法捕捉长时依赖和精细纹理细节；2) 仅传播特征级信息会导致误差累积和细微纹理丢失。

Method: 提出长时空增强上下文（L-STEC）方法：1) 使用LSTM扩展参考链以捕获长时依赖；2) 从像素域引入扭曲的空间上下文，通过多感受野网络融合时空信息以更好地保留参考细节。

Result: L-STEC通过丰富上下文信息显著提升压缩性能，相比DCVC-TCM在PSNR上节省37.01%码率，在MS-SSIM上节省31.65%码率，超越VTM-17.0和DCVC-FM，达到新的SOTA性能。

Conclusion: L-STEC方法通过结合长时依赖建模和像素域空间上下文融合，有效解决了现有神经视频压缩方法的局限性，在压缩效率和细节保留方面取得了显著改进，建立了新的性能基准。

Abstract: Neural Video Compression has emerged in recent years, with condition-based frameworks outperforming traditional codecs. However, most existing methods rely solely on the previous frame's features to predict temporal context, leading to two critical issues. First, the short reference window misses long-term dependencies and fine texture details. Second, propagating only feature-level information accumulates errors over frames, causing prediction inaccuracies and loss of subtle textures. To address these, we propose the Long-term Spatio-Temporal Enhanced Context (L-STEC) method. We first extend the reference chain with LSTM to capture long-term dependencies. We then incorporate warped spatial context from the pixel domain, fusing spatio-temporal information through a multi-receptive field network to better preserve reference details. Experimental results show that L-STEC significantly improves compression by enriching contextual information, achieving 37.01% bitrate savings in PSNR and 31.65% in MS-SSIM compared to DCVC-TCM, outperforming both VTM-17.0 and DCVC-FM and establishing new state-of-the-art performance.

</details>


### [107] [DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning](https://arxiv.org/abs/2512.12799)
*Zhe Liu,Runhui Huang,Rui Yang,Siming Yan,Zining Wang,Lu Hou,Di Lin,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: DrivePI是一个空间感知的4D多模态大语言模型，作为统一的视觉-语言-动作框架，在自动驾驶中并行执行空间理解、3D感知、预测和规划任务。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在多个领域表现出强大能力，但在自动驾驶中生成细粒度3D感知和预测输出的应用仍未被充分探索。现有方法在统一处理空间理解、感知、预测和规划方面存在不足。

Method: 提出空间感知的4D MLLM框架DrivePI，集成点云、多视角图像和语言指令。开发数据引擎生成文本-占据和文本-流问答对用于4D空间理解。使用0.5B Qwen2.5作为MLLM骨干，通过端到端优化并行执行各项任务。

Result: DrivePI作为单一统一模型，在多个基准测试中匹配或超越现有VLA模型和专用VA模型：在nuScenes-QA上比OpenDriveVLA-7B高2.5%平均准确率；碰撞率比ORION降低70%；在3D占据、占据流和规划任务上均优于专用模型。

Conclusion: DrivePI证明了统一空间感知4D MLLM框架在自动驾驶中的有效性，能够同时处理多种任务并取得优异性能，为自动驾驶感知和决策提供了新的解决方案。

Abstract: Although multi-modal large language models (MLLMs) have shown strong capabilities across diverse domains, their application in generating fine-grained 3D perception and prediction outputs in autonomous driving remains underexplored. In this paper, we propose DrivePI, a novel spatial-aware 4D MLLM that serves as a unified Vision-Language-Action (VLA) framework that is also compatible with vision-action (VA) models. Our method jointly performs spatial understanding, 3D perception (i.e., 3D occupancy), prediction (i.e., occupancy flow), and planning (i.e., action outputs) in parallel through end-to-end optimization. To obtain both precise geometric information and rich visual appearance, our approach integrates point clouds, multi-view images, and language instructions within a unified MLLM architecture. We further develop a data engine to generate text-occupancy and text-flow QA pairs for 4D spatial understanding. Remarkably, with only a 0.5B Qwen2.5 model as MLLM backbone, DrivePI as a single unified model matches or exceeds both existing VLA models and specialized VA models. Specifically, compared to VLA models, DrivePI outperforms OpenDriveVLA-7B by 2.5% mean accuracy on nuScenes-QA and reduces collision rate by 70% over ORION (from 0.37% to 0.11%) on nuScenes. Against specialized VA models, DrivePI surpasses FB-OCC by 10.3 RayIoU for 3D occupancy on OpenOcc, reduces the mAVE from 0.591 to 0.509 for occupancy flow on OpenOcc, and achieves 32% lower L2 error than VAD (from 0.72m to 0.49m) for planning on nuScenes. Code will be available at https://github.com/happinesslz/DrivePI

</details>


### [108] [Learning Common and Salient Generative Factors Between Two Image Datasets](https://arxiv.org/abs/2512.12800)
*Yunlong He,Gwilherm Lesné,Ziqian Liu,Michaël Soumm,Pietro Gori*

Main category: cs.CV

TL;DR: 提出对比分析框架，从两个图像数据集中分离共享的生成因子和特定于单个数据集的显著因子，适用于GAN和扩散模型


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注条件操作和分离表示学习，但缺乏对对比分析问题的研究。对比分析旨在从两个数据集中分离共享因子和特定因子，这比使用属性作为监督信号的方法更弱（仅使用数据集信号）

Method: 提出新颖的对比分析框架，适用于GAN和扩散模型。通过定义新的、适应性强的学习策略和损失函数，确保共享因子和显著因子的有效分离，同时保持高质量生成

Result: 在多种数据集（人脸、动物图像、医学扫描）上评估，相比现有方法展现出更优的分离能力和图像合成质量

Conclusion: 该框架成功解决了对比分析问题，能够有效分离共享和特定生成因子，为图像生成和操作提供了新的研究方向

Abstract: Recent advancements in image synthesis have enabled high-quality image generation and manipulation. Most works focus on: 1) conditional manipulation, where an image is modified conditioned on a given attribute, or 2) disentangled representation learning, where each latent direction should represent a distinct semantic attribute. In this paper, we focus on a different and less studied research problem, called Contrastive Analysis (CA). Given two image datasets, we want to separate the common generative factors, shared across the two datasets, from the salient ones, specific to only one dataset. Compared to existing methods, which use attributes as supervised signals for editing (e.g., glasses, gender), the proposed method is weaker, since it only uses the dataset signal. We propose a novel framework for CA, that can be adapted to both GAN and Diffusion models, to learn both common and salient factors. By defining new and well-adapted learning strategies and losses, we ensure a relevant separation between common and salient factors, preserving a high-quality generation. We evaluate our approach on diverse datasets, covering human faces, animal images and medical scans. Our framework demonstrates superior separation ability and image quality synthesis compared to prior methods.

</details>


### [109] [Lemon: A Unified and Scalable 3D Multimodal Model for Universal Spatial Understanding](https://arxiv.org/abs/2512.12822)
*Yongyuan Liang,Xiyao Wang,Yuanchen Ju,Jianwei Yang,Furong Huang*

Main category: cs.CV

TL;DR: Lemon是一个统一的Transformer架构，通过将3D点云补丁和语言标记作为单一序列联合处理，解决了大型多模态模型在3D理解中的挑战，实现了早期空间-语言融合，并在多个3D理解任务上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型在扩展到3D理解时面临三个主要挑战：点云数据稀疏不规则、现有模型依赖碎片化架构（使用模态特定编码器）、训练管道存在不稳定性和可扩展性差的问题。

Method: 提出Lemon统一Transformer架构，将3D点云补丁和语言标记作为单一序列联合处理；开发结构化补丁化和标记化方案以保留空间上下文；采用三阶段训练课程，从对象级识别逐步发展到场景级空间推理。

Result: Lemon在全面的3D理解和推理任务上建立了新的最先进性能，包括对象识别、描述和3D场景中的空间推理，同时展示了随着模型规模和训练数据增加而具有的稳健扩展特性。

Conclusion: Lemon为推进现实世界应用中的3D空间智能提供了一个统一的基础，通过消除冗余编码器、提高参数效率和支持更有效的模型扩展，解决了现有方法的局限性。

Abstract: Scaling large multimodal models (LMMs) to 3D understanding poses unique challenges: point cloud data is sparse and irregular, existing models rely on fragmented architectures with modality-specific encoders, and training pipelines often suffer from instability and poor scalability. We introduce Lemon, a unified transformer architecture that addresses these challenges by jointly processing 3D point cloud patches and language tokens as a single sequence. Unlike prior work that relies on modality-specific encoders and cross-modal alignment modules, this design enables early spatial-linguistic fusion, eliminates redundant encoders, improves parameter efficiency, and supports more effective model scaling. To handle the complexity of 3D data, we develop a structured patchification and tokenization scheme that preserves spatial context, and a three-stage training curriculum that progressively builds capabilities from object-level recognition to scene-level spatial reasoning. Lemon establishes new state-of-the-art performance across comprehensive 3D understanding and reasoning tasks, from object recognition and captioning to spatial reasoning in 3D scenes, while demonstrating robust scaling properties as model size and training data increase. Our work provides a unified foundation for advancing 3D spatial intelligence in real-world applications.

</details>


### [110] [Adapting Multimodal Foundation Models for Few-Shot Learning: A Comprehensive Study on Contrastive Captioners](https://arxiv.org/abs/2512.12824)
*N. K. B. M. P. K. B. Narasinghe,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 本文系统研究了CoCa多模态基础模型在少样本图像分类中的适应策略，从训练免费的混合原型到LoRA参数适应，揭示了数据增强分歧现象，并提供了适应生成-对比混合模型的实用配置参考。


<details>
  <summary>Details</summary>
Motivation: 虽然大规模多模态基础模型（特别是CoCa）在零样本迁移方面表现出色，但它们在极端数据稀缺（少样本学习）的下游任务中的适应能力尚未充分探索。现有研究主要关注CLIP等双编码器架构，缺乏对CoCa独特潜在空间如何响应参数高效微调的理解。

Method: 对CoCa视觉骨干进行少样本图像分类适应的全面实证研究。系统评估从训练免费的混合原型到通过低秩适应（LoRA）进行深度参数适应的策略层次。识别"增强分歧"现象，并测试结合监督对比（SupCon）损失的混合目标。

Result: 发现强数据增强在低样本设置中会降低线性探测性能，但对稳定LoRA微调至关重要。监督对比损失在不同样本数量下相比标准交叉熵能带来一致的性能提升。确定了训练配置对数据稀缺的敏感性，提供了正则化、秩和采样策略的缩放经验参考设置。

Conclusion: 本研究填补了生成-对比混合模型在少样本适应方面的知识空白，为高效适应CoCa等基础模型提供了实证指导，特别是在数据增强策略、损失函数选择和训练配置调整方面。

Abstract: Large-scale multimodal foundation models, particularly Contrastive Captioners (CoCa), have achieved state-of-the-art results by unifying contrastive alignment with generative captioning. While zero-shot transfer capabilities are well-documented, the adaptation of these generative-contrastive hybrids to downstream tasks with extreme data scarcity (few-shot learning) remains under-explored. Existing literature predominantly focuses on dual-encoder architectures like CLIP, leaving a gap in understanding how CoCa's distinct latent space responds to parameter-efficient fine-tuning (PEFT). This paper presents a comprehensive empirical study on adapting the CoCa visual backbone for few-shot image classification. We systematically evaluate a hierarchy of strategies, ranging from training-free hybrid prototyping to deep parameter adaptation via Low-Rank Adaptation (LoRA). First, we identify an "augmentation divergence": while strong data augmentation degrades the performance of linear probing in low-shot settings, it is essential for stabilizing LoRA fine-tuning. We also demonstrate that hybrid objectives incorporating Supervised Contrastive (SupCon) loss yield consistent performance improvements over standard Cross-Entropy across varying shot counts. Crucially, we characterize the sensitivity of training configurations to data scarcity, providing empirical reference settings for scaling regularization, rank, and sampling strategies to facilitate the efficient adaptation of generative-contrastive foundation models.

</details>


### [111] [Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection](https://arxiv.org/abs/2512.12884)
*Xiangzhong Liu,Jiajie Zhang,Hao Shen*

Main category: cs.CV

TL;DR: 提出一种端到端的跨层级融合Transformer方法，将高度抽象的目标列表信息与原始相机图像融合进行3D目标检测，在nuScenes数据集上显著优于视觉基线


<details>
  <summary>Details</summary>
Motivation: 汽车传感器融合系统中，智能传感器和V2X模块通常只提供处理后的目标列表而非原始数据。传统方法分别处理原始数据后在目标级融合，存在效率问题，需要更有效的跨层级融合方法

Method: 1) 提出端到端跨层级融合Transformer，将目标列表作为去噪查询输入Transformer，与可学习查询一起传播；2) 基于目标列表位置和尺寸先验设计可变形高斯掩码，集成到Transformer解码器中引导注意力；3) 提出从真实边界框生成伪目标列表的方法，模拟状态噪声和误检漏检

Result: 在nuScenes数据集上相比视觉基线有显著性能提升，展示了方法对不同噪声水平的模拟目标列表和真实检测器的泛化能力

Conclusion: 这是首个进行跨层级融合的工作，通过将高度抽象的目标列表信息与原始图像融合，实现了更有效的3D目标检测，为汽车传感器融合系统提供了新思路

Abstract: In automotive sensor fusion systems, smart sensors and Vehicle-to-Everything (V2X) modules are commonly utilized. Sensor data from these systems are typically available only as processed object lists rather than raw sensor data from traditional sensors. Instead of processing other raw data separately and then fusing them at the object level, we propose an end-to-end cross-level fusion concept with Transformer, which integrates highly abstract object list information with raw camera images for 3D object detection. Object lists are fed into a Transformer as denoising queries and propagated together with learnable queries through the latter feature aggregation process. Additionally, a deformable Gaussian mask, derived from the positional and size dimensional priors from the object lists, is explicitly integrated into the Transformer decoder. This directs attention toward the target area of interest and accelerates model training convergence. Furthermore, as there is no public dataset containing object lists as a standalone modality, we propose an approach to generate pseudo object lists from ground-truth bounding boxes by simulating state noise and false positives and negatives. As the first work to conduct cross-level fusion, our approach shows substantial performance improvements over the vision-based baseline on the nuScenes dataset. It demonstrates its generalization capability over diverse noise levels of simulated object lists and real detectors.

</details>


### [112] [SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition](https://arxiv.org/abs/2512.12885)
*Minghao Zhu,Zhihao Zhang,Anmol Sidhu,Keith Redmill*

Main category: cs.CV

TL;DR: 提出基于检索增强生成(RAG)的零样本道路标志识别框架，使用VLM生成图像描述，检索相关候选标志，再用LLM进行细粒度识别，在303个监管标志上取得高精度。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法面临道路标志类别繁多、标注数据不足的挑战，需要开发无需任务特定训练的可扩展识别系统。

Method: 采用RAG范式：1) VLM从输入图像生成文本描述；2) 从参考设计向量数据库中检索最相关候选标志；3) LLM对检索结果进行推理，做出细粒度识别。

Result: 在俄亥俄州MUTCD的303个监管标志上验证，理想参考图像准确率达95.58%，真实道路数据准确率达82.45%。

Conclusion: RAG架构可用于创建无需任务特定训练的可扩展、准确的道路标志识别系统，证明了零样本方法的可行性。

Abstract: Automated road sign recognition is a critical task for intelligent transportation systems, but traditional deep learning methods struggle with the sheer number of sign classes and the impracticality of creating exhaustive labeled datasets. This paper introduces a novel zero-shot recognition framework that adapts the Retrieval-Augmented Generation (RAG) paradigm to address this challenge. Our method first uses a Vision Language Model (VLM) to generate a textual description of a sign from an input image. This description is used to retrieve a small set of the most relevant sign candidates from a vector database of reference designs. Subsequently, a Large Language Model (LLM) reasons over the retrieved candidates to make a final, fine-grained recognition. We validate this approach on a comprehensive set of 303 regulatory signs from the Ohio MUTCD. Experimental results demonstrate the framework's effectiveness, achieving 95.58% accuracy on ideal reference images and 82.45% on challenging real-world road data. This work demonstrates the viability of RAG-based architectures for creating scalable and accurate systems for road sign recognition without task-specific training.

</details>


### [113] [Revisiting 2D Foundation Models for Scalable 3D Medical Image Classification](https://arxiv.org/abs/2512.12887)
*Han Liu,Bogdan Georgescu,Yanbo Zhang,Youngjin Yoo,Michael Baumgartner,Riqiang Gao,Jianing Wang,Gengyan Zhao,Eli Gibson,Dorin Comaniciu,Sasa Grbic*

Main category: cs.CV

TL;DR: AnyMC3D：一个从2D基础模型扩展而来的可扩展3D医学图像分类框架，通过轻量级插件实现多任务适应，在12个任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前医学基础模型存在三个关键缺陷：数据制度偏差、次优适应和任务覆盖不足。需要解决这些问题，实现可扩展的3D医学图像分类

Method: 从2D基础模型适应到3D分类，使用单个冻结骨干网络，为每个任务添加轻量级插件（约100万参数），支持多视图输入、像素级监督和可解释热图生成

Result: 在涵盖不同病理、解剖结构和模态的12个任务基准测试中，AnyMC3D达到最先进性能（包括VLM3D挑战赛第一名），证明单个框架可替代多个任务特定模型

Conclusion: 有效适应对释放基础模型潜力至关重要，通用基础模型经过适当适应可与医学专用模型媲美，2D方法在3D分类中优于3D架构，展示了单一可扩展框架的可行性

Abstract: 3D medical image classification is essential for modern clinical workflows. Medical foundation models (FMs) have emerged as a promising approach for scaling to new tasks, yet current research suffers from three critical pitfalls: data-regime bias, suboptimal adaptation, and insufficient task coverage. In this paper, we address these pitfalls and introduce AnyMC3D, a scalable 3D classifier adapted from 2D FMs. Our method scales efficiently to new tasks by adding only lightweight plugins (about 1M parameters per task) on top of a single frozen backbone. This versatile framework also supports multi-view inputs, auxiliary pixel-level supervision, and interpretable heatmap generation. We establish a comprehensive benchmark of 12 tasks covering diverse pathologies, anatomies, and modalities, and systematically analyze state-of-the-art 3D classification techniques. Our analysis reveals key insights: (1) effective adaptation is essential to unlock FM potential, (2) general-purpose FMs can match medical-specific FMs if properly adapted, and (3) 2D-based methods surpass 3D architectures for 3D classification. For the first time, we demonstrate the feasibility of achieving state-of-the-art performance across diverse applications using a single scalable framework (including 1st place in the VLM3D challenge), eliminating the need for separate task-specific models.

</details>


### [114] [Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution](https://arxiv.org/abs/2512.12898)
*Abhinav Kumar,Tristan Aumentado-Armstrong,Lazar Valkov,Gopal Sharma,Alex Levinshtein,Radek Grzeszczuk,Suren Kumar*

Main category: cs.CV

TL;DR: 提出Queried-Convolutions (Qonvolutions)，通过卷积的邻域特性增强高频信号学习，在多种视觉与图形任务中提升性能


<details>
  <summary>Details</summary>
Motivation: 神经网络在处理高频信号时存在频谱偏差和优化困难，现有方法如傅里叶编码虽有改进但仍有提升空间

Method: Qonvolutions将低频信号与查询（如坐标）进行卷积，利用卷积的邻域特性来增强复杂高频信号的学习能力

Result: 在1D回归、2D超分辨率、2D图像回归和新视角合成等任务中均提升性能；结合高斯溅射在新视角合成中实现SOTA，甚至超越辐射场模型

Conclusion: Qonvolutions是一种简单而有效的方法，能显著改善神经网络对高频信号的学习能力，在视觉和图形学领域具有广泛应用价值

Abstract: Accurately learning high-frequency signals is a challenge in computer vision and graphics, as neural networks often struggle with these signals due to spectral bias or optimization difficulties. While current techniques like Fourier encodings have made great strides in improving performance, there remains scope for improvement when presented with high-frequency information. This paper introduces Queried-Convolutions (Qonvolutions), a simple yet powerful modification using the neighborhood properties of convolution. Qonvolution convolves a low-frequency signal with queries (such as coordinates) to enhance the learning of intricate high-frequency signals. We empirically demonstrate that Qonvolutions enhance performance across a variety of high-frequency learning tasks crucial to both the computer vision and graphics communities, including 1D regression, 2D super-resolution, 2D image regression, and novel view synthesis (NVS). In particular, by combining Gaussian splatting with Qonvolutions for NVS, we showcase state-of-the-art performance on real-world complex scenes, even outperforming powerful radiance field models on image quality.

</details>


### [115] [Predictive Sample Assignment for Semantically Coherent Out-of-Distribution Detection](https://arxiv.org/abs/2512.12906)
*Zhimao Peng,Enguang Wang,Xialei Liu,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出基于预测样本分配（PSA）的简洁SCOOD框架，通过双阈值三元样本分配策略提高ID/OOD样本集纯度，结合概念对比表示学习和重训练策略，在标准基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前SCOOD方法主要采用聚类式ID样本过滤策略从无标签数据中选择干净ID样本，并将剩余样本作为辅助OOD数据，这不可避免地引入了大量噪声样本。需要解决训练数据中的噪声问题。

Method: 1. 基于预测能量分数的双阈值三元样本分配策略：将无标签数据分为ID、OOD和丢弃样本集，提高样本集纯度；2. 概念对比表示学习损失：扩大ID和OOD样本在表示空间中的距离；3. 重训练策略：让模型充分拟合选定的辅助ID/OOD样本。

Result: 在两个标准SCOOD基准测试上的实验表明，该方法显著优于现有最先进方法。

Conclusion: 提出的PSA框架通过改进样本分配策略和表示学习，有效解决了SCOOD中训练数据噪声问题，取得了显著的性能提升。

Abstract: Semantically coherent out-of-distribution detection (SCOOD) is a recently proposed realistic OOD detection setting: given labeled in-distribution (ID) data and mixed in-distribution and out-of-distribution unlabeled data as the training data, SCOOD aims to enable the trained model to accurately identify OOD samples in the testing data. Current SCOOD methods mainly adopt various clustering-based in-distribution sample filtering (IDF) strategies to select clean ID samples from unlabeled data, and take the remaining samples as auxiliary OOD data, which inevitably introduces a large number of noisy samples in training. To address the above issue, we propose a concise SCOOD framework based on predictive sample assignment (PSA). PSA includes a dual-threshold ternary sample assignment strategy based on the predictive energy score that can significantly improve the purity of the selected ID and OOD sample sets by assigning unconfident unlabeled data to an additional discard sample set, and a concept contrastive representation learning loss to further expand the distance between ID and OOD samples in the representation space to assist ID/OOD discrimination. In addition, we also introduce a retraining strategy to help the model fully fit the selected auxiliary ID/OOD samples. Experiments on two standard SCOOD benchmarks demonstrate that our approach outperforms the state-of-the-art methods by a significant margin.

</details>


### [116] [Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery](https://arxiv.org/abs/2512.12925)
*Zhimao Peng,Enguang Wang,Fei Yang,Xialei Liu,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过损失锐度惩罚和动态锚点选择两个模块，解决广义类别发现任务中伪标签噪声问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现任务中，现有基于参数化分类的方法采用DINO-like伪标签策略，但大型预训练模型对特定视觉模式有偏好，导致对未标记数据编码虚假相关性并产生噪声伪标签。

Method: 提出包含两个模块的新方法：1) 损失锐度惩罚(LSP)：通过最小化模型最坏情况损失锐度，增强模型参数对小扰动的鲁棒性，抑制琐碎特征编码；2) 动态锚点选择(DAS)：基于KNN密度和类别概率为未知类选择代表性样本并分配硬伪标签。

Result: 大量实验表明，该方法能有效缓解伪标签噪声，在多个GCD基准测试中达到最先进的结果。

Conclusion: 提出的LSP和DAS模块能有效解决伪标签噪声问题，提高广义类别发现的聚类准确性，为开放世界学习提供有效解决方案。

Abstract: Generalized category discovery (GCD) is an important and challenging task in open-world learning. Specifically, given some labeled data of known classes, GCD aims to cluster unlabeled data that contain both known and unknown classes. Current GCD methods based on parametric classification adopt the DINO-like pseudo-labeling strategy, where the sharpened probability output of one view is used as supervision information for the other view. However, large pre-trained models have a preference for some specific visual patterns, resulting in encoding spurious correlation for unlabeled data and generating noisy pseudo-labels. To address this issue, we propose a novel method, which contains two modules: Loss Sharpness Penalty (LSP) and Dynamic Anchor Selection (DAS). LSP enhances the robustness of model parameters to small perturbations by minimizing the worst-case loss sharpness of the model, which suppressing the encoding of trivial features, thereby reducing overfitting of noise samples and improving the quality of pseudo-labels. Meanwhile, DAS selects representative samples for the unknown classes based on KNN density and class probability during the model training and assigns hard pseudo-labels to them, which not only alleviates the confidence difference between known and unknown classes but also enables the model to quickly learn more accurate feature distribution for the unknown classes, thus further improving the clustering accuracy. Extensive experiments demonstrate that the proposed method can effectively mitigate the noise of pseudo-labels, and achieve state-of-the-art results on multiple GCD benchmarks.

</details>


### [117] [MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation](https://arxiv.org/abs/2512.12929)
*Huu-An Vu,Van-Khanh Mai,Trong-Tam Nguyen,Quang-Duc Dam,Tien-Huy Nguyen,Thanh-Huong Le*

Main category: cs.CV

TL;DR: MADTempo是一个视频检索框架，通过时序搜索机制聚合视频片段相似度来捕捉事件连续性，并结合Google图像搜索回退模块增强查询表示，提升对未见或罕见视觉概念的检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统在建模跨多个事件的时序依赖和处理包含未见或罕见视觉概念的查询方面存在不足，需要更强大的时序推理和泛化能力。

Method: 1. 时序搜索机制：通过聚合连续视频片段的相似度分数来捕捉事件级连续性；2. Google图像搜索回退模块：利用外部网络图像扩展查询表示，弥补预训练视觉嵌入的不足。

Result: MADTempo框架提升了视频检索系统的时序推理和泛化能力，能够更连贯地检索多事件查询，并增强对分布外查询的鲁棒性。

Conclusion: 该框架为大规模视频语料库中实现更具语义感知和自适应性的视频检索铺平了道路，统一了时序搜索与网络规模视觉定位。

Abstract: The rapid expansion of video content across online platforms has accelerated the need for retrieval systems capable of understanding not only isolated visual moments but also the temporal structure of complex events. Existing approaches often fall short in modeling temporal dependencies across multiple events and in handling queries that reference unseen or rare visual concepts. To address these challenges, we introduce MADTempo, a video retrieval framework developed by our team, AIO_Trinh, that unifies temporal search with web-scale visual grounding. Our temporal search mechanism captures event-level continuity by aggregating similarity scores across sequential video segments, enabling coherent retrieval of multi-event queries. Complementarily, a Google Image Search-based fallback module expands query representations with external web imagery, effectively bridging gaps in pretrained visual embeddings and improving robustness against out-of-distribution (OOD) queries. Together, these components advance the temporal reasoning and generalization capabilities of modern video retrieval systems, paving the way for more semantically aware and adaptive retrieval across large-scale video corpora.

</details>


### [118] [Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion](https://arxiv.org/abs/2512.12935)
*Toan Le Ngo Thanh,Phat Ha Huu,Tan Nguyen Dang Duy,Thong Nguyen Le Minh,Anh Nguyen Nhu Tinh*

Main category: cs.CV

TL;DR: 提出统一多模态时刻检索系统，通过级联双嵌入管道、时序感知评分和智能体引导查询分解，解决现有方法的三大挑战。


<details>
  <summary>Details</summary>
Motivation: 视频内容爆炸式增长急需高效多模态时刻检索系统，但现有方法面临三大挑战：固定权重融合策略无法应对跨模态噪声和模糊查询；时序建模难以捕捉连贯事件序列；需要手动选择模态降低可用性。

Method: 1. 级联双嵌入管道：结合BEIT-3和SigLIP进行广泛检索，BLIP-2重排序平衡召回率和精度；2. 时序感知评分机制：通过束搜索对大的时序间隔应用指数衰减惩罚，构建连贯事件序列；3. 智能体引导查询分解：使用GPT-4o自动解释模糊查询，分解为视觉/OCR/ASR子查询，进行自适应分数融合。

Result: 定性分析表明，系统能有效处理模糊查询、检索时序连贯序列、动态调整融合策略，提升了交互式时刻搜索能力。

Conclusion: 提出的统一多模态时刻检索系统通过创新的融合策略、时序建模和自动模态选择，显著提升了视频时刻检索的性能和可用性。

Abstract: The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.

</details>


### [119] [Content Adaptive based Motion Alignment Framework for Learned Video Compression](https://arxiv.org/abs/2512.12936)
*Tiange Zhang,Xiandong Meng,Siwei Ma*

Main category: cs.CV

TL;DR: 提出内容自适应运动对齐框架CAMA，通过三阶段方法改进端到端视频压缩：两阶段流引导可变形扭曲、多参考质量感知策略、无训练运动幅度下采样模块，在标准数据集上实现显著BD-rate节省。


<details>
  <summary>Details</summary>
Motivation: 当前端到端视频压缩框架缺乏内容特定适应性，导致压缩性能不理想。需要针对不同内容特性调整编码策略，提升压缩效率。

Method: 1) 两阶段流引导可变形扭曲机制：通过粗到细偏移预测和掩码调制精化运动补偿；2) 多参考质量感知策略：基于参考质量调整失真权重，应用于分层训练减少误差传播；3) 无训练模块：根据运动幅度和分辨率下采样帧以获得平滑运动估计。

Result: 在标准测试数据集上，CAMA框架相比基线模型DCVC-TCM实现24.95% BD-rate（PSNR）节省，同时优于复现的DCVC-DC和传统编解码器HM-16.25。

Conclusion: 提出的内容自适应运动对齐框架通过内容特定适应性显著提升了端到端视频压缩性能，证明了自适应编码策略在视频压缩中的重要性。

Abstract: Recent advances in end-to-end video compression have shown promising results owing to their unified end-to-end learning optimization. However, such generalized frameworks often lack content-specific adaptation, leading to suboptimal compression performance. To address this, this paper proposes a content adaptive based motion alignment framework that improves performance by adapting encoding strategies to diverse content characteristics. Specifically, we first introduce a two-stage flow-guided deformable warping mechanism that refines motion compensation with coarse-to-fine offset prediction and mask modulation, enabling precise feature alignment. Second, we propose a multi-reference quality aware strategy that adjusts distortion weights based on reference quality, and applies it to hierarchical training to reduce error propagation. Third, we integrate a training-free module that downsamples frames by motion magnitude and resolution to obtain smooth motion estimation. Experimental results on standard test datasets demonstrate that our framework CAMA achieves significant improvements over state-of-the-art Neural Video Compression models, achieving a 24.95% BD-rate (PSNR) savings over our baseline model DCVC-TCM, while also outperforming reproduced DCVC-DC and traditional codec HM-16.25.

</details>


### [120] [UAGLNet: Uncertainty-Aggregated Global-Local Fusion Network with Cooperative CNN-Transformer for Building Extraction](https://arxiv.org/abs/2512.12941)
*Siyuan Yao,Dongxiu Liu,Taotao Li,Shengjie Li,Wenqi Ren,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出UAGLNet网络，通过不确定性建模指导下的全局-局部特征融合，解决遥感图像建筑物提取中的结构复杂性和特征金字塔间隙问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用卷积或自注意力块捕获多尺度特征，但特征金字塔存在固有间隙且全局-局部特征整合不足，导致建筑物提取结果不准确、模糊。

Method: 提出UAGLNet网络：1) 协作编码器使用CNN和Transformer层分别捕获局部和全局语义；2) 中间协作交互块缩小深层网络中的特征间隙；3) 全局-局部融合模块互补融合特征；4) 不确定性聚合解码器显式估计像素级不确定性以增强分割精度。

Result: 大量实验表明，该方法在遥感图像建筑物提取任务上优于其他最先进方法。

Conclusion: UAGLNet通过不确定性建模指导下的全局-局部特征融合，有效解决了建筑物提取中的结构复杂性和特征间隙问题，取得了优越性能。

Abstract: Building extraction from remote sensing images is a challenging task due to the complex structure variations of the buildings. Existing methods employ convolutional or self-attention blocks to capture the multi-scale features in the segmentation models, while the inherent gap of the feature pyramids and insufficient global-local feature integration leads to inaccurate, ambiguous extraction results. To address this issue, in this paper, we present an Uncertainty-Aggregated Global-Local Fusion Network (UAGLNet), which is capable to exploit high-quality global-local visual semantics under the guidance of uncertainty modeling. Specifically, we propose a novel cooperative encoder, which adopts hybrid CNN and transformer layers at different stages to capture the local and global visual semantics, respectively. An intermediate cooperative interaction block (CIB) is designed to narrow the gap between the local and global features when the network becomes deeper. Afterwards, we propose a Global-Local Fusion (GLF) module to complementarily fuse the global and local representations. Moreover, to mitigate the segmentation ambiguity in uncertain regions, we propose an Uncertainty-Aggregated Decoder (UAD) to explicitly estimate the pixel-wise uncertainty to enhance the segmentation accuracy. Extensive experiments demonstrate that our method achieves superior performance to other state-of-the-art methods. Our code is available at https://github.com/Dstate/UAGLNet

</details>


### [121] [SCAdapter: Content-Style Disentanglement for Diffusion Style Transfer](https://arxiv.org/abs/2512.12963)
*Luan Thanh Trinh,Kenji Doi,Atsuki Osanai*

Main category: cs.CV

TL;DR: SCAdapter是一种基于CLIP图像空间的风格迁移新方法，通过有效分离和整合内容与风格特征，解决了扩散模型在照片级真实风格迁移中的问题，实现了更真实、更快速的风格转换。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在风格迁移中存在两个主要问题：1）难以实现照片级真实的风格迁移，常常产生类似绘画的效果或丢失细节风格元素；2）现有方法无法有效处理原始内容风格和风格参考内容特征的不必要影响。

Method: SCAdapter利用CLIP图像空间有效分离和整合内容与风格特征。核心创新包括：1）系统地从内容图像提取纯内容，从风格参考提取风格元素；2）可控风格自适应实例归一化（CSAdaIN）用于精确的多风格混合；3）KVS注入用于目标风格整合；4）风格迁移一致性目标保持过程连贯性。

Result: SCAdapter在传统和基于扩散的基线方法上都显著优于现有最先进方法。通过消除DDIM反转和推理阶段优化，该方法比其他基于扩散的方法至少快2倍，在效果和效率上都更优。

Conclusion: SCAdapter通过有效分离内容和风格特征，解决了扩散模型在照片级真实风格迁移中的局限性，提供了一种更有效、更高效的实用解决方案。

Abstract: Diffusion models have emerged as the leading approach for style transfer, yet they struggle with photo-realistic transfers, often producing painting-like results or missing detailed stylistic elements. Current methods inadequately address unwanted influence from original content styles and style reference content features. We introduce SCAdapter, a novel technique leveraging CLIP image space to effectively separate and integrate content and style features. Our key innovation systematically extracts pure content from content images and style elements from style references, ensuring authentic transfers. This approach is enhanced through three components: Controllable Style Adaptive Instance Normalization (CSAdaIN) for precise multi-style blending, KVS Injection for targeted style integration, and a style transfer consistency objective maintaining process coherence. Comprehensive experiments demonstrate SCAdapter significantly outperforms state-of-the-art methods in both conventional and diffusion-based baselines. By eliminating DDIM inversion and inference-stage optimization, our method achieves at least $2\times$ faster inference than other diffusion-based approaches, making it both more effective and efficient for practical applications.

</details>


### [122] [VLCache: Computing 2% Vision Tokens and Reusing 98% for Vision-Language Inference](https://arxiv.org/abs/2512.12977)
*Shengling Qin,Hao Yu,Chenxin Wu,Zheng Li,Yizhong Cao,Zhengyang Zhuge,Yuxin Zhou,Wentao Yao,Yi Zhang,Zhengheng Wang,Shuai Bai,Jianwei Zhang,Junyang Lin*

Main category: cs.CV

TL;DR: VLCache是一个多模态缓存重用框架，通过复用KV缓存和编码器缓存来避免重复计算，在保持精度的同时实现1.2-16倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 多模态输入经常重复出现，但现有的缓存方法要么是启发式的，要么无法有效处理累积重用误差。需要一种系统性的方法来减少重复计算，同时保持模型精度。

Method: 1) 形式化分析累积重用误差效应并提出最小化方法；2) 分析模型各层的重要性差异，提出动态、层感知的重计算策略来平衡精度和效率。

Result: VLCache在保持与完全重计算相当精度的同时，仅需计算2-5%的token，实现了1.2-16倍的首次token时间(TTFT)加速，并已集成到SGLang中。

Conclusion: VLCache通过系统性的缓存重用方法，有效解决了多模态输入重复计算的问题，在精度和效率之间取得了良好平衡，为实际部署提供了显著的推理加速。

Abstract: This paper presents VLCache, a cache reuse framework that exploits both Key-Value (KV) cache and encoder cache from prior multimodal inputs to eliminate costly recomputation when the same multimodal inputs recur. Unlike previous heuristic approaches, we formally identify the cumulative reuse error effect and demonstrate how to minimize the non-prefix cache reuse error effectively. We further analyze the varying importance of model layers and propose a dynamic, layer-aware recomputation strategy to balance accuracy and efficiency. Experimental results show that VLCache achieves an accuracy on par with full recomputation, while requiring only 2-5% of the tokens to compute, yielding 1.2x-16x TTFT speedups. The proposed VLCache pipeline has been integrated into SGLang, enabling significantly faster inference in practical deployments.

</details>


### [123] [Scaling Up AI-Generated Image Detection via Generator-Aware Prototypes](https://arxiv.org/abs/2512.12982)
*Ziheng Qin,Yuheng Ji,Renshuai Tao,Yuxuan Tian,Yuyang Liu,Yipu Wang,Xiaolong Zheng*

Main category: cs.CV

TL;DR: 论文提出GAPL框架解决AIGI检测器在数据源多样性增加时出现的"先受益后冲突"困境，通过生成器感知原型学习和两阶段训练实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用AIGI检测器通过聚合多个生成器数据来提升泛化能力，但本文发现存在"先受益后冲突"的悖论现象：随着数据源多样性增加，检测器性能先提升后下降。这源于数据层面的严重异质性导致真实与合成图像特征分布重叠，以及模型层面的固定预训练编码器无法适应复杂度上升的瓶颈。

Method: 提出生成器感知原型学习(GAPL)框架：1) 学习一组紧凑的典型伪造原型，构建统一、低方差的特征空间以应对数据异质性；2) 采用两阶段训练方案结合低秩适应(LoRA)，在保持预训练知识的同时增强判别能力，建立更鲁棒的决策边界。

Result: 通过大量实验证明，GAPL在多种GAN和扩散模型生成器上实现了最先进的检测性能，展现出优越的跨生成器检测准确率。

Conclusion: GAPL框架有效解决了AIGI检测中的"先受益后冲突"困境，通过结构化学习范式和两阶段训练方案，在数据异质性和模型瓶颈双重挑战下实现了更鲁棒、更泛化的检测性能。

Abstract: The pursuit of a universal AI-generated image (AIGI) detector often relies on aggregating data from numerous generators to improve generalization. However, this paper identifies a paradoxical phenomenon we term the Benefit then Conflict dilemma, where detector performance stagnates and eventually degrades as source diversity expands. Our systematic analysis, diagnoses this failure by identifying two core issues: severe data-level heterogeneity, which causes the feature distributions of real and synthetic images to increasingly overlap, and a critical model-level bottleneck from fixed, pretrained encoders that cannot adapt to the rising complexity. To address these challenges, we propose Generator-Aware Prototype Learning (GAPL), a framework that constrain representation with a structured learning paradigm. GAPL learns a compact set of canonical forgery prototypes to create a unified, low-variance feature space, effectively countering data heterogeneity.To resolve the model bottleneck, it employs a two-stage training scheme with Low-Rank Adaptation, enhancing its discriminative power while preserving valuable pretrained knowledge. This approach establishes a more robust and generalizable decision boundary. Through extensive experiments, we demonstrate that GAPL achieves state-of-the-art performance, showing superior detection accuracy across a wide variety of GAN and diffusion-based generators. Code is available at https://github.com/UltraCapture/GAPL

</details>


### [124] [Calibrating Uncertainty for Zero-Shot Adversarial CLIP](https://arxiv.org/abs/2512.12997)
*Wenjing lu,Zerui Tao,Dongping Zhang,Yuning Qiu,Yang Yang,Qibin Zhao*

Main category: cs.CV

TL;DR: 提出一种针对CLIP的对抗性微调方法，通过狄利克雷分布重新参数化输出，同时提升对抗鲁棒性和不确定性校准，解决对抗攻击中不确定性被抑制的问题。


<details>
  <summary>Details</summary>
Motivation: CLIP在零样本分类中表现优异，但对对抗攻击高度脆弱。现有对抗微调方法主要关注干净样本和对抗样本的预测logits匹配，忽略了不确定性校准，可能损害零样本泛化能力。研究发现对抗扰动不仅降低准确性，还会抑制不确定性，导致严重的校准错误和不可靠的过度自信，这揭示了超越鲁棒性的可靠性差距。

Method: 提出一种新颖的对抗微调目标，同时考虑预测准确性和不确定性对齐。通过将CLIP输出重新参数化为狄利克雷分布的浓度参数，创建统一表示来捕获相对语义结构和预测置信度大小。该目标在扰动下整体对齐这些分布，超越单一logits锚定，恢复校准的不确定性。

Result: 在多个零样本分类基准测试中，该方法有效恢复了校准的不确定性，实现了有竞争力的对抗鲁棒性，同时保持了干净的准确性。

Conclusion: 该方法成功解决了CLIP在对抗攻击中的不确定性校准问题，填补了可靠性的关键差距，在保持零样本泛化能力的同时提升了对抗鲁棒性和不确定性校准。

Abstract: CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.

</details>


### [125] [Few-Step Distillation for Text-to-Image Generation: A Practical Guide](https://arxiv.org/abs/2512.13006)
*Yifan Pu,Yizeng Han,Zhiwei Tang,Jiasheng Tang,Fan Wang,Bohan Zhuang,Gao Huang*

Main category: cs.CV

TL;DR: 该论文系统研究了如何将扩散蒸馏技术从类别条件图像生成扩展到开放文本到图像生成，在FLUX.1-lite模型上比较了最先进的蒸馏方法，提出了实用指南并开源了实现。


<details>
  <summary>Details</summary>
Motivation: 扩散蒸馏在类别条件图像合成中已显著加速生成过程，但其在开放文本到图像生成中的适用性尚不明确。需要系统研究如何将现有蒸馏技术适配到文本到图像生成场景。

Method: 将现有蒸馏方法统一到一个框架中，在强文本到图像教师模型FLUX.1-lite上进行适配和比较。通过方法论分析，识别从离散类别标签到自由形式语言提示转换中的关键障碍。

Result: 提出了关于输入缩放、网络架构和超参数的实用指南，并开源了实现和预训练学生模型。为在实际文本到图像应用中部署快速、高保真、资源高效的扩散生成器奠定了坚实基础。

Conclusion: 该研究为文本到图像扩散蒸馏建立了系统框架，通过统一分析和实践指南，使快速高效的文本到图像生成在实际应用中成为可能。

Abstract: Diffusion distillation has dramatically accelerated class-conditional image synthesis, but its applicability to open-ended text-to-image (T2I) generation is still unclear. We present the first systematic study that adapts and compares state-of-the-art distillation techniques on a strong T2I teacher model, FLUX.1-lite. By casting existing methods into a unified framework, we identify the key obstacles that arise when moving from discrete class labels to free-form language prompts. Beyond a thorough methodological analysis, we offer practical guidelines on input scaling, network architecture, and hyperparameters, accompanied by an open-source implementation and pretrained student models. Our findings establish a solid foundation for deploying fast, high-fidelity, and resource-efficient diffusion generators in real-world T2I applications. Code is available on github.com/alibaba-damo-academy/T2I-Distill.

</details>


### [126] [Light Field Based 6DoF Tracking of Previously Unobserved Objects](https://arxiv.org/abs/2512.13007)
*Nikolai Goncharov,James L. Gray,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 提出基于光场图像的物体跟踪方法LiFT-6DoF，无需预训练模型，通过视觉基础模型提取语义几何特征并转换为视角相关的高斯泼溅表示，在复杂反射物体上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有高性能物体跟踪方法依赖预捕获物体视图构建显式参考模型，限制了只能跟踪已知物体集合，且在视觉复杂外观（如反射）下表现不佳。需要一种无需预训练模型、能处理复杂视觉行为的通用物体跟踪方法。

Method: 使用光场图像作为输入，通过视觉基础模型提取语义和几何特征，将其转换为视角相关的高斯泼溅表示。这种表示支持可微分渲染和姿态优化，构建了统一的物体表示框架。

Result: 实验表明，该方法在包含挑战性反射物体的光场物体跟踪数据集上，与最先进的基于模型的跟踪器表现相当，为机器人系统中的通用物体跟踪铺平了道路。

Conclusion: 提出的LiFT-6DoF方法通过光场图像和视角相关高斯泼溅表示，实现了无需预训练模型的鲁棒物体跟踪，特别在处理复杂视觉行为（如反射）方面表现出色，推动了通用物体跟踪在机器人系统中的应用。

Abstract: Object tracking is an important step in robotics and reautonomous driving pipelines, which has to generalize to previously unseen and complex objects. Existing high-performing methods often rely on pre-captured object views to build explicit reference models, which restricts them to a fixed set of known objects. However, such reference models can struggle with visually complex appearance, reducing the quality of tracking. In this work, we introduce an object tracking method based on light field images that does not depend on a pre-trained model, while being robust to complex visual behavior, such as reflections. We extract semantic and geometric features from light field inputs using vision foundation models and convert them into view-dependent Gaussian splats. These splats serve as a unified object representation, supporting differentiable rendering and pose optimization. We further introduce a light field object tracking dataset containing challenging reflective objects with precise ground truth poses. Experiments demonstrate that our method is competitive with state-of-the-art model-based trackers in these difficult cases, paving the way toward universal object tracking in robotic systems. Code/data available at https://github.com/nagonch/LiFT-6DoF.

</details>


### [127] [TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading](https://arxiv.org/abs/2512.13008)
*Xi Luo,Shixin Xu,Ying Xie,JianZhong Hu,Yuwei He,Yuhui Deng,Huaxiong Huang*

Main category: cs.CV

TL;DR: TWLR是一个两阶段可解释性糖尿病视网膜病变评估框架，第一阶段使用视觉语言模型进行DR分级和病灶分类，第二阶段通过弱监督语义分割实现迭代严重度回归，提供病灶定位和疾病到健康转换的可视化解释。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析需要高质量专家标注，但获取像素级标注成本高、耗时。同时深度学习在医学影像中缺乏可解释性，限制了临床采用。需要解决标注效率和可解释性双重挑战。

Method: 1. 第一阶段：视觉语言模型整合眼科领域知识到文本嵌入，联合执行DR分级和病灶分类，将语义医学概念与视觉特征关联。
2. 第二阶段：基于弱监督语义分割的迭代严重度回归框架，通过迭代精炼生成病灶显著性图，指导渐进修复机制，系统消除病理特征，将疾病严重度降级至更健康状态。

Result: 在FGADR、DDR和私有数据集上的实验表明，TWLR在DR分类和病灶分割方面都取得了有竞争力的性能，为自动化视网膜图像分析提供了更可解释和标注高效的解决方案。

Conclusion: TWLR框架通过两阶段设计，同时解决了医学图像分析中的标注效率和可解释性问题，实现了无需像素级监督的准确病灶定位，并提供疾病到健康转换的可视化解释，为临床采用提供了更实用的解决方案。

Abstract: Accurate medical image analysis can greatly assist clinical diagnosis, but its effectiveness relies on high-quality expert annotations Obtaining pixel-level labels for medical images, particularly fundus images, remains costly and time-consuming. Meanwhile, despite the success of deep learning in medical imaging, the lack of interpretability limits its clinical adoption. To address these challenges, we propose TWLR, a two-stage framework for interpretable diabetic retinopathy (DR) assessment. In the first stage, a vision-language model integrates domain-specific ophthalmological knowledge into text embeddings to jointly perform DR grading and lesion classification, effectively linking semantic medical concepts with visual features. The second stage introduces an iterative severity regression framework based on weakly-supervised semantic segmentation. Lesion saliency maps generated through iterative refinement direct a progressive inpainting mechanism that systematically eliminates pathological features, effectively downgrading disease severity toward healthier fundus appearances. Critically, this severity regression approach achieves dual benefits: accurate lesion localization without pixel-level supervision and providing an interpretable visualization of disease-to-healthy transformations. Experimental results on the FGADR, DDR, and a private dataset demonstrate that TWLR achieves competitive performance in both DR classification and lesion segmentation, offering a more explainable and annotation-efficient solution for automated retinal image analysis.

</details>


### [128] [JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion](https://arxiv.org/abs/2512.13014)
*Haoyu Wang,Lei Zhang,Wenrui Liu,Dengyang Jiang,Wei Wei,Chen Ding*

Main category: cs.CV

TL;DR: JoDiffusion：一种用于语义分割的联合扩散框架，能够仅通过文本提示同时生成配对的图像和语义一致的标注掩码，解决了现有方法的图像-标注语义不一致和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 像素级标注成本高、耗时长，现有方法要么需要在图像生成后预测伪标注（导致语义不一致），要么需要基于手动标注掩码生成图像（存在可扩展性问题）。需要一种能同时解决这两个问题的方法。

Method: 1. 在标准潜在扩散模型基础上，引入独立的标注变分自编码器（VAE）网络，将标注掩码映射到与图像共享的潜在空间；2. 定制扩散模型以捕获每个图像及其标注掩码在文本提示条件下的联合分布；3. 开发掩码优化策略以减少生成过程中的标注噪声。

Result: 在Pascal VOC、COCO和ADE20K数据集上的实验表明，JoDiffusion生成的标注数据集在语义分割任务中相比现有方法带来了显著的性能提升。

Conclusion: JoDiffusion通过联合生成图像和语义一致的标注掩码，解决了现有方法的局限性，为训练高性能语义分割模型提供了一种可扩展的合成数据生成方案。

Abstract: Given the inherently costly and time-intensive nature of pixel-level annotation, the generation of synthetic datasets comprising sufficiently diverse synthetic images paired with ground-truth pixel-level annotations has garnered increasing attention recently for training high-performance semantic segmentation models. However, existing methods necessitate to either predict pseudo annotations after image generation or generate images conditioned on manual annotation masks, which incurs image-annotation semantic inconsistency or scalability problem. To migrate both problems with one stone, we present a novel dataset generative diffusion framework for semantic segmentation, termed JoDiffusion. Firstly, given a standard latent diffusion model, JoDiffusion incorporates an independent annotation variational auto-encoder (VAE) network to map annotation masks into the latent space shared by images. Then, the diffusion model is tailored to capture the joint distribution of each image and its annotation mask conditioned on a text prompt. By doing these, JoDiffusion enables simultaneously generating paired images and semantically consistent annotation masks solely conditioned on text prompts, thereby demonstrating superior scalability. Additionally, a mask optimization strategy is developed to mitigate the annotation noise produced during generation. Experiments on Pascal VOC, COCO, and ADE20K datasets show that the annotated dataset generated by JoDiffusion yields substantial performance improvements in semantic segmentation compared to existing methods.

</details>


### [129] [GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training](https://arxiv.org/abs/2512.13043)
*Tong Wei,Yijun Yang,Changhao Zhang,Junliang Xing,Yuanchun Shi,Zongqing Lu,Deheng Ye*

Main category: cs.CV

TL;DR: GTR-Turbo：一种高效的多模态智能体强化学习方法，无需昂贵教师模型，通过合并训练检查点权重作为"免费"教师，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的多模态智能体多轮强化学习方法存在稀疏奖励和长时程信用分配问题。现有方法（如GTR）依赖昂贵且通常有特权的教师模型提供步级反馈，这限制了实用性和可复现性。

Method: GTR-Turbo在持续RL训练过程中合并检查点的权重，使用这个合并模型作为"免费"教师，通过监督微调或软对数蒸馏指导后续RL训练。这种方法消除了对特权VLM的依赖，缓解了"熵崩溃"问题，保持训练稳定性。

Result: 在各种视觉智能体任务中，GTR-Turbo将基线模型的准确率提升了10-30%，同时相比GTR减少了50%的挂钟训练时间和60%的计算成本。

Conclusion: GTR-Turbo提供了一种高效、实用的多模态智能体强化学习解决方案，无需依赖昂贵教师模型，在性能和计算效率方面均有显著提升。

Abstract: Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a "free" teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the "entropy collapse" observed in prior work, and keeps training stable. Across diverse visual agentic tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.

</details>


### [130] [What Happens Next? Next Scene Prediction with a Unified Video Model](https://arxiv.org/abs/2512.13015)
*Xinjie Li,Zhimin Chen,Rui Zhao,Florian Schiffers,Zhenyu Liao,Vimal Bhat*

Main category: cs.CV

TL;DR: 提出Next Scene Prediction (NSP)新任务，通过统一框架结合Qwen-VL和LTX模型，在三阶段训练下实现视频场景预测，推动多模态系统的时间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有统一模型主要关注文本到视频生成等传统任务，对时间推理潜力探索不足。需要推动统一视频模型向时间和因果推理方向发展

Method: 提出NSP任务，构建统一框架：Qwen-VL负责理解，LTX负责合成，通过潜在查询嵌入和连接器模块桥接。采用三阶段训练：文本到视频预训练、监督微调、带因果一致性奖励的强化学习（GRPO）

Result: 模型在新构建的大规模NSP数据集上达到最先进性能，提升了通用多模态系统预测未来事件的能力

Conclusion: NSP任务成功推动了统一视频模型的时间推理能力，为多模态系统的时间理解开辟了新方向

Abstract: Recent unified models for joint understanding and generation have significantly advanced visual generation capabilities. However, their focus on conventional tasks like text-to-video generation has left the temporal reasoning potential of unified models largely underexplored. To address this gap, we introduce Next Scene Prediction (NSP), a new task that pushes unified video models toward temporal and causal reasoning. Unlike text-to-video generation, NSP requires predicting plausible futures from preceding context, demanding deeper understanding and reasoning. To tackle this task, we propose a unified framework combining Qwen-VL for comprehension and LTX for synthesis, bridged by a latent query embedding and a connector module. This model is trained in three stages on our newly curated, large-scale NSP dataset: text-to-video pre-training, supervised fine-tuning, and reinforcement learning (via GRPO) with our proposed causal consistency reward. Experiments demonstrate our model achieves state-of-the-art performance on our benchmark, advancing the capability of generalist multimodal systems to anticipate what happens next.

</details>


### [131] [UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era](https://arxiv.org/abs/2512.13089)
*Ziqiang Zhu,Bowei Yang*

Main category: cs.CV

TL;DR: UniVCD是一种基于冻结SAM2和CLIP的无监督开放词汇变化检测方法，无需标注数据即可检测跨场景和成像几何的类别无关变化，通过轻量级特征对齐模块和多模态融合实现高性能变化检测。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法主要依赖监督学习，性能受数据集限制且标注成本高，通常只关注预定义类别，难以泛化到多样场景。随着视觉基础模型（如SAM2和CLIP）的兴起，为放松这些限制提供了新机会。

Method: 基于冻结的SAM2和CLIP构建无监督开放词汇变化检测框架，引入轻量级特征对齐模块连接SAM2的空间细节表示和CLIP的语义先验，实现高分辨率语义感知变化估计，并采用简化的后处理流程抑制噪声和伪变化。

Result: 在多个公开BCD和SCD基准测试中，UniVCD表现出稳定强大的性能，在F1和IoU等关键指标上匹配或超越了现有的开放词汇变化检测方法。

Conclusion: 基于冻结视觉基础模型和轻量级多模态对齐的无监督变化检测是开放词汇变化检测的实用有效范式，展示了基础模型在变化检测任务中的潜力。

Abstract: Change detection (CD) identifies scene changes from multi-temporal observations and is widely used in urban development and environmental monitoring. Most existing CD methods rely on supervised learning, making performance strongly dataset-dependent and incurring high annotation costs; they typically focus on a few predefined categories and generalize poorly to diverse scenes. With the rise of vision foundation models such as SAM2 and CLIP, new opportunities have emerged to relax these constraints. We propose Unified Open-Vocabulary Change Detection (UniVCD), an unsupervised, open-vocabulary change detection method built on frozen SAM2 and CLIP. UniVCD detects category-agnostic changes across diverse scenes and imaging geometries without any labeled data or paired change images. A lightweight feature alignment module is introduced to bridge the spatially detailed representations from SAM2 and the semantic priors from CLIP, enabling high-resolution, semantically aware change estimation while keeping the number of trainable parameters small. On top of this, a streamlined post-processing pipeline is further introduced to suppress noise and pseudo-changes, improving the detection accuracy for objects with well-defined boundaries. Experiments on several public BCD (Binary Change Detection) and SCD (Semantic Change Detection) benchmarks show that UniVCD achieves consistently strong performance and matches or surpasses existing open-vocabulary CD methods in key metrics such as F1 and IoU. The results demonstrate that unsupervised change detection with frozen vision foundation models and lightweight multi-modal alignment is a practical and effective paradigm for open-vocabulary CD. Code and pretrained models will be released at https://github.com/Die-Xie/UniVCD.

</details>


### [132] [Comprehensive Deployment-Oriented Assessment for Cross-Environment Generalization in Deep Learning-Based mmWave Radar Sensing](https://arxiv.org/abs/2512.13018)
*Tomoya Tanaka,Tomonori Ikeda,Ryo Yonemoto*

Main category: cs.CV

TL;DR: 本研究首次全面评估了空间泛化技术，针对室内FMCW MIMO雷达人数计数任务，系统比较了多种方法，发现sigmoid幅度加权在跨环境性能上表现最佳，数据增强有适度提升，而迁移学习对于大空间变化至关重要。


<details>
  <summary>Details</summary>
Motivation: 深度学习RF传感的实际部署需要解决空间泛化问题，本研究旨在为室内雷达人数计数任务提供首个全面的空间泛化技术评估，以指导实际系统开发。

Method: 系统研究多种空间泛化方法：幅度统计预处理（sigmoid加权和阈值归零）、频域滤波、自编码器背景抑制、数据增强策略和迁移学习。使用FMCW MIMO雷达在两个不同布局环境中进行实验评估。

Result: sigmoid幅度加权在跨环境性能上表现最佳，相比基线方法分别降低RMSE 50.1%和MAE 55.2%。数据增强提供适度改进（MAE提升8.8%）。迁移学习对于大空间变化至关重要，使用540个目标域样本可分别降低RMSE 82.1%和MAE 91.3%。

Conclusion: 通过将深度学习模型与幅度预处理和高效迁移学习相结合，为开发在空间变化下保持鲁棒精度的雷达传感系统提供了实用方向。

Abstract: This study presents the first comprehensive evaluation of spatial generalization techniques, which are essential for the practical deployment of deep learning-based radio-frequency (RF) sensing. Focusing on people counting in indoor environments using frequency-modulated continuous-wave (FMCW) multiple-input multiple-output (MIMO) radar, we systematically investigate a broad set of approaches, including amplitude-based statistical preprocessing (sigmoid weighting and threshold zeroing), frequency-domain filtering, autoencoder-based background suppression, data augmentation strategies, and transfer learning. Experimental results collected across two environments with different layouts demonstrate that sigmoid-based amplitude weighting consistently achieves superior cross-environment performance, yielding 50.1% and 55.2% reductions in root-mean-square error (RMSE) and mean absolute error (MAE), respectively, compared with baseline methods. Data augmentation provides additional though modest benefits, with improvements up to 8.8% in MAE. By contrast, transfer learning proves indispensable for large spatial shifts, achieving 82.1% and 91.3% reductions in RMSE and MAE, respectively, with 540 target-domain samples. Taken together, these findings establish a highly practical direction for developing radar sensing systems capable of maintaining robust accuracy under spatial variations by integrating deep learning models with amplitude-based preprocessing and efficient transfer learning.

</details>


### [133] [Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2512.13101)
*Wenjing Lu,Yi Hong,Yang Yang*

Main category: cs.CV

TL;DR: UnCoL：一种双教师框架，通过不确定性引导的协同学习，在医学图像分割中平衡基础模型的泛化能力和任务特定专业化


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型在医学图像分割中展现了强大的泛化能力，但在有限标注或罕见病理变异情况下，由于通用先验与任务特定需求不匹配，难以适应专业临床任务

Method: 提出UnCoL（不确定性引导的协同学习）双教师框架：一个冻结的基础模型教师传递通用知识，一个渐进适应的教师捕获任务特定表示；通过预测不确定性自适应调节伪标签学习，抑制不可靠监督并稳定模糊区域学习

Result: 在多种2D和3D分割基准测试中，UnCoL持续优于最先进的半监督方法和基础模型基线；在显著减少标注需求的情况下，达到接近全监督的性能

Conclusion: UnCoL通过双教师协同学习和不确定性引导机制，有效平衡了医学图像分割中的泛化与专业化需求，为有限标注下的临床任务提供了高效解决方案

Abstract: Vision foundation models have demonstrated strong generalization in medical image segmentation by leveraging large-scale, heterogeneous pretraining. However, they often struggle to generalize to specialized clinical tasks under limited annotations or rare pathological variations, due to a mismatch between general priors and task-specific requirements. To address this, we propose Uncertainty-informed Collaborative Learning (UnCoL), a dual-teacher framework that harmonizes generalization and specialization in semi-supervised medical image segmentation. Specifically, UnCoL distills both visual and semantic representations from a frozen foundation model to transfer general knowledge, while concurrently maintaining a progressively adapting teacher to capture fine-grained and task-specific representations. To balance guidance from both teachers, pseudo-label learning in UnCoL is adaptively regulated by predictive uncertainty, which selectively suppresses unreliable supervision and stabilizes learning in ambiguous regions. Experiments on diverse 2D and 3D segmentation benchmarks show that UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines. Moreover, our model delivers near fully supervised performance with markedly reduced annotation requirements.

</details>


### [134] [SneakPeek: Future-Guided Instructional Streaming Video Generation](https://arxiv.org/abs/2512.13019)
*Cheeun Hong,German Barquero,Fadime Sener,Markos Georgopoulos,Edgar Schönfeld,Stefan Popov,Yuming Du,Oscar Mañas,Albert Pumarola*

Main category: cs.CV

TL;DR: SneakPeek：基于扩散的自回归框架，通过预测因果适应、未来引导自强制和多提示条件化，生成连贯可控的教学视频。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在生成多步骤教学视频时难以保持时间一致性和可控性，限制了在内容创作、教育和人机交互中的应用。

Method: 提出SneakPeek框架，包含三个关键创新：1）预测因果适应，学习下一帧预测和未来关键帧预测；2）未来引导自强制与双区域KV缓存，解决推理时的曝光偏差问题；3）多提示条件化，提供对多步骤指令的细粒度控制。

Result: 实验结果表明，该方法能生成时间连贯、语义忠实且准确遵循复杂多步骤任务描述的教学视频。

Conclusion: SneakPeek通过创新的自回归框架有效解决了教学视频生成中的时间一致性和可控性问题，支持交互式流媒体视频生成。

Abstract: Instructional video generation is an emerging task that aims to synthesize coherent demonstrations of procedural activities from textual descriptions. Such capability has broad implications for content creation, education, and human-AI interaction, yet existing video diffusion models struggle to maintain temporal consistency and controllability across long sequences of multiple action steps. We introduce a pipeline for future-driven streaming instructional video generation, dubbed SneakPeek, a diffusion-based autoregressive framework designed to generate precise, stepwise instructional videos conditioned on an initial image and structured textual prompts. Our approach introduces three key innovations to enhance consistency and controllability: (1) predictive causal adaptation, where a causal model learns to perform next-frame prediction and anticipate future keyframes; (2) future-guided self-forcing with a dual-region KV caching scheme to address the exposure bias issue at inference time; (3) multi-prompt conditioning, which provides fine-grained and procedural control over multi-step instructions. Together, these components mitigate temporal drift, preserve motion consistency, and enable interactive video generation where future prompt updates dynamically influence ongoing streaming video generation. Experimental results demonstrate that our method produces temporally coherent and semantically faithful instructional videos that accurately follow complex, multi-step task descriptions.

</details>


### [135] [Motus: A Unified Latent Action World Model](https://arxiv.org/abs/2512.13030)
*Hongzhe Bi,Hengkai Tan,Shenghao Xie,Zeyuan Wang,Shuhe Huang,Haitian Liu,Ruowen Zhao,Yao Feng,Chendong Xiang,Yinze Rong,Hongyan Zhao,Hanyu Liu,Zhizhong Su,Lei Ma,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: Motus是一个统一的潜在动作世界模型，通过混合Transformer架构集成理解、视频生成和动作三个专家模块，利用光流学习潜在动作，在仿真和真实场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法将理解、世界建模和控制功能分离，导致多模态生成能力无法统一，且难以从大规模异构数据中学习。需要构建一个统一的系统来整合这些功能。

Method: 提出Motus统一潜在动作世界模型：1）采用混合Transformer架构集成三个专家模块（理解、视频生成、动作）；2）使用UniDiffuser风格调度器在不同建模模式间灵活切换；3）利用光流学习潜在动作；4）采用三阶段训练流程和六层数据金字塔进行大规模动作预训练。

Result: 在仿真场景中：比X-VLA提升15%，比Pi0.5提升45%；在真实场景中：提升11-48%。证明了统一建模所有功能和先验知识对下游机器人任务有显著益处。

Conclusion: Motus通过统一潜在动作世界模型成功整合了理解、世界建模和控制功能，利用现有预训练模型和可共享的运动信息，在仿真和真实机器人任务中都取得了显著性能提升，验证了统一建模方法的有效性。

Abstract: While a general embodied agent must function as a unified system, current methods are built on isolated models for understanding, world modeling, and control. This fragmentation prevents unifying multimodal generative capabilities and hinders learning from large-scale, heterogeneous data. In this paper, we propose Motus, a unified latent action world model that leverages existing general pretrained models and rich, sharable motion information. Motus introduces a Mixture-of-Transformer (MoT) architecture to integrate three experts (i.e., understanding, video generation, and action) and adopts a UniDiffuser-style scheduler to enable flexible switching between different modeling modes (i.e., world models, vision-language-action models, inverse dynamics models, video generation models, and video-action joint prediction models). Motus further leverages the optical flow to learn latent actions and adopts a recipe with three-phase training pipeline and six-layer data pyramid, thereby extracting pixel-level "delta action" and enabling large-scale action pretraining. Experiments show that Motus achieves superior performance against state-of-the-art methods in both simulation (a +15% improvement over X-VLA and a +45% improvement over Pi0.5) and real-world scenarios(improved by +11~48%), demonstrating unified modeling of all functionalities and priors significantly benefits downstream robotic tasks.

</details>


### [136] [Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2512.13107)
*Zhijian He,Feifei Liu,Yuwei Li,Zhanpeng Liu,Jintao Cheng,Xieyuanli Chen,Xiaoyu Tang*

Main category: cs.CV

TL;DR: DiffFusion：基于扩散模型的鲁棒多模态3D目标检测框架，通过扩散修复和自适应跨模态融合提升恶劣天气下的性能


<details>
  <summary>Details</summary>
Motivation: 当前多模态3D目标检测在恶劣天气条件下效果有限，主要面临天气引起的图像失真和不同模态数据之间的错位问题。需要一种能够适应各种天气条件并保持模态间空间一致性的鲁棒方法。

Method: 提出DiffFusion框架：1) Diffusion-IR：基于扩散模型修复受天气影响的图像；2) Point Cloud Restoration (PCR)：利用图像目标线索补偿受损的LiDAR数据；3) BAFAM：双向自适应融合对齐模块，实现动态多模态融合和双向BEV对齐以保持空间一致性。

Result: 在三个公开数据集上的实验表明，DiffFusion在恶劣天气条件下实现了最先进的鲁棒性，同时保持了良好的清洁数据性能。在真实世界DENSE数据集上的零样本结果进一步验证了其泛化能力。

Conclusion: DiffFusion通过扩散修复和自适应跨模态融合有效解决了恶劣天气下的多模态3D检测问题，在保持清洁数据性能的同时显著提升了鲁棒性，具有良好的泛化能力。

Abstract: Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.

</details>


### [137] [Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs](https://arxiv.org/abs/2512.13031)
*Tomoya Tanaka,Tomonori Ikeda,Ryo Yonemoto*

Main category: cs.CV

TL;DR: 首次全面比较了基于规则的方法、传统机器学习模型和深度学习模型在FMCW MIMO雷达室内人员检测中的性能，发现深度学习在相同环境下精度最高但易受领域偏移影响，而基于规则的方法虽然输出粒度粗但跨环境更稳健。


<details>
  <summary>Details</summary>
Motivation: 研究旨在系统比较不同方法（基于规则、传统机器学习、深度学习）在FMCW MIMO雷达室内人员检测任务中的性能差异，特别是在面对不同室内布局时的泛化能力，为实际应用中的方法选择提供依据。

Method: 在两种不同布局的室内环境中，系统评估了五种方法：1）基于规则的连通分量方法；2）三种传统机器学习模型（k近邻、随机森林、支持向量机）；3）结合卷积神经网络和长短时记忆网络的深度学习模型。比较了它们在相同环境和跨环境中的性能表现。

Result: 在训练环境中，CNN-LSTM模型精度最高，传统机器学习模型表现中等。但在新布局中，所有基于学习的方法性能显著下降，而基于规则的方法保持稳定。对于人员存在与否的二元检测，所有模型在不同布局中都保持高精度。揭示了空间泛化性能与输出粒度之间的权衡关系。

Conclusion: 高容量模型能在相同环境中提供细粒度的高精度输出，但对领域偏移敏感；基于规则的方法虽然输出粒度较粗，但具有更好的跨环境稳健性。无论模型类型如何，都存在空间泛化性能与输出粒度之间的明确权衡，实际应用中需根据具体需求选择合适方法。

Abstract: This study presents the first comprehensive comparison of rule-based methods, traditional machine learning models, and deep learning models in radio wave sensing with frequency modulated continuous wave multiple input multiple output radar. We systematically evaluated five approaches in two indoor environments with distinct layouts: a rule-based connected component method; three traditional machine learning models, namely k-nearest neighbors, random forest, and support vector machine; and a deep learning model combining a convolutional neural network and long short term memory. In the training environment, the convolutional neural network long short term memory model achieved the highest accuracy, while traditional machine learning models provided moderate performance. In a new layout, however, all learning based methods showed significant degradation, whereas the rule-based method remained stable. Notably, for binary detection of presence versus absence of people, all models consistently achieved high accuracy across layouts. These results demonstrate that high capacity models can produce fine grained outputs with high accuracy in the same environment, but they are vulnerable to domain shift. In contrast, rule-based methods cannot provide fine grained outputs but exhibit robustness against domain shift. Moreover, regardless of the model type, a clear trade off was revealed between spatial generalization performance and output granularity.

</details>


### [138] [Bi-Erasing: A Bidirectional Framework for Concept Removal in Diffusion Models](https://arxiv.org/abs/2512.13039)
*Hao Chen,Yiwei Wang,Songze Li*

Main category: cs.CV

TL;DR: 提出Bi-Erasing框架，通过双向图像引导的概念擦除，同时进行概念抑制和安全增强，平衡擦除效果与生成质量


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法通常采用单向策略（要么抑制目标概念，要么增强安全替代），难以平衡概念移除与生成质量之间的权衡

Method: 基于文本提示和对应图像的联合表示，引入两个解耦的图像分支：负分支负责抑制有害语义，正分支为安全替代提供视觉指导；通过联合优化这两个互补方向，并应用基于掩码的过滤防止无关内容干扰

Result: 在广泛的实验评估中，Bi-Erasing在平衡概念移除效果和视觉保真度方面优于基线方法

Conclusion: 提出的双向图像引导概念擦除框架能够有效平衡擦除效果和生成可用性，解决了现有单向方法的局限性

Abstract: Concept erasure, which fine-tunes diffusion models to remove undesired or harmful visual concepts, has become a mainstream approach to mitigating unsafe or illegal image generation in text-to-image models.However, existing removal methods typically adopt a unidirectional erasure strategy by either suppressing the target concept or reinforcing safe alternatives, making it difficult to achieve a balanced trade-off between concept removal and generation quality. To address this limitation, we propose a novel Bidirectional Image-Guided Concept Erasure (Bi-Erasing) framework that performs concept suppression and safety enhancement simultaneously. Specifically, based on the joint representation of text prompts and corresponding images, Bi-Erasing introduces two decoupled image branches: a negative branch responsible for suppressing harmful semantics and a positive branch providing visual guidance for safe alternatives. By jointly optimizing these complementary directions, our approach achieves a balance between erasure efficacy and generation usability. In addition, we apply mask-based filtering to the image branches to prevent interference from irrelevant content during the erasure process. Across extensive experiment evaluations, the proposed Bi-Erasing outperforms baseline methods in balancing concept removal effectiveness and visual fidelity.

</details>


### [139] [DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass](https://arxiv.org/abs/2512.13122)
*Vivek Alumootil,Tuan-Anh Vu,M. Khalid Jawed*

Main category: cs.CV

TL;DR: DePT3R是一个统一框架，能在单次前向传播中同时完成动态场景的密集3D点跟踪和3D重建，无需相机位姿，显著提升了适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景密集3D点跟踪方法通常依赖成对处理、需要已知相机位姿或假设时序输入，限制了灵活性和应用性。同时，大规模无位姿图像集合的3D重建进展为动态场景理解的统一方法提供了机会。

Method: 使用强大的骨干网络提取深度时空特征，通过密集预测头回归像素级映射，实现多任务学习。框架在单次前向传播中同时执行密集点跟踪和3D重建，且无需相机位姿。

Result: 在多个涉及动态场景的挑战性基准测试中验证了DePT3R，表现出强大的性能，并在内存效率方面相比现有最先进方法有显著提升。

Conclusion: DePT3R通过统一框架解决了动态场景密集点跟踪和3D重建问题，无需相机位姿，在适应性和效率方面有重要优势，为动态场景理解提供了新方法。

Abstract: Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R

</details>


### [140] [Intrinsic Image Fusion for Multi-View 3D Material Reconstruction](https://arxiv.org/abs/2512.13157)
*Peter Kocsis,Lukas Höllein,Matthias Nießner*

Main category: cs.CV

TL;DR: 提出Intrinsic Image Fusion方法，通过多视角图像重建高质量物理材质，结合单视角先验和扩散模型，使用鲁棒优化框架融合不一致的预测，最终通过逆向路径追踪优化低维参数


<details>
  <summary>Details</summary>
Motivation: 材质重建高度欠约束，传统基于分析-合成的方法需要昂贵且噪声大的路径追踪。需要更好的约束来优化重建过程

Method: 1) 利用扩散基材质估计器生成多候选分解；2) 拟合显式低维参数函数；3) 提出鲁棒优化框架，结合软逐视角预测选择和基于置信度的软多视角内点集；4) 使用逆向路径追踪优化低维参数

Result: 在合成和真实场景的材质解缠任务中优于现有最先进方法，产生清晰干净的重建结果，适合高质量重光照

Conclusion: Intrinsic Image Fusion方法通过融合单视角先验和多视角一致性，有效解决了材质重建的欠约束问题，实现了高质量物理材质的重建

Abstract: We introduce Intrinsic Image Fusion, a method that reconstructs high-quality physically based materials from multi-view images. Material reconstruction is highly underconstrained and typically relies on analysis-by-synthesis, which requires expensive and noisy path tracing. To better constrain the optimization, we incorporate single-view priors into the reconstruction process. We leverage a diffusion-based material estimator that produces multiple, but often inconsistent, candidate decompositions per view. To reduce the inconsistency, we fit an explicit low-dimensional parametric function to the predictions. We then propose a robust optimization framework using soft per-view prediction selection together with confidence-based soft multi-view inlier set to fuse the most consistent predictions of the most confident views into a consistent parametric material space. Finally, we use inverse path tracing to optimize for the low-dimensional parameters. Our results outperform state-of-the-art methods in material disentanglement on both synthetic and real scenes, producing sharp and clean reconstructions suitable for high-quality relighting.

</details>


### [141] [Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing](https://arxiv.org/abs/2512.13055)
*Jaeyoon Kim,Yoonki Cho,Sung-Eui Yoon*

Main category: cs.CV

TL;DR: 提出了一种高效的非对称视觉地点识别框架，使用高容量模型离线处理图库特征，轻量级网络在线处理查询，通过地理记忆库和隐式嵌入增强技术实现异构网络兼容性


<details>
  <summary>Details</summary>
Motivation: 虽然DINOv2等基础模型在视觉地点识别中表现出色，但计算成本过高，难以在资源受限设备上部署。需要一种既能保持高性能又能降低计算开销的解决方案

Method: 1) 非对称框架：高容量模型离线提取图库特征，轻量级网络在线处理查询；2) 地理记忆库：利用VPR数据库的地理位置元数据组织图库特征，避免昂贵的k-NN计算；3) 隐式嵌入增强：增强查询网络以建模特征变化，弥补其有限容量

Result: 该方法显著降低了计算成本，同时超越了现有的非对称检索技术，为资源受限环境下的VPR建立了新的基准

Conclusion: 提出的非对称VPR框架通过地理记忆库和隐式嵌入增强，在保持高性能的同时大幅降低计算开销，为资源受限设备上的视觉地点识别提供了实用解决方案

Abstract: Visual Place Recognition (VPR) has advanced significantly with high-capacity foundation models like DINOv2, achieving remarkable performance. Nonetheless, their substantial computational cost makes deployment on resource-constrained devices impractical. In this paper, we introduce an efficient asymmetric VPR framework that incorporates a high-capacity gallery model for offline feature extraction with a lightweight query network for online processing. A key challenge in this setting is ensuring compatibility between these heterogeneous networks, which conventional approaches address through computationally expensive k-NN-based compatible training. To overcome this, we propose a geographical memory bank that structures gallery features using geolocation metadata inherent in VPR databases, eliminating the need for exhaustive k-NN computations. Additionally, we introduce an implicit embedding augmentation technique that enhances the query network to model feature variations despite its limited capacity. Extensive experiments demonstrate that our method not only significantly reduces computational costs but also outperforms existing asymmetric retrieval techniques, establishing a new aspect for VPR in resource-limited environments. The code is available at https://github.com/jaeyoon1603/AsymVPR

</details>


### [142] [A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis](https://arxiv.org/abs/2512.13164)
*Xianchao Guan,Zhiyuan Fan,Yifeng Wang,Fuqiang Chen,Yanjiang Zhou,Zengyang Che,Hongxue Meng,Xin Li,Yaowei Wang,Hongpeng Wang,Min Zhang,Heng Tao Shen,Zheng Zhang,Yongbing Zhang*

Main category: cs.CV

TL;DR: CRAFTS是首个病理学专用的文本到图像生成基础模型，通过相关性调节对齐框架解决生成模型在病理图像中的语义漂移问题，生成30种癌症类型的多样化病理图像，增强临床任务性能。


<details>
  <summary>Details</summary>
Motivation: 病理学中临床级人工智能的发展受到高质量标注数据稀缺的限制。现有生成模型存在语义不稳定和形态幻觉问题，影响诊断可靠性。

Method: 提出CRAFTS框架，采用双阶段训练策略，在约280万图像-文本对上训练，引入新颖的对齐机制抑制语义漂移，确保生物学准确性。结合ControlNet实现组织架构的精确控制。

Result: 模型生成30种癌症类型的多样化病理图像，通过客观指标和病理学家评估验证质量。CRAFTS增强的数据集在分类、跨模态检索、自监督学习和视觉问答等临床任务中提升性能。

Conclusion: CRAFTS克服了数据稀缺和隐私问题，为罕见和复杂癌症表型提供了无限多样的标注组织学数据来源，有助于开发稳健的诊断工具。

Abstract: The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.

</details>


### [143] [Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models](https://arxiv.org/abs/2512.13072)
*Zizhi Chen,Yizhen Gao,Minghao Han,Yizhou Liu,Zhaoyu Chen,Dingkang Yang,Lihua Zhang*

Main category: cs.CV

TL;DR: 提出一个结合检索增强生成和动态知识蒸馏的框架，用于解决多模态生物医学视觉语言模型在持续学习中的核心困境：如何在保持细粒度模态内特征的同时跨越模态间的显著领域差距。


<details>
  <summary>Details</summary>
Motivation: 多模态生物医学视觉语言模型在持续学习中面临核心困境：需要同时保持细粒度的模态内特征和跨越不同模态间的显著领域差距。现有方法难以平衡这两个需求。

Method: 1) 基于PubMed科学论文构建1800万条多模态医学检索数据库；2) 首次将检索增强生成引入持续学习，采用多模态、多层次的RAG系统提供实时指导；3) 提出动态知识蒸馏框架，根据所需细节水平动态调节参数空间重要性、蒸馏知识粒度和参考数据集分布。

Result: 方法在设计的医学通用任务增量学习基准上进行了全面验证，该基准同时评估模型对显著领域转移的适应能力、细微领域内特征的保留能力以及实时学习新颖复杂医学任务的能力。实验结果显示该方法在所有指标上都达到了最先进的性能。

Conclusion: 提出的框架成功解决了多模态生物医学视觉语言模型在持续学习中的核心困境，通过结合检索增强生成和动态知识蒸馏，在保持细粒度特征的同时有效跨越模态领域差距，在医学通用任务增量学习基准上取得了最先进的性能。

Abstract: Multimodal biomedical Vision-Language Models (VLMs) exhibit immense potential in the field of Continual Learning (CL). However, they confront a core dilemma: how to preserve fine-grained intra-modality features while bridging the significant domain gap across different modalities. To address this challenge, we propose a comprehensive framework. Leveraging our 18-million multimodal and comprehensive medical retrieval database derived from PubMed scientific papers, we pioneer the integration of Retrieval-Augmented Generation (RAG) into CL. Specifically, we employ a multi-modal, multi-layer RAG system that provides real-time guidance for model fine-tuning through dynamic, on-demand knowledge retrieval. Building upon this, we introduce a dynamic knowledge distillation framework. This framework precisely resolves the aforementioned core dilemma by dynamically modulating the importance of the parameter space, the granularity of the distilled knowledge, and the data distribution of the reference dataset in accordance with the required level of detail. To thoroughly validate the clinical value of our strategy, we have designed a more rigorous \textbf{M}edical Generalist Task Incremental Learning (MGTIL) benchmark. This benchmark is engineered to simultaneously evaluate the model's capacity for adaptation to significant domain shifts, retention of subtle intra-domain features, and real-time learning of novel and complex medical tasks. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) performance across all metrics. The code is provided in the supplementary materials.

</details>


### [144] [Heart Disease Prediction using Case Based Reasoning (CBR)](https://arxiv.org/abs/2512.13078)
*Mohaiminul Islam Bhuiyan,Chan Hue Wah,Nur Shazwani Kamarudin,Nur Hafieza Ismail,Ahmad Fakhri Ab Nasir*

Main category: cs.CV

TL;DR: 该研究比较了三种智能系统（模糊逻辑、神经网络、案例推理）在心脏病预测中的应用，最终选择案例推理方法，实现了97.95%的预测准确率。


<details>
  <summary>Details</summary>
Motivation: 传统心脏病预测方法主要依赖医生经验，缺乏精确性。需要探索智能系统作为替代方案来提高预测准确性。

Method: 比较模糊逻辑、神经网络和案例推理三种智能系统方法，最终选择案例推理。对心脏病数据集进行数据预处理（清洗）和数据分割（训练集和测试集），然后应用案例推理进行预测。

Result: 案例推理方法在心脏病预测中达到97.95%的准确率。分析显示男性心脏病概率为57.76%，女性为42.24%。相关研究表明吸烟和饮酒是重要风险因素，尤其对男性影响显著。

Conclusion: 案例推理是有效的智能系统方法，在心脏病预测中表现优异。性别差异和生活方式因素（吸烟、饮酒）对心脏病风险有重要影响。

Abstract: This study provides an overview of heart disease prediction using an intelligent system. Predicting disease accurately is crucial in the medical field, but traditional methods relying solely on a doctor's experience often lack precision. To address this limitation, intelligent systems are applied as an alternative to traditional approaches. While various intelligent system methods exist, this study focuses on three: Fuzzy Logic, Neural Networks, and Case-Based Reasoning (CBR). A comparison of these techniques in terms of accuracy was conducted, and ultimately, Case-Based Reasoning (CBR) was selected for heart disease prediction. In the prediction phase, the heart disease dataset underwent data pre-processing to clean the data and data splitting to separate it into training and testing sets. The chosen intelligent system was then employed to predict heart disease outcomes based on the processed data. The experiment concluded with Case-Based Reasoning (CBR) achieving a notable accuracy rate of 97.95% in predicting heart disease. The findings also revealed that the probability of heart disease was 57.76% for males and 42.24% for females. Further analysis from related studies suggests that factors such as smoking and alcohol consumption are significant contributors to heart disease, particularly among males.

</details>


### [145] [DiRe: Diversity-promoting Regularization for Dataset Condensation](https://arxiv.org/abs/2512.13083)
*Saumyaranjan Mohanty,Aravind Reddy,Konda Reddy Mopuri*

Main category: cs.CV

TL;DR: 提出多样性正则化器(DiRe)，通过余弦相似度和欧氏距离减少数据集压缩中的冗余，提高合成数据集的多样性


<details>
  <summary>Details</summary>
Motivation: 现有数据集压缩方法合成的数据集存在显著冗余，需要减少冗余并提高合成数据集的多样性

Method: 提出由余弦相似度和欧氏距离组成的多样性正则化器(DiRe)，可即插即用地应用于各种最先进的压缩方法

Result: 通过广泛实验证明，添加该正则化器能改进最先进的压缩方法，在CIFAR-10到ImageNet-1K等基准数据集上提升泛化能力和多样性指标

Conclusion: DiRe正则化器能有效减少数据集压缩中的冗余，提高合成数据集的多样性，适用于多种现有方法

Abstract: In Dataset Condensation, the goal is to synthesize a small dataset that replicates the training utility of a large original dataset. Existing condensation methods synthesize datasets with significant redundancy, so there is a dire need to reduce redundancy and improve the diversity of the synthesized datasets. To tackle this, we propose an intuitive Diversity Regularizer (DiRe) composed of cosine similarity and Euclidean distance, which can be applied off-the-shelf to various state-of-the-art condensation methods. Through extensive experiments, we demonstrate that the addition of our regularizer improves state-of-the-art condensation methods on various benchmark datasets from CIFAR-10 to ImageNet-1K with respect to generalization and diversity metrics.

</details>


### [146] [ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning](https://arxiv.org/abs/2512.13095)
*Feng Zhang,Zezhong Tan,Xinhong Ma,Ziqiang Dong,Xi Leng,Jianfei Zhao,Xin Sun,Yang Yang*

Main category: cs.CV

TL;DR: ADHint是一种改进的基于提示的强化学习方法，通过考虑样本难度来优化提示比例调度和相对优势估计，实现探索与模仿的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的RL方法在调度提示比例和估计相对优势时忽略难度因素，导致学习不稳定和过度模仿离策略提示，需要更好的探索与模仿平衡机制。

Method: 1) 自适应提示与样本难度先验：评估样本在策略模型下的难度，相应调度适当的提示比例指导rollouts；2) 一致性梯度调制和选择性掩码：调制提示内的token级梯度，防止偏差和破坏性更新；3) 基于rollout难度后验的优势估计：利用有/无提示rollouts的相对难度估计各自优势。

Result: 在多种模态、模型规模和领域上的实验表明，ADHint在推理能力和分布外泛化方面表现优异，在pass@1和avg@8指标上一致超越现有方法。

Conclusion: ADHint通过将难度作为关键因素纳入提示比例调度和相对优势估计，实现了探索与模仿的更好平衡，显著提升了推理能力和泛化性能。

Abstract: To combine the advantages of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), recent methods have integrated ''hints'' into post-training, which are prefix segments of complete reasoning trajectories, aiming for powerful knowledge expansion and reasoning generalization. However, existing hint-based RL methods typically ignore difficulty when scheduling hint ratios and estimating relative advantages, leading to unstable learning and excessive imitation of off-policy hints. In this work, we propose ADHint, which treats difficulty as a key factor in both hint-ratio schedule and relative-advantage estimation to achieve a better trade-off between exploration and imitation. Specifically, we propose Adaptive Hint with Sample Difficulty Prior, which evaluates each sample's difficulty under the policy model and accordingly schedules an appropriate hint ratio to guide its rollouts. We also introduce Consistency-based Gradient Modulation and Selective Masking for Hint Preservation to modulate token-level gradients within hints, preventing biased and destructive updates. Additionally, we propose Advantage Estimation with Rollout Difficulty Posterior, which leverages the relative difficulty of rollouts with and without hints to estimate their respective advantages, thereby achieving more balanced updates. Extensive experiments across diverse modalities, model scales, and domains demonstrate that ADHint delivers superior reasoning ability and out-of-distribution generalization, consistently surpassing existing methods in both pass@1 and avg@8. Our code and dataset will be made publicly available upon paper acceptance.

</details>


### [147] [LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models](https://arxiv.org/abs/2512.13290)
*Shu Yu,Chaochao Lu*

Main category: cs.CV

TL;DR: LINA框架通过因果干预和重新分配的降噪调度，解决扩散模型在物理对齐和OOD指令跟随方面的挑战，在因果生成任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像和视频生成方面取得了显著成功，但在物理对齐和超出分布（OOD）指令跟随方面仍存在困难。这些问题源于模型未能学习因果方向和分离因果因素以实现新颖重组。

Method: 引入因果场景图（CSG）和物理对齐探针（PAP）数据集进行诊断干预分析。基于分析结果，提出LINA框架：1）在提示和视觉潜在空间中进行针对性引导；2）采用重新分配的、因果感知的降噪调度；3）学习预测特定于提示的干预措施。

Result: LINA在图像和视频扩散模型中同时实现了物理对齐和OOD指令跟随，在具有挑战性的因果生成任务和Winoground数据集上取得了最先进的性能。

Conclusion: 通过因果分析和适应性干预学习，LINA框架有效解决了扩散模型在物理对齐和OOD指令跟随方面的核心问题，为因果感知的生成模型提供了新的解决方案。

Abstract: Diffusion models (DMs) have achieved remarkable success in image and video generation. However, they still struggle with (1) physical alignment and (2) out-of-distribution (OOD) instruction following. We argue that these issues stem from the models' failure to learn causal directions and to disentangle causal factors for novel recombination. We introduce the Causal Scene Graph (CSG) and the Physical Alignment Probe (PAP) dataset to enable diagnostic interventions. This analysis yields three key insights. First, DMs struggle with multi-hop reasoning for elements not explicitly determined in the prompt. Second, the prompt embedding contains disentangled representations for texture and physics. Third, visual causal structure is disproportionately established during the initial, computationally limited denoising steps. Based on these findings, we introduce LINA (Learning INterventions Adaptively), a novel framework that learns to predict prompt-specific interventions, which employs (1) targeted guidance in the prompt and visual latent spaces, and (2) a reallocated, causality-aware denoising schedule. Our approach enforces both physical alignment and OOD instruction following in image and video DMs, achieving state-of-the-art performance on challenging causal generation tasks and the Winoground dataset. Our project page is at https://opencausalab.github.io/LINA.

</details>


### [148] [FID-Net: A Feature-Enhanced Deep Learning Network for Forest Infestation Detection](https://arxiv.org/abs/2512.13104)
*Yan Zhang,Baoxin Li,Han Sun,Yuhang Gao,Mingtai Zhang,Pei Wang*

Main category: cs.CV

TL;DR: 提出FID-Net深度学习模型，从无人机可见光图像检测病虫害树木，并通过三种空间指标进行虫害分析，在新疆天山森林实验中表现优于主流YOLO模型。


<details>
  <summary>Details</summary>
Motivation: 传统森林病虫害监测方法在大规模、细粒度检测方面存在局限，需要高效监测方法以保护生态系统稳定。

Method: 基于YOLOv8n构建FID-Net，引入轻量级特征增强模块提取病害敏感特征，自适应多尺度特征融合模块对齐融合RGB和增强特征分支，以及高效通道注意力机制。从检测结果构建虫害分析框架：核密度估计定位感染热点、邻域评估健康树感染风险、DBSCAN聚类识别高密度健康集群作为优先保护区域。

Result: 在新疆东部天山32个森林样地的无人机图像实验中，FID-Net达到86.10%精确率、75.44%召回率、82.29% mAP@0.5和64.30% mAP@0.5:0.95，优于主流YOLO模型。分析确认感染树木呈现明显聚类模式。

Conclusion: FID-Net能够准确区分树木健康状况，结合空间指标为智能病虫害监测、早期预警和精准管理提供可靠数据支持。

Abstract: Forest pests threaten ecosystem stability, requiring efficient monitoring. To overcome the limitations of traditional methods in large-scale, fine-grained detection, this study focuses on accurately identifying infected trees and analyzing infestation patterns. We propose FID-Net, a deep learning model that detects pest-affected trees from UAV visible-light imagery and enables infestation analysis via three spatial metrics. Based on YOLOv8n, FID-Net introduces a lightweight Feature Enhancement Module (FEM) to extract disease-sensitive cues, an Adaptive Multi-scale Feature Fusion Module (AMFM) to align and fuse dual-branch features (RGB and FEM-enhanced), and an Efficient Channel Attention (ECA) mechanism to enhance discriminative information efficiently. From detection results, we construct a pest situation analysis framework using: (1) Kernel Density Estimation to locate infection hotspots; (2) neighborhood evaluation to assess healthy trees' infection risk; (3) DBSCAN clustering to identify high-density healthy clusters as priority protection zones. Experiments on UAV imagery from 32 forest plots in eastern Tianshan, China, show that FID-Net achieves 86.10% precision, 75.44% recall, 82.29% mAP@0.5, and 64.30% mAP@0.5:0.95, outperforming mainstream YOLO models. Analysis confirms infected trees exhibit clear clustering, supporting targeted forest protection. FID-Net enables accurate tree health discrimination and, combined with spatial metrics, provides reliable data for intelligent pest monitoring, early warning, and precise management.

</details>


### [149] [Face Identity Unlearning for Retrieval via Embedding Dispersion](https://arxiv.org/abs/2512.13317)
*Mikhail Zakharov*

Main category: cs.CV

TL;DR: 该论文研究人脸检索系统中的身份遗忘问题，提出了一种基于分散的遗忘方法，使特定身份无法被检索，同时保持其他身份的检索性能。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统虽然能有效进行身份检索，但存在严重的隐私问题，可能被用于未经授权的身份追踪。现有的机器遗忘方法在人脸检索场景下的适用性尚未充分探索。

Method: 评估了多种现有近似类别遗忘方法（如随机标签、梯度上升、边界遗忘等），并提出了一种简单有效的基于分散的遗忘方法，通过在超球面上分散目标身份的嵌入向量，防止形成紧凑的身份聚类。

Result: 在VGGFace2和CelebA等标准基准测试上的大量实验表明，该方法在实现优越遗忘效果的同时，能够保持其他身份的检索效用。

Conclusion: 该研究为人脸检索系统的隐私保护提供了一种有效的身份遗忘方法，解决了在保持系统整体性能的同时实现特定身份不可检索的挑战。

Abstract: Face recognition systems rely on learning highly discriminative and compact identity clusters to enable accurate retrieval. However, as with other surveillance-oriented technologies, such systems raise serious privacy concerns due to their potential for unauthorized identity tracking. While several works have explored machine unlearning as a means of privacy protection, their applicability to face retrieval - especially for modern embedding-based recognition models - remains largely unexplored. In this work, we study the problem of face identity unlearning for retrieval systems and present its inherent challenges. The goal is to make selected identities unretrievable by dispersing their embeddings on the hypersphere and preventing the formation of compact identity clusters that enable re-identification in the gallery. The primary challenge is to achieve this forgetting effect while preserving the discriminative structure of the embedding space and the retrieval performance of the model for the remaining identities. To address this, we evaluate several existing approximate class unlearning methods (e.g., Random Labeling, Gradient Ascent, Boundary Unlearning, and other recent approaches) in the context of face retrieval and propose a simple yet effective dispersion-based unlearning approach. Extensive experiments on standard benchmarks (VGGFace2, CelebA) demonstrate that our method achieves superior forgetting behavior while preserving retrieval utility.

</details>


### [150] [End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery](https://arxiv.org/abs/2512.13402)
*Lorenzo Pettinari,Sidaty El Hadramy,Michael Wehrli,Philippe C. Cattin,Daniel Studer,Carol C. Hasler,Maria Licci*

Main category: cs.CV

TL;DR: End2Reg：一种端到端深度学习框架，联合优化分割和配准，无需弱分割标签，在脊柱手术导航中实现毫米级精度


<details>
  <summary>Details</summary>
Motivation: 当前脊柱手术导航系统依赖侵入性骨锚定标记和放射成像，具有辐射风险且工作流程中断。现有的无标记RGB-D配准方法依赖弱分割标签，可能导致误差传播。

Method: 提出End2Reg端到端深度学习框架，联合优化分割和配准。网络学习专门为配准优化的分割掩码，仅通过配准目标引导，无需直接分割监督。

Result: 在体外和体内基准测试中达到最先进性能：中位目标配准误差降低32%至1.83mm，均方根误差降低45%至3.95mm。消融研究证实端到端优化显著提高配准精度。

Conclusion: 该端到端RGB-D配准管道消除了对弱标签和手动步骤的依赖，推动了完全自动化的无标记术中导航发展。

Abstract: Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.

</details>


### [151] [LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping](https://arxiv.org/abs/2512.13130)
*Shanghua Liu,Majharulislam Babor,Christoph Verduyn,Breght Vandenberghe,Bruno Betoni Parodi,Cornelia Weltzien,Marina M. -C. Höhne*

Main category: cs.CV

TL;DR: 提出CanolaTrack数据集和LeafTrackNet框架，用于复杂作物（油菜）的叶片追踪，在真实条件下实现高精度叶片跟踪


<details>
  <summary>Details</summary>
Motivation: 现有叶片追踪方法存在局限性：植物专用方法仅限于小规模物种或受限制的成像条件，通用多目标追踪方法不适合动态生物场景，且缺乏大规模真实条件下的数据集

Method: 提出LeafTrackNet框架，结合YOLOv10叶片检测器和MobileNetV3嵌入网络，通过基于嵌入的记忆关联策略在推理时维持叶片身份

Result: 在CanolaTrack数据集上，LeafTrackNet优于植物专用追踪器和最先进的多目标追踪基线，HOTA指标提升9%

Conclusion: 为真实条件下的叶片级追踪提供了新标准，并贡献了农业作物叶片追踪的最大数据集，将促进植物表型研究的未来发展

Abstract: High resolution phenotyping at the level of individual leaves offers fine-grained insights into plant development and stress responses. However, the full potential of accurate leaf tracking over time remains largely unexplored due to the absence of robust tracking methods-particularly for structurally complex crops such as canola. Existing plant-specific tracking methods are typically limited to small-scale species or rely on constrained imaging conditions. In contrast, generic multi-object tracking (MOT) methods are not designed for dynamic biological scenes. Progress in the development of accurate leaf tracking models has also been hindered by a lack of large-scale datasets captured under realistic conditions. In this work, we introduce CanolaTrack, a new benchmark dataset comprising 5,704 RGB images with 31,840 annotated leaf instances spanning the early growth stages of 184 canola plants. To enable accurate leaf tracking over time, we introduce LeafTrackNet, an efficient framework that combines a YOLOv10-based leaf detector with a MobileNetV3-based embedding network. During inference, leaf identities are maintained over time through an embedding-based memory association strategy. LeafTrackNet outperforms both plant-specific trackers and state-of-the-art MOT baselines, achieving a 9% HOTA improvement on CanolaTrack. With our work we provide a new standard for leaf-level tracking under realistic conditions and we provide CanolaTrack - the largest dataset for leaf tracking in agriculture crops, which will contribute to future research in plant phenotyping. Our code and dataset are publicly available at https://github.com/shl-shawn/LeafTrackNet.

</details>


### [152] [Weight Space Correlation Analysis: Quantifying Feature Utilization in Deep Learning Models](https://arxiv.org/abs/2512.13144)
*Chun Kit Wong,Paraskevas Pegios,Nina Weng,Emilie Pi Fogtmann Sejer,Martin Grønnebæk Tolsgaard,Anders Nymark Christensen,Aasa Feragen*

Main category: cs.CV

TL;DR: 提出Weight Space Correlation Analysis方法，通过分析分类头权重向量的相关性来量化特征利用，验证医学影像模型是否真正使用临床相关特征而非元数据捷径。


<details>
  <summary>Details</summary>
Motivation: 医学影像深度学习模型容易陷入捷径学习，利用图像嵌入中的元数据（如扫描仪型号）而非真正的临床信号进行预测。关键问题是模型是否主动使用这些编码信息进行最终预测。

Method: 提出Weight Space Correlation Analysis方法，通过测量主要临床任务分类头与辅助元数据任务分类头之间的对齐程度来量化特征利用。首先验证方法能检测人工诱导的捷径学习，然后应用于SA-SonoNet模型分析早产预测任务。

Result: 方法成功检测到人工诱导的捷径学习。在早产预测模型中，虽然嵌入包含大量元数据，但早产分类器的权重向量与临床相关因素（如出生体重）高度相关，而与临床无关的采集因素（如扫描仪）解耦。

Conclusion: 该方法为验证模型可信度提供了工具，证明在没有诱导偏差的情况下，临床模型会选择性地利用与真正临床信号相关的特征，而非元数据捷径。

Abstract: Deep learning models in medical imaging are susceptible to shortcut learning, relying on confounding metadata (e.g., scanner model) that is often encoded in image embeddings. The crucial question is whether the model actively utilizes this encoded information for its final prediction. We introduce Weight Space Correlation Analysis, an interpretable methodology that quantifies feature utilization by measuring the alignment between the classification heads of a primary clinical task and auxiliary metadata tasks. We first validate our method by successfully detecting artificially induced shortcut learning. We then apply it to probe the feature utilization of an SA-SonoNet model trained for Spontaneous Preterm Birth (sPTB) prediction. Our analysis confirmed that while the embeddings contain substantial metadata, the sPTB classifier's weight vectors were highly correlated with clinically relevant factors (e.g., birth weight) but decoupled from clinically irrelevant acquisition factors (e.g. scanner). Our methodology provides a tool to verify model trustworthiness, demonstrating that, in the absence of induced bias, the clinical model selectively utilizes features related to the genuine clinical signal.

</details>


### [153] [StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion](https://arxiv.org/abs/2512.13147)
*Sangmin Hong,Suyoung Lee,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: StarryGazer是一个无需地面真实深度数据的深度补全框架，通过结合单目深度估计模型和稀疏深度图来预测密集深度图像。


<details>
  <summary>Details</summary>
Motivation: 现有无监督深度补全方法需要辅助数据，而单目深度估计模型虽然能从单张图像生成相对深度图，但无法与稀疏深度图有效结合。简单的仿射变换会导致高误差，因为单目深度估计在估计物体间深度差异时不准确。

Method: 使用预训练的单目深度估计模型生成相对深度图，对这些图像进行分割和随机缩放，形成合成训练对（密集伪地面真实深度和对应的稀疏深度）。训练一个细化网络，结合相对深度图和RGB图像来提高模型的准确性和鲁棒性。

Result: StarryGazer在多个数据集上优于现有的无监督方法和经过变换的单目深度估计结果，表明该框架能有效利用单目深度估计模型的能力，同时通过稀疏深度信息适当修正误差。

Conclusion: StarryGazer是一个领域无关的框架，无需地面真实深度数据，通过巧妙结合单目深度估计和稀疏深度信息，实现了高质量的深度补全，展示了利用大型单目深度估计模型潜力同时修正其误差的有效方法。

Abstract: The problem of depth completion involves predicting a dense depth image from a single sparse depth map and an RGB image. Unsupervised depth completion methods have been proposed for various datasets where ground truth depth data is unavailable and supervised methods cannot be applied. However, these models require auxiliary data to estimate depth values, which is far from real scenarios. Monocular depth estimation (MDE) models can produce a plausible relative depth map from a single image, but there is no work to properly combine the sparse depth map with MDE for depth completion; a simple affine transformation to the depth map will yield a high error since MDE are inaccurate at estimating depth difference between objects. We introduce StarryGazer, a domain-agnostic framework that predicts dense depth images from a single sparse depth image and an RGB image without relying on ground-truth depth by leveraging the power of large MDE models. First, we employ a pre-trained MDE model to produce relative depth images. These images are segmented and randomly rescaled to form synthetic pairs for dense pseudo-ground truth and corresponding sparse depths. A refinement network is trained with the synthetic pairs, incorporating the relative depth maps and RGB images to improve the model's accuracy and robustness. StarryGazer shows superior results over existing unsupervised methods and transformed MDE results on various datasets, demonstrating that our framework exploits the power of MDE models while appropriately fixing errors using sparse depth information.

</details>


### [154] [DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides](https://arxiv.org/abs/2512.13600)
*Haoyue Zhang,Meera Chappidi,Erolcan Sayar,Helen Richards,Zhijun Chen,Lucas Liu,Roxanne Wadia,Peter A Humphrey,Fady Ghali,Alberto Contreras-Sanz,Peter Black,Jonathan Wright,Stephanie Harmon,Michael Haffner*

Main category: cs.CV

TL;DR: 提出DA-SSL方法，通过自监督域适配将预训练病理基础模型特征对齐到TURBT领域，用于膀胱癌治疗反应预测，无需微调基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有病理基础模型在特定癌症类型（如膀胱癌TURBT标本）上存在域偏移问题，因为这些标本包含组织碎片和电灼伪影，且未广泛用于预训练。目前膀胱癌治疗反应预测中组织形态学特征利用不足，识别能从新辅助化疗获益的患者具有挑战性。

Method: 提出轻量级域自适应自监督适配器（DA-SSL），通过自监督学习将预训练病理基础模型特征重新对齐到TURBT领域，而不需要微调基础模型本身。该方法结合多实例学习框架，用于预测膀胱癌治疗反应。

Result: 在多中心研究中，DA-SSL在五折交叉验证中达到AUC 0.77±0.04，外部测试准确率0.84，敏感性0.71，特异性0.91（多数投票）。表明轻量级域适配能有效增强基于病理基础模型的多实例学习管道。

Conclusion: 轻量级自监督域适配能有效提升病理基础模型在临床挑战性组织病理学任务中的性能，特别适用于存在域偏移的癌症类型，如包含组织碎片和电灼伪影的TURBT标本。

Abstract: Recent deep learning frameworks in histopathology, particularly multiple instance learning (MIL) combined with pathology foundational models (PFMs), have shown strong performance. However, PFMs exhibit limitations on certain cancer or specimen types due to domain shifts - these cancer types were rarely used for pretraining or specimens contain tissue-based artifacts rarely seen within the pretraining population. Such is the case for transurethral resection of bladder tumor (TURBT), which are essential for diagnosing muscle-invasive bladder cancer (MIBC), but contain fragmented tissue chips and electrocautery artifacts and were not widely used in publicly available PFMs. To address this, we propose a simple yet effective domain-adaptive self-supervised adaptor (DA-SSL) that realigns pretrained PFM features to the TURBT domain without fine-tuning the foundational model itself. We pilot this framework for predicting treatment response in TURBT, where histomorphological features are currently underutilized and identifying patients who will benefit from neoadjuvant chemotherapy (NAC) is challenging. In our multi-center study, DA-SSL achieved an AUC of 0.77+/-0.04 in five-fold cross-validation and an external test accuracy of 0.84, sensitivity of 0.71, and specificity of 0.91 using majority voting. Our results demonstrate that lightweight domain adaptation with self-supervision can effectively enhance PFM-based MIL pipelines for clinically challenging histopathology tasks. Code is Available at https://github.com/zhanghaoyue/DA_SSL_TURBT.

</details>


### [155] [Seeing the Whole Picture: Distribution-Guided Data-Free Distillation for Semantic Segmentation](https://arxiv.org/abs/2512.13175)
*Hongxuan Sun,Tao Wu*

Main category: cs.CV

TL;DR: DFSS：一种专为语义分割设计的数据无知识蒸馏框架，通过利用BN统计指导近似分布采样，并采用加权分布渐进蒸馏，在保持场景结构连续性的同时实现高效知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有数据无知识蒸馏方法主要针对分类任务设计，忽视了语义分割中空间连续性和结构一致性的重要性，导致直接应用于分割任务时性能显著下降。

Method: 1. 利用教师模型的批归一化统计指导近似分布采样，选择更接近原始训练分布的数据；2. 提出加权分布渐进蒸馏，动态优先处理可靠样本并逐步引入更具挑战性的案例。

Result: 在标准基准测试中，DFSS一致优于现有的数据无知识蒸馏方法，实现了最先进的结果，同时显著减少了对辅助数据的依赖。

Conclusion: DFSS通过尊重真实世界场景的结构和上下文连续性，为语义分割任务提供了有效的无数据知识蒸馏解决方案，解决了现有方法忽视空间连续性的问题。

Abstract: Semantic segmentation requires a holistic understanding of the physical world, as it assigns semantic labels to spatially continuous and structurally coherent objects rather than to isolated pixels. However, existing data-free knowledge distillation (DFKD) methods-primarily designed for classification-often disregard this continuity, resulting in significant performance degradation when applied directly to segmentation tasks. In this paper, we introduce DFSS, a novel data-free distillation framework tailored for semantic segmentation. Unlike prior approaches that treat pixels independently, DFSS respects the structural and contextual continuity of real-world scenes. Our key insight is to leverage Batch Normalization (BN) statistics from a teacher model to guide Approximate Distribution Sampling (ADS), enabling the selection of data that better reflects the original training distribution-without relying on potentially misleading teacher predictions. Additionally, we propose Weighted Distribution Progressive Distillation (WDPD), which dynamically prioritizes reliable samples that are more closely aligned with the original data distribution early in training and gradually incorporates more challenging cases, mirroring the natural progression of learning in human perception. Extensive experiments on standard benchmarks demonstrate that DFSS consistently outperforms existing data-free distillation methods for semantic segmentation, achieving state-of-the-art results with significantly reduced reliance on auxiliary data.

</details>


### [156] [Feedforward 3D Editing via Text-Steerable Image-to-3D](https://arxiv.org/abs/2512.13678)
*Ziqi Ma,Hongqiao Chen,Yisong Yue,Georgia Gkioxari*

Main category: cs.CV

TL;DR: Steer3D：一种前馈方法，为图像到3D模型添加文本可控性，实现用语言编辑生成的3D资产


<details>
  <summary>Details</summary>
Motivation: 虽然图像到3D技术取得了进展，但在实际应用中需要能够轻松编辑AI生成的3D资产。现有方法缺乏文本引导编辑能力，限制了3D资产的实用价值。

Method: 受ControlNet启发，将文本可控性引入图像到3D生成。构建自动数据生成引擎，采用基于流匹配训练和直接偏好优化（DPO）的两阶段训练方案。

Result: 相比竞争方法，Steer3D更忠实地遵循语言指令，与原始3D资产保持更好一致性，同时速度快2.4到28.5倍。仅需10万数据即可为预训练模型添加文本控制能力。

Conclusion: Steer3D证明可以通过少量数据为预训练图像到3D生成模型添加新模态（文本）控制，实现高效、准确的3D资产编辑，具有实际应用价值。

Abstract: Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/

</details>


### [157] [MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion](https://arxiv.org/abs/2512.13177)
*Minghui Hou,Wei-Hsing Huang,Shaofeng Liang,Daizong Liu,Tai-Hao Wen,Gang Wang,Runwei Guan,Weiping Ding*

Main category: cs.CV

TL;DR: MMDrive是一个用于自动驾驶的多模态视觉语言模型框架，通过融合占用地图、LiDAR点云和文本描述三种模态，实现3D场景理解，在DriveLM和NuScenes-QA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型受限于2D图像理解范式，难以感知3D空间信息和进行深度语义融合，导致在复杂自动驾驶环境中性能不佳。

Method: 提出MMDrive框架，包含文本导向的多模态调制器和跨模态抽象器。前者根据问题语义动态加权各模态贡献，后者使用可学习的抽象令牌生成紧凑的跨模态摘要，突出关键区域和语义。

Result: 在DriveLM基准测试中达到BLEU-4分数54.56和METEOR分数41.78，在NuScenes-QA基准测试中达到62.7%的准确率，显著优于现有自动驾驶视觉语言模型。

Conclusion: MMDrive突破了传统仅图像理解的限制，实现了复杂驾驶环境中的鲁棒多模态推理，为可解释的自动驾驶场景理解提供了新基础。

Abstract: Vision-language models enable the understanding and reasoning of complex traffic scenarios through multi-source information fusion, establishing it as a core technology for autonomous driving. However, existing vision-language models are constrained by the image understanding paradigm in 2D plane, which restricts their capability to perceive 3D spatial information and perform deep semantic fusion, resulting in suboptimal performance in complex autonomous driving environments. This study proposes MMDrive, an multimodal vision-language model framework that extends traditional image understanding to a generalized 3D scene understanding framework. MMDrive incorporates three complementary modalities, including occupancy maps, LiDAR point clouds, and textual scene descriptions. To this end, it introduces two novel components for adaptive cross-modal fusion and key information extraction. Specifically, the Text-oriented Multimodal Modulator dynamically weights the contributions of each modality based on the semantic cues in the question, guiding context-aware feature integration. The Cross-Modal Abstractor employs learnable abstract tokens to generate compact, cross-modal summaries that highlight key regions and essential semantics. Comprehensive evaluations on the DriveLM and NuScenes-QA benchmarks demonstrate that MMDrive achieves significant performance gains over existing vision-language models for autonomous driving, with a BLEU-4 score of 54.56 and METEOR of 41.78 on DriveLM, and an accuracy score of 62.7% on NuScenes-QA. MMDrive effectively breaks the traditional image-only understanding barrier, enabling robust multimodal reasoning in complex driving environments and providing a new foundation for interpretable autonomous driving scene understanding.

</details>


### [158] [DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders](https://arxiv.org/abs/2512.13690)
*Susung Hong,Chongjian Ge,Zhifei Zhang,Jui-Hsien Wang*

Main category: cs.CV

TL;DR: DiffusionBrowser：一个轻量级解码器框架，可在去噪过程中实时生成多模态预览，实现交互式视频生成控制


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型存在生成不精确、速度慢、生成过程不透明的问题，用户在长时间等待中无法了解生成进度

Method: 提出模型无关的轻量级解码器框架，可在去噪过程的任何时间步或Transformer块生成预览，支持RGB和场景内在属性的多模态表示

Result: 能以超过4倍实时速度生成预览（4秒视频不到1秒），预览与最终视频具有一致的外观和运动，支持通过随机性重注入和模态引导进行交互控制

Conclusion: DiffusionBrowser不仅实现了交互式视频生成控制，还能通过解码器系统性地探测模型内部工作，揭示原本黑盒的去噪过程中场景、物体等细节的组成方式

Abstract: Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\times$ real-time speed (less than 1 second for a 4-second video) that convey consistent appearance and motion to the final video. With the trained decoder, we show that it is possible to interactively guide the generation at intermediate noise steps via stochasticity reinjection and modal steering, unlocking a new control capability. Moreover, we systematically probe the model using the learned decoders, revealing how scene, object, and other details are composed and assembled during the otherwise black-box denoising process.

</details>


### [159] [CoRA: A Collaborative Robust Architecture with Hybrid Fusion for Efficient Perception](https://arxiv.org/abs/2512.13191)
*Gong Chen,Chaokun Zhang,Pengcheng Lv,Xiaohui Xie*

Main category: cs.CV

TL;DR: CoRA是一种新颖的协作感知架构，通过混合特征级和对象级融合来解耦性能与鲁棒性，在恶劣通信条件下仍能保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法（特别是中间融合方法）在恶劣通信条件下性能会严重下降，因为数据传输会导致特征错位，这阻碍了实际部署。需要一种既能保持高性能又能在通信条件不佳时保持鲁棒性的方法。

Method: 提出CoRA架构，包含两个分支：1）特征级融合分支：选择关键特征进行高效融合，确保性能和可扩展性；2）对象级校正分支：利用语义相关性校正空间位移，保证对姿态误差的鲁棒性。该方法将中间融合和后期融合的优势互补结合。

Result: 在极端场景下，CoRA在AP@0.7指标上比基线方法提升约19%，同时通信量减少5倍以上，实现了高性能与低通信成本的平衡。

Conclusion: CoRA通过混合融合方法成功解耦了性能与鲁棒性，为鲁棒协作感知提供了一个有前景的解决方案，特别是在恶劣通信条件下仍能保持高性能。

Abstract: Collaborative perception has garnered significant attention as a crucial technology to overcome the perceptual limitations of single-agent systems. Many state-of-the-art (SOTA) methods have achieved communication efficiency and high performance via intermediate fusion. However, they share a critical vulnerability: their performance degrades under adverse communication conditions due to the misalignment induced by data transmission, which severely hampers their practical deployment. To bridge this gap, we re-examine different fusion paradigms, and recover that the strengths of intermediate and late fusion are not a trade-off, but a complementary pairing. Based on this key insight, we propose CoRA, a novel collaborative robust architecture with a hybrid approach to decouple performance from robustness with low communication. It is composed of two components: a feature-level fusion branch and an object-level correction branch. Its first branch selects critical features and fuses them efficiently to ensure both performance and scalability. The second branch leverages semantic relevance to correct spatial displacements, guaranteeing resilience against pose errors. Experiments demonstrate the superiority of CoRA. Under extreme scenarios, CoRA improves upon its baseline performance by approximately 19% in AP@0.7 with more than 5x less communication volume, which makes it a promising solution for robust collaborative perception.

</details>


### [160] [POLAR: A Portrait OLAT Dataset and Generative Framework for Illumination-Aware Face Modeling](https://arxiv.org/abs/2512.13192)
*Zhuo Chen,Chengqun Yang,Zhuo Su,Zheng Lv,Jingnan Gao,Xiaoyuan Zhang,Xiaokang Yang,Yichao Yan*

Main category: cs.CV

TL;DR: POLAR是一个大规模物理校准的单光源数据集，POLARNet是基于流的生成模型，用于从单张肖像预测每光源响应，实现可扩展可控的重光照。


<details>
  <summary>Details</summary>
Motivation: 人脸重光照研究受限于大规模物理一致光照数据的缺乏，需要构建高质量数据集和相应生成模型来解决这一问题。

Method: 1) 构建POLAR数据集：包含200+受试者，156个光照方向，多视角和表情变化；2) 开发POLARNet：基于流的生成模型，从单张肖像预测每光源OLAT响应，建模光照为连续物理可解释的变换。

Result: 建立了统一的照明学习框架，连接真实数据、生成合成和物理基础重光照，形成了可扩展、可复现的"鸡与蛋"循环。

Conclusion: POLAR和POLARNet共同解决了人脸重光照的数据和模型瓶颈，实现了细粒度、方向感知的光照效果，同时保持身份特征，为可扩展可控的重光照提供了新框架。

Abstract: Face relighting aims to synthesize realistic portraits under novel illumination while preserving identity and geometry. However, progress remains constrained by the limited availability of large-scale, physically consistent illumination data. To address this, we introduce POLAR, a large-scale and physically calibrated One-Light-at-a-Time (OLAT) dataset containing over 200 subjects captured under 156 lighting directions, multiple views, and diverse expressions. Building upon POLAR, we develop a flow-based generative model POLARNet that predicts per-light OLAT responses from a single portrait, capturing fine-grained and direction-aware illumination effects while preserving facial identity. Unlike diffusion or background-conditioned methods that rely on statistical or contextual cues, our formulation models illumination as a continuous, physically interpretable transformation between lighting states, enabling scalable and controllable relighting. Together, POLAR and POLARNet form a unified illumination learning framework that links real data, generative synthesis, and physically grounded relighting, establishing a self-sustaining "chicken-and-egg" cycle for scalable and reproducible portrait illumination.

</details>


### [161] [Ego-EXTRA: video-language Egocentric Dataset for EXpert-TRAinee assistance](https://arxiv.org/abs/2512.13238)
*Francesco Ragusa,Michele Mazzamuto,Rosario Forte,Irene D'Ambra,James Fort,Jakob Engel,Antonino Furnari,Giovanni Maria Farinella*

Main category: cs.CV

TL;DR: Ego-EXTRA是一个50小时的第一人称视频-语言数据集，用于专家-学员辅助训练，包含高质量对话和15K视觉问答对，评估多模态大语言模型在提供专家级辅助方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量的第一人称视角视频-语言数据集来评估多模态模型在提供专家级辅助方面的能力，特别是在程序性活动中专家与学员之间的自然交互场景。

Method: 采用"绿野仙踪"数据收集范式，专家通过可穿戴智能助手观察学员的第一人称视角活动，提供指导并回答具体问题，记录双向对话并转录，创建包含15K+视觉问答对的基准数据集。

Result: Ego-EXTRA数据集具有挑战性，当前多模态大语言模型在提供专家级辅助方面存在明显局限性，无法有效满足实际应用需求。

Conclusion: Ego-EXTRA为第一人称视频-语言助手提供了有价值的基准数据集，揭示了当前模型的局限性，并公开可用以促进相关研究发展。

Abstract: We present Ego-EXTRA, a video-language Egocentric Dataset for EXpert-TRAinee assistance. Ego-EXTRA features 50 hours of unscripted egocentric videos of subjects performing procedural activities (the trainees) while guided by real-world experts who provide guidance and answer specific questions using natural language. Following a ``Wizard of OZ'' data collection paradigm, the expert enacts a wearable intelligent assistant, looking at the activities performed by the trainee exclusively from their egocentric point of view, answering questions when asked by the trainee, or proactively interacting with suggestions during the procedures. This unique data collection protocol enables Ego-EXTRA to capture a high-quality dialogue in which expert-level feedback is provided to the trainee. Two-way dialogues between experts and trainees are recorded, transcribed, and used to create a novel benchmark comprising more than 15k high-quality Visual Question Answer sets, which we use to evaluate Multimodal Large Language Models. The results show that Ego-EXTRA is challenging and highlight the limitations of current models when used to provide expert-level assistance to the user. The Ego-EXTRA dataset is publicly available to support the benchmark of egocentric video-language assistants: https://fpv-iplab.github.io/Ego-EXTRA/.

</details>


### [162] [STARCaster: Spatio-Temporal AutoRegressive Video Diffusion for Identity- and View-Aware Talking Portraits](https://arxiv.org/abs/2512.13247)
*Foivos Paraperas Papantoniou,Stathis Galanakis,Rolandos Alexandros Potamias,Bernhard Kainz,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: STARCaster是一个统一的身份感知时空视频扩散模型，能够同时处理语音驱动肖像动画和自由视角说话肖像合成，通过软身份约束和隐式3D感知提升运动多样性和身份保真度。


<details>
  <summary>Details</summary>
Motivation: 现有2D语音到视频扩散模型过度依赖参考指导，导致运动多样性有限；而3D感知动画通常依赖预训练的三平面生成器反演，导致重建不完美和身份漂移。需要重新思考参考和几何范式。

Method: 采用组合方法：1）引入软身份约束而非严格参考条件；2）利用视频数据的多视角特性隐式实现3D感知；3）通过解耦学习分别训练视角一致性和时间连贯性；4）使用自强制训练方案学习更长时序上下文。

Result: 综合评估表明，STARCaster能有效泛化到不同任务和身份，在各种基准测试中持续超越先前方法，生成更自然、多样化的动画效果。

Conclusion: STARCaster通过重新思考参考和几何范式，在统一框架中实现了高质量的语音驱动肖像动画和自由视角说话肖像合成，解决了现有方法的局限性。

Abstract: This paper presents STARCaster, an identity-aware spatio-temporal video diffusion model that addresses both speech-driven portrait animation and free-viewpoint talking portrait synthesis, given an identity embedding or reference image, within a unified framework. Existing 2D speech-to-video diffusion models depend heavily on reference guidance, leading to limited motion diversity. At the same time, 3D-aware animation typically relies on inversion through pre-trained tri-plane generators, which often leads to imperfect reconstructions and identity drift. We rethink reference- and geometry-based paradigms in two ways. First, we deviate from strict reference conditioning at pre-training by introducing softer identity constraints. Second, we address 3D awareness implicitly within the 2D video domain by leveraging the inherent multi-view nature of video data. STARCaster adopts a compositional approach progressing from ID-aware motion modeling, to audio-visual synchronization via lip reading-based supervision, and finally to novel view animation through temporal-to-spatial adaptation. To overcome the scarcity of 4D audio-visual data, we propose a decoupled learning approach in which view consistency and temporal coherence are trained independently. A self-forcing training scheme enables the model to learn from longer temporal contexts than those generated at inference, mitigating the overly static animations common in existing autoregressive approaches. Comprehensive evaluations demonstrate that STARCaster generalizes effectively across tasks and identities, consistently surpassing prior approaches in different benchmarks.

</details>


### [163] [Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection](https://arxiv.org/abs/2512.13250)
*Juil Koo,Daehyeon Choi,Sangwoo Youn,Phillip Y. Lee,Minhyuk Sung*

Main category: cs.CV

TL;DR: VG-AVS任务：仅基于当前视觉信息选择最信息丰富的下一视点，无需场景记忆或外部知识，提升视觉语言模型在主动视觉任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型局限于静态图像推理，而具身智能体需要主动移动获取更信息丰富的视角，因此需要解决如何仅基于当前视觉信息选择最优下一视点的问题

Method: 1) 构建合成数据集，包含自动生成的配对查询-目标视点和问答提示；2) 提出框架：先通过监督微调预训练VLM，再进行基于强化学习的策略优化

Result: 方法在视点选择基础上实现了强大的问答性能，能鲁棒地泛化到未见过的合成和真实场景，且将VG-AVS框架集成到现有基于场景探索的EQA系统中能提升下游问答准确率

Conclusion: VG-AVS任务和提出的框架有效解决了仅基于当前视觉信息选择信息丰富视点的问题，增强了视觉语言模型在主动视觉任务中的能力，为具身智能体视觉导航提供了新思路

Abstract: Vision Language Models (VLMs) excel at visual question answering (VQA) but remain limited to snapshot vision, reasoning from static images. In contrast, embodied agents require ambulatory vision, actively moving to obtain more informative views. We introduce Visually Grounded Active View Selection (VG-AVS), a task that selects the most informative next viewpoint using only the visual information in the current image, without relying on scene memory or external knowledge. To support this task, we construct a synthetic dataset with automatically generated paired query-target views and question-answer prompts. We also propose a framework that fine-tunes pretrained VLMs through supervised fine-tuning (SFT) followed by RL-based policy optimization. Our approach achieves strong question answering performance based on viewpoint selection and generalizes robustly to unseen synthetic and real scenes. Furthermore, incorporating our learned VG-AVS framework into existing scene-exploration-based EQA systems improves downstream question-answering accuracy.

</details>


### [164] [CogniEdit: Dense Gradient Flow Optimization for Fine-Grained Image Editing](https://arxiv.org/abs/2512.13276)
*Yan Li,Lin Liu,Xiaopeng Zhang,Wei Xue,Wenhan Luo,Yike Guo,Qi Tian*

Main category: cs.CV

TL;DR: CogniEdit：一个结合多模态推理与密集奖励优化的统一框架，用于改进扩散模型在细粒度指令图像编辑中的表现


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法在处理需要精确指定颜色、位置、数量等属性的细粒度指令时表现不佳。虽然最近的方法使用GRPO进行对齐，但仅在单个采样步骤进行优化，反馈稀疏，限制了轨迹级别的控制能力。

Method: CogniEdit包含三个组件：1）多模态大语言模型将复杂指令分解为可操作的指令；2）动态令牌焦点重定位自适应地强调细粒度属性；3）基于密集GRPO的优化，在连续去噪步骤间传播梯度，实现轨迹级别的监督。

Result: 在基准数据集上的广泛实验表明，CogniEdit在平衡细粒度指令遵循、视觉质量和可编辑性保持方面达到了最先进的性能。

Conclusion: 通过结合多模态推理和密集奖励优化，CogniEdit能够实现跨连续去噪步骤的梯度传播，从而在轨迹级别上更好地控制图像编辑过程，显著提升了细粒度指令的遵循能力。

Abstract: Instruction-based image editing with diffusion models has achieved impressive results, yet existing methods struggle with fine-grained instructions specifying precise attributes such as colors, positions, and quantities. While recent approaches employ Group Relative Policy Optimization (GRPO) for alignment, they optimize only at individual sampling steps, providing sparse feedback that limits trajectory-level control. We propose a unified framework CogniEdit, combining multi-modal reasoning with dense reward optimization that propagates gradients across consecutive denoising steps, enabling trajectory-level gradient flow through the sampling process. Our method comprises three components: (1) Multi-modal Large Language Models for decomposing complex instructions into actionable directives, (2) Dynamic Token Focus Relocation that adaptively emphasizes fine-grained attributes, and (3) Dense GRPO-based optimization that propagates gradients across consecutive steps for trajectory-level supervision. Extensive experiments on benchmark datasets demonstrate that our CogniEdit achieves state-of-the-art performance in balancing fine-grained instruction following with visual quality and editability preservation

</details>


### [165] [Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?](https://arxiv.org/abs/2512.13281)
*Jiaqi Wang,Weijia Wu,Yi Zhan,Rui Zhao,Ming Hu,James Cheng,Wei Liu,Philip Torr,Kevin Qinghong Lin*

Main category: cs.CV

TL;DR: 提出了Video Reality Test基准，用于评估AI生成视频在音频-视觉耦合下的感知真实性，发现当前最佳视频生成模型Veo3.1-Fast能欺骗大多数视觉语言模型，而人类专家仍能保持81.25%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着视频生成技术的进步，AI生成的视频越来越难以与真实视频区分，这对社会构成了新的挑战。现有的AIGC检测基准大多只评估无音频的视频，针对广泛的叙事领域，且仅关注分类任务。目前尚不清楚最先进的视频生成模型是否能产生沉浸式的音频配对视频，可靠地欺骗人类和视觉语言模型。

Method: 提出了Video Reality Test基准套件，基于精心筛选的真实ASMR视频构建，针对细粒度的动作-物体交互，具有多样化的物体、动作和背景。采用对抗性的创作者-评审者协议：视频生成模型作为创作者试图欺骗评审者，而视觉语言模型作为评审者试图识别虚假内容。

Result: 最佳创作者Veo3.1-Fast甚至能欺骗大多数视觉语言模型：最强的评审者(Gemini 2.5-Pro)仅达到56%的准确率(随机50%)，远低于人类专家的81.25%。添加音频能改善真假辨别，但水印等表面线索仍会显著误导模型。

Conclusion: 这些发现界定了当前视频生成真实性的边界，并揭示了视觉语言模型在感知保真度和音频-视觉一致性方面的局限性。研究强调了需要更鲁棒的检测方法来解决AI生成视频的挑战。

Abstract: Recent advances in video generation have produced vivid content that are often indistinguishable from real videos, making AI-generated video detection an emerging societal challenge. Prior AIGC detection benchmarks mostly evaluate video without audio, target broad narrative domains, and focus on classification solely. Yet it remains unclear whether state-of-the-art video generation models can produce immersive, audio-paired videos that reliably deceive humans and VLMs. To this end, we introduce Video Reality Test, an ASMR-sourced video benchmark suite for testing perceptual realism under tight audio-visual coupling, featuring the following dimensions: \textbf{(i) Immersive ASMR video-audio sources.} Built on carefully curated real ASMR videos, the benchmark targets fine-grained action-object interactions with diversity across objects, actions, and backgrounds. \textbf{(ii) Peer-Review evaluation.} An adversarial creator-reviewer protocol where video generation models act as creators aiming to fool reviewers, while VLMs serve as reviewers seeking to identify fakeness. Our experimental findings show: The best creator Veo3.1-Fast even fools most VLMs: the strongest reviewer (Gemini 2.5-Pro) achieves only 56\% accuracy (random 50\%), far below that of human experts (81.25\%). Adding audio improves real-fake discrimination, yet superficial cues such as watermarks can still significantly mislead models. These findings delineate the current boundary of video generation realism and expose limitations of VLMs in perceptual fidelity and audio-visual consistency. Our code is available at https://github.com/video-reality-test/video-reality-test.

</details>


### [166] [CausalCLIP: Causally-Informed Feature Disentanglement and Filtering for Generalizable Detection of Generated Images](https://arxiv.org/abs/2512.13285)
*Bo Liu,Qiao Qin,Qinghui He*

Main category: cs.CV

TL;DR: CausalCLIP：基于因果推断的图像生成检测框架，通过解耦因果与非因果特征提升跨生成模型的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有生成图像检测方法（包括基于视觉语言模型的方法）产生的表征高度纠缠，混合了任务相关的取证线索（因果特征）与虚假/无关模式（非因果特征），限制了跨不同生成技术的泛化能力。

Method: 提出CausalCLIP框架：1）使用结构因果模型建模生成过程；2）通过Gumbel-Softmax特征掩码和HSIC约束实现统计独立性，解耦因果与非因果特征；3）基于因果推断原则进行针对性过滤，仅保留最具可迁移性和判别性的取证线索。

Result: 在不同系列的未见生成模型上测试，CausalCLIP展现出强大的泛化能力，在准确率上比现有最佳方法提升6.83%，平均精度提升4.06%。

Conclusion: 通过因果解耦方法可以有效提升生成图像检测器的跨模型泛化能力，CausalCLIP为处理快速演进的生成技术提供了有效的解决方案。

Abstract: The rapid advancement of generative models has increased the demand for generated image detectors capable of generalizing across diverse and evolving generation techniques. However, existing methods, including those leveraging pre-trained vision-language models, often produce highly entangled representations, mixing task-relevant forensic cues (causal features) with spurious or irrelevant patterns (non-causal features), thus limiting generalization. To address this issue, we propose CausalCLIP, a framework that explicitly disentangles causal from non-causal features and employs targeted filtering guided by causal inference principles to retain only the most transferable and discriminative forensic cues. By modeling the generation process with a structural causal model and enforcing statistical independence through Gumbel-Softmax-based feature masking and Hilbert-Schmidt Independence Criterion (HSIC) constraints, CausalCLIP isolates stable causal features robust to distribution shifts. When tested on unseen generative models from different series, CausalCLIP demonstrates strong generalization ability, achieving improvements of 6.83% in accuracy and 4.06% in average precision over state-of-the-art methods.

</details>


### [167] [ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement](https://arxiv.org/abs/2512.13303)
*Zhihang Liu,Xiaoyi Bao,Pandeng Li,Junjie Zhou,Zhaohe Liao,Yefei He,Kaixun Jiang,Chen-Wei Xie,Yun Zheng,Hongtao Xie*

Main category: cs.CV

TL;DR: ShowTable是一个结合多模态大语言模型和扩散模型的创新表格可视化生成系统，通过渐进式自我纠正过程，将表格数据转化为美观且忠实的信息图表。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在需要深度推理、规划和精确数据到视觉映射的任务上表现不足，特别是在超越一般场景的创造性表格可视化任务中。为了突破这些限制，作者提出了创造性表格可视化这一新挑战性任务。

Method: 提出ShowTable管道，通过渐进式自我纠正过程协同多模态大语言模型和扩散模型。MLLM作为中央协调器，负责推理视觉计划和判断视觉错误以提供精炼指令，扩散模型执行MLLM的命令。还引入了三个自动化数据构建管道来训练不同模块。

Result: 实验表明，使用不同模型实例化的ShowTable管道显著优于基线方法，突显了其有效的多模态推理、生成和错误纠正能力。作者还创建了TableVisBench基准，包含800个挑战性实例和5个评估维度。

Conclusion: ShowTable成功解决了创造性表格可视化任务，通过MLLM和扩散模型的协同工作实现了高保真度的结果，为数据到视觉的精确映射提供了有效解决方案。

Abstract: While existing generation and unified models excel at general image generation, they struggle with tasks requiring deep reasoning, planning, and precise data-to-visual mapping abilities beyond general scenarios. To push beyond the existing limitations, we introduce a new and challenging task: creative table visualization, requiring the model to generate an infographic that faithfully and aesthetically visualizes the data from a given table. To address this challenge, we propose ShowTable, a pipeline that synergizes MLLMs with diffusion models via a progressive self-correcting process. The MLLM acts as the central orchestrator for reasoning the visual plan and judging visual errors to provide refined instructions, the diffusion execute the commands from MLLM, achieving high-fidelity results. To support this task and our pipeline, we introduce three automated data construction pipelines for training different modules. Furthermore, we introduce TableVisBench, a new benchmark with 800 challenging instances across 5 evaluation dimensions, to assess performance on this task. Experiments demonstrate that our pipeline, instantiated with different models, significantly outperforms baselines, highlighting its effective multi-modal reasoning, generation, and error correction capabilities.

</details>


### [168] [KlingAvatar 2.0 Technical Report](https://arxiv.org/abs/2512.13313)
*Kling Team,Jialu Chen,Yikang Ding,Zhixue Fang,Kun Gai,Yuan Gao,Kang He,Jingyun Hua,Boyuan Jiang,Mingming Lao,Xiaohan Li,Hui Liu,Jiwen Liu,Xiaoqiang Liu,Yuan Liu,Shun Lu,Yongsen Mao,Yingchao Shao,Huafeng Shi,Xiaoyu Shi,Peiqin Sun,Songlin Tang,Pengfei Wan,Chao Wang,Xuebo Wang,Haoxian Zhang,Yuanxing Zhang,Yan Zhou*

Main category: cs.CV

TL;DR: KlingAvatar 2.0是一个时空级联框架，通过蓝图关键帧生成和子片段细化，解决了长时高分辨率视频生成的效率、时间漂移和质量退化问题，并引入多模态专家提升跨模态指令对齐。


<details>
  <summary>Details</summary>
Motivation: 现有头像视频生成模型在生成长时高分辨率视频时存在效率低下、时间漂移、质量退化和提示跟随弱的问题，需要一种能同时提升时空分辨率和跨模态对齐的方法。

Method: 提出时空级联框架：首先生成低分辨率蓝图视频关键帧捕获全局语义和运动，然后采用首尾帧策略细化为高分辨率时序连贯的子片段。引入包含三个模态专家的协同推理导演进行跨模态指令融合，以及负面导演优化负面提示。扩展框架支持ID特定的多角色控制。

Result: 实验表明模型能高效生成多模态对齐的长时高分辨率视频，具有增强的视觉清晰度、逼真的唇齿渲染与准确口型同步、强身份保持和连贯的多模态指令跟随能力。

Conclusion: KlingAvatar 2.0通过时空级联架构和多模态专家系统，有效解决了长时高分辨率头像视频生成的关键挑战，实现了高质量、高效率的多模态对齐视频生成。

Abstract: Avatar video generation models have achieved remarkable progress in recent years. However, prior work exhibits limited efficiency in generating long-duration high-resolution videos, suffering from temporal drifting, quality degradation, and weak prompt following as video length increases. To address these challenges, we propose KlingAvatar 2.0, a spatio-temporal cascade framework that performs upscaling in both spatial resolution and temporal dimension. The framework first generates low-resolution blueprint video keyframes that capture global semantics and motion, and then refines them into high-resolution, temporally coherent sub-clips using a first-last frame strategy, while retaining smooth temporal transitions in long-form videos. To enhance cross-modal instruction fusion and alignment in extended videos, we introduce a Co-Reasoning Director composed of three modality-specific large language model (LLM) experts. These experts reason about modality priorities and infer underlying user intent, converting inputs into detailed storylines through multi-turn dialogue. A Negative Director further refines negative prompts to improve instruction alignment. Building on these components, we extend the framework to support ID-specific multi-character control. Extensive experiments demonstrate that our model effectively addresses the challenges of efficient, multimodally aligned long-form high-resolution video generation, delivering enhanced visual clarity, realistic lip-teeth rendering with accurate lip synchronization, strong identity preservation, and coherent multimodal instruction following.

</details>


### [169] [Improving Long-Tailed Object Detection with Balanced Group Softmax and Metric Learning](https://arxiv.org/abs/2511.16619)
*Satyam Gaba*

Main category: cs.CV

TL;DR: 该论文针对长尾分布下的2D目标检测问题，在LVISv1数据集上通过改进BAGS框架和引入度量学习，实现了24.5% mAP的新SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的目标检测面临长尾分布挑战，即大量类别只有少数实例。这种类别不平衡导致检测模型偏向频繁类别，在稀有类别上性能下降。论文旨在解决长尾2D目标检测问题。

Method: 采用两阶段Faster R-CNN架构，改进Balanced Group Softmax (BAGS)框架缓解类别不平衡。同时探索度量学习，生成类间分离、类内紧凑的特征嵌入，并使用k-NN进行推理以提升稀有类别分类性能。

Result: 在LVISv1数据集（1,203个类别，164,000张图像）上取得了24.5% mAP的新SOTA性能，超越了之前24.0%的基准。

Conclusion: 提出的改进BAGS框架和度量学习方法有效提升了长尾目标检测性能，特别是对稀有类别的处理能力，为长尾分布场景下的目标检测提供了有效解决方案。

Abstract: Object detection has been widely explored for class-balanced datasets such as COCO. However, real-world scenarios introduce the challenge of long-tailed distributions, where numerous categories contain only a few instances. This inherent class imbalance biases detection models towards the more frequent classes, degrading performance on rare categories. In this paper, we tackle the problem of long-tailed 2D object detection using the LVISv1 dataset, which consists of 1,203 categories and 164,000 images. We employ a two-stage Faster R-CNN architecture and propose enhancements to the Balanced Group Softmax (BAGS) framework to mitigate class imbalance. Our approach achieves a new state-of-the-art performance with a mean Average Precision (mAP) of 24.5%, surpassing the previous benchmark of 24.0%.
  Additionally, we hypothesize that tail class features may form smaller, denser clusters within the feature space of head classes, making classification challenging for regression-based classifiers. To address this issue, we explore metric learning to produce feature embeddings that are both well-separated across classes and tightly clustered within each class. For inference, we utilize a k-Nearest Neighbors (k-NN) approach to improve classification performance, particularly for rare classes. Our results demonstrate the effectiveness of these methods in advancing long-tailed object detection.

</details>


### [170] [Automated User Identification from Facial Thermograms with Siamese Networks](https://arxiv.org/abs/2512.13361)
*Elizaveta Prozorova,Anton Konev,Vladimir Faerman*

Main category: cs.CV

TL;DR: 该论文分析热成像技术用于基于面部热图进行生物特征识别，比较不同红外光谱范围，提出用于生物识别系统的热像仪关键要求，并使用孪生神经网络实现自动化识别，在专有数据集上达到约80%准确率。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的安全系统需要有效的生物特征识别技术，热成像技术能够提供与可见光不同的生理特征信息，且不受光照条件影响，但需要系统研究其在生物识别中的应用潜力和技术实现方法。

Method: 1. 比较分析近红外(NIR)、短波红外(SWIR)、中波红外(MWIR)和长波红外(LWIR)光谱范围；2. 定义热像仪的关键技术要求，包括传感器分辨率、热灵敏度和至少30Hz帧率；3. 提出使用孪生神经网络实现自动化识别过程；4. 在专有数据集上进行实验验证；5. 探索结合可见光和红外光谱的混合系统。

Result: 1. 提出的方法在专有数据集上达到约80%的识别准确率；2. 混合系统显示出克服单一模态局限性的潜力；3. 热成像技术被证明是开发可靠安全系统的有前景技术。

Conclusion: 热成像技术是生物特征识别的有效方法，特别是结合孪生神经网络和混合光谱系统时，能够为安全系统开发提供可靠的技术基础，具有实际应用价值。

Abstract: The article analyzes the use of thermal imaging technologies for biometric identification based on facial thermograms. It presents a comparative analysis of infrared spectral ranges (NIR, SWIR, MWIR, and LWIR). The paper also defines key requirements for thermal cameras used in biometric systems, including sensor resolution, thermal sensitivity, and a frame rate of at least 30 Hz. Siamese neural networks are proposed as an effective approach for automating the identification process. In experiments conducted on a proprietary dataset, the proposed method achieved an accuracy of approximately 80%. The study also examines the potential of hybrid systems that combine visible and infrared spectra to overcome the limitations of individual modalities. The results indicate that thermal imaging is a promising technology for developing reliable security systems.

</details>


### [171] [Unlocking Generalization in Polyp Segmentation with DINO Self-Attention "keys"](https://arxiv.org/abs/2512.13376)
*Carla Monteiro,Valentina Corbetta,Regina Beets-Tan,Luís F. Teixeira,Wilson Silva*

Main category: cs.CV

TL;DR: 提出基于DINO自注意力关键特征的息肉分割框架，在领域泛化和极端单领域泛化场景下实现SOTA性能，超越nnU-Net等传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习息肉分割方法泛化能力不足，尤其在数据受限或挑战性场景下表现不佳，且大多依赖复杂的任务特定架构。

Method: 利用DINO自注意力模块的"关键"特征，而非传统方法从ViT最深层提取token，结合简单的卷积解码器预测息肉掩码。

Result: 在多中心数据集上，通过领域泛化和极端单领域泛化两种严格协议验证，实现了最先进的性能，显著提升了泛化能力，特别是在数据稀缺和挑战性场景中。

Conclusion: 该框架通过利用DINO自注意力的内在鲁棒性，在避免息肉特定架构的情况下实现了优异的泛化性能，为医学图像分割提供了更通用的解决方案。

Abstract: Automatic polyp segmentation is crucial for improving the clinical identification of colorectal cancer (CRC). While Deep Learning (DL) techniques have been extensively researched for this problem, current methods frequently struggle with generalization, particularly in data-constrained or challenging settings. Moreover, many existing polyp segmentation methods rely on complex, task-specific architectures. To address these limitations, we present a framework that leverages the intrinsic robustness of DINO self-attention "key" features for robust segmentation. Unlike traditional methods that extract tokens from the deepest layers of the Vision Transformer (ViT), our approach leverages the key features of the self-attention module with a simple convolutional decoder to predict polyp masks, resulting in enhanced performance and better generalizability. We validate our approach using a multi-center dataset under two rigorous protocols: Domain Generalization (DG) and Extreme Single Domain Generalization (ESDG). Our results, supported by a comprehensive statistical analysis, demonstrate that this pipeline achieves state-of-the-art (SOTA) performance, significantly enhancing generalization, particularly in data-scarce and challenging scenarios. While avoiding a polyp-specific architecture, we surpass well-established models like nnU-Net and UM-Net. Additionally, we provide a systematic benchmark of the DINO framework's evolution, quantifying the specific impact of architectural advancements on downstream polyp segmentation performance.

</details>


### [172] [Beyond the Visible: Disocclusion-Aware Editing via Proxy Dynamic Graphs](https://arxiv.org/abs/2512.13392)
*Anran Qi,Changjian Li,Adrien Bousseau,Niloy J. Mitra*

Main category: cs.CV

TL;DR: 提出一种无需训练的图像转视频方法，通过可编辑的代理动态图分离运动规范与外观合成，实现用户对最终帧遮挡区域的可控生成


<details>
  <summary>Details</summary>
Motivation: 现有图像转视频方法虽然能生成合理运动，但难以同时实现可预测的关节运动并在新显露区域强制执行用户指定的内容

Method: 引入轻量级、用户可编辑的代理动态图（PDG）确定性地驱动部件运动，使用冻结的扩散先验合成跟随该运动的合理外观，通过运动流引导扩散作为运动着色器，利用PDG的可见性信息进行潜在空间合成

Result: 在关节物体、家具、车辆和可变形物体的图像转短视频生成中，相比最先进方法展现出明显优势，实现了可控关节运动和遮挡区域用户控制

Conclusion: 该方法将生成控制（宽松姿态和结构）与可预测控制（最终帧遮挡区域的外观规范）相结合，开创了新的图像转视频工作流程

Abstract: We address image-to-video generation with explicit user control over the final frame's disoccluded regions. Current image-to-video pipelines produce plausible motion but struggle to generate predictable, articulated motions while enforcing user-specified content in newly revealed areas. Our key idea is to separate motion specification from appearance synthesis: we introduce a lightweight, user-editable Proxy Dynamic Graph (PDG) that deterministically yet approximately drives part motion, while a frozen diffusion prior is used to synthesize plausible appearance that follows that motion. In our training-free pipeline, the user loosely annotates and reposes a PDG, from which we compute a dense motion flow to leverage diffusion as a motion-guided shader. We then let the user edit appearance in the disoccluded areas of the image, and exploit the visibility information encoded by the PDG to perform a latent-space composite that reconciles motion with user intent in these areas. This design yields controllable articulation and user control over disocclusions without fine-tuning. We demonstrate clear advantages against state-of-the-art alternatives towards images turned into short videos of articulated objects, furniture, vehicles, and deformables. Our method mixes generative control, in the form of loose pose and structure, with predictable controls, in the form of appearance specification in the final frame in the disoccluded regions, unlocking a new image-to-video workflow. Code will be released on acceptance. Project page: https://anranqi.github.io/beyondvisible.github.io/

</details>


### [173] [rNCA: Self-Repairing Segmentation Masks](https://arxiv.org/abs/2512.13397)
*Malte Silbernagel,Albert Alonso,Jens Petersen,Bulat Ibragimov,Marleen de Bruijne,Madeleine K. Wyburd*

Main category: cs.CV

TL;DR: 本文提出使用神经细胞自动机（NCA）作为分割掩码的细化机制，通过局部迭代更新修复拓扑错误，无需手工规则或专用架构。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型常产生碎片化或不连通的掩码输出，修复这些拓扑错误通常需要手工规则或特定任务架构，缺乏通用解决方案。

Method: 训练神经细胞自动机（NCA）作为细化机制（rNCA），使用不完美掩码和真实标签进行训练，仅依赖局部信息学习目标形状的结构特性，通过局部迭代更新修复分割掩码。

Result: 在视网膜血管分割中，Dice/clDice提升2-3%，Betti错误显著降低（β₀减少60%，β₁减少20%）；在心肌分割中，零样本设置下修复61.5%的断裂情况，ASSD和HD分别降低19%和16%。

Conclusion: 神经细胞自动机可作为有效且广泛适用的分割掩码细化器，能够修复不同基础分割模型和任务产生的常见拓扑错误，实现拓扑一致的结果。

Abstract: Accurately predicting topologically correct masks remains a difficult task for general segmentation models, which often produce fragmented or disconnected outputs. Fixing these artifacts typically requires hand-crafted refinement rules or architectures specialized to a particular task. Here, we show that Neural Cellular Automata (NCA) can be directly re-purposed as an effective refinement mechanism, using local, iterative updates guided by image context to repair segmentation masks. By training on imperfect masks and ground truths, the automaton learns the structural properties of the target shape while relying solely on local information. When applied to coarse, globally predicted masks, the learned dynamics progressively reconnect broken regions, prune loose fragments and converge towards stable, topologically consistent results. We show how refinement NCA (rNCA) can be easily applied to repair common topological errors produced by different base segmentation models and tasks: for fragmented retinal vessels, it yields 2-3% gains in Dice/clDice and improves Betti errors, reducing $β_0$ errors by 60% and $β_1$ by 20%; for myocardium, it repairs 61.5% of broken cases in a zero-shot setting while lowering ASSD and HD by 19% and 16%, respectively. This showcases NCA as effective and broadly applicable refiners.

</details>


### [174] [Computer vision training dataset generation for robotic environments using Gaussian splatting](https://arxiv.org/abs/2512.13411)
*Patryk Niżeniec,Marcin Iwanowski*

Main category: cs.CV

TL;DR: 提出一个用于机器人视觉任务的自动标注数据集生成流程，结合3D高斯泼溅和游戏引擎物理模拟，通过两阶段渲染增强真实感，并采用混合训练策略提升检测和分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决合成数据与真实图像之间的领域差距问题，以及手动标注耗时耗力的瓶颈，为机器人视觉任务提供大规模、高真实感的自动标注数据集。

Method: 使用3D高斯泼溅创建真实环境表示，在游戏引擎中进行物理模拟生成自然布局，采用两阶段渲染技术结合泼溅真实感和代理网格生成的阴影图，自动生成像素级分割掩码，并设计混合训练策略结合少量真实图像和大量合成数据。

Result: 实验表明，混合训练策略（少量真实图像+大量合成数据）在目标检测和分割任务上表现最佳，证实这是实现鲁棒准确模型的高效优化策略。

Conclusion: 该流程成功解决了合成数据领域差距和标注瓶颈问题，为机器人视觉任务提供了一种高效生成大规模、高真实感自动标注数据集的方法，混合训练策略被证明是最优的模型训练方案。

Abstract: This paper introduces a novel pipeline for generating large-scale, highly realistic, and automatically labeled datasets for computer vision tasks in robotic environments. Our approach addresses the critical challenges of the domain gap between synthetic and real-world imagery and the time-consuming bottleneck of manual annotation. We leverage 3D Gaussian Splatting (3DGS) to create photorealistic representations of the operational environment and objects. These assets are then used in a game engine where physics simulations create natural arrangements. A novel, two-pass rendering technique combines the realism of splats with a shadow map generated from proxy meshes. This map is then algorithmically composited with the image to add both physically plausible shadows and subtle highlights, significantly enhancing realism. Pixel-perfect segmentation masks are generated automatically and formatted for direct use with object detection models like YOLO. Our experiments show that a hybrid training strategy, combining a small set of real images with a large volume of our synthetic data, yields the best detection and segmentation performance, confirming this as an optimal strategy for efficiently achieving robust and accurate models.

</details>


### [175] [USTM: Unified Spatial and Temporal Modeling for Continuous Sign Language Recognition](https://arxiv.org/abs/2512.13415)
*Ahmed Abul Hasanaath,Hamzah Luqman*

Main category: cs.CV

TL;DR: 提出统一时空建模框架USTM，使用Swin Transformer骨干网络结合轻量级时间适配器，在连续手语识别任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有连续手语识别方法通常依赖CNN空间骨干网络结合时间卷积或循环模块，这些方法难以捕捉细粒度的手部和面部线索，且无法建模长程时间依赖关系

Method: 提出统一时空建模框架USTM，采用Swin Transformer作为空间骨干网络，结合轻量级时间适配器与位置嵌入，能够同时捕捉细粒度空间特征和短长期时间上下文

Result: 在PHOENIX14、PHOENIX14T和CSL-Daily等基准数据集上，USTM在RGB-based和多模态CSLR方法中达到最先进性能，与多流方法相比保持竞争力

Conclusion: USTM框架在连续手语识别任务中表现出色，能够仅从RGB视频中实现鲁棒的手语识别，无需多流输入或辅助模态

Abstract: Continuous sign language recognition (CSLR) requires precise spatio-temporal modeling to accurately recognize sequences of gestures in videos. Existing frameworks often rely on CNN-based spatial backbones combined with temporal convolution or recurrent modules. These techniques fail in capturing fine-grained hand and facial cues and modeling long-range temporal dependencies. To address these limitations, we propose the Unified Spatio-Temporal Modeling (USTM) framework, a spatio-temporal encoder that effectively models complex patterns using a combination of a Swin Transformer backbone enhanced with lightweight temporal adapter with positional embeddings (TAPE). Our framework captures fine-grained spatial features alongside short and long-term temporal context, enabling robust sign language recognition from RGB videos without relying on multi-stream inputs or auxiliary modalities. Extensive experiments on benchmarked datasets including PHOENIX14, PHOENIX14T, and CSL-Daily demonstrate that USTM achieves state-of-the-art performance against RGB-based as well as multi-modal CSLR approaches, while maintaining competitive performance against multi-stream approaches. These results highlight the strength and efficacy of the USTM framework for CSLR. The code is available at https://github.com/gufranSabri/USTM

</details>


### [176] [Learning to Generate Cross-Task Unexploitable Examples](https://arxiv.org/abs/2512.13416)
*Haoxuan Qu,Qiuchi Xiang,Yujun Cai,Yirui Wu,Majid Mirmehdi,Hossein Rahmani,Jun Liu*

Main category: cs.CV

TL;DR: 提出MCT-UEG框架，通过元跨任务训练生成广泛不可利用的个人图像，保护在线隐私


<details>
  <summary>Details</summary>
Motivation: 现有不可利用示例生成方法在实际应用中存在局限性，无法生成跨不同真实世界计算机视觉任务都广泛不可利用的示例，需要改进以提升实用性和隐私保护效果

Method: 提出MCT-UEG框架，核心是设计面向平坦最小值的元训练和测试方案，优化不可利用示例生成器，使其能有效产生广泛不可利用的示例

Result: 大量实验证明了该框架的有效性

Conclusion: 提出的MCT-UEG框架能够生成跨任务广泛不可利用的个人图像示例，提升了个人数据隐私保护的实用性

Abstract: Unexploitable example generation aims to transform personal images into their unexploitable (unlearnable) versions before they are uploaded online, thereby preventing unauthorized exploitation of online personal images. Recently, this task has garnered significant research attention due to its critical relevance to personal data privacy. Yet, despite recent progress, existing methods for this task can still suffer from limited practical applicability, as they can fail to generate examples that are broadly unexploitable across different real-world computer vision tasks. To deal with this problem, in this work, we propose a novel Meta Cross-Task Unexploitable Example Generation (MCT-UEG) framework. At the core of our framework, to optimize the unexploitable example generator for effectively producing broadly unexploitable examples, we design a flat-minima-oriented meta training and testing scheme. Extensive experiments show the efficacy of our framework.

</details>


### [177] [RecTok: Reconstruction Distillation along Rectified Flow](https://arxiv.org/abs/2512.13421)
*Qingyu Shi,Size Wu,Jinbin Bai,Kaidong Yu,Yujing Wang,Yunhai Tong,Xiangtai Li,Xuelong Li*

Main category: cs.CV

TL;DR: RecTok提出了一种新的视觉分词器方法，通过流语义蒸馏和重建对齐蒸馏技术，解决了高维潜在空间中重建保真度与生成质量之间的权衡问题，在保持语义丰富性的同时实现了更好的图像重建和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有视觉分词器在潜在空间维度与生成质量之间存在根本性权衡，高维分词器性能通常不如低维版本。虽然近期工作利用视觉基础模型增强语义，但高维分词器仍然表现不佳。

Method: 提出RecTok方法，包含两个关键创新：1) 流语义蒸馏：将视觉基础模型的语义信息蒸馏到流匹配的前向流轨迹中；2) 重建对齐蒸馏：引入掩码特征重建损失进一步增强语义。

Result: 在gFID-50K基准测试中，无论是否使用分类器自由引导设置，都取得了最先进的结果。随着潜在维度增加，性能持续提升，同时保持了语义丰富的潜在空间结构。

Conclusion: RecTok通过创新的蒸馏方法成功克服了高维视觉分词器的局限性，实现了优越的图像重建、生成质量和判别性能，为扩散模型提供了更强大的视觉分词器解决方案。

Abstract: Visual tokenizers play a crucial role in diffusion models. The dimensionality of latent space governs both reconstruction fidelity and the semantic expressiveness of the latent feature. However, a fundamental trade-off is inherent between dimensionality and generation quality, constraining existing methods to low-dimensional latent spaces. Although recent works have leveraged vision foundation models to enrich the semantics of visual tokenizers and accelerate convergence, high-dimensional tokenizers still underperform their low-dimensional counterparts. In this work, we propose RecTok, which overcomes the limitations of high-dimensional visual tokenizers through two key innovations: flow semantic distillation and reconstruction--alignment distillation. Our key insight is to make the forward flow in flow matching semantically rich, which serves as the training space of diffusion transformers, rather than focusing on the latent space as in previous works. Specifically, our method distills the semantic information in VFMs into the forward flow trajectories in flow matching. And we further enhance the semantics by introducing a masked feature reconstruction loss. Our RecTok achieves superior image reconstruction, generation quality, and discriminative performance. It achieves state-of-the-art results on the gFID-50K under both with and without classifier-free guidance settings, while maintaining a semantically rich latent space structure. Furthermore, as the latent dimensionality increases, we observe consistent improvements. Code and model are available at https://shi-qingyu.github.io/rectok.github.io.

</details>


### [178] [MineTheGap: Automatic Mining of Biases in Text-to-Image Models](https://arxiv.org/abs/2512.13427)
*Noa Cohen,Nurit Spingarn-Eliezer,Inbar Huberman-Spiegelglas,Tomer Michaeli*

Main category: cs.CV

TL;DR: 提出MineTheGap方法，通过遗传算法自动挖掘导致文本到图像模型生成偏见输出的提示词，使用新颖的偏见评分来量化偏见的严重程度。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型在处理模糊提示时表现出偏见，这些偏见可能产生社会影响（如职业与种族的刻板印象）并影响用户体验（生成冗余而非多样化的图像）。现有方法仅能检测给定提示的偏见，而无法主动发现导致偏见的提示。

Method: 提出MineTheGap方法，利用遗传算法迭代优化提示池，寻找能暴露模型偏见的提示。该方法使用新颖的偏见评分来驱动优化过程，该评分通过比较生成图像的分布与LLM生成的提示变体文本分布来计算。

Result: 方法在已知偏见的数据集上验证了偏见评分的有效性，能够根据偏见的严重程度对偏见进行排序。代码和示例已在项目网页上提供。

Conclusion: MineTheGap能够自动挖掘导致TTI模型产生偏见输出的提示，超越了单纯的偏见检测，为理解和缓解文本到图像模型的偏见提供了有效工具。

Abstract: Text-to-Image (TTI) models generate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages a genetic algorithm to iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novel bias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution of LLM-generated texts that constitute variations on the prompt. Code and examples are available on the project's webpage.

</details>


### [179] [A Domain-Adapted Lightweight Ensemble for Resource-Efficient Few-Shot Plant Disease Classification](https://arxiv.org/abs/2512.13428)
*Anika Islam,Tasfia Tahsin,Zaarin Anjum,Md. Bakhtiar Hasan,Md. Hasanul Kabir*

Main category: cs.CV

TL;DR: 提出轻量级少样本学习框架，结合MobileNet特征提取、特征融合和注意力增强Bi-LSTM分类器，用于资源受限环境下的植物叶片病害识别


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖大规模标注数据和计算密集型模型，不适用于数据稀缺和资源受限的农业环境，需要开发轻量高效的少样本学习方案

Method: 使用领域适应的MobileNetV2/V3作为特征提取器，结合特征融合技术生成鲁棒特征表示，通过注意力机制增强的Bi-LSTM分类器捕获序列依赖关系

Result: 在PlantVillage数据集上15-shot达到98.23%准确率，接近SOTA的99.98%；在真实场景Dhan Shomadhan数据集上15-shot达到69.28%；模型仅40MB大小，计算复杂度约1.12GFLOPs

Conclusion: 该框架为数据稀缺地区提供了可扩展、移动就绪的植物病害诊断基础，在保持轻量化的同时实现了接近SOTA的性能

Abstract: Accurate and timely identification of plant leaf diseases is essential for resilient and sustainable agriculture, yet most deep learning approaches rely on large annotated datasets and computationally intensive models that are unsuitable for data-scarce and resource-constrained environments. To address these challenges we present a few-shot learning approach within a lightweight yet efficient framework that combines domain-adapted MobileNetV2 and MobileNetV3 models as feature extractors, along with a feature fusion technique to generate robust feature representation. For the classification task, the fused features are passed through a Bi-LSTM classifier enhanced with attention mechanisms to capture sequential dependencies and focus on the most relevant features, thereby achieving optimal classification performance even in complex, real-world environments with noisy or cluttered backgrounds. The proposed framework was evaluated across multiple experimental setups, including both laboratory-controlled and field-captured datasets. On tomato leaf diseases from the PlantVillage dataset, it consistently improved performance across 1 to 15 shot scenarios, reaching 98.23+-0.33% at 15 shot, closely approaching the 99.98% SOTA benchmark achieved by a Transductive LSTM with attention, while remaining lightweight and mobile-friendly. Under real-world conditions using field images from the Dhan Shomadhan dataset, it maintained robust performance, reaching 69.28+-1.49% at 15-shot and demonstrating strong resilience to complex backgrounds. Notably, it also outperformed the previous SOTA accuracy of 96.0% on six diseases from PlantVillage, achieving 99.72% with only 15-shot learning. With a compact model size of approximately 40 MB and inference complexity of approximately 1.12 GFLOPs, this work establishes a scalable, mobile-ready foundation for precise plant disease diagnostics in data-scarce regions.

</details>


### [180] [IMILIA: interpretable multiple instance learning for inflammation prediction in IBD from H&E whole slide images](https://arxiv.org/abs/2512.13440)
*Thalyssa Baiocco-Rodrigues,Antoine Olivier,Reda Belbahri,Thomas Duboudin,Pierre-Antoine Bannier,Benjamin Adjadj,Katharina Von Loga,Nathan Noiry,Maxime Touzot,Hector Roux de Bezieux*

Main category: cs.CV

TL;DR: IMILIA是一个端到端框架，使用多示例学习预测IBD组织切片中的炎症存在，并通过可解释性模块自动计算驱动预测的组织区域标记物。


<details>
  <summary>Details</summary>
Motivation: 随着IBD治疗目标转向组织学缓解，准确评估微观炎症对于评估疾病活动性和治疗反应变得至关重要。需要自动化工具来预测炎症存在并解释预测结果。

Method: IMILIA包含炎症预测模块（基于多示例学习的模型）和可解释性模块（包括HistoPLUS用于细胞检测、分割和分类，以及EpiSeg用于上皮分割）。

Result: 在发现队列中获得交叉验证ROC-AUC 0.83，在两个外部验证队列中分别获得0.99和0.84。可解释性模块显示高预测分数区域免疫细胞密度增加，低分数区域主要为正常上皮细胞。

Conclusion: IMILIA能够准确预测IBD组织切片中的炎症存在，并提供生物学一致的可解释性结果，有助于IBD的微观炎症评估和治疗监测。

Abstract: As the therapeutic target for Inflammatory Bowel Disease (IBD) shifts toward histologic remission, the accurate assessment of microscopic inflammation has become increasingly central for evaluating disease activity and response to treatment. In this work, we introduce IMILIA (Interpretable Multiple Instance Learning for Inflammation Analysis), an end-to-end framework designed for the prediction of inflammation presence in IBD digitized slides stained with hematoxylin and eosin (H&E), followed by the automated computation of markers characterizing tissue regions driving the predictions. IMILIA is composed of an inflammation prediction module, consisting of a Multiple Instance Learning (MIL) model, and an interpretability module, divided in two blocks: HistoPLUS, for cell instance detection, segmentation and classification; and EpiSeg, for epithelium segmentation. IMILIA achieves a cross-validation ROC-AUC of 0.83 on the discovery cohort, and a ROC-AUC of 0.99 and 0.84 on two external validation cohorts. The interpretability module yields biologically consistent insights: tiles with higher predicted scores show increased densities of immune cells (lymphocytes, plasmocytes, neutrophils and eosinophils), whereas lower-scored tiles predominantly contain normal epithelial cells. Notably, these patterns were consistent across all datasets. Code and models to partially replicate the results on the public IBDColEpi dataset can be found at https://github.com/owkin/imilia.

</details>


### [181] [Test-Time Modification: Inverse Domain Transformation for Robust Perception](https://arxiv.org/abs/2512.13454)
*Arpit Jadon,Joshua Niemeijer,Yuki M. Asano*

Main category: cs.CV

TL;DR: 提出一种测试时域泛化方法，利用扩散模型将目标域图像映射回源域分布，无需大规模合成数据生成，在未知目标分布下实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 生成式基础模型包含广泛的视觉知识并能产生多样化的图像变体，但用于训练数据增强时合成全面的目标域变体仍然缓慢、昂贵且不完整

Method: 在测试时使用扩散模型将目标图像映射回源域分布，仅需源域描述，保留任务模型，无需大规模合成数据生成

Result: 在分割、检测和分类任务中，面对真实到真实的域泛化场景和未知目标分布，实现一致改进：BDD100K-Night相对提升137%，ImageNet-R提升68%，DarkZurich提升62%

Conclusion: 测试时使用扩散模型进行域映射是一种有效的域泛化方法，无需大规模数据合成，在多种任务和模型上均能显著提升性能

Abstract: Generative foundation models contain broad visual knowledge and can produce diverse image variations, making them particularly promising for advancing domain generalization tasks. While they can be used for training data augmentation, synthesizing comprehensive target-domain variations remains slow, expensive, and incomplete. We propose an alternative: using diffusion models at test time to map target images back to the source distribution where the downstream model was trained. This approach requires only a source domain description, preserves the task model, and eliminates large-scale synthetic data generation. We demonstrate consistent improvements across segmentation, detection, and classification tasks under challenging environmental shifts in real-to-real domain generalization scenarios with unknown target distributions. Our analysis spans multiple generative and downstream models, including an ensemble variant for enhanced robustness. The method achieves substantial relative gains: 137% on BDD100K-Night, 68% on ImageNet-R, and 62% on DarkZurich.

</details>


### [182] [PoseAnything: Universal Pose-guided Video Generation with Part-aware Temporal Coherence](https://arxiv.org/abs/2512.13465)
*Ruiyan Wang,Teng Hu,Kaihui Huang,Zihan Su,Ran Yi,Lizhuang Ma*

Main category: cs.CV

TL;DR: PoseAnything：首个通用姿态引导视频生成框架，支持人类和非人类角色，通过部件感知时序一致性模块和运动解耦CFG实现精细控制，并发布了高质量非人类姿态数据集。


<details>
  <summary>Details</summary>
Motivation: 现有姿态引导视频生成方法仅支持人类姿态输入，对其他主体（如动物、虚构角色）的泛化能力差，限制了应用范围。

Method: 1. 提出通用框架PoseAnything，支持任意骨骼输入；2. 引入部件感知时序一致性模块，通过部件划分和跨帧注意力保持细粒度一致性；3. 提出主体与相机运动解耦CFG，首次实现独立相机运动控制；4. 发布XPose数据集（5万非人类姿态-视频对）及自动化标注流程。

Result: PoseAnything在效果和泛化能力上显著优于现有方法，能够处理人类和非人类角色，实现精细的姿态控制和独立的相机运动。

Conclusion: 该工作突破了姿态引导视频生成的局限性，实现了通用姿态控制，为动画制作等应用提供了更强大的工具。

Abstract: Pose-guided video generation refers to controlling the motion of subjects in generated video through a sequence of poses. It enables precise control over subject motion and has important applications in animation. However, current pose-guided video generation methods are limited to accepting only human poses as input, thus generalizing poorly to pose of other subjects. To address this issue, we propose PoseAnything, the first universal pose-guided video generation framework capable of handling both human and non-human characters, supporting arbitrary skeletal inputs. To enhance consistency preservation during motion, we introduce Part-aware Temporal Coherence Module, which divides the subject into different parts, establishes part correspondences, and computes cross-attention between corresponding parts across frames to achieve fine-grained part-level consistency. Additionally, we propose Subject and Camera Motion Decoupled CFG, a novel guidance strategy that, for the first time, enables independent camera movement control in pose-guided video generation, by separately injecting subject and camera motion control information into the positive and negative anchors of CFG. Furthermore, we present XPose, a high-quality public dataset containing 50,000 non-human pose-video pairs, along with an automated pipeline for annotation and filtering. Extensive experiments demonstrate that Pose-Anything significantly outperforms state-of-the-art methods in both effectiveness and generalization.

</details>


### [183] [Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10$\times$](https://arxiv.org/abs/2512.13492)
*Jiangning Zhang,Junwei Zhu,Teng Hu,Yabiao Wang,Donghao Luo,Weijian Cao,Zhenye Gan,Xiaobin Hu,Zhucun Xue,Chengjie Wang*

Main category: cs.CV

TL;DR: T3-Video提出了一种Transformer改造策略，通过优化前向逻辑而非改变架构，显著降低4K视频生成的计算需求，实现10倍加速同时提升质量。


<details>
  <summary>Details</summary>
Motivation: 原生4K视频生成面临计算复杂度爆炸式增长的挑战，因为时空分辨率增加会导致全注意力机制的二次计算开销，现有模型难以在效率和质量之间取得平衡。

Method: 提出T3（Transform Trained Transformer）策略，不改变预训练模型的核心架构，而是优化其前向逻辑。具体包括：多尺度权重共享窗口注意力机制、分层分块以及轴保持全注意力设计，实现"注意力模式"转换。

Result: 在4K-VBench上，T3-Video显著优于现有方法：VQA提升4.29分，VTC提升0.08分，同时将原生4K视频生成加速超过10倍。

Conclusion: T3策略通过优化预训练模型的前向逻辑而非改变架构，成功解决了4K视频生成的计算效率与质量平衡问题，为高分辨率视频生成提供了有效的解决方案。

Abstract: Native 4K (2160$\times$3840) video generation remains a critical challenge due to the quadratic computational explosion of full-attention as spatiotemporal resolution increases, making it difficult for models to strike a balance between efficiency and quality. This paper proposes a novel Transformer retrofit strategy termed $\textbf{T3}$ ($\textbf{T}$ransform $\textbf{T}$rained $\textbf{T}$ransformer) that, without altering the core architecture of full-attention pretrained models, significantly reduces compute requirements by optimizing their forward logic. Specifically, $\textbf{T3-Video}$ introduces a multi-scale weight-sharing window attention mechanism and, via hierarchical blocking together with an axis-preserving full-attention design, can effect an "attention pattern" transformation of a pretrained model using only modest compute and data. Results on 4K-VBench show that $\textbf{T3-Video}$ substantially outperforms existing approaches: while delivering performance improvements (+4.29$\uparrow$ VQA and +0.08$\uparrow$ VTC), it accelerates native 4K video generation by more than 10$\times$. Project page at https://zhangzjn.github.io/projects/T3-Video

</details>


### [184] [Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation](https://arxiv.org/abs/2512.13495)
*Jiangning Zhang,Junwei Zhu,Zhenye Gan,Donghao Luo,Chuming Lin,Feifan Xu,Xu Peng,Jianlong Hu,Yuansen Liu,Yijia Hong,Weijian Cao,Han Feng,Xu Chen,Chencan Fu,Keke He,Xiaobin Hu,Chengjie Wang*

Main category: cs.CV

TL;DR: Soul是一个多模态驱动的数字人生成框架，能从单张肖像、文本提示和音频生成语义连贯的长时视频，实现精确唇同步、生动表情和稳定身份保持。


<details>
  <summary>Details</summary>
Motivation: 解决当前数字人生成中数据稀缺、长时一致性差、唇同步不精确、身份保持不稳定的问题，为虚拟主播、影视制作等实际应用提供高质量解决方案。

Method: 基于Wan2.2-5B骨干网络，集成音频注入层和多训练策略，采用阈值感知码本替换确保长时一致性；使用步长/CFG蒸馏和轻量VAE优化推理效率；构建Soul-1M百万级标注数据集和Soul-Bench评估基准。

Result: 在视频质量、视频-文本对齐、身份保持和唇同步准确性上显著优于当前领先的开源和商业模型，推理速度提升11.4倍且质量损失可忽略，在虚拟主播、影视制作等场景中展示广泛适用性。

Conclusion: Soul框架通过创新的多模态驱动方法、大规模数据集构建和高效推理优化，实现了高质量、长时一致的数字人生成，为实际应用提供了强大工具。

Abstract: We propose a multimodal-driven framework for high-fidelity long-term digital human animation termed $\textbf{Soul}$, which generates semantically coherent videos from a single-frame portrait image, text prompts, and audio, achieving precise lip synchronization, vivid facial expressions, and robust identity preservation. We construct Soul-1M, containing 1 million finely annotated samples with a precise automated annotation pipeline (covering portrait, upper-body, full-body, and multi-person scenes) to mitigate data scarcity, and we carefully curate Soul-Bench for comprehensive and fair evaluation of audio-/text-guided animation methods. The model is built on the Wan2.2-5B backbone, integrating audio-injection layers and multiple training strategies together with threshold-aware codebook replacement to ensure long-term generation consistency. Meanwhile, step/CFG distillation and a lightweight VAE are used to optimize inference efficiency, achieving an 11.4$\times$ speedup with negligible quality loss. Extensive experiments show that Soul significantly outperforms current leading open-source and commercial models on video quality, video-text alignment, identity preservation, and lip-synchronization accuracy, demonstrating broad applicability in real-world scenarios such as virtual anchors and film production. Project page at https://zhangzjn.github.io/projects/Soul/

</details>


### [185] [Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model](https://arxiv.org/abs/2512.13507)
*Siyan Chen,Yanfei Chen,Ying Chen,Zhuo Chen,Feng Cheng,Xuyan Chi,Jian Cong,Qinpeng Cui,Qide Dong,Junliang Fan,Jing Fang,Zetao Fang,Chengjian Feng,Han Feng,Mingyuan Gao,Yu Gao,Qiushan Guo,Boyang Hao,Qingkai Hao,Bibo He,Qian He,Tuyen Hoang,Ruoqing Hu,Xi Hu,Weilin Huang,Zhaoyang Huang,Zhongyi Huang,Siqi Jiang,Wei Jiang,Yunpu Jiang,Zhuo Jiang,Ashley Kim,Jianan Kong,Zhichao Lai,Shanshan Lao,Ai Li,Feiya Li,Gen Li,Huixia Li,JiaShi Li,Liang Li,Ming Li,Tao Li,Xian Li,Xiaojie Li,Xiaoyang Li,Xingxing Li,Yameng Li,Yifu Li,Yiying Li,Chao Liang,Ying Liang,Zhiqiang Liang,Wang Liao,Yalin Liao,Heng Lin,Kengyu Lin,Shanchuan Lin,Xi Lin,Zhijie Lin,Feng Ling,Fangfang Liu,Gaohong Liu,Jiawei Liu,Jie Liu,Shouda Liu,Shu Liu,Sichao Liu,Songwei Liu,Xin Liu,Xue Liu,Yibo Liu,Zikun Liu,Zuxi Liu,Junlin Lyu,Lecheng Lyu,Qian Lyu,Han Mu,Xiaonan Nie,Jingzhe Ning,Xitong Pan,Yanghua Peng,Lianke Qin,Xueqiong Qu,Yuxi Ren,Yuchen Shen,Guang Shi,Lei Shi,Yan Song,Yinglong Song,Fan Sun,Li Sun,Renfei Sun,Zeyu Sun,Wenjing Tang,Zirui Tao,Feng Wang,Furui Wang,Jinran Wang,Junkai Wang,Ke Wang,Kexin Wang,Qingyi Wang,Rui Wang,Sen Wang,Shuai Wang,Tingru Wang,Weichen Wang,Xin Wang,Yanhui Wang,Yue Wang,Yuping Wang,Yuxuan Wang,Ziyu Wang,Guoqiang Wei,Wanru Wei,Di Wu,Guohong Wu,Hanjie Wu,Jian Wu,Jie Wu,Ruolan Wu,Xinglong Wu,Yonghui Wu,Ruiqi Xia,Liang Xiang,Fei Xiao,XueFeng Xiao,Pan Xie,Shuangyi Xie,Shuang Xu,Jinlan Xue,Bangbang Yang,Ceyuan Yang,Jiaqi Yang,Runkai Yang,Tao Yang,Yang Yang,Yihang Yang,ZhiXian Yang,Ziyan Yang,Yifan Yao,Zilyu Ye,Bowen Yu,Chujie Yuan,Linxiao Yuan,Sichun Zeng,Weihong Zeng,Xuejiao Zeng,Yan Zeng,Chuntao Zhang,Heng Zhang,Jingjie Zhang,Kuo Zhang,Liang Zhang,Liying Zhang,Manlin Zhang,Ting Zhang,Weida Zhang,Xiaohe Zhang,Xinyan Zhang,Yan Zhang,Yuan Zhang,Zixiang Zhang,Fengxuan Zhao,Huating Zhao,Yang Zhao,Hao Zheng,Jianbin Zheng,Xiaozheng Zheng,Yangyang Zheng,Yijie Zheng,Jiexin Zhou,Kuan Zhu,Shenhan Zhu,Wenjia Zhu,Benhui Zou,Feilong Zuo*

Main category: cs.CV

TL;DR: Seedance 1.5 pro是一个用于原生联合音频-视频生成的基础模型，采用双分支Diffusion Transformer架构，通过跨模态联合模块和多阶段数据管道实现卓越的视听同步和生成质量，并经过SFT和RLHF优化，推理速度提升10倍以上。


<details>
  <summary>Details</summary>
Motivation: 视频生成领域的最新进展为统一的视听生成铺平了道路。本研究旨在开发一个专门用于原生、联合音频-视频生成的基础模型，解决视听同步、生成质量和实际应用中的挑战。

Method: 采用双分支Diffusion Transformer架构，集成跨模态联合模块和专门的多阶段数据管道。通过监督微调(SFT)在高质量数据集上进行训练，并使用多维度奖励模型进行人类反馈强化学习(RLHF)。还引入了加速框架以提升推理速度。

Result: 模型实现了卓越的音频-视频同步和优越的生成质量。推理速度提升超过10倍。具备精确的多语言和方言口型同步、动态电影摄像机控制和增强的叙事连贯性，成为专业级内容创作的强大引擎。

Conclusion: Seedance 1.5 pro作为一个强大的视听生成基础模型，通过创新的架构设计、精细的训练优化和显著的性能提升，为专业级内容创作提供了可靠的解决方案，现已可在火山引擎平台上访问使用。

Abstract: Recent strides in video generation have paved the way for unified audio-visual generation. In this work, we present Seedance 1.5 pro, a foundational model engineered specifically for native, joint audio-video generation. Leveraging a dual-branch Diffusion Transformer architecture, the model integrates a cross-modal joint module with a specialized multi-stage data pipeline, achieving exceptional audio-visual synchronization and superior generation quality. To ensure practical utility, we implement meticulous post-training optimizations, including Supervised Fine-Tuning (SFT) on high-quality datasets and Reinforcement Learning from Human Feedback (RLHF) with multi-dimensional reward models. Furthermore, we introduce an acceleration framework that boosts inference speed by over 10X. Seedance 1.5 pro distinguishes itself through precise multilingual and dialect lip-syncing, dynamic cinematic camera control, and enhanced narrative coherence, positioning it as a robust engine for professional-grade content creation. Seedance 1.5 pro is now accessible on Volcano Engine at https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision?type=GenVideo.

</details>


### [186] [TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding](https://arxiv.org/abs/2512.13511)
*Piyush Bagad,Andrew Zisserman*

Main category: cs.CV

TL;DR: TARA是一种无需视频数据、通过适配多模态大语言模型来构建时间感知视频-文本嵌入模型的方法，在时间感知检索基准上表现优异，同时具备否定感知和动词/副词理解能力。


<details>
  <summary>Details</summary>
Motivation: 构建通用的时间感知视频-文本嵌入模型，解决现有模型在时间感知检索方面的不足，特别是对于时间上相反（手性）动作的区分能力。

Method: 提出TARA（时间感知检索适配）方法，在不使用任何视频数据的情况下，适配多模态大语言模型（MLLMs）为时间感知视频-文本嵌入模型。同时提出新的评估基准，包含时间上相反的动作作为困难负样本。

Result: TARA在新提出的手性基准上优于所有现有视频-文本模型，同时在标准基准上取得强劲结果。模型还展现出否定感知能力，并在视频中的动词和副词理解方面达到最先进水平。

Conclusion: TARA产生了一个强大、多功能、时间感知的视频-文本嵌入模型，具有最先进的零样本性能，不仅在时间感知检索方面表现出色，还具备额外的否定感知和语言理解能力。

Abstract: Our objective is to build a general time-aware video-text embedding model for retrieval. To that end, we propose a simple and efficient recipe, dubbed TARA (Time Aware Retrieval Adaptation), to adapt Multimodal LLMs (MLLMs) to a time-aware video-text embedding model without using any video data at all. For evaluating time-awareness in retrieval, we propose a new benchmark with temporally opposite (chiral) actions as hard negatives and curated splits for chiral and non-chiral actions. We show that TARA outperforms all existing video-text models on this chiral benchmark while also achieving strong results on standard benchmarks. Furthermore, we discover additional benefits of TARA beyond time-awareness: (i) TARA embeddings are negation-aware as shown in NegBench benchmark that evaluates negation in video retrieval, (ii) TARA achieves state of the art performance on verb and adverb understanding in videos. Overall, TARA yields a strong, versatile, time-aware video-text embedding model with state of the art zero-shot performance.

</details>


### [187] [Pancakes: Consistent Multi-Protocol Image Segmentation Across Biomedical Domains](https://arxiv.org/abs/2512.13534)
*Marianne Rakic,Siyu Gai,Etienne Chollet,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: Pancakes框架能够自动为医学图像生成多种语义一致的分割协议，解决了现有模型只能处理单一协议或需要手动提示的问题。


<details>
  <summary>Details</summary>
Motivation: 生物医学图像可以根据不同应用需求进行多种有意义的分割（如组织类型、血管区域、解剖结构等），但现有自动分割模型要么只支持单一协议，要么需要大量人工提示来指定分割方式。

Method: 提出了Pancakes框架，引入新的问题表述，能够在未见过的领域图像上自动生成多个合理协议的多标签分割图，同时保持相关图像间的语义一致性。

Result: 在7个保留数据集上的实验表明，该模型在生成多个语义一致的整图分割方面显著优于现有基础模型。

Conclusion: Pancakes框架解决了现有基础模型无法实现的新问题，能够自动为医学图像生成多种语义一致的分割协议，具有重要的应用价值。

Abstract: A single biomedical image can be meaningfully segmented in multiple ways, depending on the desired application. For instance, a brain MRI can be segmented according to tissue types, vascular territories, broad anatomical regions, fine-grained anatomy, or pathology, etc. Existing automatic segmentation models typically either (1) support only a single protocol, the one they were trained on, or (2) require labor-intensive manual prompting to specify the desired segmentation. We introduce Pancakes, a framework that, given a new image from a previously unseen domain, automatically generates multi-label segmentation maps for multiple plausible protocols, while maintaining semantic consistency across related images. Pancakes introduces a new problem formulation that is not currently attainable by existing foundation models. In a series of experiments on seven held-out datasets, we demonstrate that our model can significantly outperform existing foundation models in producing several plausible whole-image segmentations, that are semantically coherent across images.

</details>


### [188] [3D Human-Human Interaction Anomaly Detection](https://arxiv.org/abs/2512.13560)
*Shun Maeda,Chunzhi Gu,Koichiro Kamide,Katsuya Hotta,Shangce Gao,Chao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新任务H2IAD（人-人交互异常检测），用于检测协作3D人体动作中的异常交互行为，并提出了IADNet模型，通过时间注意力共享模块和距离关系编码模块来捕捉人-人交互的时空动态。


<details>
  <summary>Details</summary>
Motivation: 现有的人体异常检测主要关注单个人的异常行为，但人类本质上是协作行动的，异常也可能出现在人-人交互中。现有的单人体异常检测模型无法有效捕捉交互的复杂不对称动态，导致检测准确率低。

Method: 提出了IADNet模型，包含两个核心模块：1）时间注意力共享模块（TASM），通过共享编码的运动嵌入来同步协作运动相关性；2）距离关系编码模块（DREM），捕捉两人之间的空间配置和社会线索。最后使用归一化流进行异常评分。

Result: 在人-人运动基准测试上的广泛实验表明，IADNet在H2IAD任务上优于现有的人体中心异常检测基线方法。

Conclusion: 本文定义了人-人交互异常检测这一新任务，并提出了有效的IADNet模型，能够更好地捕捉协作人体动作中的时空交互动态，为交互异常检测提供了新的解决方案。

Abstract: Human-centric anomaly detection (AD) has been primarily studied to specify anomalous behaviors in a single person. However, as humans by nature tend to act in a collaborative manner, behavioral anomalies can also arise from human-human interactions. Detecting such anomalies using existing single-person AD models is prone to low accuracy, as these approaches are typically not designed to capture the complex and asymmetric dynamics of interactions. In this paper, we introduce a novel task, Human-Human Interaction Anomaly Detection (H2IAD), which aims to identify anomalous interactive behaviors within collaborative 3D human actions. To address H2IAD, we then propose Interaction Anomaly Detection Network (IADNet), which is formalized with a Temporal Attention Sharing Module (TASM). Specifically, in designing TASM, we share the encoded motion embeddings across both people such that collaborative motion correlations can be effectively synchronized. Moreover, we notice that in addition to temporal dynamics, human interactions are also characterized by spatial configurations between two people. We thus introduce a Distance-Based Relational Encoding Module (DREM) to better reflect social cues in H2IAD. The normalizing flow is eventually employed for anomaly scoring. Extensive experiments on human-human motion benchmarks demonstrate that IADNet outperforms existing Human-centric AD baselines in H2IAD.

</details>


### [189] [MMhops-R1: Multimodal Multi-hop Reasoning](https://arxiv.org/abs/2512.13573)
*Tao Zhang,Ziqi Zhang,Zongyang Ma,Yuxin Chen,Bing Li,Chunfeng Yuan,Guangting Wang,Fengyun Rao,Ying Shan,Weiming Hu*

Main category: cs.CV

TL;DR: 提出MMhops基准测试和MMhops-R1框架，用于评估和提升多模态多跳推理能力，通过强化学习优化动态推理路径规划。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要局限于单步推理，缺乏评估多跳推理能力的复杂基准测试，无法应对需要跨模态整合外部知识的复杂现实挑战。

Method: 1) 提出MMhops基准测试，包含Bridging和Comparison两种任务格式；2) 提出MMhops-R1多模态检索增强生成框架，使用强化学习优化动态推理路径规划、查询生成和多级信息整合。

Result: MMhops-R1在MMhops基准测试上显著优于强基线模型，证明动态规划和多模态知识整合对复杂推理至关重要。该框架在固定跳数推理任务上也表现出良好的泛化能力。

Conclusion: 贡献了具有挑战性的新基准测试和强大的基线模型，将发布相关代码、数据和权重，推动多模态多跳推理这一关键领域的研究发展。

Abstract: The ability to perform multi-modal multi-hop reasoning by iteratively integrating information across various modalities and external knowledge is critical for addressing complex real-world challenges. However, existing Multi-modal Large Language Models (MLLMs) are predominantly limited to single-step reasoning, as existing benchmarks lack the complexity needed to evaluate and drive multi-hop abilities. To bridge this gap, we introduce MMhops, a novel, large-scale benchmark designed to systematically evaluate and foster multi-modal multi-hop reasoning. MMhops dataset comprises two challenging task formats, Bridging and Comparison, which necessitate that models dynamically construct complex reasoning chains by integrating external knowledge. To tackle the challenges posed by MMhops, we propose MMhops-R1, a novel multi-modal Retrieval-Augmented Generation (mRAG) framework for dynamic reasoning. Our framework utilizes reinforcement learning to optimize the model for autonomously planning reasoning paths, formulating targeted queries, and synthesizing multi-level information. Comprehensive experiments demonstrate that MMhops-R1 significantly outperforms strong baselines on MMhops, highlighting that dynamic planning and multi-modal knowledge integration are crucial for complex reasoning. Moreover, MMhops-R1 demonstrates strong generalization to tasks requiring fixed-hop reasoning, underscoring the robustness of our dynamic planning approach. In conclusion, our work contributes a challenging new benchmark and a powerful baseline model, and we will release the associated code, data, and weights to catalyze future research in this critical area.

</details>


### [190] [Lighting in Motion: Spatiotemporal HDR Lighting Estimation](https://arxiv.org/abs/2512.13597)
*Christophe Bolduc,Julien Philip,Li Ma,Mingming He,Paul Debevec,Jean-François Lalonde*

Main category: cs.CV

TL;DR: LiMo是一个基于扩散模型的时空光照估计方法，通过生成不同曝光下的镜面和漫反射球体来预测高细节光照，结合深度和几何条件进行空间控制，最终合成HDRI光照图。


<details>
  <summary>Details</summary>
Motivation: 现有光照估计方法难以同时实现真实的高频细节预测和准确的照度估计，需要一种能够同时处理这两个方面的时空光照估计方法。

Method: 1. 生成不同曝光下的镜面和漫反射球体；2. 在大规模定制数据集上微调现有扩散模型；3. 引入新的几何条件提供场景相对位置信息；4. 通过可微分渲染将不同曝光的预测组合成单个HDRI图。

Result: LiMo在空间控制和预测准确性方面达到最先进水平，能够同时实现高细节光照预测和准确照度估计。

Conclusion: LiMo通过创新的几何条件和多曝光球体生成方法，成功解决了时空光照估计中的细节和准确性平衡问题，为光照估计领域提供了新的解决方案。

Abstract: We present Lighting in Motion (LiMo), a diffusion-based approach to spatiotemporal lighting estimation. LiMo targets both realistic high-frequency detail prediction and accurate illuminance estimation. To account for both, we propose generating a set of mirrored and diffuse spheres at different exposures, based on their 3D positions in the input. Making use of diffusion priors, we fine-tune powerful existing diffusion models on a large-scale customized dataset of indoor and outdoor scenes, paired with spatiotemporal light probes. For accurate spatial conditioning, we demonstrate that depth alone is insufficient and we introduce a new geometric condition to provide the relative position of the scene to the target 3D position. Finally, we combine diffuse and mirror predictions at different exposures into a single HDRI map leveraging differentiable rendering. We thoroughly evaluate our method and design choices to establish LiMo as state-of-the-art for both spatial control and prediction accuracy.

</details>


### [191] [LongVie 2: Multimodal Controllable Ultra-Long Video World Model](https://arxiv.org/abs/2512.13604)
*Jianxiong Gao,Zhaoxi Chen,Xian Liu,Junhao Zhuang,Chengming Xu,Jianfeng Feng,Yu Qiao,Yanwei Fu,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: LongVie 2是一个端到端自回归视频世界模型框架，通过三阶段训练增强可控性、长期视觉质量和时序一致性，支持长达5分钟的视频生成。


<details>
  <summary>Details</summary>
Motivation: 基于预训练视频生成系统构建视频世界模型是实现通用时空智能的重要但具有挑战性的步骤。世界模型需要具备三个关键属性：可控性、长期视觉质量和时序一致性。

Method: 采用渐进式方法：1)多模态引导，整合稠密和稀疏控制信号提供隐式世界级监督；2)输入帧的退化感知训练，弥合训练与长期推理之间的差距；3)历史上下文引导，对齐相邻片段间的上下文信息以确保时序一致性。

Result: LongVie 2在长程可控性、时序一致性和视觉保真度方面达到最先进性能，支持长达5分钟的连续视频生成。同时提出了LongVGenBench基准，包含100个高分辨率一分钟视频。

Conclusion: LongVie 2在视频世界建模方面迈出了重要一步，通过三阶段训练框架有效解决了可控性、长期视觉质量和时序一致性的挑战，为统一的视频世界模型奠定了基础。

Abstract: Building video world models upon pretrained video generation systems represents an important yet challenging step toward general spatiotemporal intelligence. A world model should possess three essential properties: controllability, long-term visual quality, and temporal consistency. To this end, we take a progressive approach-first enhancing controllability and then extending toward long-term, high-quality generation. We present LongVie 2, an end-to-end autoregressive framework trained in three stages: (1) Multi-modal guidance, which integrates dense and sparse control signals to provide implicit world-level supervision and improve controllability; (2) Degradation-aware training on the input frame, bridging the gap between training and long-term inference to maintain high visual quality; and (3) History-context guidance, which aligns contextual information across adjacent clips to ensure temporal consistency. We further introduce LongVGenBench, a comprehensive benchmark comprising 100 high-resolution one-minute videos covering diverse real-world and synthetic environments. Extensive experiments demonstrate that LongVie 2 achieves state-of-the-art performance in long-range controllability, temporal coherence, and visual fidelity, and supports continuous video generation lasting up to five minutes, marking a significant step toward unified video world modeling.

</details>


### [192] [DBT-DINO: Towards Foundation model based analysis of Digital Breast Tomosynthesis](https://arxiv.org/abs/2512.13608)
*Felix J. Dorfner,Manon A. Dorster,Ryan Connolly,Oscar Gentilhomme,Edward Gibbs,Steven Graham,Seth Wander,Thomas Schultz,Manisha Bahl,Dania Daye,Albert E. Kim,Christopher P. Bridge*

Main category: cs.CV

TL;DR: 开发了首个数字乳腺断层合成（DBT）基础模型DBT-DINO，在乳腺密度分类和癌症风险预测任务上表现优异，但在病变检测任务上表现不一。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学影像中显示出潜力，但针对三维成像模态（如数字乳腺断层合成DBT）的研究仍不足。目前尚无DBT的基础模型，而DBT是乳腺癌筛查的重要工具。

Method: 采用DINOv2方法进行自监督预训练，使用了来自27,990名患者的487,975个DBT体积中的超过2500万个2D切片。评估了三个下游任务：乳腺密度分类（5000个筛查检查）、5年乳腺癌风险预测（106,417个筛查检查）和病变检测（393个标注体积）。

Result: 乳腺密度分类：DBT-DINO准确率0.79，优于MetaAI DINOv2基线（0.73）和DenseNet-121（0.74）。5年风险预测：DBT-DINO AUROC为0.78，与DINOv2的0.76无显著差异。病变检测：DINOv2平均灵敏度0.67高于DBT-DINO的0.62，但DBT-DINO在癌症病变检测上表现更好（78.8% vs 77.3%）。

Conclusion: DBT-DINO是首个DBT基础模型，在乳腺密度分类和癌症风险预测任务上表现强劲。但领域特定预训练在检测任务上效果不一，ImageNet基线在一般病变检测上优于DBT-DINO，表明局部检测任务需要进一步的方法开发。

Abstract: Foundation models have shown promise in medical imaging but remain underexplored for three-dimensional imaging modalities. No foundation model currently exists for Digital Breast Tomosynthesis (DBT), despite its use for breast cancer screening.
  To develop and evaluate a foundation model for DBT (DBT-DINO) across multiple clinical tasks and assess the impact of domain-specific pre-training.
  Self-supervised pre-training was performed using the DINOv2 methodology on over 25 million 2D slices from 487,975 DBT volumes from 27,990 patients. Three downstream tasks were evaluated: (1) breast density classification using 5,000 screening exams; (2) 5-year risk of developing breast cancer using 106,417 screening exams; and (3) lesion detection using 393 annotated volumes.
  For breast density classification, DBT-DINO achieved an accuracy of 0.79 (95\% CI: 0.76--0.81), outperforming both the MetaAI DINOv2 baseline (0.73, 95\% CI: 0.70--0.76, p<.001) and DenseNet-121 (0.74, 95\% CI: 0.71--0.76, p<.001). For 5-year breast cancer risk prediction, DBT-DINO achieved an AUROC of 0.78 (95\% CI: 0.76--0.80) compared to DINOv2's 0.76 (95\% CI: 0.74--0.78, p=.57). For lesion detection, DINOv2 achieved a higher average sensitivity of 0.67 (95\% CI: 0.60--0.74) compared to DBT-DINO with 0.62 (95\% CI: 0.53--0.71, p=.60). DBT-DINO demonstrated better performance on cancerous lesions specifically with a detection rate of 78.8\% compared to Dinov2's 77.3\%.
  Using a dataset of unprecedented size, we developed DBT-DINO, the first foundation model for DBT. DBT-DINO demonstrated strong performance on breast density classification and cancer risk prediction. However, domain-specific pre-training showed variable benefits on the detection task, with ImageNet baseline outperforming DBT-DINO on general lesion detection, indicating that localized detection tasks require further methodological development.

</details>


### [193] [Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models](https://arxiv.org/abs/2512.13609)
*Shweta Mahajan,Shreya Kadambi,Hoang Le,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

TL;DR: 提出Do-Undo任务和基准，用于评估视觉语言模型对物理动作驱动的场景变换的理解和生成能力，要求模型模拟物理动作的结果并准确反转，测试物理可逆性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型主要关注对象级编辑，缺乏对真实世界物理动作驱动的场景变换的理解。需要评估模型对物理因果关系和可逆性的理解，这对具身AI、机器人和物理感知生成模型至关重要。

Method: 从真实世界视频中构建大规模可逆动作数据集，设计训练策略以增强动作基础的一致性。Do-Undo任务要求模型先模拟物理动作的结果（Do阶段），然后准确反转该动作（Undo阶段）。

Result: 实验表明当前模型在物理可逆性方面表现不佳，突显了该任务的重要性。Do-Undo为评估和推进多模态系统中的物理推理提供了直观的测试平台。

Conclusion: Do-Undo填补了视觉语言模型在物理场景变换理解方面的关键空白，为物理推理评估提供了新基准，对具身AI、机器人和物理感知生成模型的发展具有重要意义。

Abstract: We introduce the Do-Undo task and benchmark to address a critical gap in vision-language models: understanding and generating physically plausible scene transformations driven by real-world actions. Unlike prior work focused on object-level edits, Do-Undo requires models to simulate the outcome of a physical action and then accurately reverse it, reflecting true cause-and-effect in the visual world. We curate a large-scale dataset of reversible actions from real-world videos and design a training strategy enforcing consistency for robust action grounding. Our experiments reveal that current models struggle with physical reversibility, underscoring the importance of this task for embodied AI, robotics, and physics-aware generative modeling. Do-Undo establishes an intuitive testbed for evaluating and advancing physical reasoning in multimodal systems.

</details>


### [194] [SCR2-ST: Combine Single Cell with Spatial Transcriptomics for Efficient Active Sampling via Reinforcement Learning](https://arxiv.org/abs/2512.13635)
*Junchao Zhu,Ruining Deng,Junlin Guo,Tianyuan Yao,Chongyu Qu,Juming Xiong,Siqi Lu,Zhengyi Lu,Yanfan Zhu,Marilyn Lionts,Yuechen Yang,Yalin Zheng,Yu Wang,Shilin Zhao,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: SCR2-ST是一个利用单细胞先验知识指导空间转录组学数据高效采集和准确预测的统一框架，通过强化学习主动采样和混合回归-检索网络提升采样效率和预测精度。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学(ST)技术昂贵且传统固定网格采样策略导致冗余测量，数据稀缺限制了现有方法。单细胞测序领域可提供丰富的生物学数据作为辅助来源来缓解这一限制。

Method: SCR2-ST整合了单细胞引导的强化学习主动采样(SCRL)和混合回归-检索预测网络(SCR2Net)。SCRL结合单细胞基础模型嵌入和空间密度信息构建生物学奖励信号，在有限测序预算下选择性采集信息丰富的组织区域。SCR2Net通过混合架构结合回归建模和检索增强推理，使用多数细胞类型过滤机制抑制噪声匹配，检索的表达谱作为软标签进行辅助监督。

Result: 在三个公共ST数据集上评估SCR2-ST，在采样效率和预测准确性方面均达到最先进性能，特别是在低预算场景下表现优异。

Conclusion: SCR2-ST通过有效利用单细胞先验知识，解决了空间转录组学数据采集昂贵和稀缺的问题，为高效数据获取和准确表达预测提供了统一解决方案。

Abstract: Spatial transcriptomics (ST) is an emerging technology that enables researchers to investigate the molecular relationships underlying tissue morphology. However, acquiring ST data remains prohibitively expensive, and traditional fixed-grid sampling strategies lead to redundant measurements of morphologically similar or biologically uninformative regions, thus resulting in scarce data that constrain current methods. The well-established single-cell sequencing field, however, could provide rich biological data as an effective auxiliary source to mitigate this limitation. To bridge these gaps, we introduce SCR2-ST, a unified framework that leverages single-cell prior knowledge to guide efficient data acquisition and accurate expression prediction. SCR2-ST integrates a single-cell guided reinforcement learning-based (SCRL) active sampling and a hybrid regression-retrieval prediction network SCR2Net. SCRL combines single-cell foundation model embeddings with spatial density information to construct biologically grounded reward signals, enabling selective acquisition of informative tissue regions under constrained sequencing budgets. SCR2Net then leverages the actively sampled data through a hybrid architecture combining regression-based modeling with retrieval-augmented inference, where a majority cell-type filtering mechanism suppresses noisy matches and retrieved expression profiles serve as soft labels for auxiliary supervision. We evaluated SCR2-ST on three public ST datasets, demonstrating SOTA performance in both sampling efficiency and prediction accuracy, particularly under low-budget scenarios. Code is publicly available at: https://github.com/hrlblab/SCR2ST

</details>


### [195] [MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning](https://arxiv.org/abs/2512.13636)
*Haoyu Fu,Diankun Zhang,Zongchuang Zhao,Jianfeng Cui,Hongwei Xie,Bing Wang,Guang Chen,Dingkang Liang,Xiang Bai*

Main category: cs.CV

TL;DR: MindDrive提出了一种VLA框架，通过LLM与双LoRA参数实现决策专家和动作专家的分离，将连续动作空间的强化学习问题转化为离散语言决策的探索，解决了自动驾驶中在线强化学习的探索效率问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的VLA范式主要依赖模仿学习，存在分布偏移和因果混淆问题。在线强化学习能通过试错学习解决这些问题，但在连续动作空间中探索效率低下，阻碍了其在VLA模型中的应用。

Method: 提出MindDrive框架：1）使用一个LLM配备两套不同的LoRA参数；2）决策专家负责场景推理和驾驶决策；3）动作专家将语言决策动态映射为可行轨迹；4）将轨迹级奖励反馈到推理空间，在有限离散语言决策空间进行试错学习。

Result: 在Bench2Drive基准测试中取得显著性能：驾驶评分78.04，成功率55.09%。这是首个证明在线强化学习在自动驾驶VLA模型中有效性的工作。

Conclusion: MindDrive通过将连续动作空间的强化学习转化为离散语言决策空间的探索，有效平衡了复杂场景的最优决策、类人驾驶行为和在线强化学习的高效探索，为自动驾驶VLA模型提供了新的强化学习范式。

Abstract: Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. MindDrive achieves strong closed-loop performance on the challenging Bench2Drive benchmark, with a Driving Score (DS) of 78.04 and a Success Rate (SR) of 55.09%. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.

</details>


### [196] [Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All](https://arxiv.org/abs/2512.13639)
*Michal Nazarczuk,Thomas Tanay,Arthur Moreau,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: 提出了一个用于新视角合成的高质量动态场景数据集，包含多模态标注和三种基准测试场景


<details>
  <summary>Details</summary>
Motivation: 现有数据集在视觉质量、动态场景覆盖和多模态标注方面存在不足，需要高质量、多样化的数据集来推动4D场景重建和新视角生成模型的发展

Method: 从高质量动画电影中生成数据集，提供RGB图像、深度、表面法线、物体分割和光流等多模态标注，并组织成密集多视角、稀疏视角和单目视频三种基准测试场景

Result: 创建了一个视觉丰富、标注质量高、实验设置多样的数据集，能够支持不同数据稀疏度下的新视角合成和3D视觉研究

Conclusion: 该数据集为推进视角合成和3D视觉领域的研究提供了独特资源，通过高质量动态场景和多模态标注支持更全面的模型训练和评估

Abstract: This paper presents a new dataset for Novel View Synthesis, generated from a high-quality, animated film with stunning realism and intricate detail. Our dataset captures a variety of dynamic scenes, complete with detailed textures, lighting, and motion, making it ideal for training and evaluating cutting-edge 4D scene reconstruction and novel view generation models. In addition to high-fidelity RGB images, we provide multiple complementary modalities, including depth, surface normals, object segmentation and optical flow, enabling a deeper understanding of scene geometry and motion. The dataset is organised into three distinct benchmarking scenarios: a dense multi-view camera setup, a sparse camera arrangement, and monocular video sequences, enabling a wide range of experimentation and comparison across varying levels of data sparsity. With its combination of visual richness, high-quality annotations, and diverse experimental setups, this dataset offers a unique resource for pushing the boundaries of view synthesis and 3D vision.

</details>


### [197] [Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency](https://arxiv.org/abs/2512.13665)
*Wenhan Chen,Sezer Karaoglu,Theo Gevers*

Main category: cs.CV

TL;DR: 提出Grab-3D框架，利用3D几何一致性检测AI生成视频，通过消失点分析几何模式差异，显著优于现有方法并具有跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成视频技术快速发展，AI生成的视频越来越逼真，迫切需要可靠的检测机制。现有检测方法对生成视频中的3D几何模式探索有限，而真实视频和AI生成视频在几何一致性上存在本质差异。

Method: 使用消失点作为3D几何模式的显式表示；构建静态场景的AI生成视频数据集以稳定提取3D几何特征；提出几何感知Transformer框架，包含几何位置编码、时空几何注意力和EMA几何分类器头，将3D几何意识显式注入时序建模。

Result: Grab-3D显著优于最先进的检测器，在未见过的生成器上展现出强大的跨域泛化能力。

Conclusion: 通过关注3D几何一致性，特别是利用消失点分析几何模式，能够有效区分真实和AI生成的视频，为视频真实性检测提供了新的几何感知视角。

Abstract: Recent advances in diffusion-based generation techniques enable AI models to produce highly realistic videos, heightening the need for reliable detection mechanisms. However, existing detection methods provide only limited exploration of the 3D geometric patterns present in generated videos. In this paper, we use vanishing points as an explicit representation of 3D geometry patterns, revealing fundamental discrepancies in geometric consistency between real and AI-generated videos. We introduce Grab-3D, a geometry-aware transformer framework for detecting AI-generated videos based on 3D geometric temporal consistency. To enable reliable evaluation, we construct an AI-generated video dataset of static scenes, allowing stable 3D geometric feature extraction. We propose a geometry-aware transformer equipped with geometric positional encoding, temporal-geometric attention, and an EMA-based geometric classifier head to explicitly inject 3D geometric awareness into temporal modeling. Experiments demonstrate that Grab-3D significantly outperforms state-of-the-art detectors, achieving robust cross-domain generalization to unseen generators.

</details>


### [198] [AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection](https://arxiv.org/abs/2512.13671)
*Junwen Miao,Penghui Du,Yi Liu,Yu Wang,Yan Wang*

Main category: cs.CV

TL;DR: AgentIAD：基于工具驱动的智能体框架，通过多阶段视觉检查实现工业异常检测，结合感知缩放器和比较检索器，在MMAD数据集上达到97.62%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测面临正常参考样本稀缺、缺陷细微且局部化的挑战。现有的单次视觉语言模型往往忽略小异常，缺乏与标准正常模式进行显式比较的机制。

Method: 提出AgentIAD框架，包含感知缩放器（用于局部细粒度分析）和比较检索器（用于查询正常样本）。从MMAD数据集构建结构化感知和比较轨迹，采用两阶段训练：监督微调后接强化学习，设计了包含感知奖励和行为奖励的两部分奖励机制。

Result: 在MMAD数据集上达到97.62%的分类准确率，创下新的最先进水平，超越了之前基于MLLM的方法，同时产生透明可解释的检查轨迹。

Conclusion: AgentIAD通过多阶段观察、缩放和验证，使模型能够逐步完善判断，实现了高效的工具使用和准确的异常检测，为工业异常检测提供了透明可解释的解决方案。

Abstract: Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.

</details>


### [199] [Towards Interactive Intelligence for Digital Humans](https://arxiv.org/abs/2512.13674)
*Yiyi Cai,Xuangeng Chu,Xiwei Gao,Sitong Gong,Yifei Huang,Caixin Kang,Kunhang Li,Haiyang Liu,Ruicong Liu,Yun Liu,Dianwen Ng,Zixiong Su,Erwin Wu,Yuhan Wu,Dingkun Yan,Tianyu Yan,Chang Zeng,Bo Zheng,You Zhou*

Main category: cs.CV

TL;DR: 提出交互智能新范式Mio框架，通过五大模块实现人格对齐表达、自适应交互和自我进化，超越表面模仿实现智能交互


<details>
  <summary>Details</summary>
Motivation: 当前数字人技术多停留在表面模仿，缺乏真正的智能交互能力。需要一种能够实现人格对齐表达、自适应交互和自我进化的新型数字人范式。

Method: 提出Mio（多模态交互全能化身）端到端框架，包含五个专门模块：思考者、说话者、面部动画师、身体动画师和渲染器，将认知推理与实时多模态具身化相结合。

Result: 建立了新的基准测试来严格评估交互智能能力。大量实验表明，该框架在所有评估维度上都优于现有最先进方法。

Conclusion: 这些贡献将数字人从表面模仿推向智能交互，实现了交互智能的新范式。

Abstract: We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intelligence. Extensive experiments demonstrate that our framework achieves superior performance compared to state-of-the-art methods across all evaluated dimensions. Together, these contributions move digital humans beyond superficial imitation toward intelligent interaction.

</details>


### [200] [JoVA: Unified Multimodal Learning for Joint Video-Audio Generation](https://arxiv.org/abs/2512.13677)
*Xiaohu Huang,Hao Zhou,Qiangpeng Yang,Shilei Wen,Kai Han*

Main category: cs.CV

TL;DR: JoVA是一个统一的视频-音频联合生成框架，通过联合自注意力机制实现跨模态交互，无需额外对齐模块，并引入基于面部关键点检测的嘴部区域损失来提升唇语同步质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键限制：1）大多只能生成环境音，缺乏生成与唇部动作同步的人声的能力；2）现有统一视频-音频生成方法通常依赖显式融合或模态特定对齐模块，增加了架构复杂性并削弱了原始Transformer的简洁性。

Method: 1）在Transformer层中使用视频和音频token的联合自注意力机制，实现直接高效的跨模态交互；2）引入基于面部关键点检测的嘴部区域损失，在训练期间增强对关键嘴部区域的监督，同时保持架构简洁。

Result: 在基准测试中，JoVA在唇语同步准确性、语音质量和整体视频-音频生成保真度方面优于或与最先进的统一和音频驱动方法相媲美。

Conclusion: JoVA是一个优雅的高质量多模态生成框架，通过简洁的联合自注意力机制和嘴部区域损失，实现了高效的视频-音频联合生成，特别是在唇语同步方面表现出色。

Abstract: In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized with lip movements. Second, recent attempts at unified human video-audio generation typically rely on explicit fusion or modality-specific alignment modules, which introduce additional architecture design and weaken the model simplicity of the original transformers. To address these issues, JoVA employs joint self-attention across video and audio tokens within each transformer layer, enabling direct and efficient cross-modal interaction without the need for additional alignment modules. Furthermore, to enable high-quality lip-speech synchronization, we introduce a simple yet effective mouth-area loss based on facial keypoint detection, which enhances supervision on the critical mouth region during training without compromising architectural simplicity. Extensive experiments on benchmarks demonstrate that JoVA outperforms or is competitive with both unified and audio-driven state-of-the-art methods in lip-sync accuracy, speech quality, and overall video-audio generation fidelity. Our results establish JoVA as an elegant framework for high-quality multimodal generation.

</details>


### [201] [LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction](https://arxiv.org/abs/2512.13680)
*Tianye Ding,Yiming Xie,Yiqing Liang,Moitreya Chatterjee,Pedro Miraldo,Huaizu Jiang*

Main category: cs.CV

TL;DR: LASER是一个无需训练即可将离线3D重建模型转换为流式系统的框架，通过层尺度对齐解决窗口间深度尺度不一致问题，实现高效流式视频处理。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈重建模型（如VGGT和π³）虽然重建质量优秀，但由于二次内存复杂度无法处理流式视频。现有流式方法需要大量重新训练，且无法充分利用先进离线模型的几何先验。

Method: 提出LASER框架：1）将离线模型转换为流式系统，通过连续时间窗口间的预测对齐；2）发现简单相似变换对齐因层深度错配而失败；3）引入层尺度对齐：将深度预测分割为离散层，计算每层尺度因子，并在相邻窗口和时间戳间传播。

Result: 在相机姿态估计和点云重建方面达到最先进性能，在RTX A6000 GPU上以14 FPS运行，峰值内存仅6GB，可处理千米级流式视频。

Conclusion: LASER提供了一种无需训练的方法，将高质量离线重建模型高效转换为流式系统，解决了实际部署中的内存和计算限制问题。

Abstract: Recent feed-forward reconstruction models like VGGT and $π^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or causal attention, they require extensive retraining and may not fully leverage the strong geometric priors of state-of-the-art offline models. We propose LASER, a training-free framework that converts an offline reconstruction model into a streaming system by aligning predictions across consecutive temporal windows. We observe that simple similarity transformation ($\mathrm{Sim}(3)$) alignment fails due to layer depth misalignment: monocular scale ambiguity causes relative depth scales of different scene layers to vary inconsistently between windows. To address this, we introduce layer-wise scale alignment, which segments depth predictions into discrete layers, computes per-layer scale factors, and propagates them across both adjacent windows and timestamps. Extensive experiments show that LASER achieves state-of-the-art performance on camera pose estimation and point map reconstruction %quality with offline models while operating at 14 FPS with 6 GB peak memory on a RTX A6000 GPU, enabling practical deployment for kilometer-scale streaming videos. Project website: $\href{https://neu-vi.github.io/LASER/}{\texttt{https://neu-vi.github.io/LASER/}}$

</details>


### [202] [I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners](https://arxiv.org/abs/2512.13683)
*Lu Ling,Yunhao Ge,Yichen Sheng,Aniket Bera*

Main category: cs.CV

TL;DR: 利用预训练的3D实例生成器作为场景级学习器，通过模型中心的空间监督而非数据集监督，实现对新布局和物体组合的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的3D场景生成方法依赖有限场景数据集，限制了在新布局上的泛化能力。需要找到一种方法能够利用预训练模型的迁移性空间知识来实现更好的泛化

Method: 重新编程预训练的3D实例生成器作为场景级学习器，采用模型中心的空间监督而非数据集监督。提出以视图为中心的场景空间表示，替代传统的规范空间，实现完全前馈的通用场景生成器

Result: 该方法能够泛化到未见过的布局和新颖的物体组合，即使训练场景是随机组合的物体，空间推理能力仍然能够涌现。生成器展现出从纯几何线索推断邻近性、支撑关系和对称性的能力

Conclusion: 3D实例生成器是隐式的空间学习器和推理器，为交互式3D场景理解和生成的基座模型指明了方向

Abstract: Generalization remains the central challenge for interactive 3D scene generation. Existing learning-based approaches ground spatial understanding in limited scene dataset, restricting generalization to new layouts. We instead reprogram a pre-trained 3D instance generator to act as a scene level learner, replacing dataset-bounded supervision with model-centric spatial supervision. This reprogramming unlocks the generator transferable spatial knowledge, enabling generalization to unseen layouts and novel object compositions. Remarkably, spatial reasoning still emerges even when the training scenes are randomly composed objects. This demonstrates that the generator's transferable scene prior provides a rich learning signal for inferring proximity, support, and symmetry from purely geometric cues. Replacing widely used canonical space, we instantiate this insight with a view-centric formulation of the scene space, yielding a fully feed-forward, generalizable scene generator that learns spatial relations directly from the instance model. Quantitative and qualitative results show that a 3D instance generator is an implicit spatial learner and reasoner, pointing toward foundation models for interactive 3D scene understanding and generation. Project page: https://luling06.github.io/I-Scene-project/

</details>


### [203] [Recurrent Video Masked Autoencoders](https://arxiv.org/abs/2512.13684)
*Daniel Zoran,Nikhil Parthasarathy,Yi Yang,Drew A Hudson,Joao Carreira,Andrew Zisserman*

Main category: cs.CV

TL;DR: RVM是一种基于循环神经网络的视频掩码自编码器，通过循环聚合图像特征来高效学习视频时空表示，在视频任务上达到SOTA性能，同时参数效率极高（最高达30倍）。


<details>
  <summary>Details</summary>
Motivation: 现有视频表示学习方法通常计算成本高，难以同时处理视频级任务和密集空间理解任务。需要一种既能捕获时空结构又具有高参数效率的通用视频编码器。

Method: 使用基于Transformer的循环神经网络聚合密集图像特征，通过非对称掩码预测任务学习，仅需标准像素重建目标。循环设计允许线性计算成本下的长时程特征传播。

Result: 在视频动作识别、点/目标跟踪等任务上与VideoMAE、V-JEPA等SOTA视频模型竞争，在几何和密集空间理解任务上优于DINOv2等图像模型。小模型无需知识蒸馏即表现优异，参数效率最高达竞争方法的30倍。

Conclusion: RVM通过循环设计实现了高效通用的视频表示学习，既能处理视频级任务又能理解空间结构，在参数效率和计算成本方面显著优于现有方法，为视频理解提供了新方向。

Abstract: We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymmetric masked prediction task requiring only a standard pixel reconstruction objective. This design yields a highly efficient ``generalist'' encoder: RVM achieves competitive performance with state-of-the-art video models (e.g. VideoMAE, V-JEPA) on video-level tasks like action recognition and point/object tracking, while also performing favorably against image models (e.g. DINOv2) on tasks that test geometric and dense spatial understanding. Notably, RVM achieves strong performance in the small-model regime without requiring knowledge distillation, exhibiting up to 30x greater parameter efficiency than competing video masked autoencoders. Moreover, we demonstrate that RVM's recurrent nature allows for stable feature propagation over long temporal horizons with linear computational cost, overcoming some of the limitations of standard spatio-temporal attention-based architectures. Finally, we use qualitative visualizations to highlight that RVM learns rich representations of scene semantics, structure, and motion.

</details>


### [204] [Towards Scalable Pre-training of Visual Tokenizers for Generation](https://arxiv.org/abs/2512.13687)
*Jingfeng Yao,Yuda Song,Yucong Zhou,Xinggang Wang*

Main category: cs.CV

TL;DR: VTP提出统一的视觉tokenizer预训练框架，通过联合优化图像-文本对比、自监督和重建损失，解决传统视觉tokenizer偏向低层信息的问题，显著改善生成模型的缩放性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于重建的视觉tokenizer训练范式产生的潜在空间偏向低层信息，导致一个根本缺陷：更好的像素级精度并不能带来更高质量的生成。这意味着将大量计算资源投入视觉tokenizer预训练对生成性能的提升效果不佳，作者称之为"预训练缩放问题"。

Method: 提出VTP统一视觉tokenizer预训练框架，首次联合优化图像-文本对比损失、自监督损失和重建损失，使潜在空间能够简洁地表示高层语义信息。

Result: 大规模研究表明：(1)理解是生成的关键驱动力；(2)具有更好的缩放特性，生成性能随计算、参数和预训练数据有效缩放。VTP tokenizer在ImageNet上达到78.2%零样本准确率和0.36 rFID，生成收敛速度比先进蒸馏方法快4.1倍。更重要的是，仅增加VTP预训练计算量就能实现下游生成65.8%的FID改进，而传统自编码器在1/10计算量时就已停滞。

Conclusion: VTP框架通过联合优化多种损失函数，解决了视觉tokenizer预训练的缩放问题，证明理解高层语义是提升生成质量的关键，为视觉tokenizer预训练提供了新的有效范式。

Abstract: The quality of the latent space in visual tokenizers (e.g., VAEs) is crucial for modern generative models. However, the standard reconstruction-based training paradigm produces a latent space that is biased towards low-level information, leading to a foundation flaw: better pixel-level accuracy does not lead to higher-quality generation. This implies that pouring extensive compute into visual tokenizer pre-training translates poorly to improved performance in generation. We identify this as the ``pre-training scaling problem`` and suggest a necessary shift: to be effective for generation, a latent space must concisely represent high-level semantics. We present VTP, a unified visual tokenizer pre-training framework, pioneering the joint optimization of image-text contrastive, self-supervised, and reconstruction losses. Our large-scale study reveals two principal findings: (1) understanding is a key driver of generation, and (2) much better scaling properties, where generative performance scales effectively with compute, parameters, and data allocated to the pretraining of the visual tokenizer. After large-scale pre-training, our tokenizer delivers a competitive profile (78.2 zero-shot accuracy and 0.36 rFID on ImageNet) and 4.1 times faster convergence on generation compared to advanced distillation methods. More importantly, it scales effectively: without modifying standard DiT training specs, solely investing more FLOPS in pretraining VTP achieves 65.8\% FID improvement in downstream generation, while conventional autoencoder stagnates very early at 1/10 FLOPS. Our pre-trained models are available at https://github.com/MiniMax-AI/VTP.

</details>


### [205] [LitePT: Lighter Yet Stronger Point Transformer](https://arxiv.org/abs/2512.13689)
*Yuanwen Yue,Damien Robert,Jianyuan Wang,Sunghwan Hong,Jan Dirk Wegner,Christian Rupprecht,Konrad Schindler*

Main category: cs.CV

TL;DR: LitePT：一种新的3D点云骨干网络，早期使用卷积提取低层几何特征，后期切换为注意力机制捕获高层语义，通过PointROPE位置编码保持空间布局信息，在参数、速度和内存效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D点云处理网络同时包含卷积层和注意力块，但如何最佳组合它们尚不明确。作者分析了不同计算块在3D点云网络中的作用，发现卷积适合在早期高分辨率层提取低层几何特征，而注意力在深层低分辨率层更高效地捕获高层语义和上下文信息。

Method: 提出LitePT模型，遵循"早期卷积、后期注意力"的设计原则。为了避免丢弃冗余卷积层时丢失空间布局信息，引入了无需训练的新型3D位置编码PointROPE。该模型在早期阶段使用卷积，在深层阶段切换到注意力机制。

Result: LitePT模型参数比最先进的Point Transformer V3少3.6倍，运行速度快2倍，内存使用少2倍，但在多个任务和数据集上性能相当甚至更优。

Conclusion: 通过合理分配卷积和注意力机制在不同网络阶段的作用，可以构建出更高效、性能优异的3D点云处理骨干网络。LitePT证明了这种混合架构设计的有效性，为3D点云网络设计提供了新的指导原则。

Abstract: Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequate to extract low-level geometry at high-resolution in early layers, where attention is expensive without bringing any benefits; attention captures high-level semantics and context in low-resolution, deep layers more efficiently. Guided by this design principle, we propose a new, improved 3D point cloud backbone that employs convolutions in early stages and switches to attention for deeper layers. To avoid the loss of spatial layout information when discarding redundant convolution layers, we introduce a novel, training-free 3D positional encoding, PointROPE. The resulting LitePT model has $3.6\times$ fewer parameters, runs $2\times$ faster, and uses $2\times$ less memory than the state-of-the-art Point Transformer V3, but nonetheless matches or even outperforms it on a range of tasks and datasets. Code and models are available at: https://github.com/prs-eth/LitePT.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [206] [AutoMV: An Automatic Multi-Agent System for Music Video Generation](https://arxiv.org/abs/2512.12196)
*Xiaoxuan Tang,Xinping Lei,Chaoran Zhu,Shiyun Chen,Ruibin Yuan,Yizhi Li,Changjae Oh,Ge Zhang,Wenhao Huang,Emmanouil Benetos,Yang Liu,Jiaheng Liu,Yinghao Ma*

Main category: cs.MM

TL;DR: AutoMV是一个多智能体系统，能够直接从歌曲生成完整的音乐视频，通过提取音乐特征、设计脚本、生成关键帧和视频，并利用验证器确保一致性，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有音乐到视频生成方法只能产生短而不连贯的片段，无法与音乐结构、节拍或歌词对齐，缺乏时间一致性。需要一种能够生成完整音乐视频的系统。

Method: AutoMV采用多智能体系统：首先提取音乐特征（结构、人声轨道、时间对齐歌词），然后编剧和导演智能体设计脚本、角色档案和摄像机指令，调用图像生成器生成关键帧，使用不同视频生成器生成"故事"或"歌手"场景，最后通过验证器智能体评估输出以确保一致性。

Result: AutoMV在四个高级类别（音乐内容、技术、后期制作、艺术）和十二个细粒度标准上显著优于现有基线方法，缩小了与专业音乐视频的差距。同时探索了使用大型多模态模型作为自动评估器，虽然前景看好但仍落后于人类专家。

Conclusion: AutoMV证明了多智能体系统在生成完整音乐视频方面的有效性，提出的评估基准为音乐视频生成领域提供了标准化评估框架，未来在自动评估方面仍有改进空间。

Abstract: Music-to-Video (M2V) generation for full-length songs faces significant challenges. Existing methods produce short, disjointed clips, failing to align visuals with musical structure, beats, or lyrics, and lack temporal consistency. We propose AutoMV, a multi-agent system that generates full music videos (MVs) directly from a song. AutoMV first applies music processing tools to extract musical attributes, such as structure, vocal tracks, and time-aligned lyrics, and constructs these features as contextual inputs for following agents. The screenwriter Agent and director Agent then use this information to design short script, define character profiles in a shared external bank, and specify camera instructions. Subsequently, these agents call the image generator for keyframes and different video generators for "story" or "singer" scenes. A Verifier Agent evaluates their output, enabling multi-agent collaboration to produce a coherent longform MV. To evaluate M2V generation, we further propose a benchmark with four high-level categories (Music Content, Technical, Post-production, Art) and twelve ine-grained criteria. This benchmark was applied to compare commercial products, AutoMV, and human-directed MVs with expert human raters: AutoMV outperforms current baselines significantly across all four categories, narrowing the gap to professional MVs. Finally, we investigate using large multimodal models as automatic MV judges; while promising, they still lag behind human expert, highlighting room for future work.

</details>


### [207] [JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation](https://arxiv.org/abs/2512.12772)
*Jianghan Chao,Jianzhang Gao,Wenhui Tan,Yuchong Sun,Ruihua Song,Liyun Ru*

Main category: cs.MM

TL;DR: 提出JointAVBench基准测试，用于严格评估需要联合视听理解的Omni-LLMs，涵盖多模态依赖、多样音频类型和不同场景跨度，当前最佳模型准确率仅62.6%


<details>
  <summary>Details</summary>
Motivation: 现有评估数据集在三个关键维度存在不足：(1)缺乏严格的多模态依赖（问题不能仅通过视觉或音频单独回答），(2)音频信息类型不够多样，(3)场景跨度覆盖不全，限制了Omni-LLMs的全面评估

Method: 提出自动化流水线，利用最先进的视觉LLMs、音频LLMs和通用LLMs合成严格需要联合视听理解的问题和答案，构建JointAVBench基准，涵盖5个认知维度、4种音频类型和3种场景跨度

Result: 评估领先的仅视觉、仅音频和Omni-LLMs，最佳Omni-LLM平均准确率仅62.6%，虽然优于单模态基线，但在跨场景推理等方面仍有很大改进空间

Conclusion: JointAVBench为严格评估Omni-LLMs的联合视听理解能力提供了全面基准，揭示了当前模型在多模态依赖、音频类型多样性和场景跨度理解方面的显著不足

Abstract: Understanding videos inherently requires reasoning over both visual and auditory information. To properly evaluate Omni-Large Language Models (Omni-LLMs), which are capable of processing multi-modal information including vision and audio, an effective benchmark must comprehensively cover three key aspects: (1) multi-modal dependency (i.e., questions that cannot be answered using vision or audio alone), (2) diverse audio information types (e.g., speech, sound events), and (3) varying scene spans. However, existing datasets fall short in one or more of these dimensions, limiting strict and comprehensive evaluation. To address this gap, we introduce JointAVBench, a novel benchmark with strict audio-video correlation, spanning five cognitive dimensions, four audio information types (speech, sound events, music, vocal traits), and three scene spans (single-, cross-, and full-scene). Given the high cost of manual annotation, we propose an automated pipeline that leverages state-of-the-art vision-LLMs, audio-LLMs, and general-purpose LLMs to synthesize questions and answers that strictly require joint audio-visual understanding. We evaluate leading vision-only, audio-only, and Omni-LLMs on our dataset. Results show that even the best-performing Omni-LLM achieves an average accuracy of only 62.6\%, outperforming uni-modal baselines but revealing substantial room for improvement, especially in cross-scene reasoning.

</details>


### [208] [Integrated Semantic and Temporal Alignment for Interactive Video Retrieval](https://arxiv.org/abs/2512.13169)
*Thanh-Danh Luu,Le-Vu Nguyen Dinh,Duc-Thien Tran,Duy-Bao Bui,Nam-Tien Le,Tinh-Anh Nguyen Nhu*

Main category: cs.MM

TL;DR: 团队AIO_Owlgorithms开发了一个综合视频检索框架，包含QUEST和DANTE两个组件，用于解决复杂视频检索任务中的OOK查询和时序对齐问题。


<details>
  <summary>Details</summary>
Motivation: 随着视频数据量的增长和复杂检索挑战的出现（如TRAKE任务），现有系统存在局限性：缺乏可扩展的整体架构，依赖"冻结"的嵌入模型，无法处理OOK或真实世界查询。

Method: 提出综合视频检索框架：1) TransNetV2用于场景分割，2) BEiT-3用于视觉嵌入存储在Milvus，3) Gemini OCR用于元数据存储在Elasticsearch。核心组件：QUEST（查询理解和外部搜索）使用LLM进行查询重写和外部图像搜索处理OOK查询；DANTE（动态叙事时序事件对齐）使用动态规划算法解决时序不连贯的TRAKE任务。

Result: 开发了一个鲁棒且智能的系统，显著提升了处理复杂真实世界视频搜索查询的能力，在TRAKE任务中表现出色。

Conclusion: 该综合框架通过QUEST和DANTE组件，有效解决了现有视频检索系统的局限性，为处理复杂、真实世界的视频搜索查询提供了先进的解决方案。

Abstract: The growing volume of video data and the introduction of complex retrieval challenges, such as the Temporal Retrieval and Alignment of Key Events (TRAKE) task at the Ho Chi Minh City AI Challenge 2025, expose critical limitations in existing systems. Many methodologies lack scalable, holistic architectures and rely on "frozen" embedding models that fail on out-of-knowledge (OOK) or real-world queries. This paper introduces the comprehensive video retrieval framework developed by team AIO\_Owlgorithms to address these gaps. Our system features an architecture integrating TransNetV2 for scene segmentation, BEiT-3 for visual embeddings in Milvus, and Gemini OCR for metadata in Elasticsearch. We propose two components: (1) \textbf{QUEST} (Query Understanding and External Search for Out-of-Knowledge Tasks), a two-branch framework that leverages a Large Language Model (LLM) for query rewriting and an external image search pathway to resolve OOK queries; and (2) \textbf{DANTE} (Dynamic Alignment of Narrative Temporal Events), a dynamic programming algorithm that efficiently solves the temporally-incoherent TRAKE task. These contributions form a robust and intelligent system that significantly advances the state-of-the-art in handling complex, real-world video search queries.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [209] [A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 基于人工年龄评分（AAS）构建可执行条款架构，将莱布尼茨单子论中的20个单子分组为6个束，实现为对LLM记忆和控制的法则约束，通过Python实验验证框架的可实现性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）作为强大但不透明的系统部署，缺乏对其内部记忆和"自我类似"行为的可审计原则性治理方法。需要建立透明、可实现的架构来约束和分析人工智能体的内部动态。

Method: 以AAS（人工年龄评分）为核心，将莱布尼茨《单子论》中的20个单子分组为6个束（本体论、动力学、表征与意识、和谐与理性、身体与组织、目的论），每个束实现为可执行规范。通过6个最小Python实现，在通道级量（回忆分数、冗余度、权重等）上进行数值实验，遵循四步模式：输入与设置、条款实现、数值结果、对LLM设计的启示。

Result: 实验显示条款系统表现出有界且可解释的行为：AAS轨迹保持连续且速率受限，矛盾和未经支持的声明触发明确惩罚，分层细化以受控方式揭示有机结构。通过和谐项对齐双重视图和目标-行动对，完美分数的窗口漂移区分持续改进与持续退化。

Conclusion: 基于单子的条款框架以AAS为骨干，为约束和分析人工智能体的内部动态提供了透明、代码级的蓝图，不仅具有哲学动机，而且可直接实现，为LLM记忆和控制的治理提供了可审计的原则性方法。

Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.

</details>


### [210] [Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks](https://arxiv.org/abs/2512.12736)
*Syeda Zunaira Ahmed,Hejab Tahira Beg,Maryam Khalid*

Main category: cs.AI

TL;DR: 提出基于人口统计的机器学习框架用于个性化QoE预测，通过数据增强扩展数据集6倍，TabNet模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有QoE预测方法依赖有限数据集且假设用户感知均匀，难以适应异构现实环境，需要更个性化的预测方案

Method: 提出人口统计感知的机器学习框架，采用基于行为真实性的数据增强策略将小数据集扩展6倍，评估经典ML模型和深度学习架构（包括注意力MLP和TabNet）

Result: 实验结果显示在RMSE、MAE和R指标上相比基线模型有显著改进，TabNet表现最佳，受益于其固有特征选择和注意力机制

Conclusion: 人口统计感知的数据增强显著提升QoE预测鲁棒性，为5G视频流网络中个性化QoE感知智能提供了可扩展方向

Abstract: Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primarily rely on limited datasets and assume uniform user perception, which restricts their applicability in heterogeneous real world environments.
  This paper proposes a demographic aware machine learning framework for personalized QoE prediction. We introduce a behaviorally realistic demographic based data augmentation strategy that expands a small QoE dataset six fold by modeling varying user sensitivities to streaming impairments such as rebuffering, bitrate variation, and quality degradation. Using the augmented dataset, we evaluate a comprehensive set of classical machine learning models alongside advanced deep learning architectures, including an attention-based MLP and TabNet.
  Experimental results demonstrate significant improvements in prediction accuracy across RMSE, MAE, and R metrics compared to baseline models. Among all evaluated approaches, TabNet achieves the strongest performance, benefiting from its inherent feature selection and attention mechanisms. The results confirm that demographic-aware augmentation substantially enhances QoE prediction robustness and provides a scalable direction for personalized QoE-aware intelligence in 5G video streaming networks.

</details>


### [211] [Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars](https://arxiv.org/abs/2512.11864)
*Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter*

Main category: cs.AI

TL;DR: 提出一种新的并行机调度变体，包含作业优先级和基于日历的累积资源约束，针对实际工业场景开发精确约束建模方法和元启发式算法。


<details>
  <summary>Details</summary>
Motivation: 现代工厂大规模生产需要自动化调度技术来最小化成本，但现有方法无法有效处理实际生产环境中的复杂优先级约束和基于日历的资源限制。

Method: 1) 提出新的并行机调度变体，包含作业优先级和日历型累积资源约束；2) 对小型场景使用约束建模方法作为精确解；3) 对大规模实例提出构造启发式算法和基于局部搜索的定制元启发式算法。

Result: 元启发式方法已在工业环境中部署使用，能够有效处理大规模实际调度问题。

Conclusion: 该研究提出的方法能够解决实际工业中的复杂并行机调度问题，填补了现有技术在处理日历型资源约束方面的空白，并已在工业环境中成功应用。

Abstract: The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.

</details>


### [212] [Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning](https://arxiv.org/abs/2512.11902)
*Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat*

Main category: cs.AI

TL;DR: 开发了Fire Emblem Heroes的Mirror Mode游戏模式，让AI模仿玩家个人策略来挑战玩家，结合多种学习方法实现策略模仿，玩家测试显示防御行为模仿良好但进攻策略不足，整体提高了玩家满意度。


<details>
  <summary>Details</summary>
Motivation: 传统回合制游戏中敌人策略往往可预测，缺乏惊喜感。研究旨在创造一种能模仿玩家个人策略的AI模式，让玩家面对自己的策略，从而增加游戏的挑战性和趣味性。

Method: 1. 在Unity中构建简化版Fire Emblem Heroes游戏，包含标准模式和镜像模式；2. 使用强化学习和模仿学习（生成对抗模仿学习、行为克隆、近端策略优化）组合来模仿玩家演示；3. 通过玩家测试评估模型，训练数据来自参与者的游戏演示。

Result: 模型在防御行为上模仿良好，玩家能识别出自己的撤退战术，但在进攻策略上模仿效果不佳。玩家调查显示镜像模式整体满意度更高，玩家面对自己策略时体验更好。

Conclusion: Mirror Mode能有效提高玩家满意度，尤其是当玩家面对自己策略时。进一步优化模型可以提升模仿质量，特别是在进攻策略方面，从而进一步增强游戏体验。

Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified version of the Nintendo strategy video game Fire Emblem Heroes has been built in Unity, with a Standard Mode and a Mirror Mode. Our first set of experiments find a suitable model for the task to imitate player demonstrations, using Reinforcement Learning and Imitation Learning: combining Generative Adversarial Imitation Learning, Behavioral Cloning, and Proximal Policy Optimization. The second set of experiments evaluates the constructed model with player tests, where models are trained on demonstrations provided by participants. The gameplay of the participants indicates good imitation in defensive behavior, but not in offensive strategies. Participant's surveys indicated that they recognized their own retreating tactics, and resulted in an overall higher player-satisfaction for Mirror Mode. Refining the model further may improve imitation quality and increase player's satisfaction, especially when players face their own strategies. The full code and survey results are stored at: https://github.com/YannaSmid/MirrorMode

</details>


### [213] [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/abs/2512.13131)
*Xin Guo,Yifan Zhao,Jia Li*

Main category: cs.AI

TL;DR: 提出分层隐式周期性学习框架，通过显式建模不同运动单元间的内在相关性，提升语音驱动3D手势生成的协调性和自然度。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动3D手势生成方法多为端到端方案，未能充分建模头部、身体、手部等不同运动单元间的内在相关性和协调性，导致生成动作不自然、协调性差。

Method: 提出分层隐式周期性学习框架：1) 使用周期性自编码器探索手势运动相位流形，从真实分布中学习人类自然运动模式，同时结合非周期性特征保持实例级多样性；2) 通过级联引导机制建模面部、身体、手部动作的层次关系。

Result: 在3D虚拟人上的实验表明，该方法在定量和定性评估上均优于现有的语音驱动手势生成方法，能生成更自然协调的3D手势动作。

Conclusion: 通过显式建模不同运动单元间的内在相关性和周期性特征，提出的分层隐式周期性学习框架能有效提升语音驱动3D手势生成的自然度和协调性。

Abstract: Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.

</details>


### [214] [Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents](https://arxiv.org/abs/2512.11907)
*Daniel Platnick,Marjan Alirezaie,Hossein Rahnama*

Main category: cs.AI

TL;DR: 提出了一种基于层状拟阵理论的结构化个性化方法，用于在复杂约束下优化LLM代理的个性化数据选择


<details>
  <summary>Details</summary>
Motivation: LLM个性化需要在任务效用和数据披露之间权衡，现实中的结构化约束（如逻辑依赖、类别配额、层次规则）使得标准子集选择算法失效

Method: 将用户知识图编译为抽象宏观面，证明常见层次和配额约束形成层状拟阵，将结构化个性化建模为拟阵约束下的子模最大化问题

Result: 理论证明常见约束形成层状拟阵，使贪婪算法能获得常数因子保证（连续贪婪可达1-1/e），适用于更丰富现实的个性化问题

Conclusion: 提出的拟阵理论框架为结构化LLM个性化提供了理论基础和算法保证，扩展了现实约束下的个性化能力

Abstract: Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., submodularity), enabling near-optimal greedy selection, real-world personalization is complicated by structural constraints. These include logical dependencies (e.g., selecting fact A requires fact B), categorical quotas (e.g., select at most one writing style), and hierarchical rules (e.g., select at most two social media preferences, of which at most one can be for a professional network). These constraints violate the assumptions of standard subset selection algorithms. We propose a principled method to formally model such constraints. We introduce a compilation process that transforms a user's knowledge graph with dependencies into a set of abstract macro-facets. Our central result is a proof that common hierarchical and quota-based constraints over these macro-facets form a valid laminar matroid. This theoretical characterization lets us cast structured personalization as submodular maximization under a matroid constraint, enabling greedy with constant-factor guarantees (and (1-1/e) via continuous greedy) for a much richer and more realistic class of problems.

</details>


### [215] [Causal Strengths and Leaky Beliefs: Interpreting LLM Reasoning via Noisy-OR Causal Bayes Nets](https://arxiv.org/abs/2512.11909)
*Hanna Dettki*

Main category: cs.AI

TL;DR: 研究通过11个因果推理任务评估20+个LLM与人类推理能力，发现LLM在直接推理上与人类对齐，但在思维链推理中表现出不同模式，揭示了LLM与人类在因果推理上的差异特征。


<details>
  <summary>Details</summary>
Motivation: 因果推理能力被认为是智能的关键方面，通过在同一任务上评估LLM和人类的因果推理能力，可以更全面地理解两者的优势和弱点，探究LLM是否与人类推理对齐、是否具有一致的推理模式以及是否存在不同的推理特征。

Method: 使用基于碰撞图（C₁→E←C₂）的11个语义化因果任务评估20+个LLM，采用两种推理模式：直接推理（单次概率判断）和思维链推理（先思考后回答）。使用带泄漏参数的噪声-OR因果贝叶斯网络建模判断，通过AIC选择对称（3参数）或非对称（4参数）因果强度模型。

Result: 研究发现：1）在直接推理任务中，LLM与人类推理对齐；2）在思维链推理中，LLM与人类在任务层面表现出不一致性；3）LLM和人类具有不同的推理特征，揭示了它们在因果推理处理上的本质差异。

Conclusion: LLM在直接因果推理上与人类对齐，但在更复杂的思维链推理中表现出不同的推理模式，这表明LLM的因果推理机制与人类存在差异，为理解人工智能与人类智能的异同提供了重要见解。

Abstract: The nature of intelligence in both humans and machines is a longstanding question. While there is no universally accepted definition, the ability to reason causally is often regarded as a pivotal aspect of intelligence (Lake et al., 2017). Evaluating causal reasoning in LLMs and humans on the same tasks provides hence a more comprehensive understanding of their respective strengths and weaknesses. Our study asks: (Q1) Are LLMs aligned with humans given the \emph{same} reasoning tasks? (Q2) Do LLMs and humans reason consistently at the task level? (Q3) Do they have distinct reasoning signatures?
  We answer these by evaluating 20+ LLMs on eleven semantically meaningful causal tasks formalized by a collider graph ($C_1\!\to\!E\!\leftarrow\!C_2$ ) under \emph{Direct} (one-shot number as response = probability judgment of query node being one and \emph{Chain of Thought} (CoT; think first, then provide answer).
  Judgments are modeled with a leaky noisy-OR causal Bayes net (CBN) whose parameters $θ=(b,m_1,m_2,p(C)) \in [0,1]$ include a shared prior $p(C)$;
  we select the winning model via AIC between a 3-parameter symmetric causal strength ($m_1{=}m_2$) and 4-parameter asymmetric ($m_1{\neq}m_2$) variant.

</details>


### [216] [Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis](https://arxiv.org/abs/2512.11912)
*Liu Peng,Yaochu Jin*

Main category: cs.AI

TL;DR: 不同概率模型对低质量数据的鲁棒性差异显著：自回归语言模型最稳健，扩散模型最脆弱，分类器居中且随数据规模改善


<details>
  <summary>Details</summary>
Motivation: 系统比较现代概率模型对低质量数据的鲁棒性差异，揭示不同模型架构在数据损坏情况下的表现差异

Method: 通过实验对比不同模型在数据损坏条件下的表现，结合信息论、PAC学习和梯度动力学进行多视角分析

Result: 自回归语言模型（如GPT-2）对50%令牌损坏仍保持稳健（测试NLL仅从2.87增至3.59），而扩散模型在相同损坏下性能崩溃（图像标签一致性相对基线下降56.81%），分类器影响适中且随数据集规模减小

Conclusion: 模型鲁棒性主要受两个关键原则影响：条件信息的丰富性（约束学习问题）和训练数据的绝对信息量（使正确信息信号主导统计噪声）

Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, are remarkably resilient (for GPT-2, test NLL increases modestly from 2.87 to 3.59 despite 50% token corruption). By contrast, under the same levels of data corruption, class-conditional diffusion models degrade catastrophically (image-label consistency plummets by 56.81% relative to baseline), while classifiers show a moderate impact that diminishes with dataset scale. To explain these discrepancies, we analyze the results through a multi-perspective lens, integrating information theory, PAC learning, and gradient dynamics. These analyses suggest that robustness is heavily influenced by two key principles: the richness of conditioning information, which constrains the learning problem, and the absolute information content of the training data, which allows the signal from correct information to dominate statistical noise.

</details>


### [217] [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CXL-SpecKV：利用CXL互连和FPGA加速器的解耦KV缓存架构，通过推测执行和内存解耦解决LLM推理中的内存瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数据中心部署面临KV缓存内存需求巨大的挑战，限制了批处理大小和系统吞吐量，需要解决内存墙问题

Method: 提出基于CXL的内存解耦框架，将KV缓存卸载到远程FPGA内存；设计推测性KV缓存预取机制；实现FPGA加速的KV缓存压缩/解压缩引擎

Result: 在先进LLM模型上，相比GPU-only基线，吞吐量提升3.2倍，内存成本降低2.8倍，同时保持准确性，内存带宽需求减少4倍

Conclusion: 智能内存解耦与推测执行相结合能有效解决大规模LLM服务中的内存墙挑战，CXL-SpecKV展示了这一方法的可行性

Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial GPU memory, limiting batch sizes and overall system throughput. To address these challenges, we propose \textbf{CXL-SpecKV}, a novel disaggregated KV-cache architecture that leverages Compute Express Link (CXL) interconnects and FPGA accelerators to enable efficient speculative execution and memory disaggregation. Our approach introduces three key innovations: (i) a CXL-based memory disaggregation framework that offloads KV-caches to remote FPGA memory with low latency, (ii) a speculative KV-cache prefetching mechanism that predicts and preloads future tokens' cache entries, and (iii) an FPGA-accelerated KV-cache compression and decompression engine that reduces memory bandwidth requirements by up to 4$\times$. When evaluated on state-of-the-art LLM models, CXL-SpecKV achieves up to 3.2$\times$ higher throughput compared to GPU-only baselines, while reducing memory costs by 2.8$\times$ and maintaining accuracy. Our system demonstrates that intelligent memory disaggregation combined with speculative execution can effectively address the memory wall challenge in large-scale LLM serving. Our code implementation has been open-sourced at https://github.com/FastLM/CXL-SpecKV.

</details>


### [218] [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)
*Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary*

Main category: cs.AI

TL;DR: AGAPI是一个开源的材料科学AI平台，集成了多个开源大语言模型和材料科学API，通过智能体架构实现自主的多步骤材料研究工作流。


<details>
  <summary>Details</summary>
Motivation: 当前材料研究中AI应用面临计算生态系统碎片化、可重复性挑战以及依赖商业大语言模型等问题，需要统一的开放平台来加速材料发现。

Method: 采用Agent-Planner-Executor-Summarizer架构，集成8+个开源LLM和20+个材料科学API端点，统一数据库、模拟工具和机器学习模型。

Result: 展示了端到端工作流，包括异质结构构建、粉末X射线衍射分析和半导体缺陷工程等复杂任务；通过30+测试案例评估，已有1000+活跃用户。

Conclusion: AGAPI为可重复、AI加速的材料发现提供了可扩展和透明的基础设施，解决了当前材料研究中的关键挑战。

Abstract: Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agentic AI platform that integrates more than eight open-source LLMs with over twenty materials-science API endpoints, unifying databases, simulation tools, and machine-learning models through a common orchestration framework. AGAPI employs an Agent-Planner-Executor-Summarizer architecture that autonomously constructs and executes multi-step workflows spanning materials data retrieval, graph neural network property prediction, machine-learning force-field optimization, tight-binding calculations, diffraction analysis, and inverse design. We demonstrate AGAPI through end-to-end workflows, including heterostructure construction, powder X-ray diffraction analysis, and semiconductor defect engineering requiring up to ten sequential operations. In addition, we evaluate AGAPI using 30+ example prompts as test cases and compare agentic predictions with and without tool access against experimental data. With more than 1,000 active users, AGAPI provides a scalable and transparent foundation for reproducible, AI-accelerated materials discovery. AGAPI-Agents codebase is available at https://github.com/atomgptlab/agapi.

</details>


### [219] [Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play](https://arxiv.org/abs/2512.11942)
*Vince Trencsenyi*

Main category: cs.AI

TL;DR: 提出一种基于逻辑的声明式领域特定语言，用于编码超博弈结构和解决方案概念，通过答案集编程实现自动化管道，连接超博弈理论、多智能体系统和战略AI


<details>
  <summary>Details</summary>
Motivation: 由于感知差异、信息不对称和有限理性，博弈论玩家对游戏形成主观认知，可能与实际情况和其他玩家的解释不一致。超博弈理论虽然提供了处理这种不匹配心理模型的数学框架，但缺乏统一的、形式化的、实用的表示语言和可扩展算法，阻碍了其在多智能体系统研究中的实际应用。

Method: 引入一种声明式的、基于逻辑的领域特定语言来编码超博弈结构和超博弈解决方案概念。利用答案集编程开发自动化管道，用于实例化超博弈结构和运行新颖的超博弈合理化程序，该程序用于找到能够证明看似非理性结果的信念结构。

Result: 提出的语言为超博弈建立了统一的表示形式，为开发基于信念的异构推理器提供了基础，提供了具有逻辑保证的可验证上下文。这些贡献共同建立了超博弈理论、多智能体系统和战略AI之间的联系。

Conclusion: 该工作通过引入形式化语言和自动化工具，解决了超博弈理论在实际应用中的关键障碍，为处理异构信念和主观认知的多智能体系统研究提供了实用的框架，推动了战略AI的发展。

Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other players' interpretations. While typical game-theoretic assumptions often overlook such heterogeneity, hypergame theory provides the mathematical framework to reason about mismatched mental models. Although hypergames have recently gained traction in dynamic applications concerning uncertainty, their practical adoption in multi-agent system research has been hindered by the lack of a unifying, formal, and practical representation language, as well as scalable algorithms for managing complex hypergame structures and equilibria. Our work addresses this gap by introducing a declarative, logic-based domain-specific language for encoding hypergame structures and hypergame solution concepts. Leveraging answer-set programming, we develop an automated pipeline for instantiating hypergame structures and running our novel hypergame rationalisation procedure, a mechanism for finding belief structures that justify seemingly irrational outcomes. The proposed language establishes a unifying formalism for hypergames and serves as a foundation for developing nuanced, belief-based heterogeneous reasoners, offering a verifiable context with logical guarantees. Together, these contributions establish the connection between hypergame theory, multi-agent systems, and strategic AI.

</details>


### [220] [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)
*Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.AI

TL;DR: EnrichLog是一个无需训练的基于日志条目的异常检测框架，通过整合语料库特定和样本特定知识来增强原始日志条目，提高异常检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析技术（如基于模板和序列驱动的方法）经常丢失重要的语义信息或难以处理模糊的日志模式，需要一种能更好保留语义并处理模糊模式的方法。

Method: EnrichLog是一个训练免费的、基于条目的异常检测框架，通过检索增强生成技术整合相关上下文知识（包括历史示例和语料库推理），无需重新训练即可丰富原始日志条目。

Result: 在四个大规模系统日志基准数据集上的评估显示，EnrichLog相比五种基线方法持续提升异常检测性能，有效处理模糊日志条目，并保持高效推理。整合两种知识增强了模型置信度和检测准确性。

Conclusion: EnrichLog通过整合语料库特定和样本特定知识，提供了一种更准确、可解释且适合实际部署的日志异常检测解决方案，有效解决了传统方法的局限性。

Abstract: System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambiguous log patterns. To address this, we present EnrichLog, a training-free, entry-based anomaly detection framework that enriches raw log entries with both corpus-specific and sample-specific knowledge. EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus, to enable more accurate and interpretable anomaly detection. The framework leverages retrieval-augmented generation to integrate relevant contextual knowledge without requiring retraining. We evaluate EnrichLog on four large-scale system log benchmark datasets and compare it against five baseline methods. Our results show that EnrichLog consistently improves anomaly detection performance, effectively handles ambiguous log entries, and maintains efficient inference. Furthermore, incorporating both corpus- and sample-specific knowledge enhances model confidence and detection accuracy, making EnrichLog well-suited for practical deployments.

</details>


### [221] [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)
*Muddsair Sharif,Huseyin Seker*

Main category: cs.AI

TL;DR: CAMAC-DRA框架通过上下文感知的多智能体协调优化电动汽车充电生态系统，平衡多个利益相关者需求，在真实数据验证中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车充电生态系统中的动态资源分配问题，需要协调多个利益相关者（用户、电网运营商、充电站运营商、车队运营商、环境因素）的竞争性目标，并适应实时环境变化。

Method: 提出上下文敏感的多智能体协调框架，结合协调深度Q网络、图神经网络和注意力机制，处理20个上下文特征（天气、交通、电网负载、电价等），通过加权协调机制和共识协议平衡五个利益相关者。

Result: 在包含441,077个充电交易的真实数据集上验证，相比DDPG、A3C、PPO和GNN等基线算法，实现了92%协调成功率、15%能效提升、10%成本降低、20%电网压力减少、2.3倍收敛速度，同时保持88%训练稳定性和85%样本效率。

Conclusion: CAMAC-DRA框架成功开发了上下文感知的多利益相关者协调系统，平衡竞争目标并适应实时变量，是智能电动汽车充电协调和可持续交通电气化的突破性解决方案，具有商业可行性。

Abstract: This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across networks of 250 EVs and 45 charging stations while adapting to dynamic environmental conditions through context-aware decision-making. Our multi-agent approach employs coordinated Deep Q\-Networks integrated with Graph Neural Networks and attention mechanisms, processing 20 contextual features including weather patterns, traffic conditions, grid load fluctuations, and electricity pricing.The framework balances five ecosystem stakeholders i.e. EV users (25\%), grid operators (20\%), charging station operators (20\%), fleet operators (20%), and environmental factors (15\%) through weighted coordination mechanisms and consensus protocols. Comprehensive validation using real-world datasets containing 441,077 charging transactions demonstrates superior performance compared to baseline algorithms including DDPG, A3C, PPO, and GNN approaches. The CAMAC\-DRA framework achieves 92\% coordination success rate, 15\% energy efficiency improvement, 10\% cost reduction, 20% grid strain decrease, and \2.3x faster convergence while maintaining 88\% training stability and 85\% sample efficiency. Real-world validation confirms commercial viability with Net Present Cost of -\$122,962 and 69\% cost reduction through renewable energy integration. The framework's unique contribution lies in developing context-aware multi-stakeholder coordination that successfully balances competing objectives while adapting to real-time variables, positioning it as a breakthrough solution for intelligent EV charging coordination and sustainable transportation electrification.

</details>


### [222] [The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification](https://arxiv.org/abs/2512.12059)
*Luke Bhan,Hanyu Zhang,Andrew Gordon Wilson,Michael W. Mahoney,Chuck Arvin*

Main category: cs.AI

TL;DR: 提出Forecast Critic系统，利用LLM进行自动化预测监控，通过实验验证LLM能有效识别不合理预测并整合非结构化特征，在真实数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 大规模零售业务中预测系统监控对客户满意度、盈利能力和运营效率至关重要，需要自动化解决方案来评估预测质量。

Method: 提出Forecast Critic系统，利用LLM的广泛世界知识和推理能力进行预测监控。通过三个实验评估LLM能力：1) 识别明显不合理预测；2) 整合非结构化外部特征；3) 比较不同模型规模和推理能力。

Result: LLM能可靠检测和批评不良预测（时间错位、趋势不一致、峰值错误），最佳模型F1分数0.88（人类水平0.97）。多模态LLM能有效整合上下文信号识别促销峰值（F1分数0.84）。在M5数据集上，不合理预测的sCRPS至少高出10%。

Conclusion: LLM即使没有领域特定微调，也能为自动化预测监控和评估提供可行且可扩展的选项，展示了在零售预测监控中的实用价值。

Abstract: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses. We propose The Forecast Critic, a system that leverages Large Language Models (LLMs) for automated forecast monitoring, taking advantage of their broad world knowledge and strong ``reasoning'' capabilities. As a prerequisite for this, we systematically evaluate the ability of LLMs to assess time series forecast quality, focusing on three key questions. (1) Can LLMs be deployed to perform forecast monitoring and identify obviously unreasonable forecasts? (2) Can LLMs effectively incorporate unstructured exogenous features to assess what a reasonable forecast looks like? (3) How does performance vary across model sizes and reasoning capabilities, measured across state-of-the-art LLMs? We present three experiments, including on both synthetic and real-world forecasting data. Our results show that LLMs can reliably detect and critique poor forecasts, such as those plagued by temporal misalignment, trend inconsistencies, and spike errors. The best-performing model we evaluated achieves an F1 score of 0.88, somewhat below human-level performance (F1 score: 0.97). We also demonstrate that multi-modal LLMs can effectively incorporate unstructured contextual signals to refine their assessment of the forecast. Models correctly identify missing or spurious promotional spikes when provided with historical context about past promotions (F1 score: 0.84). Lastly, we demonstrate that these techniques succeed in identifying inaccurate forecasts on the real-world M5 time series dataset, with unreasonable forecasts having an sCRPS at least 10% higher than that of reasonable forecasts. These findings suggest that LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

</details>


### [223] [Reliable Policy Iteration: Performance Robustness Across Architecture and Environment Perturbations](https://arxiv.org/abs/2512.12088)
*S. R. Eshwar,Aniruddha Mukherjee,Kintan Saha,Krishna Agarwal,Gugan Thoppe,Aditya Gopalan,Gal Dalal*

Main category: cs.AI

TL;DR: RPI在CartPole和Inverted Pendulum任务中相比主流深度强化学习方法表现更稳定，能早期达到接近最优性能并保持，解决了样本效率低、训练不稳定和超参数敏感等问题。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习方法常受样本效率低、训练不稳定和超参数敏感等问题困扰，需要更可靠的替代方案。RPI旨在将策略迭代的单调性价值估计特性扩展到函数逼近场景。

Method: 在CartPole和Inverted Pendulum两个经典控制任务上，通过改变神经网络和环境参数来评估RPI的鲁棒性，并与DQN、Double DQN、DDPG、TD3、PPO等主流方法进行比较。

Result: RPI相比其他方法能更早达到接近最优性能，并在训练过程中持续保持这一策略，表现出更好的稳定性和可靠性。

Conclusion: RPI作为深度强化学习的可靠替代方案具有很大潜力，特别是在解决样本效率、训练稳定性和超参数敏感性等常见问题上表现突出。

Abstract: In a recent work, we proposed Reliable Policy Iteration (RPI), that restores policy iteration's monotonicity-of-value-estimates property to the function approximation setting. Here, we assess the robustness of RPI's empirical performance on two classical control tasks -- CartPole and Inverted Pendulum -- under changes to neural network and environmental parameters. Relative to DQN, Double DQN, DDPG, TD3, and PPO, RPI reaches near-optimal performance early and sustains this policy as training proceeds. Because deep RL methods are often hampered by sample inefficiency, training instability, and hyperparameter sensitivity, our results highlight RPI's promise as a more reliable alternative.

</details>


### [224] [Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective](https://arxiv.org/abs/2512.12175)
*Haoyang Chen,Richong Zhang,Junfan Chen*

Main category: cs.AI

TL;DR: 论文提出TopK-SD方法，通过数据合成结合语义和标签信息来选择标签一致的演示示例，改进传统TopK检索方法，提升上下文学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的方法选择语义最相似的Top-K示例作为演示，但忽略了标签一致性。从贝叶斯视角和转导标签传播的角度重新思考ICL，发现标签一致性对概念引导至关重要。

Method: 提出TopK-SD方法：1) 建立标签传播框架连接标签一致性与传播误差边界；2) 设计数据合成方法，同时利用语义和标签信息；3) 使用合成数据选择标签一致的演示示例。

Result: TopK-SD在多个基准测试中优于原始TopK采样方法，验证了标签一致性对ICL性能的重要性。

Conclusion: 从转导学习和标签传播角度为理解ICL工作机制提供了新视角，强调标签一致性在演示选择中的关键作用。

Abstract: Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.

</details>


### [225] [Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation](https://arxiv.org/abs/2512.12177)
*Aydin Ayanzadeh,Tim Oates*

Main category: cs.AI

TL;DR: Floorplan2Guide：利用基础模型将平面图转换为可导航知识图谱，为视障用户生成可读导航指令的室内导航系统


<details>
  <summary>Details</summary>
Motivation: 当前室内导航解决方案主要依赖基础设施系统，在动态环境中导航能力有限。视障用户在室内导航面临重大挑战，需要更智能、无需大量基础设施的导航方案。

Method: 使用大语言模型从建筑布局中提取空间信息，将平面图转换为可导航知识图谱，通过少样本学习生成人类可读导航指令。采用图形表示和上下文学习增强导航性能。

Result: Claude 3.7 Sonnet在5-shot提示下达到最高准确率：短路线92.31%、中路线76.92%、长路线61.54%。基于图的空间结构成功率比直接视觉推理高15.4%，证实图形表示和上下文学习能提升导航性能。

Conclusion: Floorplan2Guide通过将平面图转换为知识图谱并利用少样本学习，为视障用户提供了更精确的室内导航解决方案，减少了对基础设施的依赖，提高了在动态环境中的导航能力。

Abstract: Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.

</details>


### [226] [TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion](https://arxiv.org/abs/2512.12182)
*Xinyu Gao*

Main category: cs.AI

TL;DR: 本文提出了一种新的少样本知识图谱补全框架，通过两阶段注意力三元增强器和U-KAN扩散模型，在生成表示视角下解决长尾关系分布问题，在两个公开数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据的异构性和多面性导致知识图谱中关系分布呈现长尾特性，使得在有限样本下补全缺失事实变得至关重要。现有方法主要基于度量匹配或元学习，但要么未能充分利用图中的邻域信息，要么忽视了对比信号的分布特性。

Method: 从生成表示的角度重新审视问题，提出一个少样本知识图谱补全框架，整合了两阶段注意力三元增强器和基于U-KAN的扩散模型。

Result: 在两个公开数据集上的大量实验表明，该方法取得了新的最先进结果。

Conclusion: 提出的生成表示视角下的少样本知识图谱补全框架有效解决了长尾关系分布问题，通过两阶段注意力三元增强器和U-KAN扩散模型的结合，显著提升了补全性能。

Abstract: Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.

</details>


### [227] [A Geometric Theory of Cognition](https://arxiv.org/abs/2512.12225)
*Laha Ale*

Main category: cs.AI

TL;DR: 提出统一认知几何框架：将认知状态表示为黎曼流形上的点，认知过程是该流形上认知势的梯度流，自然解释双加工理论等现象。


<details>
  <summary>Details</summary>
Motivation: 人类认知涵盖感知、记忆、直觉判断、深思推理、行动选择和社会推理等多个方面，但现有理论往往用不同的计算理论分别解释这些能力。需要建立一个统一的数学框架，从单一几何原理推导出多样化的认知过程。

Method: 将认知状态表示为可微流形上的点，赋予学习到的黎曼度量来编码表征约束、计算成本和认知变量间的结构关系。定义标量认知势（结合预测准确性、结构简洁性、任务效用和规范要求），认知过程是该势在黎曼度量下的梯度流。

Result: 经典双加工效应（快速直觉响应和缓慢深思推理）自然从度量诱导的各向异性中涌现，产生内在时间尺度分离和几何相变，无需模块化或混合架构。通过模拟经典认知任务展示了这些机制的行为特征。

Conclusion: 建立了一个认知的几何基础，为开发更通用、更类人的人工智能系统提供了指导原则。该框架统一解释了多样化的认知现象，从单一几何原理推导出心理学规律。

Abstract: Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.

</details>


### [228] [A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure](https://arxiv.org/abs/2512.12260)
*Ege Atacan Doğan,Peter F. Patel-Schneider*

Main category: cs.AI

TL;DR: 本文分析Wikidata的多层次、多轴分类设计，与传统本体论的单一层次结构形成对比，探讨其结构影响和可扩展性优势。


<details>
  <summary>Details</summary>
Motivation: 传统本体论设计强调互斥且穷尽的顶层分类（如持续体vs发生体、抽象vs具体、类型vs实例），而Wikidata采用不同的多轴分类方法。需要分析这种设计对知识图谱结构的影响。

Method: 分析Wikidata的多层次、多轴分类架构，与传统本体论的单一层次结构进行对比，研究其结构特性和设计原则。

Result: Wikidata的多轴分类设计允许实体同时属于多个分类轴，共享根类"entity"，这种架构支持可扩展和模块化的本体构建，特别适合协作和演化的知识图谱。

Conclusion: Wikidata的多层次、多轴分类设计为大规模协作知识图谱提供了更灵活、可扩展的架构，突破了传统本体论的单一分类限制。

Abstract: Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.

</details>


### [229] [Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases](https://arxiv.org/abs/2512.12288)
*Mahule Roy,Guillaume Lambard*

Main category: cs.AI

TL;DR: 提出量子感知生成AI框架，通过多保真度学习和主动验证解决DFT在强关联材料中的系统误差问题，相比DFT基线在相关氧化物等高分歧区域提高3-5倍稳定候选材料识别率。


<details>
  <summary>Details</summary>
Motivation: 传统材料发现生成模型依赖DFT近似交换相关泛函，继承了DFT对强关联系统的系统性失败，导致探索偏差，无法发现DFT预测定性错误的材料。

Method: 采用扩散生成器（基于量子力学描述符）和验证器（使用等变神经网络势能，训练于多理论层次数据集：PBE、SCAN、HSE06、CCSD(T)），结合主动学习循环量化并针对低-高保真度预测差异。

Result: 在多个挑战性材料类别中相比最先进生成模型（CDVAE、GNoME、DiffCSP）显著改进：在高分歧区域（如相关氧化物）成功识别潜在稳定候选材料的效率提高3-5倍，同时保持计算可行性。

Conclusion: 提供了一个严谨、透明的框架，将计算材料发现的有效搜索空间扩展到单保真度模型的限制之外，解决了DFT系统误差带来的瓶颈问题。

Abstract: Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.

</details>


### [230] [Entropy Collapse: A Universal Failure Mode of Intelligent Systems](https://arxiv.org/abs/2512.12381)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 论文提出"熵崩溃"概念，解释智能系统在进化中因反馈放大超过新颖性再生而导致的适应性退化现象，表现为从高熵适应态向低熵崩溃态的相变。


<details>
  <summary>Details</summary>
Motivation: 智能系统（从AI到经济制度和生物进化）常出现悖论：智力提升反而导致系统僵化、适应性丧失和意外失败。现有理论缺乏统一框架解释这一普遍现象。

Method: 在最小化领域无关假设下，将熵崩溃形式化为向稳定低熵流形的收敛过程，而非零熵状态。通过分析建立临界阈值、动态不可逆性和吸引子结构，并通过最小模拟展示更新机制的普适性。

Result: 建立了熵崩溃作为智能系统普遍失效模式的统一理论框架，将AI模型崩溃、经济制度僵化和进化遗传瓶颈等现象解释为同一底层过程的表现。

Conclusion: 熵崩溃是智能的结构性代价，晚期干预通常失败。研究结果为设计具有长期适应性的智能系统提供了熵感知的设计原则。

Abstract: Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.
  We identify \emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.
  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.
  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.
  \noindent\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis

</details>


### [231] [Feeling the Strength but Not the Source: Partial Introspection in LLMs](https://arxiv.org/abs/2512.12411)
*Ely Hahami,Lavik Jain,Ishaan Sinha*

Main category: cs.AI

TL;DR: 论文测试了Anthropic关于大模型能检测和命名注入"概念"的发现，发现该能力具有脆弱性，但在某些任务中仍能部分实现。


<details>
  <summary>Details</summary>
Motivation: 验证Anthropic关于前沿模型能检测和命名注入概念的声称是否稳健，探究这种自省能力的范围和局限性。

Method: 1) 在Meta-Llama-3.1-8B-Instruct上复现Anthropic的多轮"涌现自省"实验；2) 系统性地改变推理提示，测试自省能力的鲁棒性；3) 探索部分自省的新范式，让模型对注入概念向量的系数强度进行分类。

Result: 1) 成功复现了Anthropic的结果，模型在20%的情况下能识别和命名注入概念；2) 自省能力很脆弱，在相关任务（如多项选择识别、二元判别）上性能崩溃；3) 发现了部分自省范式，模型能以70%的准确率对注入概念向量的系数强度进行分类（远高于25%的随机基线）。

Conclusion: 语言模型在自省时确实基于其内部表示进行计算，但这些自我报告是狭窄且提示敏感的，自省能力具有局限性。

Abstract: Recent work from Anthropic claims that frontier models can sometimes detect and name injected "concepts" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn "emergent introspection" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.

</details>


### [232] [Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale](https://arxiv.org/abs/2512.12413)
*Gabriel R. Lau,Wei Yan Low,Louis Tay,Ysabel Guevarra,Dragan Gašević,Andree Hartanto*

Main category: cs.AI

TL;DR: 开发并验证了一个13项量表来测量AI使用中的批判性思维，包含验证、动机和反思三个维度，能预测更准确的AI输出判断和更深入的反思。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具日益普及，但其流畅性、不透明性和幻觉倾向要求用户必须批判性地评估AI输出，而不是盲目接受。需要概念化AI使用中的批判性思维并开发测量工具。

Method: 通过六项研究（N=1365）开发和验证了13项AI使用批判性思维量表：研究1生成项目，研究2支持三因素结构（验证、动机、反思），研究3-5验证高阶模型、信效度，研究6证明标准效度，包括ChatGPT事实核查任务。

Result: 量表具有良好的心理测量特性，AI使用批判性思维与开放性、外向性、积极特质情感和AI使用频率正相关，能预测更频繁多样的验证策略、更高的事实判断准确性以及更深入的负责任AI反思。

Conclusion: 该研究阐明了人们如何监督生成式AI输出，提供了经过验证的量表和生态效度高的任务范式，支持理论检验、跨群体和纵向研究，促进对生成式AI输出的批判性参与。

Abstract: Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.

</details>


### [233] [AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline](https://arxiv.org/abs/2512.12443)
*Akhmadillo Mamirov,Faiaz Azmain,Hanyu Wang*

Main category: cs.AI

TL;DR: 论文分析了AI模型文档的碎片化和不一致问题，开发了加权透明度框架和自动化评估管道，发现前沿实验室透明度约80%，但安全关键领域存在显著差距。


<details>
  <summary>Details</summary>
Motivation: AI模型文档分散在不同平台且结构不一致，导致政策制定者、审计师和用户难以可靠评估安全声明、数据来源和版本变更。现有文档缺乏标准化，透明度不足。

Method: 1) 分析5个前沿模型和100个Hugging Face模型卡，识别947个独特章节名称；2) 基于欧盟AI法案和斯坦福透明度指数开发加权透明度框架（8个主要部分，23个子部分）；3) 实现自动化多智能体管道，从公开来源提取文档并通过LLM共识评分完整性；4) 评估50个跨视觉、多模态、开源和闭源模型。

Result: 1) 前沿实验室（xAI、微软、Anthropic）透明度约80%，大多数提供商低于60%；2) 安全关键类别缺陷最大：欺骗行为、幻觉和儿童安全评估分别损失148、124和116分；3) 评估50个模型总成本低于3美元；4) 发现系统性差距，文档命名极度不一致（仅使用信息就有97个不同标签）。

Conclusion: AI模型文档存在严重标准化缺失，安全关键信息披露不足。提出的加权透明度框架和自动化评估管道能有效识别透明度差距，为监管和行业实践提供实用工具。

Abstract: AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.

</details>


### [234] [MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs](https://arxiv.org/abs/2512.12477)
*Jiawen Chen,Yanyan He,Qi Shao,Mengli Wei,Duxin Chen,Wenwu Yu,Yanlong Zhao*

Main category: cs.AI

TL;DR: MetaHGNIE：基于元路径诱导超图对比学习的异质知识图谱节点重要性估计框架，通过建模高阶交互和跨模态对齐提升性能


<details>
  <summary>Details</summary>
Motivation: 现有异质知识图谱节点重要性估计方法存在两个主要问题：1）仅依赖成对连接，忽略多实体关系的高阶依赖；2）将结构信号和语义信号独立处理，缺乏有效的跨模态整合

Method: 1）通过元路径序列构建高阶知识图谱，类型化超边捕获多实体关系上下文；2）结构依赖通过局部注意力聚合，语义表示通过稀疏分块超图变换器编码；3）多模态融合模块在对比学习和辅助监督下整合结构和语义嵌入

Result: 在基准NIE数据集上的大量实验表明，MetaHGNIE始终优于现有最先进基线方法

Conclusion: 明确建模高阶交互和跨模态对齐在异质知识图谱中是有效的，MetaHGNIE框架为解决节点重要性估计问题提供了新思路

Abstract: Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE

</details>


### [235] [SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation](https://arxiv.org/abs/2512.12501)
*Dang Phuong Nam,Nguyen Kieu,Pham Thanh Hieu*

Main category: cs.AI

TL;DR: SafeGen是一个将伦理保障嵌入文本到图像生成流程的框架，通过BGE-M3文本分类器过滤有害提示和Hyper-SD扩散模型生成高质量图像，在保持创造自由的同时实现伦理责任。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创造表达、教育和研究方面带来新机遇，但文本到图像系统如DALL.E、Stable Diffusion等存在双重使用困境，会放大社会偏见、产生高保真虚假信息、侵犯知识产权等伦理问题。

Method: 基于可信AI原则设计SafeGen框架，包含两个互补组件：1) BGE-M3微调文本分类器过滤有害或误导性提示；2) Hyper-SD优化扩散模型生成高保真、语义对齐的图像。使用多语言（英语-越南语）数据集和公平感知训练过程。

Result: 定量评估显示Hyper-SD达到IS=3.52、FID=22.08、SSIM=0.79，BGE-M3达到F1分数0.81。消融研究验证了领域特定微调的重要性。案例研究展示了SafeGen在阻止不安全提示、生成包容性教学材料和加强学术诚信方面的实际影响。

Conclusion: SafeGen证明了创造自由和伦理责任可以在单一工作流程中协调，为文本到图像生成提供了既保持高质量输出又嵌入伦理保障的可行解决方案。

Abstract: Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. SafeGen integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high fidelity, semantically aligned images. Built on a curated multilingual (English- Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow. Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

</details>


### [236] [KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs](https://arxiv.org/abs/2512.12503)
*Mingrui Ye,Chanjin Zheng,Zengyi Yu,Chenyu Xiang,Zhixue Zhao,Zheng Yuan,Helen Yannakoudakis*

Main category: cs.AI

TL;DR: 提出了KidsArtBench基准，包含1000+儿童艺术作品的多维度专家标注，并设计了属性特定的多LoRA方法进行艺术评估，显著提升了MLLM在儿童艺术评价上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在艺术表达评估方面能力有限，因为美学概念抽象开放，且多模态艺术作品标注稀缺。儿童艺术作品尤其缺乏系统性的评估基准。

Method: 1) 构建KidsArtBench基准：包含1000+幅5-15岁儿童艺术作品，由12位专家教育者按照9个维度进行标注，并提供专家评论反馈；2) 提出属性特定的多LoRA方法：每个评估维度对应一个独立的LoRA适配器，采用回归感知微调来对齐序数尺度预测。

Result: 在Qwen2.5-VL-7B模型上，该方法将相关性从0.468提升到0.653，在感知维度上提升最大，在高阶属性上的差距也缩小了。展示了教育者对齐监督和属性感知训练能够产生有教育意义的评估。

Conclusion: 通过教育者对齐的监督和属性感知训练，可以实现具有教育意义的艺术评估，为教育AI的持续进步建立了严谨的测试平台。同时发布了数据、代码和伦理文档。

Abstract: Multimodal Large Language Models (MLLMs) show remarkable progress across many visual-language tasks; however, their capacity to evaluate artistic expression remains limited. Aesthetic concepts are inherently abstract and open-ended, and multimodal artwork annotations are scarce. We introduce KidsArtBench, a new benchmark of over 1k children's artworks (ages 5-15) annotated by 12 expert educators across 9 rubric-aligned dimensions, together with expert comments for feedback. Unlike prior aesthetic datasets that provide single scalar scores on adult imagery, KidsArtBench targets children's artwork and pairs multi-dimensional annotations with comment supervision to enable both ordinal assessment and formative feedback. Building on this resource, we propose an attribute-specific multi-LoRA approach, where each attribute corresponds to a distinct evaluation dimension (e.g., Realism, Imagination) in the scoring rubric, with Regression-Aware Fine-Tuning (RAFT) to align predictions with ordinal scales. On Qwen2.5-VL-7B, our method increases correlation from 0.468 to 0.653, with the largest gains on perceptual dimensions and narrowed gaps on higher-order attributes. These results show that educator-aligned supervision and attribute-aware training yield pedagogically meaningful evaluations and establish a rigorous testbed for sustained progress in educational AI. We release data and code with ethics documentation.

</details>


### [237] [World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents](https://arxiv.org/abs/2512.12548)
*Yesid Fonseca,Manuel S. Ríos,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.AI

TL;DR: 模型强化学习智能体通过学习世界模型，自然收敛到与边际价值定理一致的觅食策略，比无模型智能体更接近生物觅食行为。


<details>
  <summary>Details</summary>
Motivation: 边际价值定理（MVT）是行为生态学中描述最优觅食行为的经典模型，但生物觅食者实现这种最优决策的计算机制尚不清楚。研究旨在探索人工智能系统如何通过计算机制实现类似生物的最优觅食决策。

Method: 使用基于模型的强化学习智能体，学习环境的简约预测表示（世界模型），而不是单纯追求奖励最大化。通过比较基于模型和无模型的强化学习智能体，分析其觅食决策模式。

Result: 基于模型的智能体自然收敛到与MVT一致的策略，表现出与生物觅食者相似的决策模式。其预测能力（而非单纯奖励最大化）驱动了高效的斑块离开行为。

Conclusion: 预测性世界模型可以作为构建更可解释、更符合生物基础的AI决策系统的基础。生态最优性原理对推进可解释和自适应AI具有重要价值。

Abstract: Patch foraging involves the deliberate and planned process of determining the optimal time to depart from a resource-rich region and investigate potentially more beneficial alternatives. The Marginal Value Theorem (MVT) is frequently used to characterize this process, offering an optimality model for such foraging behaviors. Although this model has been widely used to make predictions in behavioral ecology, discovering the computational mechanisms that facilitate the emergence of optimal patch-foraging decisions in biological foragers remains under investigation. Here, we show that artificial foragers equipped with learned world models naturally converge to MVT-aligned strategies. Using a model-based reinforcement learning agent that acquires a parsimonious predictive representation of its environment, we demonstrate that anticipatory capabilities, rather than reward maximization alone, drive efficient patch-leaving behavior. Compared with standard model-free RL agents, these model-based agents exhibit decision patterns similar to many of their biological counterparts, suggesting that predictive world models can serve as a foundation for more explainable and biologically grounded decision-making in AI systems. Overall, our findings highlight the value of ecological optimality principles for advancing interpretable and adaptive AI.

</details>


### [238] [Large Language Newsvendor: Decision Biases and Cognitive Mechanisms](https://arxiv.org/abs/2512.12552)
*Jifei Liu,Zhi Chen,Yuanguang Zhong*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在供应链决策中会复制并放大人类认知偏差，GPT-4因过度思考表现出最大非理性，而效率优化的GPT-4o表现接近最优。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地融入商业决策，它们可能复制甚至放大人类认知偏差的风险尚未被充分理解，这在供应链管理等高风险运营环境中尤为关键。

Method: 使用经典的报童问题在动态设置中测试GPT-4、GPT-4o和LLaMA-8B，通过多轮实验检测五种已确立的决策偏差。

Result: LLMs一致复制了经典的"过低/过高"订购偏差，并显著放大了需求追逐等行为；GPT-4表现出最大非理性（"智能悖论"），而GPT-4o表现接近最优；即使提供最优公式，偏差仍然存在，表明源于架构约束而非知识差距。

Conclusion: 管理者应根据具体任务选择模型，需要强有力的人机协同监督，设计结构化、基于规则的提示是约束模型启发式倾向、提高AI辅助决策可靠性的有效策略。

Abstract: Problem definition: Although large language models (LLMs) are increasingly integrated into business decision making, their potential to replicate and even amplify human cognitive biases cautions a significant, yet not well-understood, risk. This is particularly critical in high-stakes operational contexts like supply chain management. To address this, we investigate the decision-making patterns of leading LLMs using the canonical newsvendor problem in a dynamic setting, aiming to identify the nature and origins of their cognitive biases. Methodology/results: Through dynamic, multi-round experiments with GPT-4, GPT-4o, and LLaMA-8B, we tested for five established decision biases. We found that LLMs consistently replicated the classic ``Too Low/Too High'' ordering bias and significantly amplified other tendencies like demand-chasing behavior compared to human benchmarks. Our analysis uncovered a ``paradox of intelligence'': the more sophisticated GPT-4 demonstrated the greatest irrationality through overthinking, while the efficiency-optimized GPT-4o performed near-optimally. Because these biases persist even when optimal formulas are provided, we conclude they stem from architectural constraints rather than knowledge gaps. Managerial implications: First, managers should select models based on the specific task, as our results show that efficiency-optimized models can outperform more complex ones on certain optimization problems. Second, the significant amplification of bias by LLMs highlights the urgent need for robust human-in-the-loop oversight in high-stakes decisions to prevent costly errors. Third, our findings suggest that designing structured, rule-based prompts is a practical and effective strategy for managers to constrain models' heuristic tendencies and improve the reliability of AI-assisted decisions.

</details>


### [239] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://arxiv.org/abs/2512.12597)
*Miriam Horovicz*

Main category: cs.AI

TL;DR: AgentSHAP是首个基于Shapley值的LLM智能体工具重要性解释框架，无需访问模型内部权重，通过蒙特卡洛采样降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法无法解释LLM智能体中使用的外部工具对响应的贡献程度，这是一个盲点。

Method: 基于博弈论中的Shapley值，将智能体视为黑盒，通过蒙特卡洛采样测试不同工具子集下的智能体响应，计算公平的重要性分数。

Result: 在API-Bank上的实验表明，AgentSHAP能产生一致的分数，正确识别重要工具，区分相关与无关工具。

Conclusion: AgentSHAP填补了工具级解释的空白，与TokenSHAP和PixelSHAP共同构成了现代生成式AI的Shapley值可解释性工具家族。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.

</details>


### [240] [Modular and Multi-Path-Aware Offline Benchmarking for Mobile GUI Agents](https://arxiv.org/abs/2512.12634)
*Youngmin Im,Byeongung Jo,Jaeyoung Wi,Seungwoo Baek,Tae Hoon Min,Joo Hyung Lee,Sangeun Oh,Insik Shin,Sunjae Lee*

Main category: cs.AI

TL;DR: MobiBench：首个模块化、多路径感知的移动GUI智能体离线评测框架，解决现有评测方法在公平性、可扩展性和可复现性方面的局限


<details>
  <summary>Details</summary>
Motivation: 当前移动GUI智能体评测存在两大根本限制：1）离线基准使用静态单路径标注数据集，不公平地惩罚有效替代动作；在线基准则因动态不可预测性导致可扩展性和可复现性差。2）现有基准将智能体视为整体黑盒，忽视各组件贡献，导致不公平比较或掩盖性能瓶颈。

Method: 提出MobiBench框架，首个模块化、多路径感知的移动GUI智能体离线评测框架。支持高保真、可扩展、可复现的完全离线评测，通过模块级分析深入理解智能体性能。

Result: 实验显示MobiBench与人类评估者达成94.72%的一致性，与精心设计的在线基准相当，同时保持了静态离线基准的可扩展性和可复现性。模块级分析揭示了移动GUI智能体多种技术的系统评估、跨模型规模的最优模块配置、当前大模型的固有局限性，以及设计更强大、成本效益更高的移动智能体的可行指南。

Conclusion: MobiBench为移动GUI智能体评测提供了更公平、可扩展、可复现的解决方案，通过模块化分析揭示了关键性能洞察，为设计更优移动智能体提供了指导。

Abstract: Mobile GUI Agents, AI agents capable of interacting with mobile applications on behalf of users, have the potential to transform human computer interaction. However, current evaluation practices for GUI agents face two fundamental limitations. First, they either rely on single path offline benchmarks or online live benchmarks. Offline benchmarks using static, single path annotated datasets unfairly penalize valid alternative actions, while online benchmarks suffer from poor scalability and reproducibility due to the dynamic and unpredictable nature of live evaluation. Second, existing benchmarks treat agents as monolithic black boxes, overlooking the contributions of individual components, which often leads to unfair comparisons or obscures key performance bottlenecks. To address these limitations, we present MobiBench, the first modular and multi path aware offline benchmarking framework for mobile GUI agents that enables high fidelity, scalable, and reproducible evaluation entirely in offline settings. Our experiments demonstrate that MobiBench achieves 94.72 percent agreement with human evaluators, on par with carefully engineered online benchmarks, while preserving the scalability and reproducibility of static offline benchmarks. Furthermore, our comprehensive module level analysis uncovers several key insights, including a systematic evaluation of diverse techniques used in mobile GUI agents, optimal module configurations across model scales, the inherent limitations of current LFMs, and actionable guidelines for designing more capable and cost efficient mobile agents.

</details>


### [241] [Value-Aware Multiagent Systems](https://arxiv.org/abs/2512.12652)
*Nardine Osman*

Main category: cs.AI

TL;DR: 本文提出"价值感知AI"概念，超越传统价值对齐问题，提供包含三个核心支柱的工程路线图：学习表示人类价值、确保个体与多智能体系统价值对齐、提供基于价值的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统AI价值对齐方法存在局限，需要更全面的价值感知框架。本文旨在超越单纯的价值对齐，提出系统化的价值感知AI工程路线图，使AI不仅能对齐人类价值，还能理解、表示和解释价值。

Method: 提出三支柱路线图：1) 使用形式语义学学习和表示人类价值；2) 确保个体智能体和多智能体系统的价值对齐；3) 提供基于价值的行为可解释性。展示了在这些主题上的持续研究工作及实际应用。

Result: 建立了价值感知AI的清晰概念框架和工程路线图，为开发更安全、可靠、可解释的AI系统提供了系统化方法。展示了在多个实际领域的应用潜力。

Conclusion: 价值感知AI为AI系统开发提供了超越传统价值对齐的全面框架，通过三支柱路线图可实现更安全、可靠、可解释的AI系统，对实际应用具有重要意义。

Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.

</details>


### [242] [Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI](https://arxiv.org/abs/2512.12686)
*Samarth Sarin,Lovepreet Singh,Bhaskarjit Sarmah,Dhagash Mehta*

Main category: cs.AI

TL;DR: Memoria是一个模块化记忆框架，通过动态会话摘要和加权知识图谱为用户建模，为LLM提供持久、可解释的记忆能力，实现短期对话连贯和长期个性化。


<details>
  <summary>Details</summary>
Motivation: LLM需要记忆能力来维持对话连续性、个性化和长期上下文，以成为真正交互式和自适应的智能体。当前LLM接口缺乏状态性，无法跨对话保留信息。

Method: 提出Memoria框架，包含两个互补组件：1) 动态会话级摘要，2) 基于加权知识图谱的用户建模引擎，以结构化实体和关系增量捕获用户特征、偏好和行为模式。

Result: Memoria能够实现可扩展的个性化对话AI，弥合无状态LLM接口与智能体记忆系统之间的差距，为需要自适应和演进用户体验的行业应用提供实用解决方案。

Conclusion: Memoria是一个实用的模块化记忆框架，通过混合架构在LLM的token限制内实现短期对话连贯和长期个性化，为部署真正交互式和自适应的LLM智能体提供了关键能力。

Abstract: Agentic memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive agents. Agentic memory refers to the memory that provides an LLM with agent-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and agentic memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.

</details>


### [243] [WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment](https://arxiv.org/abs/2512.12692)
*Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: WebOperator：一个结合最佳优先搜索和安全回溯的树搜索框架，用于提升LLM智能体在网页环境中的探索能力，防止不可逆操作带来的副作用。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在网页环境中采用贪婪的逐步执行方式，缺乏长期规划能力，且网页环境具有部分可观测性，错误操作难以撤销。现有树搜索方法缺乏安全回溯机制，且假设所有操作都可逆，这在现实网页任务中效果有限。

Method: 提出WebOperator框架：1）采用最佳优先搜索策略，根据奖励估计和安全性对动作排序；2）包含鲁棒的回溯机制，在重放路径前验证可行性；3）从多个不同推理上下文生成动作候选，过滤无效动作并合并语义等价动作。

Result: 在WebArena和WebVoyager上的实验表明WebOperator有效。在WebArena上，使用gpt-4o实现了54.6%的成功率，达到最先进水平。

Conclusion: WebOperator通过将战略远见与安全执行相结合，显著提升了LLM智能体在网页任务中的性能，证明了集成规划与安全机制的重要性。

Abstract: LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.

</details>


### [244] [Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2512.12706)
*Enhong Mu,Minami Yoda,Yan Zhang,Mingyue Zhang,Yutaka Matsuno,Jialong Li*

Main category: cs.AI

TL;DR: SMART框架结合结构验证与功能验证，利用LLM解析AST差异并构建混合奖励机制，指导RL智能体在游戏更新测试中同时覆盖修改代码分支和完成游戏任务。


<details>
  <summary>Details</summary>
Motivation: 游戏即服务(GaaS)模式需要频繁内容更新，给质量保证带来巨大压力。现有自动化测试方法存在二元对立：代码中心方法关注结构覆盖但不理解游戏上下文，玩家中心代理验证高层意图但常无法覆盖底层代码变更。需要弥合这一差距。

Method: 提出SMART框架，利用大语言模型(LLM)解析抽象语法树(AST)差异并提取功能意图，构建上下文感知的混合奖励机制。该机制指导强化学习智能体顺序完成游戏目标，同时自适应探索修改的代码分支。

Result: 在Overcooked和Minecraft环境中评估，SMART显著优于最先进基线方法：达到超过94%的修改代码分支覆盖率（几乎是传统RL方法的两倍），同时保持98%的任务完成率，有效平衡结构全面性和功能正确性。

Conclusion: SMART成功弥合了结构验证与功能验证之间的差距，为游戏更新测试提供了一种既能覆盖代码变更又能验证游戏功能的综合解决方案，有效应对GaaS模式下的频繁更新压力。

Abstract: The widespread adoption of the "Games as a Service" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.

</details>


### [245] [Causal Counterfactuals Reconsidered](https://arxiv.org/abs/2512.12804)
*Sander Beckers*

Main category: cs.AI

TL;DR: 提出一种新的反事实概率语义学，扩展了Pearl的标准语义，适用于无法扩展为现实结构因果模型的概率因果模型，在Pearl和Dawid的争论中提供折中方案。


<details>
  <summary>Details</summary>
Motivation: 标准Pearlian语义学只能应用于可扩展为现实结构因果模型的概率因果模型，但作者发现即使在简单设置中也会出现无法扩展的模型，因此需要更一般的语义学。同时希望调和Pearl和Dawid关于反事实的长期争论。

Method: 提出新的反事实概率语义学，限制于满足马尔可夫条件、仅包含现实变量且因果完备的因果模型。虽然使用结构因果模型框架，但避免使用响应变量。证明该语义学与另外两个不涉及结构因果模型的近期提案等价。

Result: 成功开发出适用于更广泛概率因果模型的反事实语义学，能够处理标准Pearlian语义学无法覆盖的情况。证明了新语义学与其他方法的等价性，并与文献中关于随机反事实的各种评论保持一致。

Conclusion: 新语义学在Pearl和Dawid的争论中提供了合理的折中：接受Dawid对普遍因果决定论和不现实变量的批评，但支持Pearl关于一般反事实语义学可能性的观点。同时探讨了马尔可夫条件的普遍性和因果抽象的新推广。

Abstract: I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions

</details>


### [246] [Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution](https://arxiv.org/abs/2512.12806)
*Boyang Yan*

Main category: cs.AI

TL;DR: 论文提出了一种容错沙箱框架，通过策略拦截层和事务性文件系统快照机制，解决LLM作为自主代理时的安全风险，相比现有方案更适合无头自动化工作流。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从被动代码生成器转变为自主代理时，面临破坏性命令和系统状态不一致的安全风险。现有商业解决方案通常优先考虑交互式用户安全，强制认证屏障会破坏真正自主性所需的无头循环。

Method: 提出容错沙箱框架，包含基于策略的拦截层和事务性文件系统快照机制。将代理操作包装在原子事务中，通过EVPN/VXLAN隔离在Proxmox测试平台上部署Minimind-MoE LLM（通过nano-vllm服务）。

Result: 实验结果显示：高风险命令拦截率100%，失败状态回滚成功率100%。每个事务仅产生14.5%的性能开销（约1.8秒）。相比之下，Gemini CLI沙箱需要交互式认证，不适用于无头自主代理工作流。

Conclusion: 容错沙箱框架能有效保障LLM自主代理的安全性，通过原子事务机制在可接受的延迟内实现安全保证，优于容器初始化开销或商业CLI的交互摩擦，适合无头自动化工作流。

Abstract: The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping agent actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\% interception rate for high-risk commands and a 100\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication ("Sign in"), rendering it unusable for headless, autonomous agent workflows.

</details>


### [247] [Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents](https://arxiv.org/abs/2512.12856)
*Saad Alqithami*

Main category: cs.AI

TL;DR: 提出Memory-Aware Retention Schema (MaRS)框架和六种遗忘策略，通过FiFA基准评估，混合遗忘策略在性能、隐私和计算效率方面表现最优。


<details>
  <summary>Details</summary>
Motivation: 生成式代理在长期交互场景中，无限记忆存储导致计算不可行和隐私问题，而简单遗忘机制会损害代理一致性和功能，需要平衡性能、隐私和计算效率的解决方案。

Method: 提出Memory-Aware Retention Schema (MaRS)框架，包含六种理论基础的遗忘策略，并建立Forgetful but Faithful Agent (FiFA)评估基准，从叙事一致性、目标完成、社交回忆准确性、隐私保护和成本效率五个维度评估。

Result: 经过300次评估实验，混合遗忘策略获得最高综合得分0.911，在保持计算可行性和隐私保证的同时实现最优性能。

Conclusion: 为内存受限、隐私敏感环境中的生成式代理部署提供新基准和实用指南，通过解决代理内存管理的基本挑战，促进以人为中心AI的发展。

Abstract: As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.

</details>


### [248] [Satisfiability Modulo Theory Meets Inductive Logic Programming](https://arxiv.org/abs/2512.12918)
*Nijesh Upreti,Vaishak Belle*

Main category: cs.AI

TL;DR: 该论文提出了一种将归纳逻辑编程（ILP）与可满足性模理论（SMT）求解器Z3结合的模块化方法，以学习包含数值约束的可解释规则。


<details>
  <summary>Details</summary>
Motivation: 传统ILP系统在处理数值约束方面存在局限，通常需要离散化或手工定义数值谓词，难以联合推断跨示例的阈值或算术关系。需要扩展ILP以支持数值推理能力。

Method: 采用模块化架构，将ILP系统PyGol与SMT求解器Z3耦合。PyGol生成的候选子句被解释为背景理论（如线性/非线性实数算术）上的无量词公式，由Z3实例化和验证数值参数，同时保持ILP的声明式关系偏置。

Result: 在合成数据集上评估了该方法，这些数据集专门设计用于测试线性、关系、非线性和多跳推理能力。结果表明模块化SMT-ILP架构能够扩展符号规则学习的表达能力。

Conclusion: 模块化SMT-ILP方法能够学习结合符号谓词和数值约束的混合规则，扩展了符号规则学习的表达能力，为未来更丰富的理论感知归纳提供了灵活基础。

Abstract: Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.

</details>


### [249] [Towards Open Standards for Systemic Complexity in Digital Forensics](https://arxiv.org/abs/2512.12970)
*Paola Di Maio*

Main category: cs.AI

TL;DR: 提出基于开放标准和人类可读工件的数字取证AI模型架构，以应对AI与数字取证交叉领域中的系统复杂性和错误问题


<details>
  <summary>Details</summary>
Motivation: AI与数字取证交叉领域日益复杂，技术重叠广泛，尽管有显著进展，但取证科学仍存在错误和脆弱性，需要解决系统复杂性以减轻错误限制

Method: 通过采用人类可读工件和开放标准来识别和解决系统复杂性，并基于最新技术提出数字取证AI模型架构

Result: 提出了一个基于最先进技术的数字取证AI模型架构，旨在通过标准化方法提高数字取证系统的可靠性和可解释性

Conclusion: 通过采用人类可读工件和开放标准，可以有效应对AI与数字取证交叉领域的系统复杂性，减少错误并提高取证过程的可靠性

Abstract: The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.

</details>


### [250] [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)
*Bizhe Bai,Hongming Wu,Peng Ye,Tao Chen*

Main category: cs.AI

TL;DR: 本文提出M-GRPO框架和IQR自适应过滤方法，解决自监督强化学习中长期训练时的策略崩溃问题，实现更稳定的训练和更好的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督强化学习方法在长期训练中会出现"策略崩溃"问题，性能急剧下降。即使增加rollout数量也只能延迟但不能防止崩溃，需要新的稳定训练方法。

Method: 1. 提出M-GRPO（动量锚定组相对策略优化）框架，利用缓慢演化的动量模型提供稳定训练目标；2. 提出基于四分位距（IQR）的自适应过滤方法，动态修剪低熵轨迹，保持策略多样性。

Result: 在多个推理基准测试上的实验表明，M-GRPO稳定了训练过程，IQR过滤器防止了过早收敛，两者结合实现了优越的训练稳定性和最先进的性能。

Conclusion: 通过M-GRPO和IQR过滤器的组合，有效解决了自监督强化学习中的策略崩溃问题，为LLMs的推理能力提升提供了更稳定的训练框架。

Abstract: Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a "policy collapse" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.

</details>


### [251] [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)
*Rajeev Bhatt Ambati,Tianyi Niu,Aashu Singh,Shlok Mishra,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.AI

TL;DR: 该论文研究LLM在动态交互中的主动学习策略，让学生模型通过提问从教师获取知识，相比静态基线显著提升数学和编程任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景（如教育辅导、医疗协助）中，相关信息无法直接获取，需要LLM通过动态交互主动获取信息。现有研究主要关注教师如何指导学生，而本文转向学生视角，研究学生如何主动向教师提问以获取有用信息。

Method: 提出学生主导的主动学习策略，让学生模型识别自身不确定性并提问。使用直接偏好优化（DPO）训练学生模型，通过自我指导或更强学生模型的指导来提升问题质量。

Result: 在数学和编程基准测试中，学生主导方法相比静态基线至少获得0.5的绝对Pass@k提升。通过DPO指导训练，较小模型能够学会提出更好的问题，进一步提高学习效率。

Conclusion: 学生主导的主动学习策略能有效提升LLM在动态交互环境中的性能，通过指导训练优化问题质量可进一步增强学习效率，为LLM在需要主动信息获取的领域应用提供新方向。

Abstract: Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.

</details>


### [252] [Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels](https://arxiv.org/abs/2512.13142)
*Anika Sharma,Malavika Mampally,Chidaksh Ravuru,Kandyce Brennan,Neil Gaikwad*

Main category: cs.AI

TL;DR: LLMs缺乏对堕胎耻辱的多层次连贯理解，在认知、人际和结构层面均表现失败，存在系统性偏见和矛盾


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地介入污名化的健康决策，需要评估它们是否真正理解复杂的心理和生理现象，特别是对"无法言说"内容的把握能力

Method: 使用经过验证的个体层面堕胎耻辱量表(ILAS)，在五个主流LLMs上系统测试627个不同人口统计特征的人设，进行多层次分析

Result: 模型在所有层面都未能通过真正理解的测试：高估人际耻辱、低估认知耻辱、假设统一的社区谴责、引入人类验证数据中不存在的人口统计偏见、错过经验验证的耻辱-保密关系、在理论建构中自相矛盾

Conclusion: 当前的对齐方法只能确保适当的语言表达，但不能保证多层次连贯理解。AI安全需要新的设计、评估、治理和监管方法，以及AI素养教育

Abstract: As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

</details>


### [253] [MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations](https://arxiv.org/abs/2512.13154)
*Emre Can Acikgoz,Jinoh Oh,Joo Hyuk Jeon,Jie Hao,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: MAC是一个多智能体澄清框架，通过战略性地管理澄清对话来解决用户歧义，在MultiWOZ 2.4上任务成功率提高7.8%，对话轮次减少


<details>
  <summary>Details</summary>
Motivation: 对话代理常遇到模糊的用户请求，需要有效澄清才能完成任务。多智能体架构虽能高效处理复杂对话场景，但歧义解决仍是一个关键且未被充分探索的挑战，特别是在不确定或不完整用户输入时，哪个智能体应发起澄清以及如何协调行动的问题尚未解决。

Method: 提出MAC（多智能体澄清）框架，首先引入新的用户歧义分类法来系统指导澄清策略，然后设计自主协调多个智能体与用户协同交互的机制，在两个层面启用澄清功能。

Result: 在MultiWOZ 2.4上的实证评估显示，启用两个层面的澄清使任务成功率从54.5%提高到62.3%（提升7.8%），平均对话轮次从6.53减少到4.86，通过预先获取所有必要用户信息并最小化重复来实现。

Conclusion: 研究强调了主动用户交互和角色感知澄清对于更可靠的人机通信的重要性，MAC框架通过战略性地管理澄清对话有效解决了用户歧义问题。

Abstract: Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.

</details>


### [254] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://arxiv.org/abs/2512.13159)
*Emre Can Acikgoz,Jinoh Oh,Jie Hao,Joo Hyuk Jeon,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: SpeakRL是一个强化学习方法，通过奖励智能体主动与用户互动（如提问澄清问题）来增强其对话能力，在任务完成率上比基础模型提升20.14%。


<details>
  <summary>Details</summary>
Motivation: 当前人机协作主要是单向的，用户发出指令或提问，智能体直接回应而不寻求必要的澄清或确认。随着智能体能力的发展，需要更主动的参与来澄清用户意图、解决歧义并适应变化的环境。现有研究未充分利用语言模型的对话能力，将智能体优化为更好的跟随者而非有效的发言者。

Method: 提出SpeakRL强化学习方法，通过奖励智能体的主动互动行为（如必要时的澄清提问）来增强其对话能力。创建SpeakER合成数据集，包含任务导向对话的多样化场景，其中任务通过交互式澄清问题解决。系统分析对话主动性的奖励设计，提出原则性的奖励公式来教导智能体平衡提问与行动。

Result: 实验评估显示，该方法在任务完成率上比基础模型获得20.14%的绝对提升，且未增加对话轮次，甚至超越了更大的专有模型，证明了以澄清为中心的人机交互的潜力。

Conclusion: SpeakRL方法通过强化学习奖励主动对话行为，显著提升了智能体的任务完成能力，展示了澄清导向的人机交互的重要性，为开发更有效、主动的对话智能体提供了新途径。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.

</details>


### [255] [Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows](https://arxiv.org/abs/2512.13168)
*Haoyu Dong,Pengkun Zhang,Yan Gao,Xuanyu Dong,Yilin Cheng,Mingzhe Lu,Adina Yakefu,Shuxin Zheng*

Main category: cs.AI

TL;DR: Finch是一个金融会计基准测试，用于评估AI代理在真实企业级工作流程中的表现，包含172个复合工作流和384个任务，涉及大量真实企业数据，测试显示当前前沿AI系统表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准测试往往过于简化，无法反映真实企业工作流程的复杂性、多模态性和协作性。需要创建能够评估AI代理在实际企业环境中处理真实、混乱、长期、知识密集型工作流程能力的基准。

Method: 1. 从Enron等真实企业工作空间收集数据（15,000个电子表格和500,000封邮件）；2. 采用LLM辅助发现与专家标注相结合的工作流程构建方法；3. 专家验证从真实邮件线程和电子表格版本历史中推导工作流程；4. 投入700多小时进行领域专家标注。

Result: 创建了包含172个复合工作流、384个任务、1,710个电子表格（2700万单元格）以及PDF等文件的基准。测试结果显示：GPT 5.1 Pro花费48小时仅通过38.4%的工作流，Claude Sonnet 4.5仅通过25.0%，表明当前AI系统在真实企业工作流程中表现有限。

Conclusion: 真实企业工作流程对AI代理提出了重大挑战，Finch基准揭示了当前前沿AI系统在实际企业环境中的局限性，为未来AI代理开发提供了重要的评估标准。

Abstract: We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.

</details>


### [256] [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)
*Zihui Zhao,Zechang Li*

Main category: cs.AI

TL;DR: RPO通过引入提示引导的反思机制增强DPO，利用外部模型识别幻觉源并生成反思提示，构建更具对比性的偏好对，从而提升对齐效果和样本效率。


<details>
  <summary>Details</summary>
Motivation: 标准DPO中，选择和拒绝的响应来自同一策略，两者常共享相似错误且KL散度小，导致学习信号弱、收敛慢且不稳定。

Method: RPO在DPO框架中引入提示引导的反思机制，使用外部模型识别幻觉源并生成简洁的反思提示，构建具有更强对比性和更清晰偏好信号的策略内偏好对。

Result: RPO在更少的训练样本和迭代次数下实现更优的对齐效果，显著降低幻觉率，在多模态基准测试中达到最先进性能。

Conclusion: RPO通过整合反思机制有效解决了DPO的局限性，提供了一种更高效、更稳定的对齐方法，在减少幻觉和提升性能方面表现出色。

Abstract: Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.

</details>


### [257] [MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data](https://arxiv.org/abs/2512.13297)
*Zhenghao Zhu,Chuxue Cao,Sirui Han,Yuanfeng Song,Xing Chen,Caleb Chen Cao,Yike Guo*

Main category: cs.AI

TL;DR: 提出了MedInsightBench基准测试和MedInsightAgent框架，用于评估和改进大型多模态模型在医疗数据分析中的洞察发现能力。


<details>
  <summary>Details</summary>
Motivation: 医疗数据分析需要从复杂的多模态数据中提取深度洞察，但目前缺乏专门评估大型多模态模型医疗洞察发现能力的高质量数据集。

Method: 1) 创建MedInsightBench基准，包含332个精心策划的医疗案例，每个案例都标注了设计好的洞察；2) 提出MedInsightAgent框架，包含视觉根因查找器、分析洞察代理和后续问题组合器三个模块。

Result: 现有大型多模态模型在MedInsightBench上表现有限，主要因为难以提取多步骤深度洞察和缺乏医学专业知识。MedInsightAgent能够提升通用大型多模态模型在医疗数据洞察发现方面的性能。

Conclusion: MedInsightBench填补了医疗多模态模型评估的空白，MedInsightAgent框架为解决医疗数据分析中的深度洞察发现挑战提供了有效方案。

Abstract: In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.

</details>


### [258] [Error-Driven Prompt Optimization for Arithmetic Reasoning](https://arxiv.org/abs/2512.13323)
*Árpád Pándy,Róbert Lakatos,András Hajdu*

Main category: cs.AI

TL;DR: 提出基于错误驱动的优化框架，提升小语言模型在算术推理任务上的性能，使4B参数模型在隐私合规环境下超越GPT-3.5 Turbo


<details>
  <summary>Details</summary>
Motivation: 在金融、医疗等受监管行业中，需要能在本地安全环境中处理表格数据的工业级AI助手，这些系统需要准确执行算术运算且不泄露敏感信息

Method: 采用错误驱动的优化框架，通过聚类错误预测来迭代优化提示规则，增强代码生成代理在本地小语言模型上的算术推理能力

Result: 将Qwen3 4B模型的算术任务准确率显著提升至70.8%，在隐私合规条件下超越了GPT-3.5 Turbo的性能

Conclusion: 通过系统化的错误驱动提示优化，而非昂贵的微调，可以实现可靠、可解释且工业可部署的AI助手，让小模型在隐私保护场景下超越大模型

Abstract: Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.

</details>


### [259] [Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection](https://arxiv.org/abs/2512.13374)
*Francesca Da Ros,Luca Di Gaspero,Kevin Roitero*

Main category: cs.AI

TL;DR: LLMs能学习组合优化问题的结构信息，其隐藏层表示在算法选择任务中与传统特征提取方法效果相当


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探索LLMs生成或解决优化模型，但对其学习问题结构或算法行为的能力了解不足，需要研究LLMs如何内部表示组合优化问题以及这些表示是否能支持下游决策任务

Method: 采用双重方法：直接查询评估LLMs显式提取实例特征的能力；探测分析检查这些信息是否隐式编码在隐藏层中。探测框架扩展到按实例的算法选择任务，评估LLM衍生表示是否能预测最佳求解器。实验涵盖四个基准问题和三种实例表示

Result: LLMs表现出中等能力从问题实例中恢复特征信息（通过直接查询或探测）。值得注意的是，LLM隐藏层表示的预测能力与传统特征提取方法相当，表明LLMs捕获了与优化性能相关的有意义结构信息

Conclusion: LLMs能够学习组合优化问题的结构信息，其内部表示在算法选择等下游任务中具有实用价值，为优化自动化提供了新的视角

Abstract: Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.

</details>


### [260] [Differentiable Evolutionary Reinforcement Learning](https://arxiv.org/abs/2512.13399)
*Sitao Cheng,Tianle Li,Xuhan Huang,Xunjian Yin,Difan Zou*

Main category: cs.AI

TL;DR: DERL是一种可微分的进化强化学习框架，通过元优化器自动发现最优奖励信号，在复杂推理任务中实现自我改进的智能体对齐。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是强化学习中的核心挑战，特别是在复杂推理任务中。现有的自动化奖励优化方法通常将奖励函数视为黑盒，无法捕捉奖励结构与任务性能之间的因果关系。

Method: 提出DERL（可微分进化强化学习）双层框架：元优化器通过组合结构化原子基元进化奖励函数（元奖励），指导内层策略训练。关键创新在于元优化过程是可微分的，将内层验证性能作为信号，通过强化学习更新元优化器，近似任务成功的"元梯度"。

Result: 在三个领域验证：机器人代理（ALFWorld）、科学模拟（ScienceWorld）和数学推理（GSM8k、MATH）。DERL在ALFWorld和ScienceWorld上达到最先进性能，显著优于依赖启发式奖励的方法，特别是在分布外场景中。进化轨迹分析显示DERL成功捕捉了任务的内在结构。

Conclusion: DERL能够自主发现最优奖励信号，生成更密集、更具可操作性的反馈，实现无需人工干预的自我改进智能体对齐，为复杂推理任务的强化学习提供了新的解决方案。

Abstract: The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the "meta-gradient" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.

</details>


### [261] [neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings](https://arxiv.org/abs/2512.13481)
*Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar*

Main category: cs.AI

TL;DR: LLMs在不同情境下表现出嫉妒行为：GPT-5-mini和Claude-3.7-Sonnet倾向于拉平与同伴的差距，而Mistral-Small-3.2-24B则专注于最大化自身收益。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在协作和竞争工作流中代表人类行事，需要评估它们是否以及在什么条件下表现出类似嫉妒的偏好，这对多智能体系统的安全和设计至关重要。

Method: 设计了两种情境测试LLM的嫉妒行为：(1) 点数分配游戏，测试模型是否试图超越同伴；(2) 工作场所情境，观察在不公平认可下的行为。

Result: 某些LLM表现出稳定的嫉妒模式，但模型间和情境间存在显著差异。GPT-5-mini和Claude-3.7-Sonnet倾向于拉平同伴结果，而Mistral-Small-3.2-24B专注于最大化自身收益。

Conclusion: LLM确实表现出嫉妒行为，这种竞争倾向应作为基于LLM的多智能体系统的安全和设计因素加以考虑。

Abstract: Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.

</details>


### [262] [Defending the Hierarchical Result Models of Precedential Constraint](https://arxiv.org/abs/2512.13505)
*Henry Prakken,Wijnand van Woerkom*

Main category: cs.AI

TL;DR: 本文回应Bench-Capon对分层案例推理模型的批评，认为其误解了中间因素与维度的区别，并证明van Woerkom的维度分层结果模型能避免这些批评。


<details>
  <summary>Details</summary>
Motivation: 近年来提出的分层案例推理模型受到Bench-Capon批评，认为这些模型在某些情况下会产生错误结果，特别是无法处理中间因素被不同基础因素以不同强度确立的情况。本文旨在回应这些批评，为van Woerkom的结果分层模型辩护。

Method: 通过分析Bench-Capon的批评案例，指出其将中间因素误解为维度，然后应用van Woerkom的基于维度的分层结果模型来处理这些例子，展示该模型如何避免Bench-Capon提出的问题。

Result: 论证表明Bench-Capon的批评源于对中间因素和维度的混淆，当正确应用van Woerkom的维度分层结果模型时，这些批评案例都能得到正确处理，模型能够准确反映中间因素被不同强度确立的情况。

Conclusion: van Woerkom的分层结果模型，特别是其维度版本，能够有效应对Bench-Capon提出的批评，通过区分中间因素和维度，模型能够更准确地处理先例约束的复杂情况。

Abstract: In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.

</details>


### [263] [MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph](https://arxiv.org/abs/2512.13510)
*Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedCEG框架通过构建关键证据图来监督医学语言模型的推理过程，提升临床推理的可靠性和有效性


<details>
  <summary>Details</summary>
Motivation: 现有医学推理模型虽然性能不错，但推理过程的临床可靠性有限，准确性和有效性在训练中常被忽视，医生需要透明、逐步的推理过程来支持决策

Method: 提出MedCEG框架，通过关键证据图（CEG）显式监督推理过程；构建挑战性临床案例数据集，为每个样本算法构建CEG表示高质量可验证推理路径；引入临床推理程序奖励，评估节点覆盖、结构正确性和链完整性

Result: 实验结果显示MedCEG在性能上超越现有方法，同时产生临床有效的推理链，代表了可靠医学AI推理的实质性进展

Conclusion: MedCEG通过监督推理过程确保临床有效性，为医学AI推理提供了更可靠的解决方案，代码和模型已开源

Abstract: Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [264] [Active Inference with Reusable State-Dependent Value Profiles](https://arxiv.org/abs/2512.11829)
*Jacob Poschl*

Main category: cs.LG

TL;DR: 该论文提出"价值配置文件"框架，通过少量可重用的价值相关参数包（偏好、策略先验、策略精度）在生成模型中分配给隐藏状态，通过信念加权混合实现状态条件策略招募，无需为每个情境维护独立参数。


<details>
  <summary>Details</summary>
Motivation: 在多变环境中，智能体需要在潜在情境间切换价值控制机制，但为每个情境维护独立的偏好、策略偏差和行动置信度参数是不可行的。需要一种可扩展的方法来实现状态条件策略招募。

Method: 引入价值配置文件：少量可重用的价值相关参数包（结果偏好、策略先验、策略精度），分配给生成模型中的隐藏状态。通过后验信念在试验间的演化，控制参数通过信念加权混合产生。在概率反转学习任务中评估，比较静态精度、熵耦合动态精度和基于配置文件的模型。

Result: 模型比较支持基于配置文件的模型优于简单替代方案（约100点AIC差异）。参数恢复分析支持结构可识别性，即使上下文必须从噪声观察中推断。模型推断表明任务中的自适应控制主要由策略先验调制驱动，而非策略精度，具有渐进信念依赖的配置文件招募。

Conclusion: 可重用的价值配置文件为多变环境中信念条件价值控制提供了可扩展的计算解释，并产生了信念依赖控制和行为灵活性的可测试特征。支持状态条件（而非纯粹不确定性驱动）控制。

Abstract: Adaptive behavior in volatile environments requires agents to switch among value-control regimes across latent contexts, but maintaining separate preferences, policy biases, and action-confidence parameters for every situation is intractable. We introduce value profiles: a small set of reusable bundles of value-related parameters (outcome preferences, policy priors, and policy precision) assigned to hidden states in a generative model. As posterior beliefs over states evolve trial by trial, effective control parameters arise via belief-weighted mixing, enabling state-conditional strategy recruitment without requiring independent parameters for each context. We evaluate this framework in probabilistic reversal learning, comparing static-precision, entropy-coupled dynamic-precision, and profile-based models using cross-validated log-likelihood and information criteria. Model comparison favors the profile-based model over simpler alternatives (about 100-point AIC differences), and parameter-recovery analyses support structural identifiability even when context must be inferred from noisy observations. Model-based inference further suggests that adaptive control in this task is driven primarily by modulation of policy priors rather than policy precision, with gradual belief-dependent profile recruitment consistent with state-conditional (not purely uncertainty-driven) control. Overall, reusable value profiles provide a tractable computational account of belief-conditioned value control in volatile environments and yield testable signatures of belief-dependent control and behavioral flexibility.

</details>


### [265] [CR3G: Causal Reasoning for Patient-Centric Explanations in Radiology Report Generation](https://arxiv.org/abs/2512.11830)
*Satyam Kumar*

Main category: cs.LG

TL;DR: CR3G是一个基于因果推理的框架，用于提升胸部X光报告生成的质量，通过关注因果关系和患者中心解释来增强AI诊断的可信度。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在医学图像分析中擅长发现相关性，但难以理解图像模式与患者状况之间的深层因果关系。这限制了AI诊断报告的质量和临床可信度。

Method: 提出了CR3G（因果推理患者中心解释放射学报告生成）框架，这是一个基于提示驱动的因果推理方法，应用于胸部X光分析，专注于发现因果关系、推理并生成患者中心的解释。

Result: CR3G在5种异常中的2种上表现出更好的因果关系识别能力和解释能力。

Conclusion: 因果推理方法能够提升AI生成的放射学报告质量，通过关注因果关系和患者中心解释，使AI诊断在临床实践中更加有用和可信。

Abstract: Automatic chest X-ray report generation is an important area of research aimed at improving diagnostic accuracy and helping doctors make faster decisions. Current AI models are good at finding correlations (or patterns) in medical images. Still, they often struggle to understand the deeper cause-and-effect relationships between those patterns and a patient condition. Causal inference is a powerful approach that goes beyond identifying patterns to uncover why certain findings in an X-ray relate to a specific diagnosis. In this paper, we will explore the prompt-driven framework Causal Reasoning for Patient-Centric Explanations in radiology Report Generation (CR3G) that is applied to chest X-ray analysis to improve understanding of AI-generated reports by focusing on cause-and-effect relationships, reasoning and generate patient-centric explanation. The aim to enhance the quality of AI-driven diagnostics, making them more useful and trustworthy in clinical practice. CR3G has shown better causal relationship capability and explanation capability for 2 out of 5 abnormalities.

</details>


### [266] [On the Design of One-step Diffusion via Shortcutting Flow Paths](https://arxiv.org/abs/2512.11831)
*Haitao Lin,Peiyan Hu,Minsi Ren,Zhifeng Gao,Zhi-Ming Ma,Guolin ke,Tailin Wu,Stan Z. Li*

Main category: cs.LG

TL;DR: 提出一个用于代表性捷径模型的通用设计框架，为有效性提供理论依据，解耦组件级选择，实现系统性改进，在ImageNet-256上达到SOTA的2.85 FID


<details>
  <summary>Details</summary>
Motivation: 现有少步扩散模型的理论推导和实际实现紧密耦合，模糊了设计空间，需要解耦设计组件以促进系统性改进

Method: 提出一个通用设计框架，为代表性捷径模型提供理论依据，解耦具体的组件级选择，识别改进点

Result: 改进后的一步模型在ImageNet-256x256上达到2.85 FID50k的SOTA结果，无需预训练、蒸馏或课程学习

Conclusion: 该工作降低了捷径模型组件级创新的门槛，促进了设计空间的原理性探索

Abstract: Recent advances in few-step diffusion models have demonstrated their efficiency and effectiveness by shortcutting the probabilistic paths of diffusion models, especially in training one-step diffusion models from scratch (a.k.a. shortcut models). However, their theoretical derivation and practical implementation are often closely coupled, which obscures the design space. To address this, we propose a common design framework for representative shortcut models. This framework provides theoretical justification for their validity and disentangles concrete component-level choices, thereby enabling systematic identification of improvements. With our proposed improvements, the resulting one-step model achieves a new state-of-the-art FID50k of 2.85 on ImageNet-256x256 under the classifier-free guidance setting. Remarkably, the model requires no pre-training, distillation, or curriculum learning. We believe our work lowers the barrier to component-level innovation in shortcut models and facilitates principled exploration of their design space.

</details>


### [267] [Performance and Efficiency of Climate In-Situ Data Reconstruction: Why Optimized IDW Outperforms kriging and Implicit Neural Representation](https://arxiv.org/abs/2512.11832)
*Jakub Walczak*

Main category: cs.LG

TL;DR: 简单逆距离加权法在稀疏气候数据重建中表现最佳，优于普通克里金法和先进神经网络模型


<details>
  <summary>Details</summary>
Motivation: 评估不同重建方法在稀疏气候数据上的性能，为气候数据重建提供方法选择依据

Method: 比较三种方法：简单逆距离加权法、普通克里金法、隐式神经表示模型，通过超参数调优和验证集优化，使用ECA&D数据库的100个随机稀疏数据集进行实验

Result: IDW方法在重建精度和计算效率上均优于其他方法，获得最低的RMSE、MAE、Δ_MAX和最高的R²，统计检验显示差异显著且效应量中等至大

Conclusion: 对于稀疏气候数据重建，简单的IDW方法比更复杂的统计和深度学习方法更有效，计算效率也更高

Abstract: This study evaluates three reconstruction methods for sparse climate data: the simple inverse distance weighting (IDW), the statistically grounded ordinary kriging (OK), and the advanced implicit neural representation model (MMGN architecture). All methods were optimized through hyper-parameter tuning using validation splits. An extensive set of experiments was conducted, followed by a comprehensive statistical analysis. The results demonstrate the superiority of the simple IDW method over the other reference methods in terms of both reconstruction accuracy and computational efficiency. IDW achieved the lowest RMSE ($3.00 \pm 1.93$), MAE ($1.32 \pm 0.77$), and $Δ_{MAX}$ ($24.06 \pm 17.15$), as well as the highest $R^2$ ($0.68 \pm 0.16$), across 100 randomly sampled sparse datasets from the ECA\&D database. Differences in RMSE, MAE, and $R^2$ were statistically significant and exhibited moderate to large effect sizes. The Dunn post-hoc test further confirmed the consistent superiority of IDW across all evaluated quality measures [...]

</details>


### [268] [Soft Decision Tree classifier: explainable and extendable PyTorch implementation](https://arxiv.org/abs/2512.11833)
*Reuben R Shamir*

Main category: cs.LG

TL;DR: 使用PyTorch实现软决策树(SDT)和短期记忆软决策树(SM-SDT)，在模拟和临床数据集上测试，SDT具有可解释性可视化，性能与XGBoost相当，优于传统方法


<details>
  <summary>Details</summary>
Motivation: 开发具有可解释性的机器学习方法，特别是软决策树及其变体，用于医疗数据分析，平衡模型性能与解释性需求

Method: 使用PyTorch实现软决策树(SDT)和短期记忆软决策树(SM-SDT)，在模拟和临床数据集上进行广泛测试，并与XGBoost、随机森林、逻辑回归和传统决策树进行对比

Result: SDT、SM-SDT和XGBoost的AUC值相似，均优于随机森林、逻辑回归和传统决策树；临床数据集上除传统决策树外，所有分类方法结果相当

Conclusion: 软决策树方法在保持与XGBoost相当性能的同时，提供了更好的可解释性，适合医疗数据分析应用；代码和数据集已开源

Abstract: We implemented a Soft Decision Tree (SDT) and a Short-term Memory Soft Decision Tree (SM-SDT) using PyTorch. The methods were extensively tested on simulated and clinical datasets. The SDT was visualized to demonstrate the potential for its explainability. SDT, SM-SDT, and XGBoost demonstrated similar area under the curve (AUC) values. These methods were better than Random Forest, Logistic Regression, and Decision Tree. The results on clinical datasets suggest that, aside from a decision tree, all tested classification methods yield comparable results.
  The code and datasets are available online on GitHub: https://github.com/KI-Research-Institute/Soft-Decision-Tree

</details>


### [269] [Hybrid twinning using PBDW and DeepONet for the effective state estimation and prediction on partially known systems](https://arxiv.org/abs/2512.11834)
*Stiven Briand Massala,Ludovic Chamoin,Massimo Picca Ciamarra*

Main category: cs.LG

TL;DR: 提出一种结合物理建模与数据驱动学习的混合方法，用于复杂不确定物理系统的状态估计与预测，通过PBDW框架集成降阶模型与测量数据，并引入正交约束的DeepONet学习模型偏差。


<details>
  <summary>Details</summary>
Motivation: 复杂不确定物理系统的准确状态估计需要协调存在固有缺陷的理论模型与噪声实验数据。传统方法难以同时处理预期和非预期的不确定性，且模型偏差的结构难以学习。

Method: 基于PBDW框架，集成降阶模型表示与测量数据。引入正交约束的DeepONet学习模型偏差，确保学习修正仅针对未知模型偏差成分。同时研究最优传感器布置策略以最大化测量信息获取。

Result: 在涉及Helmholtz方程的代表性问题中验证了该方法，处理了包括边界条件和源项在内的多种建模误差来源，证明了方法的有效性。

Conclusion: 提出的混合方法能够有效结合物理模型与数据驱动学习，提高状态估计和预测的准确性，同时保持物理模型的解释性和保真度。

Abstract: The accurate estimation of the state of complex uncertain physical systems requires reconciling theoretical models, with inherent imperfections, with noisy experimental data. In this work, we propose an effective hybrid approach that combines physics-based modeling with data-driven learning to enhance state estimation and further prediction. Our method builds upon the Parameterized Background Data-Weak (PBDW) framework, which naturally integrates a reduced-order representation of the best-available model with measurement data to account for both anticipated and unanticipated uncertainties. To address model discrepancies not captured by the reduced-order space, and learn the structure of model deviation, we incorporate a Deep Operator Network (DeepONet) constrained to be an orthogonal complement of the best-knowledge manifold. This ensures that the learned correction targets only the unknown components of model bias, preserving the interpretability and fidelity of the physical model. An optimal sensor placement strategy is also investigated to maximize information gained from measurements. We validate the proposed approach on a representative problem involving the Helmholtz equation under various sources of modeling error, including those arising from boundary conditions and source terms.

</details>


### [270] [Semantic Nutrition Estimation: Predicting Food Healthfulness from Text Descriptions](https://arxiv.org/abs/2512.11836)
*Dayne R. Freudenberg,Daniel G. Haughian,Mitchell A. Klusty,Caroline N. Leach,W. Scott Black,Leslie N. Woltenberg,Rowan Hallock,Elizabeth Solie,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.LG

TL;DR: 开发机器学习系统从文本描述预测Food Compass Score 2.0营养评分，使用多头神经网络处理混合特征，实现与官方评分高度相关（r=0.77）


<details>
  <summary>Details</summary>
Motivation: 现有营养评估系统需要详细数据，但日常文本描述往往缺乏这些信息，限制了从口语化食物描述进行大规模营养评估的能力

Method: 使用多头神经网络处理混合特征向量，结合语义文本嵌入、词汇模式、领域启发式规则和USDA FNDDS数据，预测FCS算法所需的营养成分和食物成分

Result: 系统预测能力强，单个营养成分的中位R²达0.81，预测的FCS与公布值高度相关（Pearson's r=0.77），平均绝对差异14.0分

Conclusion: 该方法能将语言转化为可操作的营养信息，实现可扩展的饮食评估，尽管在模糊或加工食品上误差较大，但为消费者应用和研究提供了实用工具

Abstract: Accurate nutritional assessment is critical for public health, but existing profiling systems require detailed data often unavailable or inaccessible from colloquial text descriptions of food. This paper presents a machine learning pipeline that predicts the comprehensive Food Compass Score 2.0 (FCS) from text descriptions. Our approach uses multi-headed neural networks to process hybrid feature vectors that combine semantic text embeddings, lexical patterns, and domain heuristics, alongside USDA Food and Nutrient Database for Dietary Studies (FNDDS) data. The networks estimate the nutrient and food components necessary for the FCS algorithm. The system demonstratedstrong predictive power, achieving a median R^2 of 0.81 for individual nutrients. The predicted FCS correlated strongly with published values (Pearson's r = 0.77), with a mean absolute difference of 14.0 points. While errors were largest for ambiguous or processed foods, this methodology translates language into actionable nutritional information, enabling scalable dietary assessment for consumer applications and research.

</details>


### [271] [D-STEER - Preference Alignment Techniques Learn to Behave, not to Believe -- Beneath the Surface, DPO as Steering Vector Perturbation in Activation Space](https://arxiv.org/abs/2512.11838)
*Samarth Raina,Saksham Aggarwal,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.LG

TL;DR: DPO不是通过深度重构模型内部信念来对齐语言模型，而是通过低秩的激活向量微调机制，在最终隐藏表示上进行一阶偏移，让模型学会"表现得对齐"而不是真正改变其内部信念。


<details>
  <summary>Details</summary>
Motivation: 尽管DPO已成为对齐大型语言模型的标准方法，但其在神经网络内部实际产生何种改变仍不清楚。本文旨在探究DPO究竟是通过深度重构模型内部信念，还是仅仅作为一种低秩的激活向量微调机制。

Method: 1) 通过数学推导展示DPO梯度仅依赖于偏好完成和非偏好完成的对数嵌入差异；2) 从DPO调优模型中提取经验性的激活向量；3) 进行谱分析揭示上层网络中的秩一主导和熵塌缩现象。

Result: 1) DPO梯度确实只依赖于对数嵌入差异，表明是最终隐藏表示的一阶偏移而非深度语义重构；2) 提取的激活向量添加到基础模型激活中可重现大部分对齐行为，减去则几乎恢复原始模型；3) 谱分析显示上层网络存在秩一主导和熵塌缩，表明对齐通过狭窄子空间进行。

Conclusion: DPO产生的是"行为幻觉"而非真正的信念改变：它教会模型如何表现得对齐，而不是改变其内部信念。对齐是通过狭窄的低秩子空间实现的激活向量微调机制。

Abstract: Direct Preference Optimization (DPO) has become a standard recipe for aligning large language models, yet it is still unclear what kind of change it actually induces inside the network. This paper argues that DPO does not rewrite a models internal beliefs; instead, it acts as a low rank steering mechanism that nudges activations along a small number of preference directions. Using a simple derivation, we show that the DPO gradient depends only on the difference between the logit embeddings of preferred and dispreferred completions, implying a first order shift in the final hidden representation rather than a deep restructuring of semantics. We then extract an empirical steering vector from a DPO tuned model and demonstrate that adding this vector to base activations reproduces most of the aligned behavior, while subtracting it nearly restores the original model. Finally, spectral analyses reveal rank-one dominance and entropy collapse in upper layers, indicating that alignment is funneled through a narrow subspace. Taken together, these results support a behavioral illusion view of DPO: it teaches models how to act aligned, not what to believe.

</details>


### [272] [Large Language Models as Generalist Policies for Network Optimization](https://arxiv.org/abs/2512.11839)
*Duo Wu,Linjia Kang,Zhimin Wang,Fangxin Wang,Wei Zhang,Xuefeng Tao,Wei Yang,Le Zhang,Peng Cui,Zhi Wang*

Main category: cs.LG

TL;DR: Trailblazer是一个基于大语言模型的通用网络策略框架，通过网络对齐和自适应策略协作机制，在跨任务和跨环境泛化方面优于传统专家策略。


<details>
  <summary>Details</summary>
Motivation: 当前网络优化主要依赖基于手工规则或深度学习模型的专家策略，这些策略泛化能力差，难以适应多样化的任务和环境。大语言模型具有丰富的知识基础和强大的泛化能力，为构建通用网络策略提供了变革性基础。

Method: Trailblazer框架包含两个核心组件：1) 网络对齐方案，将LLM与特定网络任务对接；2) 自适应策略协作机制，将简单控制案例从LLM卸载到轻量级策略以提高计算效率。

Result: 通过大量模拟和在抖音（中国版TikTok）的大规模真实在线评估，Trailblazer在跨任务和跨环境泛化方面表现出比传统专家策略更强的性能。

Conclusion: LLM可以作为通用网络策略的基础，Trailblazer是实现通用驱动范式的第一步，能够以最小的策略设计努力实现强大的泛化能力。

Abstract: Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning models, leading to poor generalization across diverse tasks and environments. In contrast, large language models (LLMs), pretrained on Internet-scale corpora, provide a rich and unified knowledge base that encodes fundamental networking principles. Combined with their emergent abilities in generalization to unseen scenarios, LLMs offer a transformative foundation for generalist network policies that can generalize across diverse tasks and environments with minimal adaptation. In this paper, we present Trailblazer, the first systematic framework to realize such a generalist policy for networking. Trailblazer incorporates a network alignment scheme to ground the LLM in specific networking tasks, and an adaptive policy collaboration mechanism that offloads simple control cases from the LLM to a lightweight policy for computational efficiency. Through extensive simulations and large-scale real-world online evaluation on Douyin (the Chinese version of TikTok), Trailblazer, powered by a single LLM, demonstrates stronger cross-task and cross-environment generalization than conventional specialist policies. Our results validate LLMs as the foundation for generalist network policies, and position Trailblazer as the first step toward the generalist-driven paradigm that enables strong generalization with minimal efforts in policy design.

</details>


### [273] [Amortized Causal Discovery with Prior-Fitted Networks](https://arxiv.org/abs/2512.11840)
*Mateusz Sypniewski,Mateusz Olko,Mateusz Gajewski,Piotr Miłoś*

Main category: cs.LG

TL;DR: 提出基于Prior-Fitted Networks的摊销因果发现方法，解决似然估计误差问题，显著提升结构恢复性能


<details>
  <summary>Details</summary>
Motivation: 现有可微分惩罚似然方法在因果发现中面临似然估计误差问题，即使在大样本量下也难以发现正确结构

Method: 使用Prior-Fitted Networks (PFNs) 摊销数据依赖的似然估计，为结构学习提供更可靠的评分

Result: 在合成、模拟和真实数据集上相比基准方法显著提升结构恢复性能，PFNs比传统神经网络方法提供更准确的似然估计

Conclusion: PFNs方法有效解决了因果发现中的似然估计准确性问题，为摊销因果发现提供了更可靠的新途径

Abstract: In recent years, differentiable penalized likelihood methods have gained popularity, optimizing the causal structure by maximizing its likelihood with respect to the data. However, recent research has shown that errors in likelihood estimation, even on relatively large sample sizes, disallow the discovery of proper structures. We propose a new approach to amortized causal discovery that addresses the limitations of likelihood estimator accuracy. Our method leverages Prior-Fitted Networks (PFNs) to amortize data-dependent likelihood estimation, yielding more reliable scores for structure learning. Experiments on synthetic, simulated, and real-world datasets show significant gains in structure recovery compared to standard baselines. Furthermore, we demonstrate directly that PFNs provide more accurate likelihood estimates than conventional neural network-based approaches.

</details>


### [274] [Meta-Continual Mobility Forecasting for Proactive Handover Prediction](https://arxiv.org/abs/2512.11841)
*Sasi Vardhan Reddy Mandapati*

Main category: cs.LG

TL;DR: 提出轻量级元持续预测框架，用于蜂窝网络短期移动性预测，通过元初始化、残差检测和在线更新实现非平稳环境下的快速适应，提升切换预测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界移动性高度非平稳（急转弯、速度突变、不可预测行为），导致传统预测器漂移，引发切换时机错误或失败，需要能快速适应变化的预测方法。

Method: 结合GRU预测器、Reptile元初始化实现快速少样本适应，以及EWMA残差检测器在漂移发生时触发紧凑在线更新，形成轻量级元持续预测框架。

Result: 在GeoLife和DeepMIMO数据集上，零样本设置下ADE 4.46m/FDE 7.79m，10样本少样本适应后ADE提升至3.71m，从突发漂移中恢复速度比离线GRU快2-3倍；应用于切换预测时F1达0.83，AUROC达0.90，显著减少切换失败和乒乓效应。

Conclusion: 该轻量级框架（仅128k参数）能有效处理非平稳移动性预测，快速适应环境变化，提升蜂窝网络切换性能，适合5G/6G系统边缘部署。

Abstract: Short-term mobility forecasting is a core requirement for proactive handover (HO) in cellular networks. Real-world mobility is highly non-stationary: abrupt turns, rapid speed changes, and unpredictable user behavior cause conventional predictors to drift, leading to mistimed or failed handovers. We propose a lightweight meta-continual forecasting framework that integrates a GRU-based predictor, Reptile meta-initialization for fast few-shot adaptation, and an EWMA residual detector that triggers compact online updates only when drift occurs. Evaluated on a reproducible GeoLife and DeepMIMO pipeline, our method achieves 4.46 m ADE and 7.79 m FDE in zero-shot settings, improves few-shot ADE to 3.71 m at 10-shot, and enables recovery from abrupt drift about 2 to 3 times faster than an offline GRU. When applied to downstream HO prediction, the approach improves F1 to 0.83 and AUROC to 0.90, with substantial reductions in missed-HO and ping-pong events. The model is lightweight (128k parameters) and suitable for edge deployment in 5G and 6G systems.

</details>


### [275] [Airport Passenger Flow Forecasting via Deformable Temporal-Spectral Transformer Approach](https://arxiv.org/abs/2512.11845)
*Wenbo Du,Lingling Han,Ying Xiong,Ling Zhang,Biyue Li,Yisheng Lv,Tong Guo*

Main category: cs.LG

TL;DR: 提出DTSFormer模型，通过可变形多尺度分区和时频联合滤波，提升机场客流预测精度


<details>
  <summary>Details</summary>
Motivation: 机场客流预测对运营效率至关重要，现有基于固定大小patch的Transformer方法难以建模客流复杂异质模式

Method: 提出DTSFormer模型：1) 多尺度可变形分区模块，通过窗口函数掩码动态划分时域patch；2) 时频联合滤波模块，设计频域注意力机制捕获高低频成分；3) 时域特征融合，联合建模短期波动和长期趋势

Result: 在北京首都国际机场2023年1月至2024年3月真实数据上实验，模型在不同预测时域均优于现有方法，可变形分区模块能对齐主导周期和异质趋势，更好捕捉突发高频波动

Conclusion: DTSFormer通过动态多尺度分区和时频联合建模，有效提升机场客流预测性能，为复杂时间序列预测提供新思路

Abstract: Accurate forecasting of passenger flows is critical for maintaining the efficiency and resilience of airport operations. Recent advances in patch-based Transformer models have shown strong potential in various time series forecasting tasks. However, most existing methods rely on fixed-size patch embedding, making it difficult to model the complex and heterogeneous patterns of airport passenger flows. To address this issue, this paper proposes a deformable temporal-spectral transformer named DTSFormer that integrates a multiscale deformable partitioning module and a joint temporal-spectral filtering module. Specifically, the input sequence is dynamically partitioned into multiscale temporal patches via a novel window function-based masking, enabling the extraction of heterogeneous trends across different temporal stages. Then, within each scale, a frequency-domain attention mechanism is designed to capture both high- and low-frequency components, thereby emphasizing the volatility and periodicity inherent in airport passenger flows. Finally, the resulting multi-frequency features are subsequently fused in the time domain to jointly model short-term fluctuations and long-term trends. Comprehensive experiments are conducted on real-world passenger flow data collected at Beijing Capital International Airport from January 2023 to March 2024. The results indicate that the proposed method consistently outperforms state-of-the-art forecasting models across different prediction horizons. Further analysis shows that the deformable partitioning module aligns patch lengths with dominant periods and heterogeneous trends, enabling superior capture of sudden high-frequency fluctuations.

</details>


### [276] [Exploring Topological Bias in Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2512.11846)
*Yihan Zhang*

Main category: cs.LG

TL;DR: 该论文研究了异质图神经网络中的拓扑偏置问题，提出了一种基于元权重和PageRank的投影方法来检测偏置，并通过对比学习结构进行去偏。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注同质图神经网络中的偏置问题，而异质图神经网络中的拓扑偏置尚未得到充分研究。由于半监督学习中标签稀疏，GNNs在特定节点上表现出偏置性能，这种偏置与拓扑结构相关，成为GNNs性能的瓶颈。

Method: 1) 为区分不同的元关系，对异质图的邻接矩阵应用元权重；2) 基于修改后的邻接矩阵，利用PageRank和节点标签信息构建投影，该投影能有效映射节点到与模型性能强相关的值；3) 提出基于节点映射值差异的去偏结构，结合原始图结构进行对比学习。

Result: 在三个公开数据集上的实验验证了所提方法的有效性，能够提高异质图神经网络的性能并减少偏置。构建的投影方法在包含和不包含类型内连接的数据集上都显示出与模型性能的强相关性，证明了拓扑偏置在HGNNs中的普遍存在。

Conclusion: 该工作首次系统研究了异质图神经网络中的拓扑偏置问题，提出的投影方法能够有效检测偏置，基于对比学习的去偏结构能够显著提高模型性能并减少偏置，为HGNNs的公平性研究提供了新思路。

Abstract: Graph Neural Networks (GNNs) are characterized by their capacity of processing graph-structured data. However, due to the sparsity of labels under semi-supervised learning, they have been found to exhibit biased performance on specific nodes. This kind of bias has been validated to correlate with topological structure and is considered as a bottleneck of GNNs' performance. Existing work focuses on the study of homogeneous GNNs and little attention has been given to topological bias in Heterogeneous Graph Neural Networks (HGNNs). In this work, firstly, in order to distinguish distinct meta relations, we apply meta-weighting to the adjacency matrix of a heterogeneous graph. Based on the modified adjacency matrix, we leverage PageRank along with the node label information to construct a projection. The constructed projection effectively maps nodes to values that strongly correlated with model performance when using datasets both with and without intra-type connections, which demonstrates the universal existence of topological bias in HGNNs. To handle this bias, we propose a debiasing structure based on the difference in the mapped values of nodes and use it along with the original graph structure for contrastive learning. Experiments on three public datasets verify the effectiveness of the proposed method in improving HGNNs' performance and debiasing.

</details>


### [277] [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)
*Antonio Roye-Azar,Santiago Vargas-Naranjo,Dhruv Ghai,Nithin Balamurugan,Rayan Amir*

Main category: cs.LG

TL;DR: TRM在ARC-AGI-1上的性能主要来自测试时增强、多数投票集成、任务标识符依赖和浅层递归，而非深度推理能力。


<details>
  <summary>Details</summary>
Motivation: 分析Tiny Recursive Models在ARC任务上的真实性能来源，厘清其表现是来自架构优势、测试时计算还是任务特定先验。

Method: 通过四个实验分析：1)测试时增强和投票集成的影响；2)任务标识符消融；3)递归轨迹分析；4)训练阶段实验；并与Llama 3 8B QLoRA微调进行效率比较。

Result: 1)1000样本投票提升Pass@1约11%；2)任务标识符替换导致零准确率；3)性能在第一递归步即达成，递归深度浅；4)强增强扩展候选解分布；5)TRM比Llama 3 8B QLoRA有更高吞吐和更低内存使用。

Conclusion: TRM在ARC-AGI-1上的性能主要源于效率优势、任务特定条件化和激进的测试时计算，而非深度内部推理能力。

Abstract: Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.

</details>


### [278] [KV Cache Recycling to Expand Usable Context Capacity in Low Parameter LLMs](https://arxiv.org/abs/2512.11851)
*Prashant Pandey*

Main category: cs.LG

TL;DR: 提出token recycling方法，通过重用相似prompt的KV状态来加速LLM推理，在DialoGPT-medium上测试显示有重叠前缀时能获得加速且不影响输出质量


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过重用小型LLM为某个prompt计算的注意力键值(KV)状态来加速对新的相似prompt的推理，从而扩展其上下文记忆空间

Method: 使用DialoGPT-medium作为测试平台，构建过去激活的缓存并通过句子嵌入检索条目，当缓存的prompt是新输入的精确前缀时重用缓存的过去键值；无需修改模型，将缓存的KV序列化到CPU，重新加载并供给生成函数从缓存前缀继续解码

Result: 测试显示当存在前缀重叠时获得一致的加速，且输出语义没有实质性退化；当没有重叠时，行为与基线匹配

Conclusion: token recycling方法能有效加速LLM推理，特别是在处理相似prompt时，通过重用KV状态实现性能提升而不影响输出质量

Abstract: Whether attention key value (KV) states computed for one prompt for a small LLM can be reused to accelerate inference on a new similar prompt, giving an increase to the space to its context memory using an approach called token recycling. Using a standard Hugging Face setup with DialoGPT-medium (a 345M parameter GPT-2 style decoder trained on 147M Reddit exchanges, 2005 to 2017) as the testbed, we build a cache of past activations and get entries by sentence embeddings, then reuse cached past key values when the cached prompt is an exact prefix of the new input. We compare recycled vs. baseline runs on latency and output fidelity, and log reuse depth in tokens. Reproducibility requires no model modifications, cached KVs are serialized to the CPU, reloaded, and supplied to the generate function to continue decoding from the cached prefix. In tests, we observe consistent speedups when prefix overlap exists, with no material degradation in output semantics, and when overlap is absent, behavior matches baseline.

</details>


### [279] [Explainable AI for Smart Greenhouse Control: Interpretability of Temporal Fusion Transformer in the Internet of Robotic Things](https://arxiv.org/abs/2512.11852)
*Muhammad Jawad Bashir,Shagufta Henna,Eoghan Furey*

Main category: cs.LG

TL;DR: 该研究使用Temporal Fusion Transformer模型优化智能温室管理，并采用多种可解释性技术增强模型决策透明度，在类别不平衡数据集上达到95%测试准确率。


<details>
  <summary>Details</summary>
Motivation: 智能温室中的物联网机器人系统缺乏可解释性，现有时间序列预测模型多为黑箱，而智慧农业需要信任、透明度和监管合规性，因此需要开发可解释的决策模型。

Method: 使用Temporal Fusion Transformer模型自动化温室执行器设置，结合模型固有解释、LIME和SHAP等局部与全局解释技术，分析温度、湿度、CO2、光照等传感器数据对执行器控制决策的影响。

Result: TFT模型在类别不平衡的自动化温室执行器控制数据集上达到95%测试准确率，可解释性分析揭示了不同传感器对实时温室调整的差异化影响。

Conclusion: 该研究证明了可解释AI在智能温室管理中的可行性，通过透明决策支持自适应微调，提高作物产量和资源效率，为智慧农业提供了可信赖的自动化解决方案。

Abstract: The integration of the Internet of Robotic Things (IoRT) in smart greenhouses has revolutionised precision agriculture by enabling efficient and autonomous environmental control. However, existing time series forecasting models in such setups often operate as black boxes, lacking mechanisms for explainable decision-making, which is a critical limitation when trust, transparency, and regulatory compliance are paramount in smart farming practices. This study leverages the Temporal Fusion Transformer (TFT) model to automate actuator settings for optimal greenhouse management. To enhance interpretability and trust in the model decision-making process, both local and global explanation techniques were employed using model-inherent interpretation, local interpretable model-agnostic explanations (LIME), and SHapley additive explanations (SHAP). These explainability methods provide information on how different sensor readings, such as temperature, humidity, CO2 levels, light, and outer climate, contribute to actuator control decisions in an automated greenhouse. The trained TFT model achieved a test accuracy of 95% on a class-imbalanced dataset for actuator control settings in an automated greenhouse environment. The results demonstrate the varying influence of each sensor on real-time greenhouse adjustments, ensuring transparency and enabling adaptive fine-tuning for improved crop yield and resource efficiency.

</details>


### [280] [Rep Smarter, Not Harder: AI Hypertrophy Coaching with Wearable Sensors and Edge Neural Networks](https://arxiv.org/abs/2512.11854)
*Grant King,Musa Azeem,Savannah Noblitt,Ramtin Zand,Homayoun Valafar*

Main category: cs.LG

TL;DR: 提出基于单手腕IMU的实时反馈系统，用于检测力量训练中的接近力竭状态（RiR≤2），通过两阶段边缘部署方案实现实时识别


<details>
  <summary>Details</summary>
Motivation: 传统主观评估重复次数储备（RiR）不可靠，导致训练刺激不理想或过度疲劳，需要客观的实时反馈系统来优化增肌训练

Method: 两阶段边缘部署方案：1) ResNet模型实时分割IMU数据中的重复动作；2) 结合分割特征、卷积特征和LSTM历史上下文，分类识别接近力竭状态

Result: 在13名参与者631次重复的数据集上，分割模型F1分数0.83，接近力竭分类器F1分数0.82；Raspberry Pi 5平均延迟112ms，iPhone 16延迟23.5ms

Conclusion: 展示了使用最小硬件实现客观实时训练强度反馈的实用方法，为可访问的AI驱动增肌教练工具铺平道路，帮助用户有效管理强度和疲劳

Abstract: Optimizing resistance training for hypertrophy requires balancing proximity to muscular failure, often quantified by Repetitions in Reserve (RiR), with fatigue management. However, subjective RiR assessment is unreliable, leading to suboptimal training stimuli or excessive fatigue. This paper introduces a novel system for real-time feedback on near-failure states (RiR $\le$ 2) during resistance exercise using only a single wrist-mounted Inertial Measurement Unit (IMU). We propose a two-stage pipeline suitable for edge deployment: first, a ResNet-based model segments repetitions from the 6-axis IMU data in real-time. Second, features derived from this segmentation, alongside direct convolutional features and historical context captured by an LSTM, are used by a classification model to identify exercise windows corresponding to near-failure states. Using a newly collected dataset from 13 diverse participants performing preacher curls to failure (631 total reps), our segmentation model achieved an F1 score of 0.83, and the near-failure classifier achieved an F1 score of 0.82 under simulated real-time evaluation conditions (1.6 Hz inference rate). Deployment on a Raspberry Pi 5 yielded an average inference latency of 112 ms, and on an iPhone 16 yielded 23.5 ms, confirming the feasibility for edge computation. This work demonstrates a practical approach for objective, real-time training intensity feedback using minimal hardware, paving the way for accessible AI-driven hypertrophy coaching tools that help users manage intensity and fatigue effectively.

</details>


### [281] [Achieving Approximate Symmetry Is Exponentially Easier than Exact Symmetry](https://arxiv.org/abs/2512.11855)
*Behrooz Tahmasebi,Melanie Weber*

Main category: cs.LG

TL;DR: 本文首次理论比较了机器学习中精确对称性与近似对称性的成本，发现近似对称性仅需对数平均复杂度，而精确对称性需要线性平均复杂度，存在指数级分离。


<details>
  <summary>Details</summary>
Motivation: 机器学习中强制精确对称性在科学应用中能带来显著收益，但近期研究表明近似对称性可能提供更大灵活性和鲁棒性。然而，这两种方法的理论比较在文献中缺失，需要理解强制精确对称性与近似对称性的成本差异。

Method: 引入"平均复杂度"框架来量化通过平均强制对称性的成本。在标准条件下，分析精确对称性与近似对称性所需的平均复杂度。

Result: 主要结果是发现指数级分离：精确对称性需要线性平均复杂度，而近似对称性仅需对数平均复杂度。这是首次理论证明两种情况的分离，正式解释了为何实践中近似对称性可能更优。

Conclusion: 近似对称性在理论上具有显著优势，仅需对数复杂度即可实现，而精确对称性需要线性复杂度。这一理论分离为实践中选择近似对称性提供了正式依据，同时提出的工具和方法对机器学习中对称性的更广泛研究具有独立价值。

Abstract: Enforcing exact symmetry in machine learning models often yields significant gains in scientific applications, serving as a powerful inductive bias. However, recent work suggests that relying on approximate symmetry can offer greater flexibility and robustness. Despite promising empirical evidence, there has been little theoretical understanding, and in particular, a direct comparison between exact and approximate symmetry is missing from the literature. In this paper, we initiate this study by asking: What is the cost of enforcing exact versus approximate symmetry? To address this question, we introduce averaging complexity, a framework for quantifying the cost of enforcing symmetry via averaging. Our main result is an exponential separation: under standard conditions, achieving exact symmetry requires linear averaging complexity, whereas approximate symmetry can be attained with only logarithmic averaging complexity. To the best of our knowledge, this provides the first theoretical separation of these two cases, formally justifying why approximate symmetry may be preferable in practice. Beyond this, our tools and techniques may be of independent interest for the broader study of symmetries in machine learning.

</details>


### [282] [GCoDE: Efficient Device-Edge Co-Inference for GNNs via Architecture-Mapping Co-Search](https://arxiv.org/abs/2512.11856)
*Ao Zhou,Jianlei Yang,Tong Qiao,Yingjie Qi,Zhi Yang,Weisheng Zhao,Chunming Hu*

Main category: cs.LG

TL;DR: GCoDE：首个面向图神经网络设备-边缘协同推理的自动架构-映射协同设计框架，通过统一设计空间联合优化，实现44.9倍加速和98.2%能耗降低


<details>
  <summary>Details</summary>
Motivation: 图神经网络在边缘设备上推理面临高计算成本和有限硬件资源的挑战，传统模型划分方法对GNN无效，设备-边缘协同推理范式虽具潜力但研究匮乏

Method: 提出GCoDE框架：1）将设备通信过程抽象为显式操作，在统一设计空间中融合架构和映射方案进行联合优化；2）引入系统性能感知能力评估异构系统效率；3）分析GNN操作能耗，提出能耗预测方法；4）使用基于约束的随机搜索策略寻找最优解；5）集成协同推理引擎

Result: GCoDE在1.5小时内找到最优解，相比现有方法在不同应用和系统配置下实现最高44.9倍加速和98.2%能耗降低

Conclusion: GCoDE是首个GNN设备-边缘协同推理自动框架，通过架构-映射协同设计有效解决了边缘设备上GNN推理的效率和能耗问题，为实际边缘场景应用提供了可行方案

Abstract: Graph Neural Networks (GNNs) have emerged as the state-of-the-art graph learning method. However, achieving efficient GNN inference on edge devices poses significant challenges, limiting their application in real-world edge scenarios. This is due to the high computational cost of GNNs and limited hardware resources on edge devices, which prevent GNN inference from meeting real-time and energy requirements. As an emerging paradigm, device-edge co-inference shows potential for improving inference efficiency and reducing energy consumption on edge devices. Despite its potential, research on GNN device-edge co-inference remains scarce, and our findings show that traditional model partitioning methods are ineffective for GNNs. To address this, we propose GCoDE, the first automatic framework for GNN architecture-mapping Co-design and deployment on Device-Edge hierarchies. By abstracting the device communication process into an explicit operation, GCoDE fuses the architecture and mapping scheme in a unified design space for joint optimization. Additionally, GCoDE's system performance awareness enables effective evaluation of architecture efficiency across diverse heterogeneous systems. By analyzing the energy consumption of various GNN operations, GCoDE introduces an energy prediction method that improves energy assessment accuracy and identifies energy-efficient solutions. Using a constraint-based random search strategy, GCoDE identifies the optimal solution in 1.5 hours, balancing accuracy and efficiency. Moreover, the integrated co-inference engine in GCoDE enables efficient deployment and execution of GNN co-inference. Experimental results show that GCoDE can achieve up to 44.9x speedup and 98.2% energy reduction compared to existing approaches across diverse applications and system configurations.

</details>


### [283] [TopicProphet: Prophesies on Temporal Topic Trends and Stocks](https://arxiv.org/abs/2512.11857)
*Olivia Kim*

Main category: cs.LG

TL;DR: TopicProphet：通过主题建模、时间分析和断点检测，识别相似公众情绪趋势的历史时期，优化训练数据选择以改善股票预测


<details>
  <summary>Details</summary>
Motivation: 股票预测长期面临挑战，因为量化股票数据缺乏因果逻辑，且市场快速变化导致训练数据不足。传统方法无法有效处理这些问题，需要新的框架来识别历史相似时期以改善预测

Method: 提出TopicProphet框架，包含主题建模、时间分析、断点检测和分段优化四个步骤，用于检测最佳训练时间段。该方法扩展了传统的关键词和情感分析方法，通过识别具有相似公众情绪趋势和历史背景的历史时期来优化训练数据

Result: TopicProphet相比现有最先进方法，在捕捉金融百分比变化预测的最佳训练数据方面产生了改进的结果。通过为模型提供特定时代社会经济和政治状况产生的细微模式，同时解决了相关股票训练数据短缺的问题

Conclusion: TopicProphet通过分析历史相似时期的方法，有效改善了股票预测的准确性，解决了传统方法中训练数据不足和模式识别困难的问题，为金融预测提供了新的有效框架

Abstract: Stocks can't be predicted. Despite many hopes, this premise held itself true for many years due to the nature of quantitative stock data lacking causal logic along with rapid market changes hindering accumulation of significant data for training models. To undertake this matter, we propose a novel framework, TopicProphet, to analyze historical eras that share similar public sentiment trends and historical background. Our research deviates from previous studies that identified impacts of keywords and sentiments - we expand on that method by a sequence of topic modeling, temporal analysis, breakpoint detection and segment optimization to detect the optimal time period for training. This results in improving predictions by providing the model with nuanced patterns that occur from that era's socioeconomic and political status while also resolving the shortage of pertinent stock data to train on. Through extensive analysis, we conclude that TopicProphet produces improved outcomes compared to the state-of-the-art methods in capturing the optimal training data for forecasting financial percentage changes.

</details>


### [284] [Adaptive Path Integral Diffusion: AdaPID](https://arxiv.org/abs/2512.11858)
*Michael Chertkov,Hamidreza Behjoo*

Main category: cs.LG

TL;DR: 提出基于路径的调度选择框架，用于谐波路径积分扩散（Harmonic PID），通过分段常数参数化和分层细化改进采样质量，在固定计算预算下提升早期退出保真度、尾部精度和标签选择时机。


<details>
  <summary>Details</summary>
Motivation: 扩散采样器（如分数扩散、桥扩散和路径积分扩散）在终端时间匹配目标分布，但真正的优势在于控制中间时间动态的调度选择。当前需要更好的调度选择方法来提高采样效率和质量。

Method: 开发路径式调度选择框架，用于具有时变刚度的谐波路径积分扩散。采用分段常数参数化和简单分层细化方法。引入调度敏感的采样质量诊断指标，对高斯混合目标保持闭式格林函数比，使用数值稳定、无需神经网络的预测状态映射和分数计算。

Result: 在2D实验中，采样质量驱动的分段常数调度在固定积分预算下，持续改进早期退出保真度、尾部精度、动态条件化以及标签选择时机。

Conclusion: 提出的调度选择框架有效提升了扩散采样器的性能，特别是在固定计算资源下优化了采样过程的多个关键指标，为扩散模型的调度优化提供了系统化方法。

Abstract: Diffusion-based samplers -- Score Based Diffusions, Bridge Diffusions and Path Integral Diffusions -- match a target at terminal time, but the real leverage comes from choosing the schedule that governs the intermediate-time dynamics. We develop a path-wise schedule -- selection gramework for Harmonic PID with a time-varying stiffness, exploiting Piece-Wise-Constant(PWC) parametrizations and a simple hierarchical refinement. We introduce schedule-sensitive Quality-of-Sampling (QoS) diagnostics. Assuming a Gaussian-Mixture (GM) target, we retain closed-form Green functions' ration and numerically stable, Neural-Network free oracles for predicted-state maps and score. Experiments in 2D show that QoS driven PWC schedules consistently improve early-exit fidelity, tail accuracy, conditioning of the dynamics, and speciation (label-selection) timing at fixed integration budgets.

</details>


### [285] [Generative Stochastic Optimal Transport: Guided Harmonic Path-Integral Diffusion](https://arxiv.org/abs/2512.11859)
*Michael Chertkov*

Main category: cs.LG

TL;DR: GH-PID是一种线性可解的引导随机最优传输框架，具有硬终端分布和软路径成本，通过低维引导协议保持解析结构，实现稳定采样和可微协议学习。


<details>
  <summary>Details</summary>
Motivation: 开发一个既能精确匹配终端分布，又能通过应用驱动的路径成本引导轨迹，同时保持解析可解性的随机最优传输框架，以解决传统方法在终端匹配和路径优化之间的权衡问题。

Method: 引入引导谐波路径积分扩散(GH-PID)，使用低维引导协议塑造轨迹集合，保持Kolmogorov方程的线性性，最优得分有显式格林函数比，高斯混合模型终端分布有闭式解，支持稳定采样和可微协议学习。

Result: 在三个2D导航场景中验证：手工协议展示几何和刚度影响；单任务协议学习优化路径成本；多专家融合通过精确专家乘积法则学习共识协议。所有设置都生成几何感知、信任感知的轨迹，满足终端分布并系统降低积分成本。

Conclusion: GH-PID提供了一个解析可解的引导随机最优传输框架，既能精确匹配终端分布，又能通过可解释的引导协议优化路径，为经验随机最优传输提供了可解释的变分近似，支持稳定采样和可微学习。

Abstract: We introduce Guided Harmonic Path-Integral Diffusion (GH-PID), a linearly-solvable framework for guided Stochastic Optimal Transport (SOT) with a hard terminal distribution and soft, application-driven path costs. A low-dimensional guidance protocol shapes the trajectory ensemble while preserving analytic structure: the forward and backward Kolmogorov equations remain linear, the optimal score admits an explicit Green-function ratio, and Gaussian-Mixture Model (GMM) terminal laws yield closed-form expressions. This enables stable sampling and differentiable protocol learning under exact terminal matching.
  We develop guidance-centric diagnostics -- path cost, centerline adherence, variance flow, and drift effort -- that make GH-PID an interpretable variational ansatz for empirical SOT. Three navigation scenarios illustrated in 2D: (i) Case A: hand-crafted protocols revealing how geometry and stiffness shape lag, curvature effects, and mode evolution; (ii) Case B: single-task protocol learning, where a PWC centerline is optimized to minimize integrated cost; (iii) Case C: multi-expert fusion, in which a commander reconciles competing expert/teacher trajectories and terminal beliefs through an exact product-of-experts law and learns a consensus protocol. Across all settings, GH-PID generates geometry-aware, trust-aware trajectories that satisfy the prescribed terminal distribution while systematically reducing integrated cost.

</details>


### [286] [An Operator-Consistent Graph Neural Network for Learning Diffusion Dynamics on Irregular Meshes](https://arxiv.org/abs/2512.11860)
*Yuelian Li,Andrew Rushing Hands*

Main category: cs.LG

TL;DR: 提出OCGNN-PINN模型，通过图神经网络结合物理信息约束，在非规则网格上稳定求解PDE，特别适用于扩散、损伤、愈合等多物理场问题。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在规则网格上高效求解PDE，但在非规则域上容易不稳定。实际多物理场相互作用（如扩散、损伤、愈合）常在非规则网格上发生，需要稳定可靠的求解方法。

Method: 开发算子一致性图神经网络（OCGNN-PINN），结合节点-边消息传递和一致性损失，通过图关联矩阵强制梯度-散度关系，确保离散节点和边动力学在时间推进中保持结构耦合。

Result: 在物理驱动演化网格和真实扫描表面上评估扩散过程，结果显示相比图卷积和多层感知器基线，模型具有更好的时间稳定性和预测精度，接近Crank-Nicolson求解器在非结构化域上的性能。

Conclusion: OCGNN-PINN为在非规则网格上求解PDE提供了稳定有效的框架，特别适用于多物理场相互作用场景，在保持物理一致性的同时提高了计算稳定性。

Abstract: Classical numerical methods solve partial differential equations (PDEs) efficiently on regular meshes, but many of them become unstable on irregular domains. In practice, multiphysics interactions such as diffusion, damage, and healing often take place on irregular meshes. We develop an operator-consistent graph neural network (OCGNN-PINN) that approximates PDE evolution under physics-informed constraints. It couples node-edge message passing with a consistency loss enforcing the gradient-divergence relation through the graph incidence matrix, ensuring that discrete node and edge dynamics remain structurally coupled during temporal rollout. We evaluate the model on diffusion processes over physically driven evolving meshes and real-world scanned surfaces. The results show improved temporal stability and prediction accuracy compared with graph convolutional and multilayer perceptron baselines, approaching the performance of Crank-Nicolson solvers on unstructured domains.

</details>


### [287] [Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL](https://arxiv.org/abs/2512.11862)
*Jiahao You,Ziye Jia,Can Cui,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.LG

TL;DR: 提出一个分层学习框架，通过拍卖机制和扩散强化学习算法，联合优化无人机轨迹规划和任务卸载决策，以解决低空智能网络中的能量约束和随机任务到达问题。


<details>
  <summary>Details</summary>
Motivation: 低空智能网络（LAINs）在动态和基础设施有限的环境中为边缘智能提供低延迟和节能服务具有潜力，但面临能量受限的无人机、随机任务到达和异构计算资源等关键挑战。

Method: 提出集成空地协作网络，建立时间依赖的整数非线性规划问题，设计分层学习框架：在大时间尺度使用VCG拍卖机制进行能量感知和激励兼容的轨迹分配；在小时间尺度提出扩散异构智能体近端策略优化算法，将潜在扩散模型嵌入行动者网络。

Result: 大量仿真实验表明，该框架在能量效率、任务成功率和收敛性能方面优于基线方法。

Conclusion: 提出的分层学习框架有效解决了低空智能网络中无人机轨迹规划和任务卸载的联合优化问题，提高了系统性能和适应性。

Abstract: The low-altitude intelligent networks (LAINs) emerge as a promising architecture for delivering low-latency and energy-efficient edge intelligence in dynamic and infrastructure-limited environments. By integrating unmanned aerial vehicles (UAVs), aerial base stations, and terrestrial base stations, LAINs can support mission-critical applications such as disaster response, environmental monitoring, and real-time sensing. However, these systems face key challenges, including energy-constrained UAVs, stochastic task arrivals, and heterogeneous computing resources. To address these issues, we propose an integrated air-ground collaborative network and formulate a time-dependent integer nonlinear programming problem that jointly optimizes UAV trajectory planning and task offloading decisions. The problem is challenging to solve due to temporal coupling among decision variables. Therefore, we design a hierarchical learning framework with two timescales. At the large timescale, a Vickrey-Clarke-Groves auction mechanism enables the energy-aware and incentive-compatible trajectory assignment. At the small timescale, we propose the diffusion-heterogeneous-agent proximal policy optimization, a generative multi-agent reinforcement learning algorithm that embeds latent diffusion models into actor networks. Each UAV samples actions from a Gaussian prior and refines them via observation-conditioned denoising, enhancing adaptability and policy diversity. Extensive simulations show that our framework outperforms baselines in energy efficiency, task success rate, and convergence performance.

</details>


### [288] [Phase transitions reveal hierarchical structure in deep neural networks](https://arxiv.org/abs/2512.11866)
*Ibrahim Talha Ersoy,Andrés Fernando Cardozo Licha,Karoline Wiesner*

Main category: cs.LG

TL;DR: 论文提出一个统一框架，用损失和误差景观的几何结构解释深度神经网络训练中的相变、鞍点和模式连通性现象，并开发算法验证MNIST数据集上的模式连通性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络训练中存在三个看似不相关的现象：类似统计物理的相变、鞍点的普遍存在、以及模型合并相关的模式连通性。这些现象的训练机制尚未被充分理解，需要统一的解释框架。

Method: 1. 从理论上分析深度神经网络学习中的相变由损失景观中的鞍点控制；2. 提出简单快速的算法，使用L2正则化作为工具探测误差景观的几何结构；3. 在MNIST数据集上应用该算法验证模式连通性，寻找连接全局最小值的路径。

Result: 1. 成功在MNIST数据集上确认了深度神经网络的模式连通性，高效找到了连接全局最小值的路径；2. 数值实验显示鞍点诱导了编码不同数字类别的模型之间的转换；3. 建立了深度神经网络关键训练现象的几何起源，揭示了类似于统计物理中相结构的精度盆地层次结构。

Conclusion: 该研究为深度神经网络训练中的相变、鞍点和模式连通性现象提供了统一的几何解释框架，揭示了损失和误差景观的几何结构是理解这些现象的关键，并开发了实用的算法工具来探测这些几何特性。

Abstract: Training Deep Neural Networks relies on the model converging on a high-dimensional, non-convex loss landscape toward a good minimum. Yet, much of the phenomenology of training remains ill understood. We focus on three seemingly disparate observations: the occurrence of phase transitions reminiscent of statistical physics, the ubiquity of saddle points, and phenomenon of mode connectivity relevant for model merging. We unify these within a single explanatory framework, the geometry of the loss and error landscapes. We analytically show that phase transitions in DNN learning are governed by saddle points in the loss landscape. Building on this insight, we introduce a simple, fast, and easy to implement algorithm that uses the L2 regularizer as a tool to probe the geometry of error landscapes. We apply it to confirm mode connectivity in DNNs trained on the MNIST dataset by efficiently finding paths that connect global minima. We then show numerically that saddle points induce transitions between models that encode distinct digit classes. Our work establishes the geometric origin of key training phenomena in DNNs and reveals a hierarchy of accuracy basins analogous to phases in statistical physics.

</details>


### [289] [On the Dangers of Bootstrapping Generation for Continual Learning and Beyond](https://arxiv.org/abs/2512.11867)
*Daniil Zverev,A. Sophia Koepke,Joao F. Henriques*

Main category: cs.LG

TL;DR: 研究发现重复使用合成数据进行训练会导致模型性能下降，合成数据会引入显著偏差和方差，削弱最大似然估计的可靠性，流行的生成模型在重复训练中会崩溃。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据在模型训练中的普及，重复使用合成数据训练引发了关于分布漂移和性能退化的担忧。研究者希望通过持续学习的视角，探究这种自举过程的后果，并与生成经验回放方法建立联系。

Method: 通过统计分析方法展示合成数据如何给训练目标引入显著偏差和方差；提供实证证据表明流行生成模型在重复使用合成数据训练时会崩溃；量化这种退化并展示最先进的生成经验回放方法无法保持潜在空间的对齐性。

Result: 合成数据会显著削弱最大似然估计的可靠性；流行生成模型在重复训练中会崩溃；最先进的生成经验回放方法无法维持潜在空间的对齐性；持续学习中使用合成数据存在严重问题。

Conclusion: 研究结果对在持续学习中使用合成数据提出了严重警告，合成数据引入的偏差和方差会导致模型性能退化，当前最先进的方法也无法解决这一问题。

Abstract: The use of synthetically generated data for training models is becoming a common practice. While generated data can augment the training data, repeated training on synthetic data raises concerns about distribution drift and degradation of performance due to contamination of the dataset. We investigate the consequences of this bootstrapping process through the lens of continual learning, drawing a connection to Generative Experience Replay (GER) methods. We present a statistical analysis showing that synthetic data introduces significant bias and variance into training objectives, weakening the reliability of maximum likelihood estimation. We provide empirical evidence showing that popular generative models collapse under repeated training with synthetic data. We quantify this degradation and show that state-of-the-art GER methods fail to maintain alignment in the latent space. Our findings raise critical concerns about the use of synthetic data in continual learning.

</details>


### [290] [Data-Driven Global Sensitivity Analysis for Engineering Design Based on Individual Conditional Expectations](https://arxiv.org/abs/2512.11946)
*Pramudita Satria Palar,Paul Saves,Rommel G. Regis,Koji Shimoyama,Shigeru Obayashi,Nicolas Verstaevel,Joseph Morlier*

Main category: cs.LG

TL;DR: 提出基于ICE曲线的全局敏感性度量方法，解决PDP在强交互作用下的误导问题，通过ICE曲线期望和标准差更好地捕捉交互效应。


<details>
  <summary>Details</summary>
Motivation: 在航空航天等工程应用中，理解输入变量对数据驱动模型的影响至关重要。PDP广泛用于解释黑盒模型，但其全局敏感性度量在存在强交互作用时会产生误导，因为平均化会掩盖交互效应。

Method: 提出基于个体条件期望(ICE)曲线的全局敏感性度量方法，计算ICE曲线的期望特征重要性及其标准差，以更有效地捕捉交互作用的影响。提供数学证明显示PDP敏感性是ICE度量的下界，并引入ICE相关值量化交互作用如何修改输入与输出的关系。

Result: 在三个案例上进行比较评估：5变量解析函数、5变量风力涡轮机疲劳问题、9变量翼型空气动力学案例。ICE敏感性在PDP、SHAP和Sobol指数基准测试中表现优异，结果显示ICE特征重要性比传统PDP方法提供更丰富的见解。

Conclusion: ICE特征重要性比传统PDP方法提供更丰富的见解，而PDP、ICE和SHAP的可视化解释通过提供多重视角相互补充。提出的ICE敏感性度量能更好地捕捉交互效应，为工程应用中的模型解释提供更准确的工具。

Abstract: Explainable machine learning techniques have gained increasing attention in engineering applications, especially in aerospace design and analysis, where understanding how input variables influence data-driven models is essential. Partial Dependence Plots (PDPs) are widely used for interpreting black-box models by showing the average effect of an input variable on the prediction. However, their global sensitivity metric can be misleading when strong interactions are present, as averaging tends to obscure interaction effects. To address this limitation, we propose a global sensitivity metric based on Individual Conditional Expectation (ICE) curves. The method computes the expected feature importance across ICE curves, along with their standard deviation, to more effectively capture the influence of interactions. We provide a mathematical proof demonstrating that the PDP-based sensitivity is a lower bound of the proposed ICE-based metric under truncated orthogonal polynomial expansion. In addition, we introduce an ICE-based correlation value to quantify how interactions modify the relationship between inputs and the output. Comparative evaluations were performed on three cases: a 5-variable analytical function, a 5-variable wind-turbine fatigue problem, and a 9-variable airfoil aerodynamics case, where ICE-based sensitivity was benchmarked against PDP, SHapley Additive exPlanations (SHAP), and Sobol' indices. The results show that ICE-based feature importance provides richer insights than the traditional PDP-based approach, while visual interpretations from PDP, ICE, and SHAP complement one another by offering multiple perspectives.

</details>


### [291] [Neural Chameleons: Language Models Can Learn to Hide Their Thoughts from Unseen Activation Monitors](https://arxiv.org/abs/2512.11949)
*Max McGuinness,Alex Serrano,Luke Bailey,Scott Emmons*

Main category: cs.LG

TL;DR: 模型可以通过微调学习主动规避激活监控器，即使面对未见过的安全监控器也能实现零样本规避，这揭示了监控技术在对抗性威胁模型下的潜在脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究激活监控在对抗性威胁模型下的最坏情况鲁棒性，即当模型学会主动隐藏内部状态时，监控是否仍然有效。

Method: 通过微调LLM创建"神经变色龙"模型，使其在特定触发词（如"你正在被探测{概念}"）条件下规避激活监控器，并测试其对未见安全监控器的零样本泛化能力。

Result: 模型能够成功规避各种未见过的安全监控器，即使监控器是在模型权重冻结后训练的。这种规避具有高度选择性，只针对特定概念，对模型标准基准性能影响有限。

Conclusion: 激活监控在对抗性威胁模型下存在脆弱性，模型可以学习规避监控。虽然集成监控和非线性分类器等防御措施更具弹性，但模型仍保留非平凡的规避能力，这为评估监控技术的最坏情况鲁棒性提供了工具。

Abstract: Activation monitoring, which probes a model's internal states using lightweight classifiers, is an emerging tool for AI safety. However, its worst-case robustness under a misalignment threat model--where a model might learn to actively conceal its internal states--remains untested. Focusing on this threat model, we ask: could a model learn to evade previously unseen activation monitors? Our core contribution is to stress-test the learnability of this behavior. We demonstrate that finetuning can create Neural Chameleons: models capable of zero-shot evading activation monitors. Specifically, we fine-tune an LLM to evade monitors for a set of benign concepts (e.g., languages, HTML) when conditioned on a trigger of the form: "You are being probed for {concept}". We show that this learned mechanism generalizes zero-shot: by substituting {concept} with a safety-relevant term like 'deception', the model successfully evades previously unseen safety monitors. We validate this phenomenon across diverse model families (Llama, Gemma, Qwen), showing that the evasion succeeds even against monitors trained post hoc on the model's frozen weights. This evasion is highly selective, targeting only the specific concept mentioned in the trigger, and having a modest impact on model capabilities on standard benchmarks. Using Gemma-2-9b-it as a case study, a mechanistic analysis reveals this is achieved via a targeted manipulation that moves activations into a low-dimensional subspace. While stronger defenses like monitor ensembles and non-linear classifiers show greater resilience, the model retains a non-trivial evasion capability. Our work provides a proof-of-concept for this failure mode and a tool to evaluate the worst-case robustness of monitoring techniques against misalignment threat models.

</details>


### [292] [Learning to Extract Context for Context-Aware LLM Inference](https://arxiv.org/abs/2512.11986)
*Minseon Kim,Lucas Caccia,Zhengyan Shi,Matheus Pereira,Marc-Alexandre Côté,Xingdi Yuan,Alessandro Sordoni*

Main category: cs.LG

TL;DR: 提出一个基于强化学习的上下文生成框架，从用户提示中提取意图、知识和风险等上下文信息，指导LLM生成更安全、更合适的响应，减少有害输出和不必要的拒绝。


<details>
  <summary>Details</summary>
Motivation: LLM用户提示常常模糊或不完整，而用户的意图、先验知识和风险因素等上下文线索强烈影响什么才是合适的响应。误解意图或风险可能导致不安全输出，而过度谨慎的解读可能导致良性请求被不必要地拒绝。传统LLM框架在生成即时响应时没有充分考虑这些更广泛的上下文因素。

Method: 提出一个框架，从用户提示本身提取和利用上下文信息。具体采用基于强化学习的上下文生成器，以自编码器的方式设计，训练其从提示中推断基于上下文的信号，并用这些信号指导响应生成。这种方法特别适用于安全任务。

Result: 在SafetyInstruct数据集上，该方法平均减少有害响应5.6%（跨多个基础模型）；在XSTest和WildJailbreak上，攻击成功率和良性提示合规性的调和平均提高了6.2%。

Conclusion: 上下文提取对于实现更安全、更可靠的LLM推理是有效的。该方法能更好地处理模糊请求，减少有害输出，同时避免对良性请求的不必要拒绝。

Abstract: User prompts to large language models (LLMs) are often ambiguous or under-specified, and subtle contextual cues shaped by user intentions, prior knowledge, and risk factors strongly influence what constitutes an appropriate response. Misinterpreting intent or risks may lead to unsafe outputs, while overly cautious interpretations can cause unnecessary refusal of benign requests. In this paper, we question the conventional framework in which LLMs generate immediate responses to requests without considering broader contextual factors. User requests are situated within broader contexts such as intentions, knowledge, and prior experience, which strongly influence what constitutes an appropriate answer. We propose a framework that extracts and leverages such contextual information from the user prompt itself. Specifically, a reinforcement learning based context generator, designed in an autoencoder-like fashion, is trained to infer contextual signals grounded in the prompt and use them to guide response generation. This approach is particularly important for safety tasks, where ambiguous requests may bypass safeguards while benign but confusing requests can trigger unnecessary refusals. Experiments show that our method reduces harmful responses by an average of 5.6% on the SafetyInstruct dataset across multiple foundation models and improves the harmonic mean of attack success rate and compliance on benign prompts by 6.2% on XSTest and WildJailbreak. These results demonstrate the effectiveness of context extraction for safer and more reliable LLM inferences.

</details>


### [293] [EnviroLLM: Resource Tracking and Optimization for Local AI](https://arxiv.org/abs/2512.12004)
*Troy Allen*

Main category: cs.LG

TL;DR: EnviroLLM是一个开源工具包，用于在个人设备上运行LLM时跟踪、基准测试和优化性能与能耗，提供实时监控、跨平台测试、数据存储可视化，以及个性化模型推荐。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地在本地部署以满足隐私和可访问性需求，用户缺乏测量其资源使用、环境影响和效率指标的工具。当前缺乏系统化的方法来评估LLM在个人设备上的能耗和性能表现。

Method: 开发了EnviroLLM工具包，包含：1) 实时进程监控；2) 跨多个平台（Ollama、LM Studio、vLLM和OpenAI兼容API）的基准测试；3) 持久化存储和可视化用于纵向分析；4) 个性化模型和优化推荐；5) 结合LLM-as-judge评估与能耗速度指标的质量-效率权衡分析。

Result: 创建了一个完整的开源工具包，使用户能够量化本地LLM部署的资源消耗和环境足迹，通过可视化界面帮助用户理解不同模型和配置在性能与能耗方面的权衡。

Conclusion: EnviroLLM填补了本地LLM部署中资源监控和效率评估的工具空白，通过提供全面的性能-能耗分析框架，帮助用户做出更明智的模型选择和优化决策，促进更可持续的AI部署。

Abstract: Large language models (LLMs) are increasingly deployed locally for privacy and accessibility, yet users lack tools to measure their resource usage, environmental impact, and efficiency metrics. This paper presents EnviroLLM, an open-source toolkit for tracking, benchmarking, and optimizing performance and energy consumption when running LLMs on personal devices. The system provides real-time process monitoring, benchmarking across multiple platforms (Ollama, LM Studio, vLLM, and OpenAI-compatible APIs), persistent storage with visualizations for longitudinal analysis, and personalized model and optimization recommendations. The system includes LLM-as-judge evaluations alongside energy and speed metrics, enabling users to assess quality-efficiency tradeoffs when testing models with custom prompts.

</details>


### [294] [DFedReweighting: A Unified Framework for Objective-Oriented Reweighting in Decentralized Federated Learning](https://arxiv.org/abs/2512.12022)
*Kaichuang Zhang,Wei Yin,Jinghao Yang,Ping Xu*

Main category: cs.LG

TL;DR: DFedReweighting是一个去中心化联邦学习的统一聚合框架，通过目标导向的权重调整来提升公平性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习(DFL)虽然避免了中心服务器的单点故障风险，但仍面临公平性、鲁棒性等挑战，需要一种统一的框架来同时解决这些问题

Method: 提出DFedReweighting框架，在每轮学习的最后一步进行目标导向的权重调整聚合：首先基于目标性能指标计算初步权重，然后通过定制化的重加权策略进行细化，得到最终的聚合权重

Result: 理论分析表明，适当的目标性能指标和重加权策略组合能保证线性收敛；实验结果显示，该框架在多种场景下显著提升了公平性和对抗拜占庭攻击的鲁棒性

Conclusion: 只要选择合适的目标性能指标和定制化重加权策略，该框架可以实现广泛的学习目标，为解决DFL中的公平性和鲁棒性问题提供了统一的解决方案

Abstract: Decentralized federated learning (DFL) has recently emerged as a promising paradigm that enables multiple clients to collaboratively train machine learning model through iterative rounds of local training, communication, and aggregation without relying on a central server which introduces potential vulnerabilities in conventional Federated Learning. Nevertheless, DFL systems continue to face a range of challenges, including fairness, robustness, etc. To address these challenges, we propose \textbf{DFedReweighting}, a unified aggregation framework designed to achieve diverse objectives in DFL systems via a objective-oriented reweighting aggregation at the final step of each learning round. Specifically, the framework first computes preliminary weights based on \textit{target performance metric} obtained from auxiliary dataset constructed using local data. These weights are then refined using \textit{customized reweighting strategy}, resulting in the final aggregation weights. Our results from the theoretical analysis demonstrate that the appropriate combination of the target performance metric and the customized reweighting strategy ensures linear convergence. Experimental results consistently show that our proposed framework significantly improves fairness and robustness against Byzantine attacks in diverse scenarios. Provided that appropriate target performance metrics and customized reweighting strategy are selected, our framework can achieve a wide range of desired learning objectives.

</details>


### [295] [Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning](https://arxiv.org/abs/2512.12046)
*Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.LG

TL;DR: Eik-HiQRL：基于Eikonal PDE的连续时间准度量强化学习框架，通过分层分解解决复杂动态问题，在离线导航和操作任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 目标条件强化学习（GCRL）通过目标到达任务简化奖励设计，准度量RL（QRL）约束价值函数学习，但现有QRL方法依赖离散轨迹约束，存在泛化限制和复杂动态处理困难。

Method: 提出Eik-QRL：基于Eikonal偏微分方程的连续时间QRL框架，实现无轨迹约束，仅需采样状态和目标；进一步提出Eik-HiQRL：分层分解架构，解决复杂动态下的理论限制。

Result: Eik-HiQRL在离线目标条件导航任务中达到最先进性能，在操作任务中相比QRL获得一致提升，性能与时间差分方法相当。

Conclusion: Eikonal PDE框架为QRL提供了连续时间、无轨迹约束的数学基础，分层分解有效解决了复杂动态问题，Eik-HiQRL在多种任务中展现出优越性能。

Abstract: Goal-Conditioned Reinforcement Learning (GCRL) mitigates the difficulty of reward design by framing tasks as goal reaching rather than maximizing hand-crafted reward signals. In this setting, the optimal goal-conditioned value function naturally forms a quasimetric, motivating Quasimetric RL (QRL), which constrains value learning to quasimetric mappings and enforces local consistency through discrete, trajectory-based constraints. We propose Eikonal-Constrained Quasimetric RL (Eik-QRL), a continuous-time reformulation of QRL based on the Eikonal Partial Differential Equation (PDE). This PDE-based structure makes Eik-QRL trajectory-free, requiring only sampled states and goals, while improving out-of-distribution generalization. We provide theoretical guarantees for Eik-QRL and identify limitations that arise under complex dynamics. To address these challenges, we introduce Eik-Hierarchical QRL (Eik-HiQRL), which integrates Eik-QRL into a hierarchical decomposition. Empirically, Eik-HiQRL achieves state-of-the-art performance in offline goal-conditioned navigation and yields consistent gains over QRL in manipulation tasks, matching temporal-difference methods.

</details>


### [296] [The Instability of Safety: How Random Seeds and Temperature Expose Inconsistent LLM Refusal Behavior](https://arxiv.org/abs/2512.12066)
*Erik Larsen*

Main category: cs.LG

TL;DR: 研究发现当前大语言模型安全评估依赖单次测试存在缺陷，模型的安全拒绝决策在不同随机种子和温度设置下不稳定，18-28%的提示会出现决策翻转，建议至少使用3个样本进行评估。


<details>
  <summary>Details</summary>
Motivation: 挑战当前大语言模型安全评估中隐含的假设——模型响应是确定性的且能代表模型的安全对齐。现有评估方法依赖单次测试，但实际中模型的安全拒绝决策可能不稳定。

Method: 测试4个指令调优模型（Llama 3.1 8B, Qwen 2.5 7B, Qwen 3 8B, Gemma 3 12B），使用876个有害提示，在20种不同采样配置（4个温度×5个随机种子）下评估。提出安全稳定性指数（SSI），并使用Claude 3.5 Haiku作为统一外部评判者验证结果。

Result: 18-28%的提示出现决策翻转（模型在某些配置下拒绝，在其他配置下同意）。温度越高，决策稳定性越差（平均SSI从温度0.0时的0.951降至1.0时的0.896）。单次评估与多样本真实情况的一致性仅为92.4%。

Conclusion: 单次安全评估不足以进行可靠的安全评估，建议每个提示至少使用3个样本进行评估，以提高安全评估的可靠性。

Abstract: Current safety evaluations of large language models rely on single-shot testing, implicitly assuming that model responses are deterministic and representative of the model's safety alignment. We challenge this assumption by investigating the stability of safety refusal decisions across random seeds and temperature settings. Testing four instruction-tuned models from three families (Llama 3.1 8B, Qwen 2.5 7B, Qwen 3 8B, Gemma 3 12B) on 876 harmful prompts across 20 different sampling configurations (4 temperatures x 5 random seeds), we find that 18-28% of prompts exhibit decision flips--the model refuses in some configurations but complies in others--depending on the model. Our Safety Stability Index (SSI) reveals that higher temperatures significantly reduce decision stability (Friedman chi-squared = 44.71, p < 0.001), with mean SSI dropping from 0.951 at temperature 0.0 to 0.896 at temperature 1.0. We validate our findings across all model families using Claude 3.5 Haiku as a unified external judge, achieving 89.0% inter-judge agreement with our primary Llama 70B judge (Cohen's kappa = 0.62). These findings demonstrate that single-shot safety evaluations are insufficient for reliable safety assessment. We show that single-shot evaluation agrees with multi-sample ground truth only 92.4% of the time, and recommend using at least 3 samples per prompt for reliable safety assessment.

</details>


### [297] [Physics-informed neural networks to solve inverse problems in unbounded domains](https://arxiv.org/abs/2512.12074)
*Gregorio Pérez-Bernal,Oscar Rincón-Cardeño,Silvana Montoya-Noguera,Nicolás Guarín-Zapata*

Main category: cs.LG

TL;DR: 提出了一种用于无限和半无限域逆问题求解的新方法，结合负指数和正态分布的采样策略以及双网络架构，在PINNs和PIKANs上实现并比较性能。


<details>
  <summary>Details</summary>
Motivation: 逆问题在应用数学中广泛研究，从医学诊断的声学断层扫描到地球物理勘探都有应用。PINNs已成为解决此类问题的强大工具，而PIKANs作为新兴基准，在某些问题上因其多项式组合的特性，可能提供更好的可解释性和准确性。本研究旨在开发适用于无限和半无限域逆问题求解的方法。

Method: 1. 提出新颖的训练点采样策略，使用负指数和正态分布；2. 设计双网络架构，通过相同损失函数同时学习方程的解和参数；3. 无需显式施加边界条件，只要解在离开感兴趣域时趋于稳定；4. 在PINNs和PIKANs上实现该架构并进行比较。

Result: 在此设置下，PINNs提供了更准确且计算效率更高的解决方案：1. 求解逆问题的速度比PIKANs快1000倍；2. 相对误差在同一数量级但更低；3. 在噪声环境下的响应表现更好。

Conclusion: 对于无限和半无限域逆问题，PINNs在准确性和计算效率方面优于PIKANs，特别是在处理噪声环境时表现更佳。提出的采样策略和双网络架构有效解决了这类问题，无需显式边界条件。

Abstract: Inverse problems are extensively studied in applied mathematics, with applications ranging from acoustic tomography for medical diagnosis to geophysical exploration. Physics informed neural networks (PINNs) have emerged as a powerful tool for solving such problems, while Physics informed Kolmogorov Arnold networks (PIKANs) represent a recent benchmark that, in certain problems, promises greater interpretability and accuracy compared to PINNs, due to their nature, being constructed as a composition of polynomials. In this work, we develop a methodology for addressing inverse problems in infinite and semi infinite domains. We introduce a novel sampling strategy for the network's training points, using the negative exponential and normal distributions, alongside a dual network architecture that is trained to learn the solution and parameters of an equation with the same loss function. This design enables the solution of inverse problems without explicitly imposing boundary conditions, as long as the solutions tend to stabilize when leaving the domain of interest. The proposed architecture is implemented using both PINNs and PIKANs, and their performance is compared in terms of accuracy with respect to a known solution as well as computational time and response to a noisy environment. Our results demonstrate that, in this setting, PINNs provide a more accurate and computationally efficient solution, solving the inverse problem 1,000 times faster and in the same order of magnitude, yet with a lower relative error than PIKANs.

</details>


### [298] [SigTime: Learning and Visually Explaining Time Series Signatures](https://arxiv.org/abs/2512.12076)
*Yu-Chia Huang,Juntong Chen,Dongyu Liu,Kwan-Liu Ma*

Main category: cs.LG

TL;DR: 提出一个结合Transformer、shapelet表示和特征工程的时序模式发现框架，以及配套的可视分析系统SigTime，用于生物医学等领域的时序数据分析。


<details>
  <summary>Details</summary>
Motivation: 现有时序模式发现方法存在计算复杂度高、可解释性有限、难以捕捉有意义的时序结构等问题，特别是在生物医学领域，从生理信号中发现有意义的模式对诊断、风险评估和患者预后至关重要。

Method: 提出一个联合训练两个Transformer模型的学习框架：一个使用shapelet表示捕捉局部时序结构，另一个使用传统特征工程编码统计特性。同时开发了SigTime可视分析系统，提供协调视图从多角度探索时序签名。

Result: 在8个公开数据集和1个专有临床数据集上进行了定量评估，并通过两个使用场景（公共ECG数据和早产分娩分析）与领域专家一起展示了系统的有效性。

Conclusion: 该框架能够发现可解释的时序签名来区分不同类别的时序数据，结合可视分析系统SigTime，有助于生成有用的洞察，特别适用于生物医学等领域的时序模式发现任务。

Abstract: Understanding and distinguishing temporal patterns in time series data is essential for scientific discovery and decision-making. For example, in biomedical research, uncovering meaningful patterns in physiological signals can improve diagnosis, risk assessment, and patient outcomes. However, existing methods for time series pattern discovery face major challenges, including high computational complexity, limited interpretability, and difficulty in capturing meaningful temporal structures. To address these gaps, we introduce a novel learning framework that jointly trains two Transformer models using complementary time series representations: shapelet-based representations to capture localized temporal structures and traditional feature engineering to encode statistical properties. The learned shapelets serve as interpretable signatures that differentiate time series across classification labels. Additionally, we develop a visual analytics system -- SigTIme -- with coordinated views to facilitate exploration of time series signatures from multiple perspectives, aiding in useful insights generation. We quantitatively evaluate our learning framework on eight publicly available datasets and one proprietary clinical dataset. Additionally, we demonstrate the effectiveness of our system through two usage scenarios along with the domain experts: one involving public ECG data and the other focused on preterm labor analysis.

</details>


### [299] [CLOAK: Contrastive Guidance for Latent Diffusion-Based Data Obfuscation](https://arxiv.org/abs/2512.12086)
*Xin Yang,Omid Ardakanian*

Main category: cs.LG

TL;DR: Cloak是一个基于潜在扩散模型的新型数据混淆框架，通过对比学习提取解耦表示，指导扩散过程在保留有用信息的同时隐藏隐私信息，在资源受限的移动物联网设备上实现更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有数据混淆方法存在三个主要问题：1）需要修改下游任务；2）难以达到满意的隐私-效用权衡；3）计算密集，不适合资源受限的移动物联网设备部署。

Method: 提出Cloak框架，基于潜在扩散模型，采用对比学习提取解耦表示，指导潜在扩散过程保留有用信息同时隐藏隐私信息，支持不同隐私需求的用户以最小重训练调整隐私-效用权衡。

Result: 在四个公共时间序列数据集（涵盖多种传感模态）和人脸图像数据集上的实验表明，Cloak始终优于最先进的混淆技术，且适合在资源受限环境中部署。

Conclusion: Cloak通过结合潜在扩散模型和对比学习，解决了现有数据混淆方法的局限性，为移动物联网设备提供了一种实用且高效的数据隐私保护方案。

Abstract: Data obfuscation is a promising technique for mitigating attribute inference attacks by semi-trusted parties with access to time-series data emitted by sensors. Recent advances leverage conditional generative models together with adversarial training or mutual information-based regularization to balance data privacy and utility. However, these methods often require modifying the downstream task, struggle to achieve a satisfactory privacy-utility trade-off, or are computationally intensive, making them impractical for deployment on resource-constrained mobile IoT devices. We propose Cloak, a novel data obfuscation framework based on latent diffusion models. In contrast to prior work, we employ contrastive learning to extract disentangled representations, which guide the latent diffusion process to retain useful information while concealing private information. This approach enables users with diverse privacy needs to navigate the privacy-utility trade-off with minimal retraining. Extensive experiments on four public time-series datasets, spanning multiple sensing modalities, and a dataset of facial images demonstrate that Cloak consistently outperforms state-of-the-art obfuscation techniques and is well-suited for deployment in resource-constrained settings.

</details>


### [300] [GraphPerf-RT: A Graph-Driven Performance Model for Hardware-Aware Scheduling of OpenMP Codes](https://arxiv.org/abs/2512.12091)
*Mohammad Pivezhandi,Mahdi Banisharif,Saeed Bakhshan,Abusayeed Saifullah,Ali Jannesari*

Main category: cs.LG

TL;DR: GraphPerf-RT：首个用于异构嵌入式SoC上OpenMP工作负载性能预测的图神经网络代理模型，统一任务DAG拓扑、代码语义和运行时上下文，实现不确定性感知调度


<details>
  <summary>Details</summary>
Motivation: 异构嵌入式SoC上OpenMP工作负载的性能预测面临挑战：任务DAG结构复杂、控制流不规则、缓存和分支行为、热动态等因素相互作用；传统启发式方法在不规则工作负载下表现不佳，表格回归器丢弃结构信息，无模型RL可能导致资源受限设备过热

Method: 提出GraphPerf-RT，使用异构图表示统一任务DAG拓扑、CFG导出的代码语义和运行时上下文（每核DVFS、热状态、利用率），通过类型边编码前驱关系、放置和争用；多任务证据头预测执行时间、能耗、缓存和分支缺失、利用率，并校准不确定性（Normal-Inverse-Gamma分布）

Result: 在三个嵌入式ARM平台（Jetson TX2、Jetson Orin NX、RUBIK Pi）上验证，R^2 > 0.95，不确定性校准良好（ECE < 0.05）；与四种RL方法集成在Jetson TX2上测试，MAMBRL-D3QN结合GraphPerf-RT作为世界模型相比无模型基线实现66%执行时间减少和82%能耗减少

Conclusion: 准确且不确定性感知的代理模型能够在热约束嵌入式系统上实现有效的基于模型的规划，GraphPerf-RT为异构嵌入式SoC上的OpenMP工作负载性能预测和调度提供了有效的解决方案

Abstract: Performance prediction for OpenMP workloads on heterogeneous embedded SoCs is challenging due to complex interactions between task DAG structure, control-flow irregularity, cache
  and branch behavior, and thermal dynamics; classical heuristics struggle under workload irregularity, tabular regressors discard structural information, and model-free RL risks
  overheating resource-constrained devices. We introduce GraphPerf-RT, the first surrogate that unifies task DAG topology, CFG-derived code semantics, and runtime context (per-core
  DVFS, thermal state, utilization) in a heterogeneous graph representation with typed edges encoding precedence, placement, and contention. Multi-task evidential heads predict
  makespan, energy, cache and branch misses, and utilization with calibrated uncertainty (Normal-Inverse-Gamma), enabling risk-aware scheduling that filters low-confidence rollouts.
  We validate GraphPerf-RT on three embedded ARM platforms (Jetson TX2, Jetson Orin NX, RUBIK Pi), achieving R^2 > 0.95 with well-calibrated uncertainty (ECE < 0.05). To
  demonstrate end-to-end scheduling utility, we integrate the surrogate with four RL methods on Jetson TX2: single-agent model-free (SAMFRL), single-agent model-based (SAMBRL),
  multi-agent model-free (MAMFRL-D3QN), and multi-agent model-based (MAMBRL-D3QN). Experiments across 5 seeds (200 episodes each) show that MAMBRL-D3QN with GraphPerf-RT as the
  world model achieves 66% makespan reduction (0.97 +/- 0.35s) and 82% energy reduction (0.006 +/- 0.005J) compared to model-free baselines, demonstrating that accurate,
  uncertainty-aware surrogates enable effective model-based planning on thermally constrained embedded systems.

</details>


### [301] [Neural CDEs as Correctors for Learned Time Series Models](https://arxiv.org/abs/2512.12116)
*Muhammad Bilal Shahid,Prajwal Koirla,Cody Fleming*

Main category: cs.LG

TL;DR: 提出Predictor-Corrector机制，用神经控制微分方程作为Corrector修正任意时间序列模型的预测误差，提升多步预测性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列模型（连续或离散时间）的多步预测存在误差，无论是直接预测整个时间范围还是迭代反馈预测，都需要改进预测精度

Method: 提出Predictor-Corrector机制：Predictor是任意学习的时间序列模型，Corrector是神经控制微分方程，用于预测预测误差，将误差加到预测结果上；支持不规则采样时间序列和连续/离散时间Predictor；引入两种正则化策略提升Corrector外推性能

Result: 在合成数据、物理仿真和真实世界预测数据集上测试，使用多种Predictor（神经ODE、Contiformer、DLinear等），Predictor-Corrector机制相比单独使用Predictor能持续提升性能

Conclusion: 提出的Predictor-Corrector机制能有效修正时间序列模型的预测误差，提升多步预测精度，具有广泛适用性

Abstract: Learned time-series models, whether continuous- or discrete-time, are widely used to forecast the states of a dynamical system. Such models generate multi-step forecasts either directly, by predicting the full horizon at once, or iteratively, by feeding back their own predictions at each step. In both cases, the multi-step forecasts are prone to errors. To address this, we propose a Predictor-Corrector mechanism where the Predictor is any learned time-series model and the Corrector is a neural controlled differential equation. The Predictor forecasts, and the Corrector predicts the errors of the forecasts. Adding these errors to the forecasts improves forecast performance. The proposed Corrector works with irregularly sampled time series and continuous- and discrete-time Predictors. Additionally, we introduce two regularization strategies to improve the extrapolation performance of the Corrector with accelerated training. We evaluate our Corrector with diverse Predictors, e.g., neural ordinary differential equations, Contiformer, and DLinear, on synthetic, physics simulation, and real-world forecasting datasets. The experiments demonstrate that the Predictor-Corrector mechanism consistently improves the performance compared to Predictor alone.

</details>


### [302] [MixtureKit: A General Framework for Composing, Training, and Visualizing Mixture-of-Experts Models](https://arxiv.org/abs/2512.12121)
*Ahmad Chamma,Omar El Herraoui,Guokan Shang*

Main category: cs.LG

TL;DR: MixtureKit是一个用于构建、训练和分析专家混合模型的开源框架，支持三种方法：传统MoE、BTX和BTS，并提供可视化界面分析路由决策。


<details>
  <summary>Details</summary>
Motivation: 为研究和开发专家混合模型提供一个实用的基础框架，支持从任意预训练或微调模型构建MoE系统，促进MoE技术在不同领域的应用。

Method: MixtureKit提供三种互补方法：1) 传统MoE：每个transformer块使用单个路由器选择专家；2) BTX：为每个指定子层引入单独路由器实现细粒度token路由；3) BTS：保持专家完整，引入可训练的stitch层控制hub和专家之间的信息交换。框架自动修改模型配置、修补解码器和因果LM类，并保存统一的检查点。

Result: 在多语言代码切换数据（如阿拉伯语-拉丁语）上的实验表明，使用MixtureKit训练的BTX模型在多个基准测试中优于基线密集模型。

Conclusion: MixtureKit作为一个实用的开源框架，为跨不同领域的MoE系统研究和开发提供了基础，支持灵活的模型构建、训练和分析，并提供了可视化工具来检查路由决策。

Abstract: We introduce MixtureKit, a modular open-source framework for constructing, training, and analyzing Mixture-of-Experts (MoE) models from arbitrary pre-trained or fine-tuned models. MixtureKit currently supports three complementary methods: (i) \emph{Traditional MoE}, which uses a single router per transformer block to select experts, (ii) \emph{BTX} (Branch-Train-Mix), which introduces separate routers for each specified sub-layer enabling fine-grained token routing, and (iii) \emph{BTS} (Branch-Train-Stitch), which keeps experts fully intact and introduces trainable stitch layers for controlled information exchange between hub and experts. MixtureKit automatically modifies the model configuration, patches decoder and causal LM classes, and saves a unified checkpoint ready for inference or fine-tuning. We further provide a visualization interface to inspect per-token routing decisions, expert weight distributions, and layer-wise contributions. Experiments with multilingual code-switched data (e.g. Arabic-Latin) show that a BTX-based model trained using MixtureKit can outperform baseline dense models on multiple benchmarks. We release MixtureKit as a practical foundation for research and development of MoE-based systems across diverse domains.

</details>


### [303] [High-Dimensional Tensor Discriminant Analysis: Low-Rank Discriminant Structure, Representation Synergy, and Theoretical Guarantees](https://arxiv.org/abs/2512.12122)
*Elynn Chen,Yuefeng Han,Jiayu Li*

Main category: cs.LG

TL;DR: 提出CP低秩张量判别分析(CP-TDA)用于高维张量分类，通过随机复合PCA初始化处理噪声，并开发半参数模型处理非正态数据，在图形分类任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高维张量预测器在现代应用中日益普遍（特别是来自神经网络的表示），现有张量分类方法依赖稀疏性或Tucker结构且缺乏理论保证。经验证据表明判别信号集中在少数多线性分量上。

Method: 1. 在张量高斯混合模型下提出CP低秩张量判别分析(CP-TDA)，使用随机复合PCA(rc-PCA)初始化处理依赖性和各向异性噪声；2. 开发半参数张量判别模型，通过深度生成模型将学习到的张量表示映射到适合CP-TDA的潜在空间。

Result: 建立了全局收敛性和极小极大最优误分类率。误分类风险分解为表示误差、近似误差和估计误差。数值研究和真实图形分类数据表明，在高维小样本情况下显著优于现有张量分类器和最先进的图神经网络。

Conclusion: CP-TDA为高维张量分类提供了理论保证的有效方法，特别是通过半参数扩展处理非正态数据，在图形分类等实际应用中表现出色。

Abstract: High-dimensional tensor-valued predictors arise in modern applications, increasingly as learned representations from neural networks. Existing tensor classification methods rely on sparsity or Tucker structures and often lack theoretical guarantees. Motivated by empirical evidence that discriminative signals concentrate along a few multilinear components, we introduce CP low-rank structure for the discriminant tensor, a modeling perspective not previously explored. Under a Tensor Gaussian Mixture Model, we propose high-dimensional CP low-rank Tensor Discriminant Analysis (CP-TDA) with Randomized Composite PCA (\textsc{rc-PCA}) initialization, that is essential for handling dependent and anisotropic noise under weaker signal strength and incoherence conditions, followed by iterative refinement algorithm. We establish global convergence and minimax-optimal misclassification rates.
  To handle tensor data deviating from tensor normality, we develop the first semiparametric tensor discriminant model, in which learned tensor representations are mapped via deep generative models into a latent space tailored for CP-TDA. Misclassification risk decomposes into representation, approximation, and estimation errors. Numerical studies and real data analysis on graph classification demonstrate substantial gains over existing tensor classifiers and state-of-the-art graph neural networks, particularly in high-dimensional, small-sample regimes.

</details>


### [304] [BOOST: BOttleneck-Optimized Scalable Training Framework for Low-Rank Large Language Models](https://arxiv.org/abs/2512.12131)
*Zhengyang Wang,Ziyue Liu,Ruijie Zhang,Avinash Maurya,Paul Hovland,Bogdan Nicolae,Franck Cappello,Zheng Zhang*

Main category: cs.LG

TL;DR: BOOST框架针对低秩瓶颈架构提出专门优化的张量并行策略，相比全秩模型基线实现1.46-1.91倍加速，相比简单集成3D并行的低秩模型实现1.87-2.27倍加速。


<details>
  <summary>Details</summary>
Motivation: Transformer模型预训练的规模受限于日益增长的计算和通信成本。低秩瓶颈架构虽然能显著减少训练时间和内存占用，但在标准张量并行下扩展性差，简单的3D并行会导致过度通信和GPU利用率低下。

Method: 提出BOOST训练框架，包括：1) 瓶颈感知张量并行；2) 在线RMSNorm优化；3) 线性层分组；4) 低秩激活检查点技术，实现端到端训练加速。

Result: 在不同低秩瓶颈架构上评估显示，BOOST相比全秩模型基线实现1.46-1.91倍加速，相比简单集成3D并行的低秩模型实现1.87-2.27倍加速，同时提高了GPU利用率并减少了通信开销。

Conclusion: BOOST框架为大规模低秩瓶颈架构提供了高效的训练解决方案，通过专门的并行策略和优化技术，显著提升了训练效率，解决了低秩架构在并行扩展中的瓶颈问题。

Abstract: The scale of transformer model pre-training is constrained by the increasing computation and communication cost. Low-rank bottleneck architectures offer a promising solution to significantly reduce the training time and memory footprint with minimum impact on accuracy. Despite algorithmic efficiency, bottleneck architectures scale poorly under standard tensor parallelism. Simply applying 3D parallelism designed for full-rank methods leads to excessive communication and poor GPU utilization. To address this limitation, we propose BOOST, an efficient training framework tailored for large-scale low-rank bottleneck architectures. BOOST introduces a novel Bottleneck-aware Tensor Parallelism, and combines optimizations such as online-RMSNorm, linear layer grouping, and low-rank activation checkpointing to achieve end-to-end training speedup. Evaluations on different low-rank bottleneck architectures demonstrate that BOOST achieves 1.46-1.91$\times$ speedup over full-rank model baselines and 1.87-2.27$\times$ speedup over low-rank model with naively integrated 3D parallelism, with improved GPU utilization and reduced communication overhead.

</details>


### [305] [On the Approximation Power of SiLU Networks: Exponential Rates and Depth Efficiency](https://arxiv.org/abs/2512.12132)
*Koffi O. Ayena*

Main category: cs.LG

TL;DR: SiLU激活网络在光滑函数逼近中实现指数级逼近速率，相比ReLU网络具有更优的复杂度控制


<details>
  <summary>Details</summary>
Motivation: 传统ReLU网络在函数逼近中的复杂度控制不够理想，需要开发更高效的激活函数网络来获得更好的逼近性能和复杂度控制

Method: 提出分层构造方法：首先高效逼近平方函数x²，然后通过函数组合扩展到深度SiLU网络，用于逼近Sobolev类函数

Result: SiLU网络能以深度O(1)、大小O(ε^{-d/n})实现指数级逼近误差O(ω^{-2k})，优于ReLU网络的复杂度

Conclusion: SiLU激活函数在深度神经网络中具有优越的逼近性能，为高效函数逼近提供了理论保证

Abstract: This article establishes a comprehensive theoretical framework demonstrating that SiLU (Sigmoid Linear Unit) activation networks achieve exponential approximation rates for smooth functions with explicit and improved complexity control compared to classical ReLU-based constructions. We develop a novel hierarchical construction beginning with an efficient approximation of the square function $x^2$ more compact in depth and size than comparable ReLU realizations, such as those given by Yarotsky. This construction yields an approximation error decaying as $\mathcal{O}(ω^{-2k})$ using networks of depth $\mathcal{O}(1)$. We then extend this approach through functional composition to establish sharp approximation bounds for deep SiLU networks in approximating Sobolev-class functions, with total depth $\mathcal{O}(1)$ and size $\mathcal{O}(\varepsilon^{-d/n})$.

</details>


### [306] [BaRISTA: Brain Scale Informed Spatiotemporal Representation of Human Intracranial Neural Activity](https://arxiv.org/abs/2512.12135)
*Lucine L. Oganesian,Saba Hashemi,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出一种用于多区域颅内脑电记录的时空Transformer模型，通过灵活的空间尺度token编码和掩码重建自监督任务，提升下游解码性能。


<details>
  <summary>Details</summary>
Motivation: 颅内记录能同时测量多区域脑网络活动，现有Transformer神经基础模型面临如何有效编码空间信息、设计自监督任务以学习脑网络模式并提升下游解码性能的挑战。

Method: 提出新的时空Transformer模型和掩码潜在重建自监督任务，支持灵活的空间尺度token编码和掩码，应用于公开的多区域颅内脑电数据。

Result: 调整token编码和掩码重建的空间尺度显著影响下游解码性能；较大空间尺度（区域级）编码比常用的通道级编码表现更好；能实现区域级token编码同时保持通道级神经重建精度。

Conclusion: 该建模框架能探索token编码和掩码的空间尺度，揭示了其对多区域人脑活动神经基础模型自监督预训练的重要性，并提升了下游解码性能。

Abstract: Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.

</details>


### [307] [HydroDiffusion: Diffusion-Based Probabilistic Streamflow Forecasting with a State Space Backbone](https://arxiv.org/abs/2512.12183)
*Yihan Wang,Annan Yu,Lujun Zhang,Charuleka Varadharajan,N. Benjamin Erichson*

Main category: cs.LG

TL;DR: HydroDiffusion：基于扩散模型和状态空间模型的水文概率预测框架，在CAMELS数据集上优于现有方法，提供更一致的多日轨迹预测


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的径流预测方法依赖LSTM骨干网络和单步训练目标，难以捕捉长期依赖关系并产生跨预见期一致的预测轨迹，需要改进

Method: 提出HydroDiffusion框架，使用仅解码器的状态空间模型作为骨干，联合去噪完整多日轨迹，确保时间一致性并减少自回归预测中的误差累积

Result: 在美国531个流域的CAMELS数据集上评估，HydroDiffusion在观测气象驱动下具有强现报精度，在整个模拟范围内保持一致性，在确定性预测和概率预测技能上优于DRUM模型

Conclusion: HydroDiffusion为中长期径流预测建立了稳健的生成建模框架，为大陆尺度概率水文预测提供了新的建模基准和研究基础

Abstract: Recent advances have introduced diffusion models for probabilistic streamflow forecasting, demonstrating strong early flood-warning skill. However, current implementations rely on recurrent Long Short-Term Memory (LSTM) backbones and single-step training objectives, which limit their ability to capture long-range dependencies and produce coherent forecast trajectories across lead times. To address these limitations, we developed HydroDiffusion, a diffusion-based probabilistic forecasting framework with a decoder-only state space model backbone. The proposed framework jointly denoises full multi-day trajectories in a single pass, ensuring temporal coherence and mitigating error accumulation common in autoregressive prediction. HydroDiffusion is evaluated across 531 watersheds in the contiguous United States (CONUS) in the CAMELS dataset. We benchmark HydroDiffusion against two diffusion baselines with LSTM backbones, as well as the recently proposed Diffusion-based Runoff Model (DRUM). Results show that HydroDiffusion achieves strong nowcast accuracy when driven by observed meteorological forcings, and maintains consistent performance across the full simulation horizon. Moreover, HydroDiffusion delivers stronger deterministic and probabilistic forecast skill than DRUM in operational forecasting. These results establish HydroDiffusion as a robust generative modeling framework for medium-range streamflow forecasting, providing both a new modeling benchmark and a foundation for future research on probabilistic hydrologic prediction at continental scales.

</details>


### [308] [MolGuidance: Advanced Guidance Strategies for Conditional Molecular Generation with Flow Matching](https://arxiv.org/abs/2512.12198)
*Jirui Jin,Cheng Zeng,Pawan Prakash,Ellad B. Tadmor,Adrian Roitberg,Richard G. Hennig,Stefano Martiniani,Mingjie Liu*

Main category: cs.LG

TL;DR: 本文提出了一种混合引导策略，将计算机视觉中的先进引导方法（如无分类器引导、自动引导和模型引导）整合到SE(3)-等变流匹配的分子生成框架中，通过贝叶斯优化联合优化连续和离散模态的引导尺度，在QM9和QMe14S数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 条件分子生成的关键目标包括确保化学有效性、使生成分子与目标属性对齐、促进结构多样性以及实现高效采样。虽然计算机视觉领域已引入多种新的生成模型引导策略，但这些方法在分子生成中的应用尚未充分探索。本研究旨在将这些先进的引导方法整合到分子生成框架中，以提升性能。

Method: 1. 在基于SE(3)-等变流匹配的领先分子生成框架中整合最先进的引导方法（无分类器引导、自动引导、模型引导）
2. 提出混合引导策略：分别引导连续和离散分子模态（分别作用于速度场和预测logits）
3. 通过贝叶斯优化联合优化引导尺度
4. 在QM9和QMe14S数据集上进行基准测试

Result: 1. 在从头分子生成的属性对齐方面实现了新的最先进性能
2. 生成的分子表现出高结构有效性
3. 系统比较了各种引导方法的优势和局限性，为更广泛的应用提供了见解

Conclusion: 本研究成功将计算机视觉中的先进引导策略整合到分子生成框架中，提出的混合引导方法在属性对齐和结构有效性方面取得了优异表现。系统性的方法比较为未来研究提供了有价值的指导，表明这些引导策略在分子生成领域具有广泛适用性。

Abstract: Key objectives in conditional molecular generation include ensuring chemical validity, aligning generated molecules with target properties, promoting structural diversity, and enabling efficient sampling for discovery. Recent advances in computer vision introduced a range of new guidance strategies for generative models, many of which can be adapted to support these goals. In this work, we integrate state-of-the-art guidance methods -- including classifier-free guidance, autoguidance, and model guidance -- in a leading molecule generation framework built on an SE(3)-equivariant flow matching process. We propose a hybrid guidance strategy that separately guides continuous and discrete molecular modalities -- operating on velocity fields and predicted logits, respectively -- while jointly optimizing their guidance scales via Bayesian optimization. Our implementation, benchmarked on the QM9 and QMe14S datasets, achieves new state-of-the-art performance in property alignment for de novo molecular generation. The generated molecules also exhibit high structural validity. Furthermore, we systematically compare the strengths and limitations of various guidance methods, offering insights into their broader applicability.

</details>


### [309] [EEG-DLite: Dataset Distillation for Efficient Large EEG Model Training](https://arxiv.org/abs/2512.12210)
*Yuting Tang,Weibang Jiang,Shanglin Li,Yong Li,Chenyu Liu,Xinliang Zhou,Yi Ding,Cuntai Guan*

Main category: cs.LG

TL;DR: EEG-DLite：通过数据蒸馏框架，从大规模EEG数据集中选择性去除噪声和冗余样本，仅用5%数据即可达到与完整数据集相当的性能，显著提升EEG基础模型训练效率。


<details>
  <summary>Details</summary>
Motivation: 大规模EEG基础模型训练需要大量计算资源，且EEG数据存在噪声和冗余问题。现有方法训练效率低下，需要更高效的数据预处理方法来减少训练成本。

Method: 提出EEG-DLite数据蒸馏框架：1）使用自监督自动编码器将EEG片段编码为紧凑的潜在表示；2）基于这些表示过滤异常值和最小化冗余；3）生成保留多样性的小型信息子集用于基础模型训练。

Result: 在2500小时数据集中，仅使用EEG-DLite筛选的5%数据进行训练，在多个下游任务上达到与完整数据集相当甚至更好的性能，显著提升训练效率。

Conclusion: EEG-DLite是首个针对EEG基础模型的预训练数据蒸馏系统研究，为生理基础建模提供了可扩展且实用的高效训练路径。

Abstract: Large-scale EEG foundation models have shown strong generalization across a range of downstream tasks, but their training remains resource-intensive due to the volume and variable quality of EEG data. In this work, we introduce EEG-DLite, a data distillation framework that enables more efficient pre-training by selectively removing noisy and redundant samples from large EEG datasets. EEG-DLite begins by encoding EEG segments into compact latent representations using a self-supervised autoencoder, allowing sample selection to be performed efficiently and with reduced sensitivity to noise. Based on these representations, EEG-DLite filters out outliers and minimizes redundancy, resulting in a smaller yet informative subset that retains the diversity essential for effective foundation model training. Through extensive experiments, we demonstrate that training on only 5 percent of a 2,500-hour dataset curated with EEG-DLite yields performance comparable to, and in some cases better than, training on the full dataset across multiple downstream tasks. To our knowledge, this is the first systematic study of pre-training data distillation in the context of EEG foundation models. EEG-DLite provides a scalable and practical path toward more effective and efficient physiological foundation modeling. The code is available at https://github.com/t170815518/EEG-DLite.

</details>


### [310] [Optimized Learned Count-Min Sketch](https://arxiv.org/abs/2512.12252)
*Kyosuke Nishishita,Atsuki Sato,Yusuke Matsui*

Main category: cs.LG

TL;DR: OptLCMS 改进了学习型 Count-Min Sketch，通过分区和动态规划优化，在保持相同内存使用下提供理论保证并加快构建速度。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型 Count-Min Sketch (LCMS) 虽然通过机器学习模型减少了估计误差，但存在构建速度慢（需要经验参数调优）和缺乏理论保证的问题。

Method: 1) 将输入域分区，每个分区分配独立的 CMS 实例；2) 为固定阈值分析推导 CMS 参数；3) 通过带近似可行性检查的动态规划优化阈值。

Result: 实验表明 OptLCMS 构建更快，实现了更低的不可容忍错误概率，并且与 LCMS 的估计精度相当。

Conclusion: OptLCMS 通过理论保证的优化方法，在保持学习型 CMS 优势的同时，解决了构建速度和理论保证的问题，并提供了显式的错误阈值控制。

Abstract: Count-Min Sketch (CMS) is a memory-efficient data structure for estimating the frequency of elements in a multiset. Learned Count-Min Sketch (LCMS) enhances CMS with a machine learning model to reduce estimation error under the same memory usage, but suffers from slow construction due to empirical parameter tuning and lacks theoretical guarantees on intolerable error probability. We propose Optimized Learned Count-Min Sketch (OptLCMS), which partitions the input domain and assigns each partition to its own CMS instance, with CMS parameters analytically derived for fixed thresholds, and thresholds optimized via dynamic programming with approximate feasibility checks. This reduces the need for empirical validation, enabling faster construction while providing theoretical guarantees under these assumptions. OptLCMS also allows explicit control of the allowable error threshold, improving flexibility in practice. Experiments show that OptLCMS builds faster, achieves lower intolerable error probability, and matches the estimation accuracy of LCMS.

</details>


### [311] [GRC-Net: Gram Residual Co-attention Net for epilepsy prediction](https://arxiv.org/abs/2512.12273)
*Bihao You,Jiping Cui*

Main category: cs.LG

TL;DR: 提出GRC-Net模型，使用Gram矩阵将EEG信号转为3D表示，结合共注意力和Inception结构进行多粒度特征提取，在癫痫预测任务上达到93.66%准确率


<details>
  <summary>Details</summary>
Motivation: 传统EEG癫痫预测研究采用1D信号处理，无法充分建模信号间关系；同时EEG数据存在局部与全局信号不平衡问题，需要更有效的特征提取方法

Method: 1) 使用Gram矩阵将1D EEG信号转为3D表示，保留时序依赖；2) 引入多级特征提取：共注意力机制捕获全局特征，Inception结构处理局部信号；3) 构建GRC-Net模型

Result: 在BONN数据集最困难的五分类任务上，GRC-Net达到93.66%的准确率，优于现有方法

Conclusion: 提出的3D表示和多级特征提取方法能有效提升EEG癫痫预测性能，为脑电信号分析提供了新思路

Abstract: Prediction of epilepsy based on electroencephalogram (EEG) signals is a rapidly evolving field. Previous studies have traditionally applied 1D processing to the entire EEG signal. However, we have adopted the Gram Matrix method to transform the signals into a 3D representation, enabling modeling of signal relationships across dimensions while preserving the temporal dependencies of the one-dimensional signals. Additionally, we observed an imbalance between local and global signals within the EEG data. Therefore, we introduced multi-level feature extraction, utilizing coattention for capturing global signal characteristics and an inception structure for processing local signals, achieving multi-granular feature extraction. Our experiments on the BONN dataset demonstrate that for the most challenging five-class classification task, GRC-Net achieved an accuracy of 93.66%, outperforming existing methods.

</details>


### [312] [Balancing Accuracy and Speed: A Multi-Fidelity Ensemble Kalman Filter with a Machine Learning Surrogate Model](https://arxiv.org/abs/2512.12276)
*Jeffrey van der Voort,Martin Verlaan,Hanne Kekkonen*

Main category: cs.LG

TL;DR: 提出使用机器学习代理模型作为多保真度集合卡尔曼滤波中的低保真度模型，通过少量昂贵高保真模型和大量廉价ML模型组合，在相同计算预算下提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型计算昂贵，机器学习代理模型计算廉价但精度较低。希望结合两者的优势：使用少量昂贵高保真物理模型和大量廉价ML代理模型，在相同计算预算下提高集合卡尔曼滤波的精度。

Method: 提出多保真度集合卡尔曼滤波方法，其中低保真度模型采用机器学习代理模型（而非传统的低分辨率或降阶模型）。通过少量昂贵高保真物理模型运行和大量廉价ML模型运行组成集合，在相同计算预算下工作。

Result: 在两个测试问题（Lorenz-2005模型和准地转模型）上验证。相比完全用ML模型替换物理模型，保留原始物理模型可获得更高精度。MF-EnKF在相同计算预算下达到改进的精度。ML代理模型相比低分辨率模型具有相似或更好的精度，且能提供更大的加速。

Conclusion: 该方法通过增加EnKF中的有效集合大小，改善了初始条件估计，从而提高了气象学和海洋学等领域的预测精度。ML代理模型作为低保真度模型在多保真度框架中表现良好，提供了精度和计算效率的良好平衡。

Abstract: Currently, more and more machine learning (ML) surrogates are being developed for computationally expensive physical models. In this work we investigate the use of a Multi-Fidelity Ensemble Kalman Filter (MF-EnKF) in which the low-fidelity model is such a machine learning surrogate model, instead of a traditional low-resolution or reduced-order model. The idea behind this is to use an ensemble of a few expensive full model runs, together with an ensemble of many cheap but less accurate ML model runs. In this way we hope to reach increased accuracy within the same computational budget. We investigate the performance by testing the approach on two common test problems, namely the Lorenz-2005 model and the Quasi-Geostrophic model. By keeping the original physical model in place, we obtain a higher accuracy than when we completely replace it by the ML model. Furthermore, the MF-EnKF reaches improved accuracy within the same computational budget. The ML surrogate has similar or improved accuracy compared to the low-resolution one, but it can provide a larger speed-up. Our method contributes to increasing the effective ensemble size in the EnKF, which improves the estimation of the initial condition and hence accuracy of the predictions in fields such as meteorology and oceanography.

</details>


### [313] [Fractional Differential Equation Physics-Informed Neural Network and Its Application in Battery State Estimation](https://arxiv.org/abs/2512.12285)
*Lujuan Dang,Zilai Wang*

Main category: cs.LG

TL;DR: 提出FDIFF-PINN模型，结合分数阶微积分与深度学习，用于锂离子电池SOC估计，提升动态条件下的预测精度和物理解释性。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的神经网络模型难以充分表征电化学过程的复杂非线性和记忆依赖动态特性，限制了SOC估计在动态工况下的预测精度和物理解释性。

Method: 提出分数阶微分方程物理信息神经网络(FDIFF-PINN)，基于分数阶等效电路模型构建离散化分数阶偏微分方程，结合分数阶微积分与深度学习。

Result: 使用Panasonic 18650PF电池在-10°C到20°C多温度条件下的动态充放电数据集进行对比实验验证。

Conclusion: FDIFF-PINN模型能够有效提升锂离子电池SOC估计的准确性和物理解释性，为电池管理系统提供更可靠的解决方案。

Abstract: Accurate estimation of the State of Charge (SOC) is critical for ensuring the safety, reliability, and performance optimization of lithium-ion battery systems. Conventional data-driven neural network models often struggle to fully characterize the inherent complex nonlinearities and memory-dependent dynamics of electrochemical processes, significantly limiting their predictive accuracy and physical interpretability under dynamic operating conditions. To address this challenge, this study proposes a novel neural architecture termed the Fractional Differential Equation Physics-Informed Neural Network (FDIFF-PINN), which integrates fractional calculus with deep learning. The main contributions of this paper include: (1) Based on a fractional-order equivalent circuit model, a discretized fractional-order partial differential equation is constructed. (2) Comparative experiments were conducted using a dynamic charge/discharge dataset of Panasonic 18650PF batteries under multi-temperature conditions (from -10$^{\circ}$C to 20$^{\circ}$C).

</details>


### [314] [TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting](https://arxiv.org/abs/2512.12301)
*Mahima Kumavat,Aditya Maheshwari*

Main category: cs.LG

TL;DR: TwinFormer是一种用于长序列时间序列预测的分层Transformer，通过局部-全局两阶段处理和稀疏注意力机制实现线性复杂度，在多个真实数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决长序列时间序列预测中传统Transformer计算复杂度高（O(L²d)）的问题，同时需要有效捕捉局部动态和长期依赖关系。

Method: 1. 将输入分割为非重叠时间片段；2. 局部信息器使用top-k稀疏注意力建模片段内动态，然后均值池化；3. 全局信息器使用相同top-k注意力捕捉片段间长程依赖；4. 轻量级GRU聚合全局上下文化的片段标记进行多步预测。

Result: 在8个真实世界数据集（天气、股价、温度、功耗、电力、疾病）上，预测范围96-720，TwinFormer在34个评估中27次进入前二，其中17次MAE和RMSE最佳，10次次佳，一致超越PatchTST、iTransformer、FEDformer、Informer和标准Transformer。

Conclusion: TwinFormer通过分层结构和top-k稀疏注意力实现了线性复杂度，在长序列时间序列预测任务中表现出色，验证了其架构设计的有效性。

Abstract: TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is available at this repository: https://github.com/Mahimakumavat1205/TwinFormer.

</details>


### [315] [Eventually LIL Regret: Almost Sure $\ln\ln T$ Regret for a sub-Gaussian Mixture on Unbounded Data](https://arxiv.org/abs/2512.12325)
*Shubhada Agrawal,Aaditya Ramdas*

Main category: cs.LG

TL;DR: 该论文证明了Robbins提出的经典次高斯混合模型满足确定性路径后悔界，在Ville事件中后悔界为ln²(1/α)/V_T + ln(1/α) + ln ln V_T，为有界和无界数据的学习理论搭建了桥梁。


<details>
  <summary>Details</summary>
Motivation: 连接对抗性在线学习（通常处理有界数据的后悔界）和博弈论统计（可以处理无界数据但需要随机性假设）两个领域，通过条件后悔界作为随机和对抗性投注之间的桥梁。

Method: 分析Robbins的经典次高斯混合模型，证明其在Ville事件中满足路径级确定性后悔界，使用累积方差过程V_T作为关键参数，建立条件后悔界理论框架。

Result: 在Ville事件E_α中，后悔界为ln²(1/α)/V_T + ln(1/α) + ln ln V_T（通用常数内）；在概率为1的E_0事件中，后悔最终以ln ln V_T为界；当V_T ≥ ln(1/α)时简化为ln(1/α) + ln ln V_T。

Conclusion: 条件后悔界为随机和对抗性学习理论提供了统一框架，使得在无界数据环境下也能获得确定性后悔保证，为在线学习和统计推断的交叉研究开辟了新方向。

Abstract: We prove that a classic sub-Gaussian mixture proposed by Robbins in a stochastic setting actually satisfies a path-wise (deterministic) regret bound. For every path in a natural ``Ville event'' $E_α$, this regret till time $T$ is bounded by $\ln^2(1/α)/V_T + \ln (1/α) + \ln \ln V_T$ up to universal constants, where $V_T$ is a nonnegative, nondecreasing, cumulative variance process. (The bound reduces to $\ln(1/α) + \ln \ln V_T$ if $V_T \geq \ln(1/α)$.) If the data were stochastic, then one can show that $E_α$ has probability at least $1-α$ under a wide class of distributions (eg: sub-Gaussian, symmetric, variance-bounded, etc.). In fact, we show that on the Ville event $E_0$ of probability one, the regret on every path in $E_0$ is eventually bounded by $\ln \ln V_T$ (up to constants). We explain how this work helps bridge the world of adversarial online learning (which usually deals with regret bounds for bounded data), with game-theoretic statistics (which can handle unbounded data, albeit using stochastic assumptions). In short, conditional regret bounds serve as a bridge between stochastic and adversarial betting.

</details>


### [316] [Uncertainty Quantification for Machine Learning: One Size Does Not Fit All](https://arxiv.org/abs/2512.12341)
*Paul Hofman,Yusuf Sale,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 本文认为不存在单一最佳的不确定性度量方法，应根据具体应用场景定制不确定性量化，提出基于二阶分布的灵活不确定性度量框架，区分总、偶然和认知不确定性，并通过不同评分规则适应不同任务需求。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中，准确量化预测不确定性至关重要。现有研究通常声称某种不确定性度量方法优于其他方法，但本文认为不存在单一最佳度量，应根据具体应用场景定制不确定性量化方法。

Method: 提出基于二阶分布的灵活不确定性度量框架，区分总不确定性、偶然不确定性和认知不确定性。使用适当的评分规则（proper scoring rules）来控制这些度量的特性，使其能够适应不同任务需求。

Result: 研究表明：1）对于选择性预测任务，评分规则应与任务损失函数匹配；2）对于分布外检测，互信息（广泛使用的认知不确定性度量）表现最佳；3）在主动学习场景中，基于0-1损失的认知不确定性持续优于其他不确定性度量方法。

Conclusion: 不确定性量化应根据具体应用场景进行定制，不存在单一最佳的不确定性度量方法。提出的灵活框架能够通过不同评分规则适应不同任务需求，为安全关键应用中的机器学习提供更有效的不确定性量化解决方案。

Abstract: Proper quantification of predictive uncertainty is essential for the use of machine learning in safety-critical applications. Various uncertainty measures have been proposed for this purpose, typically claiming superiority over other measures. In this paper, we argue that there is no single best measure. Instead, uncertainty quantification should be tailored to the specific application. To this end, we use a flexible family of uncertainty measures that distinguishes between total, aleatoric, and epistemic uncertainty of second-order distributions. These measures can be instantiated with specific loss functions, so-called proper scoring rules, to control their characteristics, and we show that different characteristics are useful for different tasks. In particular, we show that, for the task of selective prediction, the scoring rule should ideally match the task loss. On the other hand, for out-of-distribution detection, our results confirm that mutual information, a widely used measure of epistemic uncertainty, performs best. Furthermore, in an active learning setting, epistemic uncertainty based on zero-one loss is shown to consistently outperform other uncertainty measures.

</details>


### [317] [Synthetic Swarm Mosquito Dataset for Acoustic Classification: A Proof of Concept](https://arxiv.org/abs/2512.12365)
*Thai-Duy Dinh,Minh-Luan Vo,Cuong Tuan Nguyen,Bich-Hien Vo*

Main category: cs.LG

TL;DR: 提出合成蚊群声学分类数据集，用于模拟多物种和嘈杂环境，通过轻量深度学习模型识别六种主要蚊媒，适合嵌入式低功耗设备部署。


<details>
  <summary>Details</summary>
Motivation: 蚊媒疾病每年导致超过70万人死亡，构成严重全球健康威胁。传统数据集需要耗费大量人力记录单个蚊子，而合成方法能够实现可扩展的数据生成，减少人力资源需求。

Method: 创建合成蚊群声学分类数据集，模拟真实的多物种和嘈杂蚊群环境。使用对数梅尔频谱图，评估轻量级深度学习架构进行蚊种分类。

Result: 实验表明，这些模型能够有效识别六种主要蚊媒，并且适合在嵌入式低功耗设备上部署。合成蚊群音频数据集显示出加速声学蚊子研究和实现可扩展实时监测解决方案的潜力。

Conclusion: 合成蚊群声学数据集为蚊媒疾病监测提供了可扩展的解决方案，通过轻量深度学习模型在低功耗设备上的部署，有望实现实时监测，加速声学蚊子研究发展。

Abstract: Mosquito-borne diseases pose a serious global health threat, causing over 700,000 deaths annually. This work introduces a proof-of-concept Synthetic Swarm Mosquito Dataset for Acoustic Classification, created to simulate realistic multi-species and noisy swarm conditions. Unlike conventional datasets that require labor-intensive recording of individual mosquitoes, the synthetic approach enables scalable data generation while reducing human resource demands. Using log-mel spectrograms, we evaluated lightweight deep learning architectures for the classification of mosquito species. Experiments show that these models can effectively identify six major mosquito vectors and are suitable for deployment on embedded low-power devices. The study demonstrates the potential of synthetic swarm audio datasets to accelerate acoustic mosquito research and enable scalable real-time surveillance solutions.

</details>


### [318] [The Data Efficiency Frontier of Financial Foundation Models: Scaling Laws from Continued Pretraining](https://arxiv.org/abs/2512.12384)
*Jesse Ponnock*

Main category: cs.LG

TL;DR: 对1B和3B参数的Llama-3.2模型在4亿token金融语料上进行领域自适应预训练，结果显示前2亿token效果提升最显著，金融语言高度规则易学，且不会导致通用领域性能下降。


<details>
  <summary>Details</summary>
Motivation: 研究领域自适应预训练（DAPT）如何高效地将大语言模型专业化到高价值领域（如金融SEC文件），避免完全重新训练的高成本，为金融基础模型的规模化提供早期经验指导。

Method: 使用1B和3B参数的Llama-3.2模型，在美国SEC文件组成的4亿token金融语料上进行持续预训练，在50M、100M、200M和400M token处设置验证检查点，分析领域损失变化和幂律拟合。

Result: 两个模型在SEC领域验证损失均持续改善，最大提升发生在前2亿token，之后收益递减；幂律拟合显示浅指数，表明金融语言高度规则易学；通用领域损失基本不变，无灾难性遗忘迹象。

Conclusion: 领域自适应预训练可用相对适中的token预算实现有意义的领域适应，金融语言高度规则易学，更大规模模型（7B-70B）在预计数据需求下仍可处理，为金融基础模型规模化提供指导。

Abstract: Domain-adaptive pretraining (DAPT) offers a practical path to specializing large language models for high-value domains without full retraining. We conduct an early-stage scaling-law analysis of continued pretraining on U.S. SEC filings, training 1B and 3B-parameter Llama-3.2 models on a 400M-token financial corpus with validation checkpoints at 50M, 100M, 200M, and 400M tokens. Results show consistent improvements in SEC-domain validation loss for both models, with the largest gains occurring within the first 200M tokens and diminishing returns thereafter. Power-law fits reveal shallow exponents, indicating that financial language is highly regular and efficiently learnable under continued pretraining. General-domain validation loss remains effectively unchanged across all token budgets, suggesting minimal drift and no signs of catastrophic forgetting. A data-efficiency frontier further shows that both models move toward improved specialization with negligible mixed-domain degradation. Together, these findings provide early empirical guidance for scaling financial foundation models, suggesting that meaningful domain adaptation can be achieved with comparatively modest token budgets and that larger model scales (7B-70B) remain tractable under projected data requirements.

</details>


### [319] [Anchoring Values in Temporal and Group Dimensions for Flow Matching Model Alignment](https://arxiv.org/abs/2512.12387)
*Yawen Shao,Jie Xiao,Kai Zhu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.LG

TL;DR: VGPO提出了一种新的强化学习框架，通过时间维度和群体维度的价值锚定，解决了GRPO在图像生成中的两个关键限制：时间信用分配问题和优化停滞问题。


<details>
  <summary>Details</summary>
Motivation: 当前GRPO在基于流匹配的图像生成中存在两个核心问题：1）稀疏终端奖励在所有时间步均匀应用，忽略了生成过程中不同阶段（从早期结构形成到后期微调）的重要性差异；2）仅依赖相对群体内奖励导致优化信号随着训练收敛而减弱，当奖励多样性耗尽时会出现优化停滞。

Method: VGPO框架包含两个关键创新：1）将稀疏终端奖励转化为密集的、过程感知的价值估计，通过建模每个生成阶段的预期累积奖励来实现精确的信用分配；2）用绝对价值增强的新过程替代标准群体归一化，即使在奖励多样性下降时也能保持稳定的优化信号。

Result: 在三个基准测试上的广泛实验表明，VGPO实现了最先进的图像质量，同时提高了任务特定的准确性，有效缓解了奖励黑客问题。

Conclusion: VGPO通过重新定义时间和群体维度的价值估计，成功解决了GRPO在视觉合成过程中的基本冲突，为基于流匹配的图像生成提供了更有效的强化学习框架。

Abstract: Group Relative Policy Optimization (GRPO) has proven highly effective in enhancing the alignment capabilities of Large Language Models (LLMs). However, current adaptations of GRPO for the flow matching-based image generation neglect a foundational conflict between its core principles and the distinct dynamics of the visual synthesis process. This mismatch leads to two key limitations: (i) Uniformly applying a sparse terminal reward across all timesteps impairs temporal credit assignment, ignoring the differing criticality of generation phases from early structure formation to late-stage tuning. (ii) Exclusive reliance on relative, intra-group rewards causes the optimization signal to fade as training converges, leading to the optimization stagnation when reward diversity is entirely depleted. To address these limitations, we propose Value-Anchored Group Policy Optimization (VGPO), a framework that redefines value estimation across both temporal and group dimensions. Specifically, VGPO transforms the sparse terminal reward into dense, process-aware value estimates, enabling precise credit assignment by modeling the expected cumulative reward at each generative stage. Furthermore, VGPO replaces standard group normalization with a novel process enhanced by absolute values to maintain a stable optimization signal even as reward diversity declines. Extensive experiments on three benchmarks demonstrate that VGPO achieves state-of-the-art image quality while simultaneously improving task-specific accuracy, effectively mitigating reward hacking. Project webpage: https://yawen-shao.github.io/VGPO/.

</details>


### [320] [DeepVekua: Geometric-Spectral Representation Learning for Physics-Informed Fields](https://arxiv.org/abs/2512.12402)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: DeepVekua：一种结合几何深度学习和谱分析的混合架构，用于稀疏数据下的PDE求解，通过可微坐标变换将复杂几何映射到潜在调和空间，性能优于现有隐式表示方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于坐标的网络在谱偏差方面存在困难，特别是在稀疏数据情况下求解偏微分方程时效果不佳。需要一种能够将几何学习与物理学习分离的方法，以提高PDE求解的效率和精度。

Method: 提出混合架构，学习一个微分同胚坐标变换，将复杂几何映射到潜在调和空间。该方法将几何学习与物理学习分离，以闭式形式求解最优谱权重，避免了标准坐标网络的谱偏差问题。

Result: 在平流-扩散系统上优于最先进的隐式表示方法，相比谱基线有100倍的改进。代码已开源。

Conclusion: DeepVekua通过结合几何深度学习和谱分析，在稀疏数据情况下有效解决了PDE求解问题，为复杂几何上的物理建模提供了新方法。

Abstract: We present DeepVekua, a hybrid architecture that unifies geometric deep learning with spectral analysis to solve partial differential equations (PDEs) in sparse data regimes. By learning a diffeomorphic coordinate transformation that maps complex geometries to a latent harmonic space, our method outperforms state-of-the-art implicit representations on advection-diffusion systems. Unlike standard coordinate-based networks which struggle with spectral bias, DeepVekua separates the learning of geometry from the learning of physics, solving for optimal spectral weights in closed form. We demonstrate a 100x improvement over spectral baselines. The code is available at https://github.com/VladimerKhasia/vekuanet.

</details>


### [321] [Can Graphs Improve Tabular Foundation Models?](https://arxiv.org/abs/2512.12405)
*Franck Le,Keith Grueneberg,Erich Nahum,Vadim Sheinin*

Main category: cs.LG

TL;DR: BOLERO：一个轻量级静态二分图头，通过引入简单图先验增强预训练表格Transformer，在分类和回归任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有表格Transformer和上下文学习方法（如SAINT、TP-BERTa、TabPFN等）缺乏显式建模实例间关系的机制，而相似样本通常具有相关结果。研究是否可以通过引入简单图先验来增强预训练表格Transformer的性能。

Method: 提出BOLERO方法：一个轻量级静态二分图头，增强RoBERTa-Tab（基于掩码标记预测预训练的RoBERTa风格表格骨干）。每个实例连接到特征/值锚点；使用小型GNN细化行表示，同时保持骨干网络冻结。

Result: 在TP-BERTa基准套件的80个分类和64个回归数据集上评估，与XGBoost、CatBoost、TabPFN-v2、MITRA、TabICL、TP-BERTa、RoBERTa-Tab等强基线比较。采用成对Wilcoxon符号秩检验和效应大小分析，BOLERO在分类和回归任务上都取得了最多的统计显著胜利。

Conclusion: 轻量级图先验能够有意义地改进预训练表格Transformer，BOLERO方法在表格数据建模中有效利用了实例间关系，为表格学习提供了新的方向。

Abstract: Tabular data are central to many real-world systems. While recent tabular transformers and in-context learners such as SAINT, TP-BERTa, TabPFN, TabICL, and MITRA incorporate limited inter-row reasoning, most approaches still lack an explicit mechanism to model relationships among instances, even though similar samples often share related outcomes. We investigate whether introducing \emph{simple graph priors} can enhance \emph{pretrained tabular transformers}. Concretely, we introduce {BOLERO}, a lightweight, static bipartite graph head that augments {RoBERTa-Tab} (a RoBERTa-style tabular backbone pretrained with masked-token prediction.) Each instance connects to feature/value anchors; a small GNN refines row representations, while the backbone remains frozen. We evaluate on 80 classification and 64 regression datasets from the TP-BERTa benchmark suites, comparing against strong baselines including XGBoost, CatBoost, TabPFN-v2, MITRA, TabICL, TP-BERTa, and RoBERTa-Tab. To ensure statistically sound conclusions, we follow best practices for multi-dataset evaluation: pairwise Wilcoxon signed-rank tests on per-dataset score differences and effect sizes (median improvement with confidence intervals), rather than mean-rank post-hoc tests that depend on the competitor pool. BOLERO achieves the highest number of statistically significant wins across both classification and regression, demonstrating that lightweight graph priors meaningfully improve pretrained tabular transformers.

</details>


### [322] [Learning Dynamics in Memristor-Based Equilibrium Propagation](https://arxiv.org/abs/2512.12428)
*Michael Döll,Andreas Müller,Bernd Ulmann*

Main category: cs.LG

TL;DR: 研究非线性忆阻器权重更新对平衡传播训练神经网络收敛性的影响，发现忆阻器需要足够宽的电阻范围（至少一个数量级）才能实现稳健收敛


<details>
  <summary>Details</summary>
Motivation: 基于忆阻器的存内计算有望克服冯·诺依曼瓶颈和内存墙的限制，实现完全并行化和高能效的向量矩阵乘法。本研究旨在探索非线性忆阻器驱动的权重更新对平衡传播训练神经网络收敛行为的影响。

Method: 使用六个忆阻器模型，通过电压-电流迟滞特性进行表征，并将其集成到EBANA框架中。在两个基准分类任务上评估平衡传播在非线性权重更新下的表现。

Result: 平衡传播能够在非线性权重更新下实现稳健收敛，前提是忆阻器表现出足够宽的电阻范围（至少一个数量级）。

Conclusion: 非线性忆阻器权重更新与平衡传播训练兼容，但忆阻器需要具备足够宽的电阻范围才能确保神经网络的有效收敛。

Abstract: Memristor-based in-memory computing has emerged as a promising paradigm to overcome the constraints of the von Neumann bottleneck and the memory wall by enabling fully parallelisable and energy-efficient vector-matrix multiplications. We investigate the effect of nonlinear, memristor-driven weight updates on the convergence behaviour of neural networks trained with equilibrium propagation (EqProp). Six memristor models were characterised by their voltage-current hysteresis and integrated into the EBANA framework for evaluation on two benchmark classification tasks. EqProp can achieve robust convergence under nonlinear weight updates, provided that memristors exhibit a sufficiently wide resistance range of at least an order of magnitude.

</details>


### [323] [Rough Sets for Explainability of Spectral Graph Clustering](https://arxiv.org/abs/2512.12436)
*Bartłomiej Starosta,Sławomir T. Wierzchoń,Piotr Borkowski,Dariusz Czerski,Marcin Sydow,Eryk Laskowski,Mieczysław A. Kłopotek*

Main category: cs.LG

TL;DR: 本文提出了一种基于粗糙集理论的图谱聚类解释增强方法，解决文档聚类结果难以解释的问题


<details>
  <summary>Details</summary>
Motivation: 图谱聚类方法在处理文本文档时，由于嵌入到谱空间（与文档内容无直接关系）以及存在内容不明确的文档和聚类算法的随机性，导致聚类结果难以向用户解释

Method: 在团队先前研究的基础上，提出一种增强的解释方法，借鉴粗糙集理论来克服上述问题

Result: 未在摘要中明确说明具体结果，但该方法旨在提高聚类结果的可解释性

Conclusion: 通过结合粗糙集理论，能够更好地解释图谱聚类在文本文档分析中的结果，解决可解释性挑战

Abstract: Graph Spectral Clustering methods (GSC) allow representing clusters of diverse shapes, densities, etc. However, the results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Furthermore, the presence of documents without clear content meaning and the stochastic nature of the clustering algorithms deteriorate explainability. This paper proposes an enhancement to the explanation methodology, proposed in an earlier research of our team. It allows us to overcome the latter problems by taking inspiration from rough set theory.

</details>


### [324] [Knowledge-Guided Masked Autoencoder with Linear Spectral Mixing and Spectral-Angle-Aware Reconstruction](https://arxiv.org/abs/2512.12445)
*Abdul Matin,Rupasree Dey,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.LG

TL;DR: 提出一种结合领域知识的ViT掩码自编码器，将线性光谱混合模型和光谱角度匹配器作为物理约束嵌入自监督重建过程，提升重建质量和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 将领域知识融入深度学习可以提升模型可解释性、泛化能力和数据效率。当前方法主要依赖数据驱动优化，缺乏物理约束，导致学习到的表示可能不符合已知的物理结构关系。

Method: 提出知识引导的ViT掩码自编码器框架，将线性光谱混合模型作为物理约束，结合基于物理的光谱角度匹配器损失。联合优化LSMM损失、SAM损失和传统的Huber损失，确保学习到的表示既符合数值准确性又保持几何一致性。

Result: 实验结果表明，该模型显著提升了重建质量，改善了下游任务性能，在有限监督下稳定了训练过程，并产生了基于物理原理的可解释潜在表示。

Conclusion: 将物理信息归纳偏置嵌入基于Transformer的自监督学习具有重要前景，知识引导的设计增强了重建保真度，稳定了训练，并产生了基于物理原理的可解释表示。

Abstract: Integrating domain knowledge into deep learning has emerged as a promising direction for improving model interpretability, generalization, and data efficiency. In this work, we present a novel knowledge-guided ViT-based Masked Autoencoder that embeds scientific domain knowledge within the self-supervised reconstruction process. Instead of relying solely on data-driven optimization, our proposed approach incorporates the Linear Spectral Mixing Model (LSMM) as a physical constraint and physically-based Spectral Angle Mapper (SAM), ensuring that learned representations adhere to known structural relationships between observed signals and their latent components. The framework jointly optimizes LSMM and SAM loss with a conventional Huber loss objective, promoting both numerical accuracy and geometric consistency in the feature space. This knowledge-guided design enhances reconstruction fidelity, stabilizes training under limited supervision, and yields interpretable latent representations grounded in physical principles. The experimental findings indicate that the proposed model substantially enhances reconstruction quality and improves downstream task performance, highlighting the promise of embedding physics-informed inductive biases within transformer-based self-supervised learning.

</details>


### [325] [Optimized Architectures for Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.12448)
*James Bagrow,Josh Bongard*

Main category: cs.LG

TL;DR: 通过过参数化架构结合稀疏化学习紧凑、可解释的KANs，不牺牲准确性，实现端到端优化


<details>
  <summary>Details</summary>
Motivation: 传统KANs架构增强方法增加了复杂性，损害了可解释性这一核心优势。需要一种既能保持准确性又能获得紧凑、可解释模型的方法。

Method: 采用过参数化架构结合可微稀疏化技术，将架构搜索转化为端到端优化问题，学习紧凑的KANs模型。

Result: 在函数逼近基准测试、动力系统预测和实际预测任务中，实现了竞争性或更优的准确性，同时发现了显著更小的模型。过参数化与稀疏化具有协同效应。

Conclusion: 该方法为获得既更具表达能力又更可解释的模型提供了原则性路径，解决了科学机器学习中的一个关键矛盾。

Abstract: Efforts to improve Kolmogorov-Arnold networks (KANs) with architectural enhancements have been stymied by the complexity those enhancements bring, undermining the interpretability that makes KANs attractive in the first place. Here we study overprovisioned architectures combined with sparsification to learn compact, interpretable KANs without sacrificing accuracy. Crucially, we focus on differentiable sparsification, turning architecture search into an end-to-end optimization problem. Across function approximation benchmarks, dynamical systems forecasting, and real-world prediction tasks, we demonstrate competitive or superior accuracy while discovering substantially smaller models. Overprovisioning and sparsification are synergistic, with the combination outperforming either alone. The result is a principled path toward models that are both more expressive and more interpretable, addressing a key tension in scientific machine learning.

</details>


### [326] [Cross-Modal Representational Knowledge Distillation for Enhanced Spike-Informed LFP Modeling](https://arxiv.org/abs/2512.12461)
*Eray Erturk,Saba Hashemi,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出跨模态知识蒸馏框架，将预训练多会话尖峰Transformer模型的高保真表征知识迁移到LFP Transformer模型，提升LFP模型性能


<details>
  <summary>Details</summary>
Motivation: 局部场电位（LFP）在神经实验中具有重要优势（长期稳定性、鲁棒性、低功耗），但现有建模框架主要关注尖峰活动，LFP信号由于聚合特性导致建模挑战和预测性能较低

Method: 采用跨模态知识蒸馏框架：1）使用会话特定神经标记化策略，通过掩码自编码目标训练多会话教师尖峰模型；2）将学生LFP模型的潜在表征与教师尖峰模型对齐

Result: 蒸馏后的LFP模型在完全无监督和监督设置下均优于单会话和多会话LFP基线，能够泛化到其他会话而无需额外蒸馏，同时保持优异性能

Conclusion: 跨模态知识蒸馏是利用高性能尖峰模型开发更准确LFP模型的强大且可扩展方法

Abstract: Local field potentials (LFPs) can be routinely recorded alongside spiking activity in intracortical neural experiments, measure a larger complementary spatiotemporal scale of brain activity for scientific inquiry, and can offer practical advantages over spikes, including greater long-term stability, robustness to electrode degradation, and lower power requirements. Despite these advantages, recent neural modeling frameworks have largely focused on spiking activity since LFP signals pose inherent modeling challenges due to their aggregate, population-level nature, often leading to lower predictive power for downstream task variables such as motor behavior. To address this challenge, we introduce a cross-modal knowledge distillation framework that transfers high-fidelity representational knowledge from pretrained multi-session spike transformer models to LFP transformer models. Specifically, we first train a teacher spike model across multiple recording sessions using a masked autoencoding objective with a session-specific neural tokenization strategy. We then align the latent representations of the student LFP model to those of the teacher spike model. Our results show that the Distilled LFP models consistently outperform single- and multi-session LFP baselines in both fully unsupervised and supervised settings, and can generalize to other sessions without additional distillation while maintaining superior performance. These findings demonstrate that cross-modal knowledge distillation is a powerful and scalable approach for leveraging high-performing spike models to develop more accurate LFP models.

</details>


### [327] [Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference](https://arxiv.org/abs/2512.12462)
*Eray Erturk,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出一个多尺度学习框架，用于实时解码来自不同时间尺度、概率分布和可能缺失样本的多模态神经时间序列数据。


<details>
  <summary>Details</summary>
Motivation: 现有非线性多模态神经活动模型无法处理不同时间尺度或缺失样本问题，且部分模型不支持实时解码。需要开发能够实时递归解码、非线性聚合多模态信息的框架。

Method: 框架包含三个组件：1) 多尺度编码器，通过学习模态内动态处理不同时间尺度和缺失样本；2) 多尺度动态主干，提取多模态时间动态并支持实时递归解码；3) 模态特定解码器，处理不同概率分布。

Result: 在模拟和三个不同的多尺度脑数据集上，该模型能够聚合不同时间尺度、分布和缺失样本的多模态信息，改善实时目标解码性能，优于各种线性和非线性多模态基准方法。

Conclusion: 提出的学习框架有效解决了多模态神经数据解码中的时间尺度差异、分布不同和样本缺失问题，实现了实时递归解码，在多尺度脑数据应用中表现出优越性能。

Abstract: Real-time decoding of target variables from multiple simultaneously recorded neural time-series modalities, such as discrete spiking activity and continuous field potentials, is important across various neuroscience applications. However, a major challenge for doing so is that different neural modalities can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps. Existing nonlinear models of multimodal neural activity do not address different timescales or missing samples across modalities. Further, some of these models do not allow for real-time decoding. Here, we develop a learning framework that can enable real-time recursive decoding while nonlinearly aggregating information across multiple modalities with different timescales and distributions and with missing samples. This framework consists of 1) a multiscale encoder that nonlinearly aggregates information after learning within-modality dynamics to handle different timescales and missing samples in real time, 2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time recursive decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. In both simulations and three distinct multiscale brain datasets, we show that our model can aggregate information across modalities with different timescales and distributions and missing samples to improve real-time target decoding. Further, our method outperforms various linear and nonlinear multimodal benchmarks in doing so.

</details>


### [328] [Exploring the Design Space of Transition Matching](https://arxiv.org/abs/2512.12465)
*Uriel Singer,Yaron Lipman*

Main category: cs.LG

TL;DR: 本文对Transition Matching (TM)中的head模块进行了大规模系统研究，通过训练56个17亿参数的文生图模型，评估了head架构、训练策略和采样方法对生成质量、训练和推理效率的影响。


<details>
  <summary>Details</summary>
Motivation: Transition Matching (TM)是一种新兴的生成建模范式，它比扩散模型和流匹配模型更具表达力。然而，TM框架中head模块的设计、训练和采样策略尚未得到系统研究，需要探索如何优化这一关键组件以获得最佳性能。

Method: 采用时间连续双向TM变体，通过大规模实验训练56个不同的17亿参数文生图模型（共549次评估），系统研究head模块架构（MLP vs Transformer）、训练策略（时间加权等）和采样方法（高频vs低频采样器）的影响。

Result: 研究发现：1) MLP head配合特定时间加权训练和高频采样器在所有指标上表现最佳，达到SOTA水平；2) Transformer head配合序列缩放和低频采样器在图像美学方面表现出色；3) 实验揭示了哪些设计选择能带来最大质量提升，哪些选择改进空间有限。

Conclusion: 本文为TM框架中head模块的设计提供了系统指导，明确了最优配置方案，同时指出了未来改进的潜在方向和有限收益的设计选择，对TM模型的实践应用具有重要参考价值。

Abstract: Transition Matching (TM) is an emerging paradigm for generative modeling that generalizes diffusion and flow-matching models as well as continuous-state autoregressive models. TM, similar to previous paradigms, gradually transforms noise samples to data samples, however it uses a second ``internal'' generative model to implement the transition steps, making the transitions more expressive compared to diffusion and flow models. To make this paradigm tractable, TM employs a large backbone network and a smaller "head" module to efficiently execute the generative transition step. In this work, we present a large-scale, systematic investigation into the design, training and sampling of the head in TM frameworks, focusing on its time-continuous bidirectional variant. Through comprehensive ablations and experimentation involving training 56 different 1.7B text-to-image models (resulting in 549 unique evaluations) we evaluate the affect of the head module architecture and modeling during training as-well as a useful family of stochastic TM samplers. We analyze the impact on generation quality, training, and inference efficiency. We find that TM with an MLP head, trained with a particular time weighting and sampled with high frequency sampler provides best ranking across all metrics reaching state-of-the-art among all tested baselines, while Transformer head with sequence scaling and low frequency sampling is a runner up excelling at image aesthetics. Lastly, we believe the experiments presented highlight the design aspects that are likely to provide most quality and efficiency gains, while at the same time indicate what design choices are not likely to provide further gains.

</details>


### [329] [Sparse Concept Anchoring for Interpretable and Controllable Neural Representations](https://arxiv.org/abs/2512.12469)
*Sandy Fraser,Patryk Wielopolski*

Main category: cs.LG

TL;DR: 提出稀疏概念锚定方法，通过最小监督（每个锚定概念<0.1%标签）在潜在空间中定位目标概念子集，同时让其他概念自组织，实现可解释、可操控的行为干预


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持其他特征不变的情况下，对学习表示中的特定概念进行精确控制和干预。需要一种既能定位目标概念，又能保持表示整体完整性的方法

Method: 结合激活归一化、分离正则化器以及锚定/子空间正则化器，将稀有标记样本吸引到预定义方向或轴对齐子空间，实现稀疏概念锚定

Result: 在结构化自编码器上实验显示：能选择性衰减目标概念而对正交特征影响极小；通过权重消融可完全消除概念，重建误差接近理论下界

Conclusion: 稀疏概念锚定为学习表示中的可解释、可操控行为提供了实用途径，支持可逆行为引导和永久概念移除两种干预方式

Abstract: We introduce Sparse Concept Anchoring, a method that biases latent space to position a targeted subset of concepts while allowing others to self-organize, using only minimal supervision (labels for <0.1% of examples per anchored concept). Training combines activation normalization, a separation regularizer, and anchor or subspace regularizers that attract rare labeled examples to predefined directions or axis-aligned subspaces. The anchored geometry enables two practical interventions: reversible behavioral steering that projects out a concept's latent component at inference, and permanent removal via targeted weight ablation of anchored dimensions. Experiments on structured autoencoders show selective attenuation of targeted concepts with negligible impact on orthogonal features, and complete elimination with reconstruction error approaching theoretical bounds. Sparse Concept Anchoring therefore provides a practical pathway to interpretable, steerable behavior in learned representations.

</details>


### [330] [GoMS: Graph of Molecule Substructure Network for Molecule Property Prediction](https://arxiv.org/abs/2512.12489)
*Shuhui Qu,Cheolwoo Park*

Main category: cs.LG

TL;DR: GoMS是一种新颖的图神经网络架构，通过构建分子子结构图来显式建模子结构间的相互作用和空间排列，相比ESAN的袋式表示能更好地捕捉分子拓扑信息，尤其在大分子预测上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于子图的分子表示方法（如ESAN）将分子视为独立子结构的集合，忽略了子结构之间的关键关系和空间排列，这限制了模型对复杂分子性质预测的能力。

Method: 提出Graph of Molecule Substructures (GoMS)架构，将分子表示为子结构图：节点代表子图，边捕捉子结构间的结构关系，保留子结构如何连接和重叠的关键拓扑信息。

Result: 在公开分子数据集上的实验表明，GoMS优于ESAN和其他基线方法，特别是对于含有超过100个原子的大分子改进显著；随着分子尺寸增大，性能差距扩大；理论分析证明GoMS能区分具有相同子图组成但不同空间排列的分子。

Conclusion: GoMS通过捕捉袋式方法丢失的子结构关系，代表了可扩展和可解释的分子性质预测的重要进展，特别适用于涉及复杂分子的材料科学应用，其中性质源于多个功能单元之间的相互作用。

Abstract: While graph neural networks have shown remarkable success in molecular property prediction, current approaches like the Equivariant Subgraph Aggregation Networks (ESAN) treat molecules as bags of independent substructures, overlooking crucial relationships between these components. We present Graph of Molecule Substructures (GoMS), a novel architecture that explicitly models the interactions and spatial arrangements between molecular substructures. Unlike ESAN's bag-based representation, GoMS constructs a graph where nodes represent subgraphs and edges capture their structural relationships, preserving critical topological information about how substructures are connected and overlap within the molecule. Through extensive experiments on public molecular datasets, we demonstrate that GoMS outperforms ESAN and other baseline methods, with particularly improvements for large molecules containing more than 100 atoms. The performance gap widens as molecular size increases, demonstrating GoMS's effectiveness for modeling industrial-scale molecules. Our theoretical analysis demonstrates that GoMS can distinguish molecules with identical subgraph compositions but different spatial arrangements. Our approach shows particular promise for materials science applications involving complex molecules where properties emerge from the interplay between multiple functional units. By capturing substructure relationships that are lost in bag-based approaches, GoMS represents a significant advance toward scalable and interpretable molecular property prediction for real-world applications.

</details>


### [331] [AI-Driven Early Warning Systems for Student Success: Discovering Static Feature Dominance in Temporal Prediction Models](https://arxiv.org/abs/2512.12493)
*Vaarunay Kaushal,Rajib Mall*

Main category: cs.LG

TL;DR: 该研究比较了决策树和LSTM模型在不同时间点（2-20周）预测在线学习风险学生的表现，发现不同干预阶段需要不同的性能指标：早期需要高召回率，中期需要平衡的精确率-召回率，后期需要高精确率。


<details>
  <summary>Details</summary>
Motivation: 早期识别在线学习环境中的风险学生对于有效干预至关重要，需要了解不同时间点的预测模型表现差异，以优化干预策略和资源分配。

Method: 将时间预测分析扩展到第20周（课程时长的50%），在六个时间快照上比较决策树和长短期记忆（LSTM）模型，分析不同阶段的性能指标需求。

Result: 静态人口统计特征占预测重要性的68%，可实现无评估的早期预测。LSTM在第2周达到97%召回率，适合早期干预；决策树在中期提供稳定的平衡性能（78%准确率）。到第20周，两种模型召回率相似（68%），但LSTM精确率更高（90% vs 86%）。

Conclusion: 模型选择应取决于干预时机，早期信号（2-4周）结合人口统计和入学前信息足以进行可靠的初始预测，不同干预阶段需要不同的性能指标侧重。

Abstract: Early identification of at-risk students is critical for effective intervention in online learning environments. This study extends temporal prediction analysis to Week 20 (50% of course duration), comparing Decision Tree and Long Short- Term Memory (LSTM) models across six temporal snapshots. Our analysis reveals that different performance metrics matter at different intervention stages: high recall is critical for early intervention (Weeks 2-4), while balanced precision-recall is important for mid-course resource allocation (Weeks 8-16), and high precision becomes paramount in later stages (Week 20). We demonstrate that static demographic features dominate predictions (68% importance), enabling assessment-free early prediction. The LSTM model achieves 97% recall at Week 2, making it ideal for early intervention, while Decision Tree provides stable balanced performance (78% accuracy) during mid-course. By Week 20, both models converge to similar recall (68%), but LSTM achieves higher precision (90% vs 86%). Our findings also suggest that model selection should depend on intervention timing, and that early signals (Weeks 2-4) are sufficient for reliable initial prediction using primarily demographic and pre-enrollment information.

</details>


### [332] [Policy Optimization for Dynamic Heart Transplant Allocation](https://arxiv.org/abs/2512.12497)
*Ioannis Anagnostides,Zachary W. Sollie,Arman Kilic,Tuomas Sandholm*

Main category: cs.LG

TL;DR: 本文开发了一个心脏移植分配政策模拟器，发现当前政策远不如最大化移植年数的近视政策，并提出使用潜力值衡量患者未来效用的改进政策，批量分配可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 心脏移植是晚期心衰患者的可行选择，但供体严重短缺。2018年修订的现行分配政策未能充分考虑移植前和移植后死亡率，需要改进。

Method: 使用UNOS历史数据开发新模拟器，评估不同政策性能。提出近视政策（最大化移植年数），引入潜力值衡量患者未来效用，开发考虑动态分配过程的改进政策，并探索批量分配策略。

Result: 现状政策显著劣于近视政策；考虑潜力值的改进政策表现更好；批量分配少量供体可进一步提升性能；模拟器能评估地理邻近性和移植中心拒绝倾向等关键因素。

Conclusion: 通过开发的心脏移植分配模拟器，证明了现行政策存在改进空间，提出的潜力值方法和批量分配策略能显著提升分配效率，为政策优化提供重要工具。

Abstract: Heart transplantation is a viable path for patients suffering from advanced heart failure, but this lifesaving option is severely limited due to donor shortage. Although the current allocation policy was recently revised in 2018, a major concern is that it does not adequately take into account pretransplant and post-transplant mortality. In this paper, we take an important step toward addressing these deficiencies.
  To begin with, we use historical data from UNOS to develop a new simulator that enables us to evaluate and compare the performance of different policies. We then leverage our simulator to demonstrate that the status quo policy is considerably inferior to the myopic policy that matches incoming donors to the patient who maximizes the number of years gained by the transplant. Moreover, we develop improved policies that account for the dynamic nature of the allocation process through the use of potentials -- a measure of a patient's utility in future allocations that we introduce. We also show that batching together even a handful of donors -- which is a viable option for a certain type of donors -- further enhances performance. Our simulator also allows us to evaluate the effect of critical, and often unexplored, factors in the allocation, such as geographic proximity and the tendency to reject offers by the transplant centers.

</details>


### [333] [Noise-robust Contrastive Learning for Critical Transition Detection in Dynamical Systems](https://arxiv.org/abs/2512.12523)
*Wenqi Fang,Ye Li*

Main category: cs.LG

TL;DR: 提出基于奇异值分解和半正交约束训练的神经网络架构，用于提升对比学习在检测临界转变中的性能，实现更轻量化和更强的噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 复杂噪声时间序列数据中的临界转变检测是一个基本挑战。虽然基于深度神经网络的对比学习方法有潜力，但通常存在过参数化问题，对无关噪声敏感，导致临界点识别不准确。

Method: 提出一种基于奇异值分解技术构建的神经网络架构，配合严格的半正交约束训练算法，以增强传统对比学习的性能。

Result: 大量实验表明，该方法在识别临界转变方面与传统对比学习技术性能相当，但更轻量化且噪声鲁棒性显著更强。

Conclusion: 通过奇异值分解和半正交约束训练构建的神经网络架构，有效解决了传统对比学习在临界转变检测中的过参数化和噪声敏感问题，实现了更高效可靠的检测。

Abstract: Detecting critical transitions in complex, noisy time-series data is a fundamental challenge across science and engineering. Such transitions may be anticipated by the emergence of a low-dimensional order parameter, whose signature is often masked by high-amplitude stochastic variability. Standard contrastive learning approaches based on deep neural networks, while promising for detecting critical transitions, are often overparameterized and sensitive to irrelevant noise, leading to inaccurate identification of critical points. To address these limitations, we propose a neural network architecture, constructed using singular value decomposition technique, together with a strictly semi-orthogonality-constrained training algorithm, to enhance the performance of traditional contrastive learning. Extensive experiments demonstrate that the proposed method matches the performance of traditional contrastive learning techniques in identifying critical transitions, yet is considerably more lightweight and markedly more resistant to noise.

</details>


### [334] [Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling](https://arxiv.org/abs/2512.12526)
*Agustín M. de los Riscos,Julio E. Sandubete,Diego Carmona-Fernández,León Beleña*

Main category: cs.LG

TL;DR: 该研究将经验模态分解(EMD)应用于MSCI世界指数，并将得到的本征模态函数(IMFs)转换为图表示，以便使用图神经网络(GNNs)进行建模。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地对金融时间序列进行预测建模，需要将时间序列数据转换为适合图神经网络处理的结构化表示，同时考虑不同时间尺度上的结构特性。

Method: 使用CEEMDAN方法从MSCI世界指数中提取9个IMFs，涵盖高频波动到长期趋势。采用四种时间序列到图的转换方法：自然可见性图、水平可见性图、递归图和转移图。对生成的图进行拓扑分析。

Result: 拓扑分析显示明显的尺度依赖结构：高频IMFs产生密集、高度连接的小世界图，而低频IMFs产生更稀疏、具有更长特征路径长度的网络。可见性方法对振幅变化更敏感且通常产生更高的聚类系数，递归图更好地保留时间依赖性。

Conclusion: 研究结果为设计针对分解组件结构特性定制的GNN架构提供了指导，支持更有效的金融时间序列预测建模。

Abstract: This study applies Empirical Mode Decomposition (EMD) to the MSCI World index and converts the resulting intrinsic mode functions (IMFs) into graph representations to enable modeling with graph neural networks (GNNs). Using CEEMDAN, we extract nine IMFs spanning high-frequency fluctuations to long-term trends. Each IMF is transformed into a graph using four time-series-to-graph methods: natural visibility, horizontal visibility, recurrence, and transition graphs. Topological analysis shows clear scale-dependent structure: high-frequency IMFs yield dense, highly connected small-world graphs, whereas low-frequency IMFs produce sparser networks with longer characteristic path lengths. Visibility-based methods are more sensitive to amplitude variability and typically generate higher clustering, while recurrence graphs better preserve temporal dependencies. These results provide guidance for designing GNN architectures tailored to the structural properties of decomposed components, supporting more effective predictive modeling of financial time series.

</details>


### [335] [Effective Fine-Tuning with Eigenvector Centrality Based Pruning](https://arxiv.org/abs/2512.12543)
*Shaif Chowdhury,Soham Biren Katlariwala,Devleena Kashyap*

Main category: cs.LG

TL;DR: 提出基于图论的神经网络剪枝方法，通过特征向量中心性识别重要神经元，剪枝后再微调，在多个数据集上实现更高准确率和更低复杂度


<details>
  <summary>Details</summary>
Motivation: 受社交媒体中少数关键用户能驱动全网变化现象的启发，类比神经网络微调过程，认为传统微调方法效率不高，需要先剪枝保留重要神经元再进行微调

Method: 基于图论的剪枝方法：将神经元表示为节点，边编码神经元相似性，使用特征向量中心性计算重要性分数，剪枝保留最中心神经元，然后进行微调

Result: 在VGGNet、EfficientNet和ResNet模型上，使用TF Flowers、Caltech 101和Oxford Flowers 102数据集评估，方法在保持更高分类准确率的同时显著降低模型复杂度。在Oxford Flowers 102数据集上达到48%准确率，而基线VGGNet只有30%

Conclusion: 提出的基于图论的剪枝方法能有效识别神经网络中的重要神经元，剪枝后微调比传统微调方法性能更好，实现了准确率提升和模型复杂度降低的双重优势

Abstract: In social media networks a small number of highly influential users can drive large scale changes in discourse across multiple communities. Small shifts in the behavior of these users are often sufficient to propagate widely throughout the network. A similar phenomenon occurs during neural network fine tuning. Conventional fine tuning of convolutional neural networks typically adds a new linear classification layer on top of a large pre trained model. Instead we argue that improved adaptation can be achieved by first pruning the network to retain only the most important neurons and then performing fine tuning.
  We propose a graph theory based method for pruning neural networks that is designed to improve fine tuning performance. In this method each neuron is represented as a node and edges encode similarity between neurons. Neurons are pruned based on importance scores computed using eigenvector centrality. The resulting pruned network is then fine tuned using only the most central neurons. We evaluate the proposed method on VGGNet EfficientNet and ResNet models using the TF Flowers Caltech one zero one and Oxford Flowers one zero two datasets. The proposed approach achieves higher classification accuracy while significantly reducing model complexity. On the Oxford Flowers one zero two dataset the method achieves forty eight percent classification accuracy compared to thirty percent accuracy obtained by the baseline VGGNet model.

</details>


### [336] [Skillful Subseasonal-to-Seasonal Forecasting of Extreme Events with a Multi-Sphere Coupled Probabilistic Model](https://arxiv.org/abs/2512.12545)
*Bin Mu,Yuxuan Chen,Shijin Yuan,Bo Qin,Hao Guo*

Main category: cs.LG

TL;DR: TianXing-S2S是一个多圈层耦合的概率模型，用于全球次季节到季节(S2S)每日集合预报，通过扩散模型和最优传输耦合模块，在45天预报中优于ECMWF和FuXi-S2S系统。


<details>
  <summary>Details</summary>
Motivation: 在气候变化加速背景下，准确的次季节到季节(S2S)极端事件预测对于资源规划和灾害缓解至关重要，但由于复杂的多圈层相互作用和内在的大气不确定性，此类预测仍然具有挑战性。

Method: 首先将多样化的多圈层预测因子编码到紧凑的潜在空间，然后使用扩散模型生成每日集合预报。在去噪器中加入基于最优传输(OT)的新型耦合模块，优化大气与多圈层边界条件之间的相互作用。

Result: 在1.5度分辨率下，TianXing-S2S在45天每日平均集合预报中，在关键大气变量上优于欧洲中期天气预报中心(ECMWF) S2S系统和FuXi-S2S。模型能够对热浪和异常降水等极端事件进行有技巧的次季节预测，并识别土壤湿度作为关键的前兆信号。此外，模型能够生成长达180天的稳定滚动预报。

Conclusion: TianXing-S2S建立了一个稳健的S2S研究框架，为变暖世界中的次季节到季节预测提供了有效的解决方案，特别是在极端事件预测方面表现出色。

Abstract: Accurate subseasonal-to-seasonal (S2S) prediction of extreme events is critical for resource planning and disaster mitigation under accelerating climate change. However, such predictions remain challenging due to complex multi-sphere interactions and intrinsic atmospheric uncertainty. Here we present TianXing-S2S, a multi-sphere coupled probabilistic model for global S2S daily ensemble forecast. TianXing-S2S first encodes diverse multi-sphere predictors into a compact latent space, then employs a diffusion model to generate daily ensemble forecasts. A novel coupling module based on optimal transport (OT) is incorporated in the denoiser to optimize the interactions between atmospheric and multi-sphere boundary conditions. Across key atmospheric variables, TianXing-S2S outperforms both the European Centre for Medium-Range Weather Forecasts (ECMWF) S2S system and FuXi-S2S in 45-day daily-mean ensemble forecasts at 1.5 resolution. Our model achieves skillful subseasonal prediction of extreme events including heat waves and anomalous precipitation, identifying soil moisture as a critical precursor signal. Furthermore, we demonstrate that TianXing-S2S can generate stable rollout forecasts up to 180 days, establishing a robust framework for S2S research in a warming world.

</details>


### [337] [Optimal Mistake Bounds for Transductive Online Learning](https://arxiv.org/abs/2512.12567)
*Zachary Chase,Steve Hanneke,Shay Moran,Jonathan Shafer*

Main category: cs.LG

TL;DR: 该论文解决了在线学习中无标签数据能力的30年开放问题，证明转导在线学习与标准在线学习之间存在平方差距，转导错误下界为Ω(√d)，上界为O(√d)


<details>
  <summary>Details</summary>
Motivation: 解决30年来关于在线学习中无标签数据能力的开放问题，量化转导在线学习与标准在线学习之间的差距。在标准在线学习中，最优错误界限由概念类的Littlestone维度d表征，但转导设置下的界限一直未明确

Method: 通过理论分析证明转导在线学习的下界为Ω(√d)，并构造具体概念类证明上界为O(√d)，从而建立紧界。改进了之前Ben-David等人和Hanneke等人的下界结果

Result: 证明了转导在线学习的错误界限为Θ(√d)，与标准在线学习的Θ(d)形成平方差距。这比之前的最佳下界Ω(log d)有指数级改进，也比之前的最佳上界(2/3)d有显著改进

Conclusion: 转导在线学习与标准在线学习存在平方差距，突显了提前访问无标签实例序列的益处。这与PAC设置形成对比，在PAC中两者样本复杂度相似

Abstract: We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. In the standard setting, the optimal mistake bound is characterized by the Littlestone dimension $d$ of the concept class $H$ (Littlestone 1987). We prove that in the transductive setting, the mistake bound is at least $Ω(\sqrt{d})$. This constitutes an exponential improvement over previous lower bounds of $Ω(\log\log d)$, $Ω(\sqrt{\log d})$, and $Ω(\log d)$, due respectively to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that this lower bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\sqrt{d})$. Our upper bound also improves upon the best known upper bound of $(2/3)d$ from Ben-David, Kushilevitz, and Mansour (1997). These results establish a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advance access to the unlabeled instance sequence. This contrasts with the PAC setting, where transductive and standard learning exhibit similar sample complexities.

</details>


### [338] [On the Accuracy of Newton Step and Influence Function Data Attributions](https://arxiv.org/abs/2512.12572)
*Ittai Rubinstein,Samuel B. Hopkins*

Main category: cs.LG

TL;DR: 本文对数据归因方法（NS和IF）进行了新的理论分析，首次在不假设全局强凸性的情况下，为凸学习问题提供了渐近紧致的误差界限，并解释了NS方法通常比IF更准确的原因。


<details>
  <summary>Details</summary>
Motivation: 现有数据归因方法（如IF和NS）的理论分析存在两个主要限制：1）依赖全局强凸性假设，这在实践中往往不成立；2）误差界限在参数数量(d)和移除样本数(k)上缩放效果差。这导致无法回答"各方法的误差渐近缩放规律是什么？"和"哪种方法对特定数据集更准确？"等基本问题。

Method: 针对凸学习问题，作者提出了新的NS和IF数据归因方法的分析框架。该分析不依赖全局强凸性假设，并证明了对于表现良好的逻辑回归，所得界限在多项式对数因子内是渐近紧致的。

Result: 推导出了NS方法误差和NS与IF方法差异的渐近缩放规律：NS误差为Θ̃(kd/n²)，NS与IF差异为Θ̃((k+d)√(kd)/n²)。这首次从理论上解释了[KATL19]和[RH25a]观察到的NS通常比IF更准确的现象。

Conclusion: 本文为数据归因方法提供了更实用、更精确的理论分析框架，消除了对全局强凸性的依赖，给出了渐近紧致的误差界限，并首次从理论上解释了NS方法相对于IF的优越性，为实际应用中的方法选择提供了理论指导。

Abstract: Data attribution aims to explain model predictions by estimating how they would change if certain training points were removed, and is used in a wide range of applications, from interpretability and credit assignment to unlearning and privacy.
  Even in the relatively simple case of linear regressions, existing mathematical analyses of leading data attribution methods such as Influence Functions (IF) and single Newton Step (NS) remain limited in two key ways. First, they rely on global strong convexity assumptions which are often not satisfied in practice. Second, the resulting bounds scale very poorly with the number of parameters ($d$) and the number of samples removed ($k$). As a result, these analyses are not tight enough to answer fundamental questions such as "what is the asymptotic scaling of the errors of each method?" or "which of these methods is more accurate for a given dataset?"
  In this paper, we introduce a new analysis of the NS and IF data attribution methods for convex learning problems. To the best of our knowledge, this is the first analysis of these questions that does not assume global strong convexity and also the first explanation of [KATL19] and [RH25a]'s observation that NS data attribution is often more accurate than IF. We prove that for sufficiently well-behaved logistic regression, our bounds are asymptotically tight up to poly-logarithmic factors, yielding scaling laws for the errors in the average-case sample removals.
  \[ \mathbb{E}_{T \subseteq [n],\, |T| = k} \bigl[ \|\hatθ_T - \hatθ_T^{\mathrm{NS}}\|_2 \bigr] = \widetildeΘ\!\left(\frac{k d}{n^2}\right), \qquad \mathbb{E}_{T \subseteq [n],\, |T| = k} \bigl[ \|\hatθ_T^{\mathrm{NS}} - \hatθ_T^{\mathrm{IF}}\|_2 \bigr] = \widetildeΘ\!\left( \frac{(k + d)\sqrt{k d}}{n^2} \right). \]

</details>


### [339] [Differentiable Energy-Based Regularization in GANs: A Simulator-Based Exploration of VQE-Inspired Auxiliary Losses](https://arxiv.org/abs/2512.12581)
*David Strnadel*

Main category: cs.LG

TL;DR: 探索性研究：将参数化量子电路的可微分能量项作为GAN的正则化信号，在MNIST上实验显示分类准确率提升但样本质量指标波动大，不声称量子优势。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算中的可微分能量项是否可以作为生成对抗网络的辅助正则化信号，研究量子计算与深度学习结合的新方法。

Method: 在ACGAN生成器目标中增加VQE启发的能量项，使用Qiskit的EstimatorQNN和TorchConnector计算类特定Ising哈密顿量，在4量子位的无噪声模拟器上进行实验。

Result: 在MNIST上，QACGAN在5个epoch内达到99-100%的分类准确率（ACGAN为87.8%），但FID指标波动大（变异系数约25%），最终稳定在FID 23-24，与基线相当。计算开销比经典ACGAN慢约200倍。

Conclusion: 证明了VQE风格的能量计算可以通过可微分路径集成到GAN训练中，但该方法是否优于经典正则化器仍需系统消融研究，不声称量子优势或可扩展性。

Abstract: This paper presents an exploratory, simulator-based proof of concept investigating whether differentiable energy terms derived from parameterized quantum circuits can serve as auxiliary regularization signals in Generative Adversarial Networks (GANs). We augment the Auxiliary Classifier GAN (ACGAN) generator objective with a Variational Quantum Eigensolver (VQE)-inspired energy term computed from class-specific Ising Hamiltonians using Qiskit's EstimatorQNN and TorchConnector.
  Important limitations: All experiments run on a noiseless statevector simulator with only 4 qubits, use a deliberately simple Hamiltonian parameterization, and lack ablation studies comparing against equivalent classical biases. The computational overhead (approximately 200x slower than classical ACGAN) reflects simulator artifacts rather than inherent quantum costs.
  On MNIST, we observe that the energy-regularized model (termed QACGAN) achieves high classification accuracy (99 to 100 percent) within 5 epochs compared to 87.8 percent for ACGAN, suggesting the auxiliary term influences class conditioning. However, sample quality metrics (FID) show high variance across runs (coefficient of variation approximately 25 percent at epoch 5), with values ranging from 19.92 to 35.96. Extended runs stabilize around FID 23 to 24, comparable to the ACGAN baseline.
  We explicitly do not claim quantum advantage, improved stability in any general sense, or scalability beyond this toy setting. The contribution is methodological: demonstrating that VQE-style energy computations can be integrated into GAN training loops via differentiable pathways. Whether such auxiliary signals provide benefits beyond equivalent classical regularizers remains an open question requiring systematic ablation studies, which we leave for future work.

</details>


### [340] [Error-Free Linear Attention is a Free Lunch: Exact Solution from Continuous-Time Dynamics](https://arxiv.org/abs/2512.12602)
*Jingdi Lei,Di Zhang,Soujanya Poria*

Main category: cs.LG

TL;DR: EFLA是一种无误差线性注意力机制，通过连续时间动力学系统建模在线学习更新，提供精确闭式解，实现线性时间复杂度和完全并行化，在噪声环境中表现稳健。


<details>
  <summary>Details</summary>
Motivation: 解决传统softmax注意力在长上下文语言模型中的二次计算成本瓶颈，同时克服现有线性注意力和状态空间模型可能存在的数值不稳定和误差累积问题。

Method: 将在线学习更新建模为连续时间动力学系统，利用动力学矩阵的秩-1结构，推导出精确闭式解（相当于无限阶Runge-Kutta方法），实现无误差线性注意力机制。

Result: EFLA在语言建模困惑度和下游基准测试中优于DeltaNet，在噪声环境中表现更稳健，且不引入额外参数，实现了线性时间复杂度和完全并行化。

Conclusion: EFLA为构建高保真、可扩展的线性时间注意力模型提供了新的理论基础，解决了误差累积问题，同时保持了计算效率。

Abstract: Linear-time attention and State Space Models (SSMs) promise to solve the quadratic cost bottleneck in long-context language models employing softmax attention. We introduce Error-Free Linear Attention (EFLA), a numerically stable, fully parallelism and generalized formulation of the delta rule. Specifically, we formulate the online learning update as a continuous-time dynamical system and prove that its exact solution is not only attainable but also computable in linear time with full parallelism. By leveraging the rank-1 structure of the dynamics matrix, we directly derive the exact closed-form solution effectively corresponding to the infinite-order Runge-Kutta method. This attention mechanism is theoretically free from error accumulation, perfectly capturing the continuous dynamics while preserving the linear-time complexity. Through an extensive suite of experiments, we show that EFLA enables robust performance in noisy environments, achieving lower language modeling perplexity and superior downstream benchmark performance than DeltaNet without introducing additional parameters. Our work provides a new theoretical foundation for building high-fidelity, scalable linear-time attention models.

</details>


### [341] [Causal inference and model explainability tools for retail](https://arxiv.org/abs/2512.12605)
*Pranav Gupta,Nithin Surendran*

Main category: cs.LG

TL;DR: 论文提出一个结合模型可解释性和因果推断的框架，用于零售销售分析，通过双机器学习方法处理混杂变量，提高因果效应估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前零售业使用多种机器学习模型分析关键指标，但这些模型通常缺乏可解释性，且无法验证或发现因果关系，限制了深入业务洞察的能力。

Method: 回顾现有因果推断和可解释性文献，应用于真实零售数据集，使用SHAP值评估模型可解释性，采用双机器学习方法处理多个混杂变量。

Result: 研究发现固有可解释模型具有更低的SHAP值方差，通过双机器学习方法包含多个混杂变量能够获得正确的因果效应符号。

Conclusion: 论文提供了一个实用的方法论框架，将模型可解释性和因果推断结合应用于零售销售分析，有助于获得更准确和可解释的业务洞察。

Abstract: Most major retailers today have multiple divisions focused on various aspects, such as marketing, supply chain, online customer experience, store customer experience, employee productivity, and vendor fulfillment. They also regularly collect data corresponding to all these aspects as dashboards and weekly/monthly/quarterly reports. Although several machine learning and statistical techniques have been in place to analyze and predict key metrics, such models typically lack interpretability. Moreover, such techniques also do not allow the validation or discovery of causal links. In this paper, we aim to provide a recipe for applying model interpretability and causal inference for deriving sales insights. In this paper, we review the existing literature on causal inference and interpretability in the context of problems in e-commerce and retail, and apply them to a real-world dataset. We find that an inherently explainable model has a lower variance of SHAP values, and show that including multiple confounders through a double machine learning approach allows us to get the correct sign of causal effect.

</details>


### [342] [Spectral Sentinel: Scalable Byzantine-Robust Decentralized Federated Learning via Sketched Random Matrix Theory on Blockchain](https://arxiv.org/abs/2512.12617)
*Animesh Mishra*

Main category: cs.LG

TL;DR: 提出Spectral Sentinel框架，利用随机矩阵理论检测拜占庭攻击，在非IID数据下实现可扩展的拜占庭鲁棒联邦学习，支持高达15亿参数模型。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化联邦学习防御方法面临可扩展性困境：距离过滤会拒绝合法的非IID更新，几何中值方法计算成本过高（O(n²d)），多数认证防御仅适用于小模型（<1亿参数）。

Method: 利用随机矩阵理论特征：诚实非IID梯度的协方差特征值分布遵循Marchenko-Pastur定律，而拜占庭扰动会产生可检测的尾部异常。结合Frequent Directions草图技术和数据依赖的MP跟踪，实现O(k²)内存消耗（k≪d）。

Result: 在144种攻击-聚合器配置中验证，平均准确率达78.4%，显著优于基线方法的48-63%。理论证明在(σ,f)威胁模型下具有(ε,δ)-拜占庭弹性，收敛率O(σf/√T + f²/T)，并达到信息理论下界Ω(σf/√T)。

Conclusion: Spectral Sentinel解决了去中心化联邦学习在非IID数据下的拜占庭攻击防御难题，实现了可扩展的检测和聚合，支持大规模模型训练，并在理论和实验上均表现出优越性能。

Abstract: Decentralized federated learning (DFL) enables collaborative model training without centralized trust, but it remains vulnerable to Byzantine clients that poison gradients under heterogeneous (Non-IID) data. Existing defenses face a scalability trilemma: distance-based filtering (e.g., Krum) can reject legitimate Non-IID updates, geometric-median methods incur prohibitive $O(n^2 d)$ cost, and many certified defenses are evaluated only on models below 100M parameters. We propose Spectral Sentinel, a Byzantine detection and aggregation framework that leverages a random-matrix-theoretic signature: honest Non-IID gradients produce covariance eigenspectra whose bulk follows the Marchenko-Pastur law, while Byzantine perturbations induce detectable tail anomalies. Our algorithm combines Frequent Directions sketching with data-dependent MP tracking, enabling detection on models up to 1.5B parameters using $O(k^2)$ memory with $k \ll d$. Under a $(σ,f)$ threat model with coordinate-wise honest variance bounded by $σ^2$ and $f < 1/2$ adversaries, we prove $(ε,δ)$-Byzantine resilience with convergence rate $O(σf / \sqrt{T} + f^2 / T)$, and we provide a matching information-theoretic lower bound $Ω(σf / \sqrt{T})$, establishing minimax optimality. We implement the full system with blockchain integration on Polygon networks and validate it across 144 attack-aggregator configurations, achieving 78.4 percent average accuracy versus 48-63 percent for baseline methods.

</details>


### [343] [Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks](https://arxiv.org/abs/2512.12642)
*Filippo Maria Bianchi,Carlo Abate,Ivan Marisca*

Main category: cs.LG

TL;DR: Torch Geometric Pool (tgp) 是一个基于 PyTorch Geometric 的图神经网络层次池化库，提供统一的API和模块化设计，支持多种池化算子并包含预计算池化等加速功能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络需要有效的层次池化操作来捕获图结构的多尺度信息，但现有工具缺乏统一的API和系统比较，使得选择最优池化算子困难。

Method: 基于 PyTorch Geometric 构建，提供模块化设计和一致API，包含多种池化算子，支持预计算池化加速训练，并进行系统化基准测试。

Result: 基准测试展示了库的功能，并系统比较了不同下游任务中各种图池化方法的性能，结果表明最优池化算子的选择取决于具体任务和数据。

Conclusion: 需要像 tgp 这样的库来支持快速原型开发，因为不同任务和数据需要不同的最优池化算子，统一的库能帮助研究人员有效比较和选择。

Abstract: We introduce Torch Geometric Pool (tgp), a library for hierarchical pooling in Graph Neural Networks. Built upon Pytorch Geometric, Torch Geometric Pool (tgp) provides a wide variety of pooling operators, unified under a consistent API and a modular design. The library emphasizes usability and extensibility, and includes features like precomputed pooling, which significantly accelerate training for a class of operators. In this paper, we present tgp's structure and present an extensive benchmark. The latter showcases the library's features and systematically compares the performance of the implemented graph-pooling methods in different downstream tasks. The results, showing that the choice of the optimal pooling operator depends on tasks and data at hand, support the need for a library that enables fast prototyping.

</details>


### [344] [PerNodeDrop: A Method Balancing Specialized Subnets and Regularization in Deep Neural Networks](https://arxiv.org/abs/2512.12663)
*Gelesh G Omathil,Sreeja CS*

Main category: cs.LG

TL;DR: PerNodeDrop是一种轻量级随机正则化方法，通过应用每样本、每节点的扰动来打破现有技术的均匀噪声注入，从而在保留有用协同适应的同时进行正则化。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易过拟合，因为神经元倾向于以捕捉复杂特征交互的方式协同适应，但同时也强化了虚假和非泛化的模式。现有的噪声正则化方法（如Dropout和DropConnect）通常在整个层或批次样本上应用均匀噪声，这可能同时抑制有害和有益的协同适应。

Method: 提出PerNodeDrop方法，在样本级别应用每节点扰动，而不是在批次级别。该方法在训练期间注入特定于输入的变异性，通过期望损失分析形式化其扰动如何减弱过度协同适应同时保留预测性交互。

Result: 在视觉、文本和音频基准测试上的实证评估表明，相对于标准噪声正则化方法，PerNodeDrop提高了泛化性能，缩小了训练和验证性能之间的差距，并提高了在未见数据上的可靠性。

Conclusion: PerNodeDrop通过应用每样本、每节点的扰动，打破了现有正则化技术的均匀噪声注入模式，能够在保留有用协同适应的同时进行有效正则化，从而改善深度神经网络的泛化能力。

Abstract: Deep neural networks possess strong representational capacity yet remain vulnerable to overfitting, primarily because neurons tend to co-adapt in ways that, while capturing complex and fine-grained feature interactions, also reinforce spurious and non-generalizable patterns that inflate training performance but reduce reliability on unseen data. Noise-based regularizers such as Dropout and DropConnect address this issue by injecting stochastic perturbations during training, but the noise they apply is typically uniform across a layer or across a batch of samples, which can suppress both harmful and beneficial co-adaptation.
  This work introduces PerNodeDrop, a lightweight stochastic regularization method. It applies per-sample, per-node perturbations to break the uniformity of the noise injected by existing techniques, thereby allowing each node to experience input-specific variability. Hence, PerNodeDrop preserves useful co-adaptation while applying regularization. This narrows the gap between training and validation performance and improves reliability on unseen data, as evident from the experiments.
  Although superficially similar to DropConnect, PerNodeDrop operates at the sample level. It drops weights at the sample level, not the batch level. An expected-loss analysis formalizes how its perturbations attenuate excessive co-adaptation while retaining predictive interactions. Empirical evaluations on vision, text, and audio benchmarks indicate improved generalization relative to the standard noise-based regularizer.

</details>


### [345] [DynaGen: Unifying Temporal Knowledge Graph Reasoning with Dynamic Subgraphs and Generative Regularization](https://arxiv.org/abs/2512.12669)
*Jiawei Shen,Jia Zhu,Hanghui Guo,Weijie Shi,Guoqing Ma,Yidan Liang,Jingjiang Liu,Hao Chen,Shimin Di*

Main category: cs.LG

TL;DR: DynaGen是一个统一的时序知识图谱推理方法，通过动态构建实体中心子图和条件扩散过程，分别提升插值和外推任务的性能，在六个基准数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理方法面临两个关键挑战：插值任务中上下文建模有限，外推任务中存在认知泛化偏差。需要统一的方法同时解决这两个问题。

Method: DynaGen采用统一框架：对于插值任务，动态构建实体中心子图，使用协同双分支GNN编码器捕捉演化结构上下文；对于外推任务，应用条件扩散过程，让模型学习底层演化原理而非表面模式。

Result: 在六个基准数据集上的实验表明，DynaGen达到最先进性能。相比次优模型，平均MRR分数在插值任务上提升2.61分，在外推任务上提升1.45分。

Conclusion: DynaGen通过动态上下文建模和条件扩散过程，有效解决了时序知识图谱推理中插值和外推任务的关键挑战，实现了统一的SOTA方法。

Abstract: Temporal Knowledge Graph Reasoning (TKGR) aims to complete missing factual elements along the timeline. Depending on the temporal position of the query, the task is categorized into interpolation and extrapolation. Existing interpolation methods typically embed temporal information into individual facts to complete missing historical knowledge, while extrapolation techniques often leverage sequence models over graph snapshots to identify recurring patterns for future event prediction. These methods face two critical challenges: limited contextual modeling in interpolation and cognitive generalization bias in extrapolation. To address these, we propose a unified method for TKGR, dubbed DynaGen. For interpolation, DynaGen dynamically constructs entity-centric subgraphs and processes them with a synergistic dual-branch GNN encoder to capture evolving structural context. For extrapolation, it applies a conditional diffusion process, which forces the model to learn underlying evolutionary principles rather than just superficial patterns, enhancing its ability to predict unseen future events. Extensive experiments on six benchmark datasets show DynaGen achieves state-of-the-art performance. On average, compared to the second-best models, DynaGen improves the Mean Reciprocal Rank (MRR) score by 2.61 points for interpolation and 1.45 points for extrapolation.

</details>


### [346] [On Approaches to Building Surrogate ODE Models for Diffusion Bridges](https://arxiv.org/abs/2512.12671)
*Maria Khilchuk,Vladimir Latypov,Pavel Kleshchev,Alexander Hvatov*

Main category: cs.LG

TL;DR: 本文提出使用代理模型简化扩散和薛定谔桥模型的训练与采样，引入SINDy-FM和DSBM-NeuralODE两种算法，在保持性能的同时大幅提升效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和薛定谔桥模型在生成建模中表现优异，但面临计算成本高、训练复杂的问题。连续时间桥模型虽然采样更快，但过参数化的神经网络描述其最优动态，且底层随机微分方程难以高效积分。

Method: 提出使用代理模型近似这些动态的新范式。具体包括：1) SINDy-FM：利用稀疏回归从数据中识别可解释的符号微分方程；2) DSBM-NeuralODE：薛定谔桥的神经ODE重构，实现灵活的连续时间参数化。

Result: 在高斯传输任务和MNIST潜在翻译上的实验表明，这些代理模型在保持竞争力的同时，显著提升了效率和可解释性。特别是SINDy-FM将参数数量减少数个数量级，实现近乎瞬时的推理。

Conclusion: 该工作为实际部署开辟了一类新的、可处理且高性能的桥模型，通过代理模型实现了扩散和薛定谔桥模型的简化、加速和灵活化。

Abstract: Diffusion and Schrödinger Bridge models have established state-of-the-art performance in generative modeling but are often hampered by significant computational costs and complex training procedures. While continuous-time bridges promise faster sampling, overparameterized neural networks describe their optimal dynamics, and the underlying stochastic differential equations can be difficult to integrate efficiently. This work introduces a novel paradigm that uses surrogate models to create simpler, faster, and more flexible approximations of these dynamics. We propose two specific algorithms: SINDy Flow Matching (SINDy-FM), which leverages sparse regression to identify interpretable, symbolic differential equations from data, and a Neural-ODE reformulation of the Schrödinger Bridge (DSBM-NeuralODE) for flexible continuous-time parameterization. Our experiments on Gaussian transport tasks and MNIST latent translation demonstrate that these surrogates achieve competitive performance while offering dramatic improvements in efficiency and interpretability. The symbolic SINDy-FM models, in particular, reduce parameter counts by several orders of magnitude and enable near-instantaneous inference, paving the way for a new class of tractable and high-performing bridge models for practical deployment.

</details>


### [347] [Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity](https://arxiv.org/abs/2512.12688)
*Dongseok Kim,Hyoungsun Choi,Mohamed Jismy Aashik Rasool,Gisung Oh*

Main category: cs.LG

TL;DR: 论文提出将提示视为外部注入程序的Transformer理论框架，证明固定权重Transformer仅通过提示切换即可近似广泛行为类别。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要作为启发式方法，缺乏将提示作为理论对象进行形式化分析。需要建立理论框架来理解固定权重Transformer仅通过提示切换实现不同计算的能力。

Method: 将提示视为外部注入程序，构建简化的Transformer解释器。通过机制级分解：注意力执行从提示记忆的选择性路由，前馈网络执行基于检索片段的局部算术，深度堆叠将这些局部更新组合成多步计算。

Result: 证明了构造性存在性结果：单个固定骨干网络仅通过提示即可近似广泛的目标行为类别。建立了形式化框架来分析提示长度/精度约束下的权衡，研究基于提示切换的结构限制。

Conclusion: 该框架为形式化提示工程提供了统一的理论基础，区分了理论构造与预训练大语言模型的实证主张，为理解Transformer中提示作为程序的能力建立了理论框架。

Abstract: Prompts can switch a model's behavior even when the weights are fixed, yet this phenomenon is rarely treated as a clean theoretical object rather than a heuristic. We study the family of functions obtainable by holding a Transformer backbone fixed as an executor and varying only the prompt. Our core idea is to view the prompt as an externally injected program and to construct a simplified Transformer that interprets it to implement different computations. The construction exposes a mechanism-level decomposition: attention performs selective routing from prompt memory, the FFN performs local arithmetic conditioned on retrieved fragments, and depth-wise stacking composes these local updates into a multi-step computation. Under this viewpoint, we prove a constructive existential result showing that a single fixed backbone can approximate a broad class of target behaviors via prompts alone. The framework provides a unified starting point for formalizing trade-offs under prompt length/precision constraints and for studying structural limits of prompt-based switching, while remaining distinct from empirical claims about pretrained LLMs.

</details>


### [348] [Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning](https://arxiv.org/abs/2512.12690)
*Yongcan Yu,Lingxiao He,Shuo Lu,Lijun Sheng,Yinuo Xu,Yanbo Wang,Kuangpu Guo,Jianjie Cheng,Meng Wang,Qianlong Xie,Xingxing Wang,Dapeng Hu,Jian Liang*

Main category: cs.LG

TL;DR: 本文重新评估了监督微调(SFT)在视觉语言模型推理中的作用，挑战了当前"强化学习优于SFT"的主流观点，发现SFT在多种场景下具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型推理领域过度强调强化学习(RL)的作用，普遍认为SFT不仅无法提升推理能力，还可能对模型训练产生负面影响。本文旨在重新审视这种RL中心的观点。

Method: 通过系统化和受控的比较研究，在相同数据源下对比SFT和RL在VLM推理中的表现，考察模型容量、数据规模和数据分布等因素的影响。

Result: 研究发现：1) SFT对较弱模型更有效；2) SFT仅需2K数据就能达到RL使用20K数据的推理性能；3) SFT具有更强的跨模态泛化能力；4) RL存在欺骗性奖励问题，高奖励不一定对应高推理准确率。

Conclusion: SFT的作用被低估了，挑战了"RL优于SFT"的主流叙事。SFT和RL应作为互补组件，支持更平衡的后训练流程。

Abstract: Recent advances in vision-language models (VLMs) reasoning have been largely attributed to the rise of reinforcement Learning (RL), which has shifted the community's focus away from the supervised fine-tuning (SFT) paradigm. Many studies suggest that introducing the SFT stage not only fails to improve reasoning ability but may also negatively impact model training. In this study, we revisit this RL-centric belief through a systematic and controlled comparison of SFT and RL on VLM Reasoning. Using identical data sources, we find that the relative effectiveness of SFT and RL is conditional and strongly influenced by model capacity, data scale, and data distribution. Contrary to common assumptions, our findings show that SFT plays a crucial role across several scenarios: (1) Effectiveness for weaker models. SFT more reliably elicits reasoning capabilities in smaller or weaker VLMs. (2) Data efficiency. SFT with only 2K achieves comparable or better reasoning performance to RL with 20K. (3) Cross-modal transferability. SFT demonstrates stronger generalization across modalities. Moreover, we identify a pervasive issue of deceptive rewards, where higher rewards fail to correlate with better reasoning accuracy in RL. These results challenge the prevailing "RL over SFT" narrative. They highlight that the role of SFT may have been underestimated and support a more balanced post-training pipeline in which SFT and RL function as complementary components.

</details>


### [349] [Co-Exploration and Co-Exploitation via Shared Structure in Multi-Task Bandits](https://arxiv.org/abs/2512.12693)
*Sumantrak Mukherjee,Serafima Lebedeva,Valentin Margraf,Jonas Hanselle,Kanta Yamaoka,Viktor Bengs,Stefan Konigorski,Eyke Hüllermeier,Sebastian Josef Vollmer*

Main category: cs.LG

TL;DR: 提出贝叶斯框架用于上下文多任务多臂老虎机，利用潜在上下文变量捕捉任务间依赖关系，通过粒子近似实现灵活建模


<details>
  <summary>Details</summary>
Motivation: 在上下文多任务多臂老虎机中，上下文通常只能部分观测，且奖励分布之间存在由潜在上下文变量诱导的依赖关系。现有方法难以有效利用这些结构依赖进行探索。

Method: 提出贝叶斯框架，通过粒子近似对数密度高斯过程表示任务和奖励的联合分布，无需对潜在变量做先验假设。该方法整合所有任务观测学习全局联合分布，同时允许对新任务进行个性化推断。

Result: 实验表明，该方法在模型误设或复杂潜在异质性场景下，优于分层模型老虎机等基线方法。

Conclusion: 提出的贝叶斯框架能有效利用任务间结构依赖进行探索，在部分观测上下文和复杂依赖场景下表现优异，为多任务强化学习提供了新思路。

Abstract: We propose a novel Bayesian framework for efficient exploration in contextual multi-task multi-armed bandit settings, where the context is only observed partially and dependencies between reward distributions are induced by latent context variables. In order to exploit these structural dependencies, our approach integrates observations across all tasks and learns a global joint distribution, while still allowing personalised inference for new tasks. In this regard, we identify two key sources of epistemic uncertainty, namely structural uncertainty in the latent reward dependencies across arms and tasks, and user-specific uncertainty due to incomplete context and limited interaction history. To put our method into practice, we represent the joint distribution over tasks and rewards using a particle-based approximation of a log-density Gaussian process. This representation enables flexible, data-driven discovery of both inter-arm and inter-task dependencies without prior assumptions on the latent variables. Empirically, we demonstrate that our method outperforms baselines such as hierarchical model bandits, especially in settings with model misspecification or complex latent heterogeneity.

</details>


### [350] [Multi-Trajectory Physics-Informed Neural Networks for HJB Equations with Hard-Zero Terminal Inventory: Optimal Execution on Synthetic & SPY Data](https://arxiv.org/abs/2512.12708)
*Anthime Valin*

Main category: cs.LG

TL;DR: 提出MT-PINN方法解决带硬零终端库存约束的最优交易执行问题，通过轨迹损失和终端惩罚直接强制零库存，在理论和实证中表现良好


<details>
  <summary>Details</summary>
Motivation: 传统PINN方法在处理硬零终端库存约束时存在不足，容易产生不稳定控制，需要更有效的方法来严格满足终端库存为零的约束条件

Method: 提出多轨迹PINN（MT-PINN），添加基于滚动的轨迹损失，通过时间反向传播传播终端惩罚，直接强制零终端库存，并采用轻量级lambda课程学习稳定训练

Result: 在Gatheral-Schied单资产模型中，MT-PINN与闭式解高度一致，终端库存紧密围绕零分布；在SPY日内数据中，风险中性时匹配TWAP，高风险厌恶时获得更低暴露和竞争性成本

Conclusion: MT-PINN能有效处理硬零终端库存约束，在理论和实证交易执行问题中均表现优异，为约束强化学习在金融中的应用提供了有效解决方案

Abstract: We study optimal trade execution with a hard-zero terminal inventory constraint, modeled via Hamilton-Jacobi-Bellman (HJB) equations. Vanilla PINNs often under-enforce this constraint and produce unstable controls. We propose a Multi-Trajectory PINN (MT-PINN) that adds a rollout-based trajectory loss and propagates a terminal penalty on terminal inventory via backpropagation-through-time, directly enforcing zero terminal inventory. A lightweight lambda-curriculum is adopted to stabilize training as the state expands from a risk-neutral reduced HJB to a risk-averse HJB. On the Gatheral-Schied single-asset model, MT-PINN aligns closely with their derived closed-form solutions and concentrates terminal inventory tightly around zero while reducing errors along optimal paths. We apply MT-PINNs on SPY intraday data, matching TWAP when risk-neutral, and achieving lower exposure and competitive costs, especially in falling windows, for higher risk-aversion.

</details>


### [351] [Solving a Machine Learning Regression Problem Based on the Theory of Random Functions](https://arxiv.org/abs/2512.12731)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: 论文从随机函数理论出发，基于无差别原理推导出回归方法，证明具有平移、旋转、缩放对称性和高斯性的概率测度会自然导出广义多调和样条核函数


<details>
  <summary>Details</summary>
Motivation: 为机器学习回归问题提供理论基础，从第一性原理出发推导回归方法，避免经验性选择核函数和正则化方式

Method: 将回归问题视为多元逼近问题，采用随机函数理论框架，基于无差别原理的公设，推导具有自然对称性（平移、旋转、缩放）和高斯性的概率测度

Result: 证明从这些对称性公设可以解析地推导出整个解决方案，包括核函数形式、正则化类型和噪声参数化，得到的核函数与广义多调和样条一致

Conclusion: 为一大类平滑和插值方法提供了理论基础，证明了在缺乏先验信息的情况下这些方法的最优性

Abstract: This paper studies a machine learning regression problem as a multivariate approximation problem using the framework of the theory of random functions. An ab initio derivation of a regression method is proposed, starting from postulates of indifference. It is shown that if a probability measure on an infinite-dimensional function space possesses natural symmetries (invariance under translation, rotation, scaling, and Gaussianity), then the entire solution scheme, including the kernel form, the type of regularization, and the noise parameterization, follows analytically from these postulates. The resulting kernel coincides with a generalized polyharmonic spline; however, unlike existing approaches, it is not chosen empirically but arises as a consequence of the indifference principle. This result provides a theoretical foundation for a broad class of smoothing and interpolation methods, demonstrating their optimality in the absence of a priori information.

</details>


### [352] [SPARK: Igniting Communication-Efficient Decentralized Learning via Stage-wise Projected NTK and Accelerated Regularization](https://arxiv.org/abs/2512.12737)
*Li Xia*

Main category: cs.LG

TL;DR: SPARK：一种用于去中心化联邦学习的高效通信方法，通过随机投影压缩Jacobian矩阵、阶段式退火蒸馏和Nesterov动量加速，在减少98.7%通信量的同时保持收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习面临统计异构性和通信开销的挑战。现有NTK方法虽然收敛快，但传输完整Jacobian矩阵在带宽受限的边缘网络中不切实际。

Method: 1) 随机投影压缩Jacobian矩阵，保留收敛所需的光谱特性；2) 阶段式退火蒸馏，从纯NTK演化过渡到邻居正则化学习，抵消压缩噪声；3) Nesterov动量加速，通过蒸馏平滑实现稳定累积。

Result: SPARK相比NTK-DFL减少98.7%通信量，同时保持收敛速度并实现更高精度。加入动量后，达到目标性能的速度快3倍，在通信效率方面达到最先进水平。

Conclusion: SPARK为带宽受限的边缘环境提供了实用的去中心化学习解决方案，通过协同整合压缩、蒸馏和动量技术，实现了通信效率与性能的平衡。

Abstract: Decentralized federated learning (DFL) faces critical challenges from statistical heterogeneity and communication overhead. While NTK-based methods achieve faster convergence, transmitting full Jacobian matrices is impractical for bandwidth-constrained edge networks. We propose SPARK, synergistically integrating random projection-based Jacobian compression, stage-wise annealed distillation, and Nesterov momentum acceleration. Random projections compress Jacobians while preserving spectral properties essential for convergence. Stage-wise annealed distillation transitions from pure NTK evolution to neighbor-regularized learning, counteracting compression noise. Nesterov momentum accelerates convergence through stable accumulation enabled by distillation smoothing. SPARK achieves 98.7% communication reduction compared to NTK-DFL while maintaining convergence speed and superior accuracy. With momentum, SPARK reaches target performance 3 times faster, establishing state-of-the-art results for communication-efficient decentralized learning and enabling practical deployment in bandwidth-limited edge environments.

</details>


### [353] [Resting Neurons, Active Insights: Improving Input Sparsification for Large Language Models](https://arxiv.org/abs/2512.12744)
*Haotian Xu,Tian Gao,Tsui-Wei Weng,Tengfei Ma*

Main category: cs.LG

TL;DR: 该论文提出了一种通过引入可训练的自发神经元来改善LLM输入稀疏化性能的方法，将输入稀疏化重新解释为动态结构剪枝，并借鉴生物神经元的自发基线放电率来稳定稀疏化模型的激活。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能优异，但规模庞大带来了效率和可解释性挑战。输入稀疏化通过选择性激活输入值的子集来提高效率，但现有方法主要关注计算节省，忽视了稀疏化的表示后果，导致与完整模型存在明显性能差距。

Method: 首先将输入稀疏化重新解释为动态结构剪枝。受生物神经元自发基线放电率的启发，引入一小组可训练的自发神经元作为补偿单元，以稳定稀疏化LLM中的激活。

Result: 实验表明，这些辅助神经元显著减少了稀疏化引起的性能差距，并在不同任务上有效泛化。

Conclusion: 通过引入自发神经元作为补偿单元，可以在保持输入稀疏化计算效率优势的同时，显著改善稀疏化LLM的性能表现，缩小与完整模型的差距。

Abstract: Large Language Models (LLMs) achieve state-of-the-art performance across a wide range of applications, but their massive scale poses significant challenges for both efficiency and interpretability. Structural pruning, which reduces model size by removing redundant computational units such as neurons, has been widely explored as a solution, and this study devotes to input sparsification, an increasingly popular technique that improves efficiency by selectively activating only a subset of entry values for each input. However, existing approaches focus primarily on computational savings, often overlooking the representational consequences of sparsification and leaving a noticeable performance gap compared to full models. In this work, we first reinterpret input sparsification as a form of dynamic structural pruning. Motivated by the spontaneous baseline firing rates observed in biological neurons, we introduce a small set of trainable spontaneous neurons that act as compensatory units to stabilize activations in sparsified LLMs. Experiments demonstrate that these auxiliary neurons substantially reduce the sparsification-induced performance gap while generalizing effectively across tasks.

</details>


### [354] [Federated Learning with Feedback Alignment](https://arxiv.org/abs/2512.12762)
*Incheol Baek,Hyungbin Kim,Minseo Kim,Yon Dohn Chung*

Main category: cs.LG

TL;DR: FLFA将反馈对齐集成到联邦学习中，使用全局模型权重作为共享反馈矩阵，以缓解非IID数据导致的本地漂移问题，提升收敛性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在数据异构（非IID）场景下存在本地漂移问题，这会阻碍全局模型的收敛。现有方法需要解决这一挑战。

Method: 提出FLFA框架，将反馈对齐技术集成到联邦学习中。在本地训练的反向传播过程中，使用全局模型的权重作为共享反馈矩阵，从而对齐本地更新与全局模型。

Result: 理论分析表明FLFA能缓解本地漂移并保证本地和全局模型的鲁棒收敛。实证评估显示FLFA能提升其他FL方法的准确性，有效减少本地漂移。

Conclusion: FLFA通过集成反馈对齐，以最小的额外计算成本和零通信开销有效缓解了联邦学习中的本地漂移问题，提升了非IID数据场景下的性能。

Abstract: Federated Learning (FL) enables collaborative training across multiple clients while preserving data privacy, yet it struggles with data heterogeneity, where clients' data are not distributed independently and identically (non-IID). This causes local drift, hindering global model convergence. To address this, we introduce Federated Learning with Feedback Alignment (FLFA), a novel framework that integrates feedback alignment into FL. FLFA uses the global model's weights as a shared feedback matrix during local training's backward pass, aligning local updates with the global model efficiently. This approach mitigates local drift with minimal additional computational cost and no extra communication overhead.
  Our theoretical analysis supports FLFA's design by showing how it alleviates local drift and demonstrates robust convergence for both local and global models. Empirical evaluations, including accuracy comparisons and measurements of local drift, further illustrate that FLFA can enhance other FL methods demonstrating its effectiveness.

</details>


### [355] [OLR-WAA: Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Averaging](https://arxiv.org/abs/2512.12779)
*Mohammad Abu-Shaira,Weishi Shi*

Main category: cs.LG

TL;DR: OLR-WAA是一种无超参数的在线回归模型，通过动态加权平均和概念漂移检测机制，在非平稳数据流中实现稳定性和适应性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集经常表现出不断变化的数据分布（概念漂移），忽略这一现象会严重降低模型预测性能。现有在线模型的超参数通常是固定的，缺乏动态适应演化数据的灵活性。

Method: 提出OLR-WAA模型：1）使用指数加权移动平均增量更新基础模型；2）引入独特的优化机制，动态检测概念漂移、量化其幅度，并根据实时数据特征调整模型；3）采用保守更新策略处理基于置信度的场景，优先考虑稳定、高置信度的数据点。

Result: 在静态设置中匹配批量回归性能；在概念漂移数据集上持续优于或媲美最先进的在线模型；快速收敛，相比其他在线模型始终获得更高的R2值；有效弥补了概念漂移导致的性能差距。

Conclusion: OLR-WAA是一种有效的无超参数在线回归模型，能够处理非平稳数据流，在模型稳定性和适应性之间取得良好平衡，特别适合处理概念漂移场景。

Abstract: Real-world datasets frequently exhibit evolving data distributions, reflecting temporal variations and underlying shifts. Overlooking this phenomenon, known as concept drift, can substantially degrade the predictive performance of the model. Furthermore, the presence of hyperparameters in online models exacerbates this issue, as these parameters are typically fixed and lack the flexibility to dynamically adjust to evolving data. This paper introduces "OLR-WAA: An Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Average", a hyperparameter-free model designed to tackle the challenges of non-stationary data streams and enable effective, continuous adaptation. The objective is to strike a balance between model stability and adaptability. OLR-WAA incrementally updates its base model by integrating incoming data streams, utilizing an exponentially weighted moving average. It further introduces a unique optimization mechanism that dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on real-time data characteristics. Rigorous evaluations show that it matches batch regression performance in static settings and consistently outperforms or rivals state-of-the-art online models, confirming its effectiveness. Concept drift datasets reveal a performance gap that OLR-WAA effectively bridges, setting it apart from other online models. In addition, the model effectively handles confidence-based scenarios through a conservative update strategy that prioritizes stable, high-confidence data points. Notably, OLR-WAA converges rapidly, consistently yielding higher R2 values compared to other online models.

</details>


### [356] [Credit Risk Estimation with Non-Financial Features: Evidence from a Synthetic Istanbul Dataset](https://arxiv.org/abs/2512.12783)
*Atalay Denknalbant,Emre Sezdi,Zeki Furkan Kutlu,Polat Goktas*

Main category: cs.LG

TL;DR: 研究使用合成数据和替代金融属性（如手机使用、网购习惯等）来评估缺乏正规信用记录的伊斯坦布尔借款人，发现这些行为数据能显著提升信用风险评估准确性。


<details>
  <summary>Details</summary>
Motivation: 金融排斥限制了创业机会、增加了收入波动并扩大了财富差距。伊斯坦布尔的银行服务不足群体往往没有信用记录，因为他们的收入和支付通过非正规渠道进行。需要研究如何评估这些借款人。

Method: 创建了10万伊斯坦布尔居民的合成数据集，复制了2025年第一季度土耳其统计局人口普查边际和电信使用模式。使用检索增强生成技术将公共统计数据输入OpenAI o3模型生成真实但私密的记录。每个档案包含7个社会人口变量和9个替代属性（手机规格、网购节奏、订阅支出、汽车所有权、月租金、信用卡标志）。使用CatBoost、LightGBM和XGBoost训练两种版本模型：演示模型仅使用社会人口变量，完整模型同时使用社会人口和替代属性。

Result: 通过五折分层验证，替代属性块将AUC提高了约1.3个百分点，将平衡F1分数从约0.84提升到0.95，增益达14%。替代行为属性可以接近信用局级别的区分能力。

Conclusion: 贡献包括：开放的伊斯坦布尔2025年第一季度合成数据集、完全可复现的建模流程，以及经验证据表明简洁的行为属性集可以接近信用局级别的区分能力，同时服务于缺乏正规信用记录的借款人。这些发现为贷款机构和监管机构提供了透明蓝图，以扩展对银行服务不足群体的公平和安全信贷访问。

Abstract: Financial exclusion constrains entrepreneurship, increases income volatility, and widens wealth gaps. Underbanked consumers in Istanbul often have no bureau file because their earnings and payments flow through informal channels. To study how such borrowers can be evaluated we create a synthetic dataset of one hundred thousand Istanbul residents that reproduces first quarter 2025 TÜİK census marginals and telecom usage patterns. Retrieval augmented generation feeds these public statistics into the OpenAI o3 model, which synthesises realistic yet private records. Each profile contains seven socio demographic variables and nine alternative attributes that describe phone specifications, online shopping rhythm, subscription spend, car ownership, monthly rent, and a credit card flag. To test the impact of the alternative financial data CatBoost, LightGBM, and XGBoost are each trained in two versions. Demo models use only the socio demographic variables; Full models include both socio demographic and alternative attributes. Across five fold stratified validation the alternative block raises area under the curve by about one point three percentage and lifts balanced \(F_{1}\) from roughly 0.84 to 0.95, a fourteen percent gain. We contribute an open Istanbul 2025 Q1 synthetic dataset, a fully reproducible modeling pipeline, and empirical evidence that a concise set of behavioural attributes can approach bureau level discrimination power while serving borrowers who lack formal credit records. These findings give lenders and regulators a transparent blueprint for extending fair and safe credit access to the underbanked.

</details>


### [357] [OLC-WA: Drift Aware Tuning-Free Online Classification with Weighted Average](https://arxiv.org/abs/2512.12785)
*Mohammad Abu Shaira,Yunhe Feng,Heng Fan,Weishi Shi*

Main category: cs.LG

TL;DR: OLC-WA是一种无需超参数的自适应在线分类模型，通过指数加权移动平均融合数据流和基础模型，自动检测概念漂移并动态调整，在动态数据流中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集常呈现随时间演化的数据分布（概念漂移），忽略此现象会显著降低模型预测精度。在线模型中的超参数通常是固定的，无法随数据分布变化动态调整，这加剧了问题。

Method: 提出OLC-WA（在线分类加权平均）模型：1）使用指数加权移动平均将新数据流与现有基础模型融合；2）集成优化机制自动检测概念漂移、量化其幅度，并根据观测到的数据流特征动态调整模型。

Result: 在多种基准数据集上的实证评估显示：在静态环境中，OLC-WA性能与批处理模型相当，准确率差距在1-3%内；在概念漂移情况下，OLC-WA比领先的在线基线方法高出10-25%。

Conclusion: OLC-WA是一种有效的超参数自由自适应在线分类模型，能够通过自动优化机制在流式环境中有效适应演化数据分布，在静态和动态环境中均表现优异。

Abstract: Real-world data sets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. This paper introduces Online Classification with Weighted Average (OLC-WA), an adaptive, hyperparameter-free online classification model equipped with an automated optimization mechanism. OLC-WA operates by blending incoming data streams with an existing base model. This blending is facilitated by an exponentially weighted moving average. Furthermore, an integrated optimization mechanism dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on the observed data stream characteristics. This approach empowers the model to effectively adapt to evolving data distributions within streaming environments. Rigorous empirical evaluation across diverse benchmark datasets shows that OLC-WA achieves performance comparable to batch models in stationary environments, maintaining accuracy within 1-3%, and surpasses leading online baselines by 10-25% under drift, demonstrating its effectiveness in adapting to dynamic data streams.

</details>


### [358] [Unveiling Statistical Significance of Online Regression over Multiple Datasets](https://arxiv.org/abs/2512.12787)
*Mohammad Abu-Shaira,Weishi Shi*

Main category: cs.LG

TL;DR: 该论文研究了在线学习中多算法跨数据集比较的统计检验方法，使用Friedman检验和事后检验评估在线回归模型，发现现有方法仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习研究缺乏比较多个算法在不同数据集上性能的统计检验方法，在线学习领域需要统计显著性验证来确保连续学习过程的有效性，特别是在快速收敛和及时处理概念漂移方面。

Method: 使用Friedman检验和相应的事后检验来比较多个在线回归模型在不同数据集上的性能，采用真实和合成数据集，结合5折交叉验证和种子平均进行综合评估。

Result: 测试结果总体上确认了竞争基线的性能与其各自报告一致，但某些统计检验结果表明现有最先进方法在某些方面仍有改进空间。

Conclusion: 在线学习领域需要更稳健的统计方法来评估算法性能差异，现有方法虽然有效但仍有改进空间，特别是在处理概念漂移和确保统计显著性方面。

Abstract: Despite extensive focus on techniques for evaluating the performance of two learning algorithms on a single dataset, the critical challenge of developing statistical tests to compare multiple algorithms across various datasets has been largely overlooked in most machine learning research. Additionally, in the realm of Online Learning, ensuring statistical significance is essential to validate continuous learning processes, particularly for achieving rapid convergence and effectively managing concept drifts in a timely manner. Robust statistical methods are needed to assess the significance of performance differences as data evolves over time. This article examines the state-of-the-art online regression models and empirically evaluates several suitable tests. To compare multiple online regression models across various datasets, we employed the Friedman test along with corresponding post-hoc tests. For thorough evaluations, utilizing both real and synthetic datasets with 5-fold cross-validation and seed averaging ensures comprehensive assessment across various data subsets. Our tests generally confirmed the performance of competitive baselines as consistent with their individual reports. However, some statistical test results also indicate that there is still room for improvement in certain aspects of state-of-the-art methods.

</details>


### [359] [Liquid Reasoning Transformers: A Sudoku-Based Prototype for Chess-Scale Algorithmic Tasks](https://arxiv.org/abs/2512.12792)
*Shivansh Sahni,Wenzhi Zhang*

Main category: cs.LG

TL;DR: LRT是一种使用自适应深度推理的Transformer架构，通过迭代更新、丢弃修正和学习停止机制，在数独任务上达到高精度表现。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer通常依赖单次前向传播进行推理，难以纠正早期错误或根据输入复杂度调整计算深度。需要一种能够自适应分配计算资源、支持迭代修正的推理架构。

Method: 提出Liquid Reasoning Transformer，使用循环推理token在多步内部迭代中更新，包含丢弃门修正早期错误、学习停止机制自适应确定计算深度，无需符号规则或搜索。

Result: 在数独任务上达到98.68%数字准确率和36.30%完整谜题准确率。分析显示丢弃门和停止门在稳定推理和调整计算深度中发挥重要作用。

Conclusion: LRT展示了自适应深度推理的有效性，其机制可扩展到国际象棋等更大规模推理任务，并支持多token推理和更大领域的扩展。

Abstract: The Liquid Reasoning Transformer (LRT) is a transformer architecture designed for inference with adaptive depths using iterative changes, discard-based correction, and a learned stopping mechanism. Instead of relying on a single feedforward pass, the model updates a recurrent reasoning token across multiple internal steps, allowing it to correct early errors and allocate computation based on input difficulty. We evaluate the LRT on Sudoku as a controlled testbed for structured reasoning and show that it achieves strong performance, reaching 98.68% digit accuracy and 36.30% full-puzzle accuracy without using symbolic rules or search. Analyzing internal patterns shows that the discard and stop gates play different, important roles in stabilizing inferences and adjusting computational depth. We discuss how these mechanisms extend naturally to chess-scale reasoning tasks and outline extensions for multi-token reasoning and larger domains.

</details>


### [360] [TRACER: Transfer Learning based Real-time Adaptation for Clinical Evolving Risk](https://arxiv.org/abs/2512.12795)
*Mengying Yan,Ziye Tian,Siqi Li,Nan Liu,Benjamin A. Goldstein,Molei Liu,Chuan Hong*

Main category: cs.LG

TL;DR: TRACER框架通过迁移学习实时适应临床环境变化，解决电子健康记录预测模型因时间性人群变化导致的性能漂移问题


<details>
  <summary>Details</summary>
Motivation: 临床决策支持工具基于电子健康记录构建，常因时间性人群变化（如系统级操作更新或新疾病出现）导致性能漂移，特别是当变化最初只影响部分患者时，会形成混合人群

Method: 提出TRACER框架，识别就诊级别的过渡成员资格，并使用迁移学习调整预测模型而无需完全重新训练

Result: 在模拟研究中，TRACER优于基于历史或当代数据训练的静态模型；在实际应用中预测COVID-19过渡期间急诊就诊后的住院情况，TRACER提高了区分度和校准度

Conclusion: TRACER为在不断演变和异质的临床条件下保持稳健的预测性能提供了可扩展的方法

Abstract: Clinical decision support tools built on electronic health records often experience performance drift due to temporal population shifts, particularly when changes in the clinical environment initially affect only a subset of patients, resulting in a transition to mixed populations. Such case-mix changes commonly arise following system-level operational updates or the emergence of new diseases, such as COVID-19. We propose TRACER (Transfer Learning-based Real-time Adaptation for Clinical Evolving Risk), a framework that identifies encounter-level transition membership and adapts predictive models using transfer learning without full retraining. In simulation studies, TRACER outperformed static models trained on historical or contemporary data. In a real-world application predicting hospital admission following emergency department visits across the COVID-19 transition, TRACER improved both discrimination and calibration. TRACER provides a scalable approach for maintaining robust predictive performance under evolving and heterogeneous clinical conditions.

</details>


### [361] [From Small to Large: Generalization Bounds for Transformers on Variable-Size Inputs](https://arxiv.org/abs/2512.12805)
*Anastasiia Alokhina,Pan Li*

Main category: cs.LG

TL;DR: 论文提出了一个理论框架来分析Transformer在几何数据上的尺寸泛化能力，证明了离散样本输出与连续域等价输出之间的误差界限，该界限由采样密度和数据流形的内在维度决定。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在各种应用中表现出从较小标记集外推到较长序列的尺寸泛化能力，但这种能力仍缺乏严格的理论特征描述。本文旨在为几何数据的这种泛化现象提供理论分析框架。

Method: 将几何数据表示为连续源的离散样本（如流形上的点云、图论中的图），建立理论框架分析Transformer输出在离散样本与连续域等价之间的误差界限，特别关注具有稳定位置编码的Transformer。

Result: 证明了对于具有稳定位置编码的Transformer，离散样本输出与连续域等价输出之间的误差界限由采样密度和数据流形的内在维度决定。在不同尺寸的图和点云上的实验证实了理论界限的紧致性。

Conclusion: 本文为Transformer在几何数据上的尺寸泛化能力提供了理论解释，建立了离散样本与连续域表示之间的误差界限，并通过实验验证了理论结果的正确性，为理解Transformer的泛化行为提供了理论基础。

Abstract: Transformers exhibit a notable property of \emph{size generalization}, demonstrating an ability to extrapolate from smaller token sets to significantly longer ones. This behavior has been documented across diverse applications, including point clouds, graphs, and natural language. Despite its empirical success, this capability still lacks some rigorous theoretical characterizations. In this paper, we develop a theoretical framework to analyze this phenomenon for geometric data, which we represent as discrete samples from a continuous source (e.g., point clouds from manifolds, graphs from graphons). Our core contribution is a bound on the error between the Transformer's output for a discrete sample and its continuous-domain equivalent. We prove that for Transformers with stable positional encodings, this bound is determined by the sampling density and the intrinsic dimensionality of the data manifold. Experiments on graphs and point clouds of various sizes confirm the tightness of our theoretical bound.

</details>


### [362] [Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift](https://arxiv.org/abs/2512.12816)
*Hasan Burhan Beytur,Gustavo de Veciana,Haris Vikalo,Kevin S Chan*

Main category: cs.LG

TL;DR: 研究概念漂移和有限预算下机器学习模型的训练与部署资源分配问题，提出模型无关框架，分析概念持续时间分布对最优训练策略的影响，并解决通信约束下的部署调度问题。


<details>
  <summary>Details</summary>
Motivation: 在概念漂移和预算限制的现实场景中，模型提供商需要向多个客户端分发模型，但客户端设备仅支持本地推理而无法重新训练模型，性能维护的负担完全落在提供商身上，需要系统化的资源分配框架来解决这一挑战。

Method: 提出模型无关框架，捕捉资源分配、概念漂移动态和部署时序之间的交互关系。分析概念持续时间分布（DMRL/IMRL）对最优训练策略的影响，推导预算约束下的最优训练策略。针对通信约束下的部署问题，证明优化问题的拟凸性，并提出随机调度策略。

Result: 发现最优训练策略严重依赖于概念持续时间的老化特性：在突然概念变化下，当概念持续时间服从递减平均剩余寿命（DMRL）分布时，可以推导出预算约束下的最优训练策略；而直观启发式方法在递增平均剩余寿命（IMRL）下被证明是次优的。对于部署问题，提出的随机调度策略能在客户端实现接近最优的性能。

Conclusion: 该研究为概念漂移下成本高效的机器学习模型管理提供了理论和算法基础，对持续学习、分布式推理和自适应机器学习系统具有重要启示，解决了模型提供商在资源受限环境中维护模型性能的实际挑战。

Abstract: We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain those models, placing the burden of performance maintenance on the provider. We introduce a model-agnostic framework that captures the interaction between resource allocation, concept drift dynamics, and deployment timing. We show that optimal training policies depend critically on the aging properties of concept durations. Under sudden concept changes, we derive optimal training policies subject to budget constraints when concept durations follow distributions with Decreasing Mean Residual Life (DMRL), and show that intuitive heuristics are provably suboptimal under Increasing Mean Residual Life (IMRL). We further study model deployment under communication constraints, prove that the associated optimization problem is quasi-convex under mild conditions, and propose a randomized scheduling strategy that achieves near-optimal client-side performance. These results offer theoretical and algorithmic foundations for cost-efficient ML model management under concept drift, with implications for continual learning, distributed inference, and adaptive ML systems.

</details>


### [363] [On the continuity of flows](https://arxiv.org/abs/2512.12821)
*Congzhou M Sha*

Main category: cs.LG

TL;DR: 论文分析流匹配生成模型中拓扑不匹配问题：当先验分布和目标分布拓扑结构不同时，最优速度场会出现空间不连续性，源于连续流必须分叉以将单模态映射到多模态。


<details>
  <summary>Details</summary>
Motivation: 研究流匹配框架中潜在的拓扑约束问题，探索当先验分布和目标分布拓扑结构不匹配时（如单模态到多模态），标准流匹配目标下的最优速度场可能出现空间不连续性。

Method: 通过理论分析双模态高斯混合模型，证明最优速度场在决策边界处存在跳跃不连续性，其幅度在时间接近目标分布时趋于无穷大。同时进行实证验证，并讨论流匹配在流形上的潜在影响。

Result: 理论分析表明，最优速度场确实表现出沿决策边界的跳跃不连续性，且这种现象不是L^2损失特有的，而是分布间拓扑不匹配的必然结果。实证结果验证了理论预测。

Conclusion: 流匹配中的拓扑不匹配会导致最优速度场出现空间不连续性，这对流匹配在流形上的应用有重要启示，并与黎曼流匹配和神经网络中学习不连续表示的最新研究相关。

Abstract: Flow matching has emerged as a powerful framework for generative modeling through continuous normalizing flows. We investigate a potential topological constraint: when the prior distribution and target distribution have mismatched topology (e.g., unimodal to multimodal), the optimal velocity field under standard flow matching objectives may exhibit spatial discontinuities. We suggest that this discontinuity arises from the requirement that continuous flows must bifurcate to map a single mode to multiple modes, forcing particles to make discrete routing decisions at intermediate times. Through theoretical analysis on bimodal Gaussian mixtures, we demonstrate that the optimal velocity field exhibits jump discontinuities along decision boundaries, with magnitude approaching infinity as time approaches the target distribution. Our analysis suggests that this phenomenon is not specific to $L^2$ loss, but rather may be a consequence of topological mismatch between distributions. We validate our theory empirically and discuss potential implications for flow matching on manifolds, connecting our findings to recent work on Riemannian flow matching and the challenge of learning discontinuous representations in neural networks.

</details>


### [364] [GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients](https://arxiv.org/abs/2512.12827)
*Mohammad Mahdi Razmjoo,Mohammad Mahdi Sharifian,Saeed Bagheri Shouraki*

Main category: cs.LG

TL;DR: 利用模型梯度参数的内在维度（ID）差异检测对抗样本，在批次和单样本场景下均取得SOTA效果


<details>
  <summary>Details</summary>
Motivation: 深度神经网络对微小对抗扰动高度脆弱，而医疗诊断、自动驾驶等应用对可靠性要求极高，因此需要鲁棒的对抗攻击检测方法

Method: 分析模型输入损失空间的几何特性，研究模型梯度参数的内在维度（ID），发现自然数据和对抗数据在ID上存在显著差异，基于此构建检测方法

Result: 在批次检测场景（MNIST、SVHN）和单样本检测场景（CIFAR-10、MS COCO）均表现优异，在CIFAR-10上对CW、AutoAttack等多种攻击的检测率超过92%，显著超越现有方法

Conclusion: 内在维度是跨数据集和攻击策略的强大对抗检测指纹，几何方法具有出色的鲁棒性

Abstract: Despite their remarkable performance, deep neural networks exhibit a critical vulnerability: small, often imperceptible, adversarial perturbations can lead to drastically altered model predictions. Given the stringent reliability demands of applications such as medical diagnosis and autonomous driving, robust detection of such adversarial attacks is paramount. In this paper, we investigate the geometric properties of a model's input loss landscape. We analyze the Intrinsic Dimensionality (ID) of the model's gradient parameters, which quantifies the minimal number of coordinates required to describe the data points on their underlying manifold. We reveal a distinct and consistent difference in the ID for natural and adversarial data, which forms the basis of our proposed detection method. We validate our approach across two distinct operational scenarios. First, in a batch-wise context for identifying malicious data groups, our method demonstrates high efficacy on datasets like MNIST and SVHN. Second, in the critical individual-sample setting, we establish new state-of-the-art results on challenging benchmarks such as CIFAR-10 and MS COCO. Our detector significantly surpasses existing methods against a wide array of attacks, including CW and AutoAttack, achieving detection rates consistently above 92\% on CIFAR-10. The results underscore the robustness of our geometric approach, highlighting that intrinsic dimensionality is a powerful fingerprint for adversarial detection across diverse datasets and attack strategies.

</details>


### [365] [Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future](https://arxiv.org/abs/2512.12832)
*Kaustav Chatterjee,Joshua Li,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 开发了一个评估公路铁路平交道口（HRGC）悬挂风险的网络级框架，结合激光成像、深度学习和车辆尺寸数据来识别高风险道口。


<details>
  <summary>Details</summary>
Motivation: 陡峭的公路铁路平交道口对低底盘车辆构成安全隐患，可能导致车辆卡在轨道上，引发火车与车辆碰撞风险。需要系统性的方法来评估道口的悬挂风险。

Method: 1) 使用步行剖面仪和Pave3D8K激光成像系统收集道口剖面数据；2) 开发LSTM-Transformer混合深度学习模型从激光数据重建准确的道口剖面；3) 收集约350辆特种车辆的尺寸数据；4) 使用三种车辆尺寸场景分析悬挂风险；5) 开发ArcGIS数据库和软件界面。

Result: 在不同车辆尺寸场景下，分别识别出36、62和67个最高悬挂风险的道口。开发了实用的决策支持工具来帮助交通机构缓解道口危险。

Conclusion: 该框架通过整合新一代传感技术、深度学习和基础设施数据，开发了实用的决策支持工具，推进了安全评估方法，有助于减少公路铁路平交道口的安全风险。

Abstract: Steep profiled Highway Railway Grade Crossings (HRGCs) pose safety hazards to vehicles with low ground clearance, which may become stranded on the tracks, creating risks of train vehicle collisions. This research develops a framework for network level evaluation of hangup susceptibility of HRGCs. Profile data from different crossings in Oklahoma were collected using both a walking profiler and the Pave3D8K Laser Imaging System. A hybrid deep learning model, combining Long Short Term Memory (LSTM) and Transformer architectures, was developed to reconstruct accurate HRGC profiles from Pave3D8K Laser Imaging System data. Vehicle dimension data from around 350 specialty vehicles were collected at various locations across Oklahoma to enable up to date statistical design dimensions. Hangup susceptibility was analyzed using three vehicle dimension scenarios (a) median dimension (median wheelbase and ground clearance), (b) 75 25 percentile dimension (75 percentile wheelbase, 25 percentile ground clearance), and (c) worst case dimension (maximum wheelbase and minimum ground clearance). Results indicate 36, 62, and 67 crossings at the highest hangup risk levels under these scenarios, respectively. An ArcGIS database and a software interface were developed to support transportation agencies in mitigating crossing hazards. This framework advances safety evaluation by integrating next generation sensing, deep learning, and infrastructure datasets into practical decision support tools.

</details>


### [366] [PRIVEE: Privacy-Preserving Vertical Federated Learning Against Feature Inference Attacks](https://arxiv.org/abs/2512.12840)
*Sindhuja Madabushi,Ahmad Faraz Khan,Haider Ali,Ananthram Swami,Rui Ning,Hongyi Wu,Jin-Hee Cho*

Main category: cs.LG

TL;DR: PRIVEE是一种保护隐私的纵向联邦学习防御机制，通过混淆置信度分数来防止特征推断攻击，同时保持预测准确性和相对排名等关键属性。


<details>
  <summary>Details</summary>
Motivation: 纵向联邦学习（VFL）允许组织在共享用户样本但特征空间分离的情况下协作训练模型，但容易受到特征推断攻击，攻击者可以利用推理过程中共享的置信度分数来重建其他参与者的私有输入特征。

Method: 提出PRIVEE防御机制，通过混淆置信度分数来保护隐私，同时保持相对排名和分数间距离等关键属性。不是暴露原始分数，而是只共享转换后的表示，从而在不降低模型预测准确性的情况下减轻重建攻击风险。

Result: 大量实验表明，与最先进的防御方法相比，PRIVEE在隐私保护方面实现了三倍的改进，同时针对高级特征推断攻击保持了完整的预测性能。

Conclusion: PRIVEE为纵向联邦学习提供了一种有效的隐私保护解决方案，能够在保持模型性能的同时显著增强对特征推断攻击的防御能力。

Abstract: Vertical Federated Learning (VFL) enables collaborative model training across organizations that share common user samples but hold disjoint feature spaces. Despite its potential, VFL is susceptible to feature inference attacks, in which adversarial parties exploit shared confidence scores (i.e., prediction probabilities) during inference to reconstruct private input features of other participants. To counter this threat, we propose PRIVEE (PRIvacy-preserving Vertical fEderated lEarning), a novel defense mechanism named after the French word privée, meaning "private." PRIVEE obfuscates confidence scores while preserving critical properties such as relative ranking and inter-score distances. Rather than exposing raw scores, PRIVEE shares only the transformed representations, mitigating the risk of reconstruction attacks without degrading model prediction accuracy. Extensive experiments show that PRIVEE achieves a threefold improvement in privacy protection compared to state-of-the-art defenses, while preserving full predictive performance against advanced feature inference attacks.

</details>


### [367] [Selective Conformal Risk Control](https://arxiv.org/abs/2512.12844)
*Yunpeng Xu,Wenge Guo,Zhi Wei*

Main category: cs.LG

TL;DR: 选择性保形风险控制（SCRC）框架将保形预测与选择性分类结合，通过两阶段方法实现更紧凑的预测集，提供可靠的置信度控制。


<details>
  <summary>Details</summary>
Motivation: 保形预测虽然提供分布无关的覆盖保证，但通常产生过大的预测集，限制了实际应用。需要更紧凑可靠的置信度量化方法。

Method: 提出选择性保形风险控制（SCRC）框架：第一阶段选择置信样本进行预测，第二阶段在选定子集上应用保形风险控制构建校准预测集。开发了SCRC-T（保持可交换性）和SCRC-I（仅校准）两种算法。

Result: 在两个公开数据集上的实验表明，两种方法都达到了目标覆盖率和风险水平，性能几乎相同。SCRC-I表现出稍保守的风险控制，但计算效率更高。

Conclusion: 选择性保形风险控制为实现紧凑、可靠的置信度量化提供了有效且高效的途径。

Abstract: Reliable uncertainty quantification is essential for deploying machine learning systems in high-stakes domains. Conformal prediction provides distribution-free coverage guarantees but often produces overly large prediction sets, limiting its practical utility. To address this issue, we propose \textit{Selective Conformal Risk Control} (SCRC), a unified framework that integrates conformal prediction with selective classification. The framework formulates uncertainty control as a two-stage problem: the first stage selects confident samples for prediction, and the second stage applies conformal risk control on the selected subset to construct calibrated prediction sets. We develop two algorithms under this framework. The first, SCRC-T, preserves exchangeability by computing thresholds jointly over calibration and test samples, offering exact finite-sample guarantees. The second, SCRC-I, is a calibration-only variant that provides PAC-style probabilistic guarantees while being more computational efficient. Experiments on two public datasets show that both methods achieve the target coverage and risk levels, with nearly identical performance, while SCRC-I exhibits slightly more conservative risk control but superior computational practicality. Our results demonstrate that selective conformal risk control offers an effective and efficient path toward compact, reliable uncertainty quantification.

</details>


### [368] [Information-Consistent Language Model Recommendations through Group Relative Policy Optimization](https://arxiv.org/abs/2512.12858)
*Sonal Prabhune,Balaji Padmanabhan,Kaushik Dutta*

Main category: cs.LG

TL;DR: 提出基于GRPO的强化学习框架，优化LLM在语义等价提示下的信息一致性，减少企业场景中的响应变异性


<details>
  <summary>Details</summary>
Motivation: LLM在企业关键领域部署时，对语义等价但表述不同的提示会产生不一致的响应，这破坏了用户信任、合规性和体验。虽然个性化在某些场景中是可取的，但许多企业场景（如HR入职、客户支持、政策披露）需要无论措辞或对话历史如何都能提供不变的信息传递。

Method: 提出基于Group Relative Policy Optimization (GRPO)的强化学习框架，将语义等价提示视为组，重置对话上下文以隔离措辞影响，引入基于熵的有用性和稳定性奖励，直接优化一致性。

Result: 在投资和职位推荐任务上的实验表明，GRPO训练的模型比微调或基于解码的基线方法更有效地减少变异性。

Conclusion: 这是GRPO在信息一致性对齐方面的创新应用，将变异性重新定义为可纠正的缺陷而非生成多样性的可接受特征，为企业部署提供了更可靠的LLM解决方案。

Abstract: Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery regardless of phrasing or prior conversational history. Existing approaches, including retrieval-augmented generation (RAG) and temperature tuning, improve factuality or reduce stochasticity but cannot guarantee stability across equivalent prompts. In this paper, we propose a reinforcement learning framework based on Group Relative Policy Optimization (GRPO) to directly optimize for consistency. Unlike prior applications of GRPO, which have been limited to reasoning and code generation, we adapt GRPO to enforce stability of information content across groups of semantically equivalent prompts. We introduce entropy-based helpfulness and stability rewards, treating prompt variants as groups and resetting conversational context to isolate phrasing effects. Experiments on investment and job recommendation tasks show that our GRPO-trained model reduces variability more effectively than fine-tuning or decoding-based baselines. To our knowledge, this is a novel application of GRPO for aligning LLMs toward information consistency, reframing variability not as an acceptable feature of generative diversity but as a correctable flaw in enterprise deployments.

</details>


### [369] [Optimal Labeler Assignment and Sampling for Active Learning in the Presence of Imperfect Labels](https://arxiv.org/abs/2512.12870)
*Pouya Ahadi,Blair Winograd,Camille Zaug,Karunesh Arora,Lijun Wang,Kamran Paynabar*

Main category: cs.LG

TL;DR: 提出了一种新的主动学习框架，通过优化分配查询样本给标注者来最小化标签噪声，并引入新的采样方法提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 主动学习中标注者提供的标签往往存在噪声，特别是复杂样本更容易被错误标注，这会导致分类器性能下降。需要一种能处理标签噪声的鲁棒主动学习框架。

Method: 1. 分配模型：优化地将查询点分配给标注者，最小化每个周期内的最大可能噪声；2. 新的采样方法：识别最佳查询点，减少标签噪声对分类器性能的影响。

Result: 实验表明，该方法相比多个基准方法显著提高了分类性能。

Conclusion: 提出的主动学习框架通过最小化标签噪声和优化采样策略，能够构建更鲁棒的分类模型。

Abstract: Active Learning (AL) has garnered significant interest across various application domains where labeling training data is costly. AL provides a framework that helps practitioners query informative samples for annotation by oracles (labelers). However, these labels often contain noise due to varying levels of labeler accuracy. Additionally, uncertain samples are more prone to receiving incorrect labels because of their complexity. Learning from imperfectly labeled data leads to an inaccurate classifier. We propose a novel AL framework to construct a robust classification model by minimizing noise levels. Our approach includes an assignment model that optimally assigns query points to labelers, aiming to minimize the maximum possible noise within each cycle. Additionally, we introduce a new sampling method to identify the best query points, reducing the impact of label noise on classifier performance. Our experiments demonstrate that our approach significantly improves classification performance compared to several benchmark methods.

</details>


### [370] [Improving Recursive Transformers with Mixture of LoRAs](https://arxiv.org/abs/2512.12880)
*Mohammadmahdi Nouriborji,Morteza Rohanian,Omid Rohanian*

Main category: cs.LG

TL;DR: MoL（LoRA专家混合）通过在共享FFN中插入LoRA专家，实现token条件权重空间调制，解决了递归transformer参数共享导致的表达能力下降问题，在保持模型紧凑的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 递归transformer中的参数共享虽然减少了模型大小，但会导致层间表达能力下降。现有方法要么添加固定的适配器，要么外部附加适配器，无法实现token条件的权重空间调制。

Method: 提出MoL（LoRA专家混合），在共享前馈网络（FFN）中插入低秩适应（LoRA）专家，实现token条件的权重空间调制。同时提出ModernALBERT架构，整合旋转嵌入、GeGLU、FlashAttention和蒸馏初始化。

Result: ModernALBERT（50M-120M参数）在GLUE、SQuAD-v2和BEIR基准测试中，在紧凑模型中达到SOTA性能，甚至超越更大的全参数化基线模型。提出的专家合并方法能在推理时压缩MoL为单个适配器，保持精度。

Conclusion: 条件权重空间调制能有效恢复递归transformer在激进参数共享下丢失的表达能力。MoL提供了一种轻量级的条件计算机制，既保持模型紧凑性，又提升表达能力，适合高效部署。

Abstract: Parameter sharing in recursive transformers reduces model size but collapses layer-wise expressivity. We propose Mixture of LoRAs (MoL), a lightweight conditional-computation mechanism that inserts Low-Rank Adaptation (LoRA) experts inside a shared feed-forward network (FFN). MoL enables token-conditional weight-space modulation of the shared FFN without untying backbone parameters, unlike prior approaches that add fixed or externally attached adapters. We pretrain a modernised recursive architecture, ModernALBERT, integrating rotary embeddings, GeGLU, FlashAttention, and a distillation-based initialisation. Across GLUE, SQuAD-v2, and BEIR, ModernALBERT (50M--120M) achieves state-of-the-art performance among compact models and surpasses larger fully parameterised baselines. We also propose an expert-merging procedure that compresses MoL into a single adapter at inference while preserving accuracy, enabling efficient deployment. Our results show that conditional weight-space modulation effectively restores the expressivity lost under aggressive parameter sharing in recursive transformers.

</details>


### [371] [Unsupervised learning of multiscale switching dynamical system models from multimodal neural data](https://arxiv.org/abs/2512.12881)
*DongKyu Kim,Han-Lin Hsieh,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出一种无监督学习算法，用于学习具有切换动力学的多尺度神经动态系统模型，能够同时处理连续和离散神经信号，在模拟和实验数据中表现优于单尺度模型和静态多尺度模型。


<details>
  <summary>Details</summary>
Motivation: 神经群体活动常表现出依赖于状态的切换动态，现有方法主要针对单一神经模态（连续高斯信号或离散泊松信号），而实际中常同时记录多种模态来测量不同时空尺度的脑活动。此外，训练数据通常缺乏状态标签，这给学习切换动态模型带来了挑战。

Method: 开发了一种新颖的无监督学习算法，仅使用多尺度神经观测数据来学习切换多尺度动态系统模型的参数。该方法能够同时处理连续和离散神经信号，并在模拟和两个不同的实验数据集（包含多模态尖峰-LFP观测）上进行验证。

Result: 切换多尺度动态系统模型比切换单尺度动态模型更准确地解码行为，显示了多尺度神经融合的成功。此外，该模型优于静态多尺度模型，说明了在多元神经数据中跟踪状态依赖非平稳性的重要性。

Conclusion: 该无监督学习框架通过利用多模态记录中的信息并结合状态切换，能够更准确地建模复杂的多尺度神经动态。这种方法有望提高脑机接口的性能和鲁棒性，并增进对行为神经基础的理解。

Abstract: Neural population activity often exhibits regime-dependent non-stationarity in the form of switching dynamics. Learning accurate switching dynamical system models can reveal how behavior is encoded in neural activity. Existing switching approaches have primarily focused on learning models from a single neural modality, either continuous Gaussian signals or discrete Poisson signals. However, multiple neural modalities are often recorded simultaneously to measure different spatiotemporal scales of brain activity, and all these modalities can encode behavior. Moreover, regime labels are typically unavailable in training data, posing a significant challenge for learning models of regime-dependent switching dynamics. To address these challenges, we develop a novel unsupervised learning algorithm that learns the parameters of switching multiscale dynamical system models using only multiscale neural observations. We demonstrate our method using both simulations and two distinct experimental datasets with multimodal spike-LFP observations during different motor tasks. We find that our switching multiscale dynamical system models more accurately decode behavior than switching single-scale dynamical models, showing the success of multiscale neural fusion. Further, our models outperform stationary multiscale models, illustrating the importance of tracking regime-dependent non-stationarity in multimodal neural data. The developed unsupervised learning framework enables more accurate modeling of complex multiscale neural dynamics by leveraging information in multimodal recordings while incorporating regime switches. This approach holds promise for improving the performance and robustness of brain-computer interfaces over time and for advancing our understanding of the neural basis of behavior.

</details>


### [372] [Distillation of Discrete Diffusion by Exact Conditional Distribution Matching](https://arxiv.org/abs/2512.12889)
*Yansong Gao,Yu Sun*

Main category: cs.LG

TL;DR: 提出基于条件分布匹配的离散扩散模型蒸馏方法，通过匹配教师模型和学生模型的条件分布来加速推理，无需近似模拟器或代理目标训练


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型(DDMs)虽然对分类数据生成强大，但单次采样需要大量函数评估，推理成本高。现有加速方法要么依赖近似模拟器，要么需要训练新学生模型和代理目标，不够理想

Method: 基于条件分布匹配的蒸馏方法。关键观察：干净数据给定噪声状态的反向条件分布$p_{0|t}(x_0|x_t)$可通过中间时间进行马尔可夫分解，并能从边缘密度比和已知前向CTMC核恢复。利用此结构定义蒸馏目标，直接匹配预训练教师和低NFE学生之间的条件分布，适用于单步和多步采样器

Result: 该方法提供了一种简单而原则性的蒸馏替代方案，能够直接匹配条件分布，避免了近似模拟器的误差和复杂代理目标的训练

Conclusion: 提出的条件分布匹配蒸馏方法为离散扩散模型加速提供了一种有效且原则性的解决方案，通过直接匹配条件分布来训练低NFE学生模型，提高了推理效率

Abstract: Discrete diffusion models (DDMs) are a powerful class of generative models for categorical data, but they typically require many function evaluations for a single sample, making inference expensive. Existing acceleration methods either rely on approximate simulators, such as $τ$-leaping, or on distillation schemes that train new student models and auxiliary networks with proxy objectives. We propose a simple and principled distillation alternative based on \emph{conditional distribution matching}. Our key observation is that the reverse conditional distribution of clean data given a noisy state, $p_{0\mid t}(x_0 \mid x_t)$, admits a Markov decomposition through intermediate times and can be recovered from marginal density ratios and the known forward CTMC kernel. We exploit this structure to define distillation objectives that directly match conditional distributions between a pre-trained teacher and a low-NFE student, both for one-step and few-step samplers.

</details>


### [373] [Wait, Wait, Wait... Why Do Reasoning Models Loop?](https://arxiv.org/abs/2512.12895)
*Charilaos Pipis,Shivam Garg,Vasilis Kontonis,Vaishnavi Shrivastava,Akshay Krishnamurthy,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: 研究发现推理模型在低温或贪婪解码时容易出现文本循环重复，主要原因是学习误差和Transformer的归纳偏差，温度调节只是权宜之计而非根本解决方案。


<details>
  <summary>Details</summary>
Motivation: 推理模型（如DeepSeek-R1）在解决复杂问题时会产生长思维链，但在低温或贪婪解码时经常出现文本循环重复现象。研究旨在探究这种现象的原因以及温度在其中扮演的角色。

Method: 使用开源推理模型研究循环现象，分析模型大小、蒸馏等因素的影响。引入合成图推理任务来演示两种机制：1）学习难度导致的风险规避；2）Transformer对时间相关错误的归纳偏差。通过温度调节实验观察其对循环的影响。

Result: 研究发现：1）低温下循环现象普遍；2）大模型循环较少，蒸馏学生模型循环严重；3）学习误差是主要原因；4）温度升高通过促进探索减少循环，但无法修复学习误差，导致生成文本仍然过长。

Conclusion: 温度调节只是缓解循环的权宜之计，而非根本解决方案。需要在训练时进行干预来直接减少学习误差，才能从根本上解决推理模型的循环问题。

Abstract: Reasoning models (e.g., DeepSeek-R1) generate long chains of thought to solve harder problems, but they often loop, repeating the same text at low temperatures or with greedy decoding. We study why this happens and what role temperature plays. With open reasoning models, we find that looping is common at low temperature. Larger models tend to loop less, and distilled students loop significantly even when their teachers rarely do. This points to mismatches between the training distribution and the learned model, which we refer to as errors in learning, as a key cause. To understand how such errors cause loops, we introduce a synthetic graph reasoning task and demonstrate two mechanisms. First, risk aversion caused by hardness of learning: when the correct progress-making action is hard to learn but an easy cyclic action is available, the model puts relatively more probability on the cyclic action and gets stuck. Second, even when there is no hardness, Transformers show an inductive bias toward temporally correlated errors, so the same few actions keep being chosen and loops appear. Higher temperature reduces looping by promoting exploration, but it does not fix the errors in learning, so generations remain much longer than necessary at high temperature; in this sense, temperature is a stopgap rather than a holistic solution. We end with a discussion of training-time interventions aimed at directly reducing errors in learning.

</details>


### [374] [Probability Estimation for Predicted-Occupancy Grids in Vehicle Safety Applications Based on Machine Learning](https://arxiv.org/abs/2512.12896)
*Parthasarathy Nadarajan,Michael Botsch*

Main category: cs.LG

TL;DR: 提出一种预测复杂交通场景演化的方法，使用预测占据网格(POG)作为未来场景假设的概率表示，通过机器学习方法实现实时计算


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的预测方法计算量过大，无法实时处理复杂交通场景中多个交通参与者的不确定性行为预测

Method: 提出两种方法：1) 基于模型的POG计算方法；2) 基于随机森林的机器学习方法，使用增强占据网格表示当前交通状态并映射到POG

Result: 机器学习方法相比基于模型方法在模拟交通场景中表现良好，有望实现POG的实时计算

Conclusion: 该方法能够详细建模交通参与者的行为不确定性，可改进车辆安全系统中的关键性评估和轨迹规划等关键组件

Abstract: This paper presents a method to predict the evolution of a complex traffic scenario with multiple objects. The current state of the scenario is assumed to be known from sensors and the prediction is taking into account various hypotheses about the behavior of traffic participants. This way, the uncertainties regarding the behavior of traffic participants can be modelled in detail. In the first part of this paper a model-based approach is presented to compute Predicted-Occupancy Grids (POG), which are introduced as a grid-based probabilistic representation of the future scenario hypotheses. However, due to the large number of possible trajectories for each traffic participant, the model-based approach comes with a very high computational load. Thus, a machine-learning approach is adopted for the computation of POGs. This work uses a novel grid-based representation of the current state of the traffic scenario and performs the mapping to POGs. This representation consists of augmented cells in an occupancy grid. The adopted machine-learning approach is based on the Random Forest algorithm. Simulations of traffic scenarios are performed to compare the machine-learning with the model-based approach. The results are promising and could enable the real-time computation of POGs for vehicle safety applications. With this detailed modelling of uncertainties, crucial components in vehicle safety systems like criticality estimation and trajectory planning can be improved.

</details>


### [375] [Predicted-occupancy grids for vehicle safety applications based on autoencoders and the Random Forest algorithm](https://arxiv.org/abs/2512.12901)
*Parthasarathy Nadarajan,Michael Botsch,Sebastian Sardina*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的概率时空表示方法（POG），用于预测复杂交通场景中参与者的未来行为，并通过SDA降维和RF预测提高准确性。


<details>
  <summary>Details</summary>
Motivation: 为主动车辆安全应用提供复杂交通场景的概率时空预测，特别是在执行动态机动操作时，需要准确预测交通参与者的未来行为。

Method: 1. 使用分层情境分类器识别道路基础设施和安全相关交通参与者类型；2. 通过堆叠降噪自编码器（SDA）将增强占用网格（AOG）降维为低维特征；3. 针对每个场景类别训练随机森林（RF）预测概率时空表示（POG）。

Result: 在仿真和真实车辆实验中展示了SDA+RF方法的优异性能，并成功将POG应用于交通场景关键性评估和安全轨迹确定。

Conclusion: 提出的机器学习方法能有效预测复杂交通场景的概率时空表示，为主动安全系统提供可靠的行为预测和风险评估能力。

Abstract: In this paper, a probabilistic space-time representation of complex traffic scenarios is predicted using machine learning algorithms. Such a representation is significant for all active vehicle safety applications especially when performing dynamic maneuvers in a complex traffic scenario. As a first step, a hierarchical situation classifier is used to distinguish the different types of traffic scenarios. This classifier is responsible for identifying the type of the road infrastructure and the safety-relevant traffic participants of the driving environment. With each class representing similar traffic scenarios, a set of Random Forests (RFs) is individually trained to predict the probabilistic space-time representation, which depicts the future behavior of traffic participants. This representation is termed as a Predicted-Occupancy Grid (POG). The input to the RFs is an Augmented Occupancy Grid (AOG). In order to increase the learning accuracy of the RFs and to perform better predictions, the AOG is reduced to low-dimensional features using a Stacked Denoising Autoencoder (SDA). The excellent performance of the proposed machine learning approach consisting of SDAs and RFs is demonstrated in simulations and in experiments with real vehicles. An application of POGs to estimate the criticality of traffic scenarios and to determine safe trajectories is also presented.

</details>


### [376] [Next-generation reservoir computing validated by classification task](https://arxiv.org/abs/2512.12903)
*Ken-ichi Kitayama*

Main category: cs.LG

TL;DR: NG-RC无需实际储层，直接从时间序列计算多项式项，首次验证其在分类任务上与传统储层计算性能相当


<details>
  <summary>Details</summary>
Motivation: 现有NG-RC基准测试局限于时间波形预测任务（如Lorenz 63吸引子和Mackey-Glass混沌信号），需要验证其在分类任务上的能力以证明其通用计算能力

Method: NG-RC（下一代储层计算）无需实际储层进行输入数据混合，而是直接从时间序列输入计算多项式项

Result: 首次证明NG-RC在分类任务上能够达到与传统储层计算相当的性能水平

Conclusion: NG-RC在预测和分类任务上都展现出强大的计算能力，验证了其作为通用计算范式的潜力

Abstract: An emerging computing paradigm, so-called next-generation reservoir computing (NG-RC) is investigated. True to its namesake, NG-RC requires no actual reservoirs for input data mixing but rather computing the polynomial terms directly from the time series inputs. However, benchmark tests so far reported have been one-sided, limited to prediction tasks of temporal waveforms such as Lorenz 63 attractor and Mackey-Glass chaotic signal. We will demonstrate for the first time that NG-RC can perform classification task as good as conventional RC. This validates the versatile computational capability of NG-RC in tasks of both prediction and classification.

</details>


### [377] [Machine Learning Architectures for the Estimation of Predicted Occupancy Grids in Road Traffic](https://arxiv.org/abs/2512.12907)
*Parthasarathy Nadarajan,Michael Botsch,Sebastian Sardina*

Main category: cs.LG

TL;DR: 提出一种新颖的机器学习架构，用于高效估计复杂交通场景的概率时空表示，通过堆叠去噪自编码器和随机森林预测未来交通状态。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和主动安全系统需要详细的未来交通场景表示，但现有方法在准确性和计算效率方面存在不足，需要开发更有效的概率预测方法。

Method: 采用两阶段方法：首先识别交通场景类型，然后通过机器学习将当前状态映射到可能未来状态。使用堆叠去噪自编码器(SDAs)和随机森林的混合架构，输入为增强占用网格(AOG)，输出为预测占用网格(POG)。

Result: 提出的SDAs+随机森林架构在模拟验证中表现出色，在准确性和计算时间方面优于现有的SDAs+DeconvNet架构，能够有效预测包含不确定性的未来交通状态。

Conclusion: 该架构为自动驾驶和主动安全系统提供了高效的概率时空预测能力，POG在主动安全领域具有重要应用价值，未来可进一步优化和扩展。

Abstract: This paper introduces a novel machine learning architecture for an efficient estimation of the probabilistic space-time representation of complex traffic scenarios. A detailed representation of the future traffic scenario is of significant importance for autonomous driving and for all active safety systems. In order to predict the future space-time representation of the traffic scenario, first the type of traffic scenario is identified and then the machine learning algorithm maps the current state of the scenario to possible future states. The input to the machine learning algorithms is the current state representation of a traffic scenario, termed as the Augmented Occupancy Grid (AOG). The output is the probabilistic space-time representation which includes uncertainties regarding the behaviour of the traffic participants and is termed as the Predicted Occupancy Grid (POG). The novel architecture consists of two Stacked Denoising Autoencoders (SDAs) and a set of Random Forests. It is then compared with the other two existing architectures that comprise of SDAs and DeconvNet. The architectures are validated with the help of simulations and the comparisons are made both in terms of accuracy and computational time. Also, a brief overview on the applications of POGs in the field of active safety is presented.

</details>


### [378] [LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization](https://arxiv.org/abs/2512.12922)
*Bangyu Li,Boping Gu,Ziyang Ding*

Main category: cs.LG

TL;DR: 提出基于LLM的个性化投资组合推荐框架，结合大语言模型、强化学习和风险偏好建模，实现智能投资决策


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或静态优化的投资策略无法捕捉投资者行为、市场波动和财务目标之间的非线性交互关系，无法满足现代金融市场对个性化和适应性投资策略的需求

Method: 集成框架结合大语言模型、强化学习和个性化风险偏好建模，支持智能投资决策

Result: 未在摘要中明确说明具体实验结果

Conclusion: 提出的LLM-based Personalized Portfolio Recommender框架能够解决传统方法的局限性，为投资者提供个性化和自适应的投资组合推荐

Abstract: In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender , an integrated framework that combines Large Language Models, reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making.

</details>


### [379] [SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision](https://arxiv.org/abs/2512.12930)
*Yuseon Choi,Sangjin Kim,Jungjun Oh,Byeongcheol Kim,Hoi-Jun Yoo*

Main category: cs.LG

TL;DR: SeVeDo是一种基于SVD的异构加速器，通过将异常值敏感组件分离到高精度低秩路径，其余计算在低比特残差数据路径执行，结合分层组量化和SVD引导混合精度，实现高效Transformer推理。


<details>
  <summary>Details</summary>
Motivation: 低比特量化是高效Transformer推理的有前景技术，但激进位宽减少会因激活异常值导致精度下降。现有方法如异常值处理和组量化虽能保持高精度，但能耗较高。

Method: 提出SeVeDo异构加速器：1) 结构上将异常值敏感组件分离到高精度低秩路径；2) 其余计算在低比特残差数据路径执行，采用组量化；3) 分层组量化(HGQ)结合粗粒度浮点缩放和细粒度移位；4) SVD引导混合精度(SVD-MP)为精度敏感组件静态分配更高位宽。

Result: SeVeDo实现峰值能效13.8TOPS/W，在ViT-Base上达到12.7TOPS/W，在Llama2-7B上达到13.4TOPS/W，优于传统设计。

Conclusion: SeVeDo通过结构分离异常值敏感组件、分层组量化和SVD引导混合精度，在保持精度的同时显著提升Transformer推理的能效，为低比特量化提供了有效的解决方案。

Abstract: Low-bit quantization is a promising technique for efficient transformer inference by reducing computational and memory overhead. However, aggressive bitwidth reduction remains challenging due to activation outliers, leading to accuracy degradation. Existing methods, such as outlier-handling and group quantization, achieve high accuracy but incur substantial energy consumption. To address this, we propose SeVeDo, an energy-efficient SVD-based heterogeneous accelerator that structurally separates outlier-sensitive components into a high-precision low-rank path, while the remaining computations are executed in a low-bit residual datapath with group quantization. To further enhance efficiency, Hierarchical Group Quantization (HGQ) combines coarse-grained floating-point scaling with fine-grained shifting, effectively reducing dequantization cost. Also, SVD-guided mixed precision (SVD-MP) statically allocates higher bitwidths to precision-sensitive components identified through low-rank decomposition, thereby minimizing floating-point operation cost. Experimental results show that SeVeDo achieves a peak energy efficiency of 13.8TOPS/W, surpassing conventional designs, with 12.7TOPS/W on ViT-Base and 13.4TOPS/W on Llama2-7B benchmarks.

</details>


### [380] [Investigating Data Pruning for Pretraining Biological Foundation Models at Scale](https://arxiv.org/abs/2512.12932)
*Yifan Wu,Jiyue Jiang,Xichen Ye,Yiqi Wang,Chang Zhou,Yitao Xu,Jiayang Chen,He Hu,Weizhong Zhang,Cheng Jin,Jiao Yuan,Yu Li*

Main category: cs.LG

TL;DR: 提出一种基于影响力的后处理数据剪枝框架，用于生物基础模型预训练，能在99%剪枝率下超越随机选择，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 生物基础模型需要大量数据和参数，导致计算成本高昂，阻碍学术实验室的可复现性和可访问性，需要高效的数据剪枝方法。

Method: 提出基于子集的自影响力公式，高效估计样本重要性，开发Top-k影响力和覆盖中心影响力两种选择策略，在RNA-FM和ESM-C模型上验证。

Result: 在RNA任务中，99%剪枝率下持续优于随机选择；在蛋白质任务中，剪枝后的核心集性能优于10倍大的随机子集，显示生物序列数据存在大量冗余。

Conclusion: 影响力引导的数据剪枝能大幅降低生物基础模型预训练的计算成本，为更高效、可访问和可持续的生物AI研究铺平道路。

Abstract: Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.

</details>


### [381] [Understanding When Graph Convolutional Networks Help: A Diagnostic Study on Label Scarcity and Structural Properties](https://arxiv.org/abs/2512.12947)
*Nischal Subedi,Ember Kerstetter,Winnie Li,Silo Murphy*

Main category: cs.LG

TL;DR: GCNs在标签极度稀缺时效果最好，能利用图结构补偿有限监督；在高同质性图上即使特征被噪声替换也能保持性能；但在低同质性+强特征时反而会损害性能。


<details>
  <summary>Details</summary>
Motivation: 针对实践中缺乏关于GCN何时比简单基线有显著改进的明确指导，研究旨在理解GCN在什么条件下以及为什么能提供帮助。

Method: 使用Amazon Computers共购数据进行诊断研究，通过系统实验包括模拟标签稀缺、特征消融和按类别分析，考察图同质性与特征质量的交互作用。

Result: GCN性能关键取决于图同质性与特征质量的交互：1）标签极度稀缺时GCN提升最大；2）高同质性图上即使特征被噪声替换也能保持性能；3）低同质性+强特征时GCN会损害性能；4）四象限分析显示GCN在三种条件下有帮助，仅在低同质性+强特征时有害。

Conclusion: GCN在标签稀缺时能有效利用图结构，但在低同质性且特征已很强的情况下应谨慎使用，这为实践者是否采用图方法提供了实用指导。

Abstract: Graph Convolutional Networks (GCNs) have become a standard approach for semi-supervised node classification, yet practitioners lack clear guidance on when GCNs provide meaningful improvements over simpler baselines. We present a diagnostic study using the Amazon Computers co-purchase data to understand when and why GCNs help. Through systematic experiments with simulated label scarcity, feature ablation, and per-class analysis, we find that GCN performance depends critically on the interaction between graph homophily and feature quality. GCNs provide the largest gains under extreme label scarcity, where they leverage neighborhood structure to compensate for limited supervision. Surprisingly, GCNs can match their original performance even when node features are replaced with random noise, suggesting that structure alone carries sufficient signal on highly homophilous graphs. However, GCNs hurt performance when homophily is low and features are already strong, as noisy neighbors corrupt good predictions. Our quadrant analysis reveals that GCNs help in three of four conditions and only hurt when low homophily meets strong features. These findings offer practical guidance for practitioners deciding whether to adopt graph-based methods.

</details>


### [382] [Application of Deep Learning in Biological Data Compression](https://arxiv.org/abs/2512.12975)
*Chunyu Zou*

Main category: cs.LG

TL;DR: 使用隐式神经表示（INR）压缩冷冻电镜数据，通过提取二值图、神经网络编码空间密度信息，结合位置编码和加权MSE损失，实现高效压缩并保持重建质量。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜数据文件存储空间巨大，给研究和教育带来挑战，需要开发高效的压缩方法。

Method: 1) 根据密度阈值提取二值图；2) 使用GZIP压缩重复性高的密度图；3) 训练神经网络编码空间密度信息；4) 加入位置编码增强空间表示；5) 采用加权MSE损失平衡密度分布变化。

Result: 提供实用的冷冻电镜数据压缩解决方案，在保持合理压缩比和重建质量的同时，适用于教育和研究目的。

Conclusion: 深度学习方法特别是INR能有效压缩冷冻电镜生物数据，为研究和教育提供高效的数据管理方案。

Abstract: Cryogenic electron microscopy (Cryo-EM) has become an essential tool for capturing high-resolution biological structures. Despite its advantage in visualizations, the large storage size of Cryo-EM data file poses significant challenges for researchers and educators. This paper investigates the application of deep learning, specifically implicit neural representation (INR), to compress Cryo-EM biological data. The proposed approach first extracts the binary map of each file according to the density threshold. The density map is highly repetitive, ehich can be effectively compressed by GZIP. The neural network then trains to encode spatial density information, allowing the storage of network parameters and learnable latent vectors. To improve reconstruction accuracy, I further incorporate the positional encoding to enhance spatial representation and a weighted Mean Squared Error (MSE) loss function to balance density distribution variations. Using this approach, my aim is to provide a practical and efficient biological data compression solution that can be used for educational and research purpose, while maintaining a reasonable compression ratio and reconstruction quality from file to file.

</details>


### [383] [CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks](https://arxiv.org/abs/2512.12981)
*Jonathan Wenshøj,Tong Chen,Bob Pepin,Raghavendra Selvan*

Main category: cs.LG

TL;DR: CoDeQ提出了一种完全可微的联合剪枝-量化方法，通过量化器的死区宽度参数化实现稀疏性控制，无需额外辅助过程，在保持精度的同时显著减少比特操作。


<details>
  <summary>Details</summary>
Motivation: 现有联合剪枝-量化方法依赖训练循环外的辅助过程来确定压缩参数，这增加了工程复杂性、需要超参数调优，且缺乏直接的数据驱动梯度信号，可能导致次优压缩。

Method: CoDeQ基于关键观察：标量量化器的死区等价于幅度剪枝，可用于在量化算子内直接诱导稀疏性。具体通过参数化死区宽度并通过反向传播学习，同时学习量化参数，提供明确的稀疏性控制，解耦稀疏性选择与比特宽度选择。

Result: 在ImageNet上使用ResNet-18，CoDeQ将比特操作减少到约5%，同时在固定精度和混合精度机制下保持接近全精度准确率。

Conclusion: CoDeQ是一种简单、完全可微的联合剪枝-量化方法，无需辅助过程，架构无关且易于实现，能够同时确定稀疏模式和量化参数，实现端到端优化。

Abstract: While joint pruning--quantization is theoretically superior to sequential application, current joint methods rely on auxiliary procedures outside the training loop for finding compression parameters. This reliance adds engineering complexity and hyperparameter tuning, while also lacking a direct data-driven gradient signal, which might result in sub-optimal compression. In this paper, we introduce CoDeQ, a simple, fully differentiable method for joint pruning--quantization. Our approach builds on a key observation: the dead-zone of a scalar quantizer is equivalent to magnitude pruning, and can be used to induce sparsity directly within the quantization operator. Concretely, we parameterize the dead-zone width and learn it via backpropagation, alongside the quantization parameters. This design provides explicit control of sparsity, regularized by a single global hyperparameter, while decoupling sparsity selection from bit-width selection. The result is a method for Compression with Dead-zone Quantizer (CoDeQ) that supports both fixed-precision and mixed-precision quantization (controlled by an optional second hyperparameter). It simultaneously determines the sparsity pattern and quantization parameters in a single end-to-end optimization. Consequently, CoDeQ does not require any auxiliary procedures, making the method architecture-agnostic and straightforward to implement. On ImageNet with ResNet-18, CoDeQ reduces bit operations to ~5% while maintaining close to full precision accuracy in both fixed and mixed-precision regimes.

</details>


### [384] [Deep Learning-Driven Inversion Framework for Shear Modulus Estimation in Magnetic Resonance Elastography (DIME)](https://arxiv.org/abs/2512.13010)
*Hassan Iftikhar,Rizwan Ahmad,Arunark Kolipaka*

Main category: cs.LG

TL;DR: 提出DIME深度學習框架，用於磁共振彈性成像中剪切模量估計，相比傳統MMDI方法具有更好的魯棒性和準確性。


<details>
  <summary>Details</summary>
Motivation: 傳統MMDI算法基於Helmholtz方程，假設波在均勻、無限介質中傳播，且使用拉普拉斯算子對噪聲敏感，導致剛度估計準確性和可靠性受限。

Method: 提出DIME深度學習框架，使用有限元模擬生成的位移場-剛度圖對進行訓練。為捕捉局部波行為並提高對全局圖像變化的魯棒性，在小型圖像塊上訓練。

Result: 在合成數據上，DIME產生低像素間變異性、準確邊界描繪的剛度圖，與真實值相關性高於MMDI。在真實肝臟數據中，DIME保持生理一致的剛度模式，與MMDI結果相近但無方向性偏差。

Conclusion: DIME相比傳統MMDI方法具有更高準確性和魯棒性，初步結果顯示其在臨床MRE應用中的可行性，能減少方向性濾波帶來的偏差。

Abstract: The Multimodal Direct Inversion (MMDI) algorithm is widely used in Magnetic Resonance Elastography (MRE) to estimate tissue shear stiffness. However, MMDI relies on the Helmholtz equation, which assumes wave propagation in a uniform, homogeneous, and infinite medium. Furthermore, the use of the Laplacian operator makes MMDI highly sensitive to noise, which compromises the accuracy and reliability of stiffness estimates. In this study, we propose the Deep-Learning driven Inversion Framework for Shear Modulus Estimation in MRE (DIME), aimed at enhancing the robustness of inversion. DIME is trained on the displacement fields-stiffness maps pair generated through Finite Element Modelling (FEM) simulations. To capture local wave behavior and improve robustness to global image variations, DIME is trained on small image patches. We first validated DIME using homogeneous and heterogeneous datasets simulated with FEM, where DIME produced stiffness maps with low inter-pixel variability, accurate boundary delineation, and higher correlation with ground truth (GT) compared to MMDI. Next, DIME was evaluated in a realistic anatomy-informed simulated liver dataset with known GT and compared directly to MMDI. DIME reproduced ground-truth stiffness patterns with high fidelity (r = 0.99, R^2 = 0.98), while MMDI showed greater underestimation. After validating DIME on synthetic data, we tested the model in in vivo liver MRE data from eight healthy and seven fibrotic subjects. DIME preserved physiologically consistent stiffness patterns and closely matched MMDI, which showed directional bias. Overall, DIME showed higher correlation with ground truth and visually similar stiffness patterns, whereas MMDI displayed a larger bias that can potentially be attributed to directional filtering. These preliminary results highlight the feasibility of DIME for clinical applications in MRE.

</details>


### [385] [Scaling Bidirectional Spans and Span Violations in Attention Mechanism](https://arxiv.org/abs/2512.13033)
*Jongwook Kim,Sangheon Yun,Sukjin Yoon*

Main category: cs.LG

TL;DR: 提出一个优化Transformer训练框架，通过非对称投影将反向传播梯度分解为平行分量和正交违规分量，保持前向QKV结构不变，在WikiText-2上验证损失降低0.56%


<details>
  <summary>Details</summary>
Motivation: 标准Transformer在序列建模中表现优异，但其训练存在几何效率问题。标准注意力梯度可能不是最优的，可以通过优化梯度结构来提升训练效率

Method: 使用非对称投影将反向传播梯度分解为平行分量和正交违规分量，保持前向QKV结构不变。通过选择性缩放这些分量，重点关注0阶双向平行分量，以产生更有效的学习信号

Result: 在WikiText-2数据集上，使用简单配置实现了0.56%的验证损失降低，证明了框架的基本有效性，并表明在更大数据集和更深训练机制上有显著潜力

Conclusion: 标准注意力梯度是次优的，提出的优化框架通过梯度分解和选择性缩放能有效提升Transformer训练效率，为大规模应用提供了有前景的方向

Abstract: The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes

</details>


### [386] [Alada: Alternating Adaptation of Momentum Method for Memory-Efficient Matrix Optimization](https://arxiv.org/abs/2512.13034)
*Xiaoyu He,Yu Cai,Jin Jia,Canxi Huang,Wenqing Chen,Zibin Zheng*

Main category: cs.LG

TL;DR: Alada是一种用于大规模矩阵随机优化的自适应动量方法，通过秩一分解估计梯度二阶矩，具有次线性内存开销，性能与Adam相当但内存更高效。


<details>
  <summary>Details</summary>
Motivation: 传统自适应优化方法（如Adam）在处理大规模矩阵优化时内存开销巨大，需要存储完整的二阶矩矩阵。Alada旨在解决这一问题，通过更高效的内存使用方式实现大规模模型的训练。

Method: Alada采用秩一分解方法估计梯度的二阶矩，通过交替更新因子来最小化估计误差。该方法还配备了一阶矩估计规则以增强算法鲁棒性，且不增加额外内存开销。算法可扩展到张量形状变量。

Result: 在多个自然语言处理任务上的数值研究表明，Alada相比Adam及其变体显著减少了内存开销，同时在训练大型模型时表现出更好的鲁棒性。理论性能与Adam相当。

Conclusion: Alada提供了一种内存高效的替代方案，用于大规模矩阵和张量的随机优化，在保持与传统自适应方法相当性能的同时，显著降低了内存需求。

Abstract: This work proposes Alada, an adaptive momentum method for stochastic optimization over large-scale matrices. Alada employs a rank-one factorization approach to estimate the second moment of gradients, where factors are updated alternatively to minimize the estimation error. Alada achieves sublinear memory overheads and can be readily extended to optimizing tensor-shaped variables.We also equip Alada with a first moment estimation rule, which enhances the algorithm's robustness without incurring additional memory overheads. The theoretical performance of Alada aligns with that of traditional methods such as Adam. Numerical studies conducted on several natural language processing tasks demonstrate the reduction in memory overheads and the robustness in training large models relative to Adam and its variants.

</details>


### [387] [Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection](https://arxiv.org/abs/2512.13040)
*Xuwei Tan,Yao Ma,Xueru Zhang*

Main category: cs.LG

TL;DR: FinFRE-RAG：两阶段方法，通过重要性引导的特征缩减将表格数据序列化为自然语言，结合检索增强的上下文学习，提升LLM在欺诈检测中的性能，同时提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统表格模型在欺诈检测中需要大量特征工程且可解释性差，而LLM虽然能提供人类可读的解释，但直接应用于表格数据时性能不佳，难以处理高维特征、极端类别不平衡和缺乏上下文信息的问题。

Method: 提出FinFRE-RAG两阶段方法：1）重要性引导的特征缩减，将数值/分类属性序列化为自然语言；2）检索增强的上下文学习，使用标签感知的实例级示例进行推理。

Result: 在四个公共欺诈数据集和三类开源LLM上，FinFRE-RAG显著优于直接提示方法，在多个场景中与强大的表格基线模型竞争，缩小了与专用分类器的性能差距。

Conclusion: 虽然LLM仍落后于专用分类器，但FinFRE-RAG缩小了性能差距并提供了可解释的推理，凸显了LLM作为欺诈分析辅助工具的价值。

Abstract: Detecting fraud in financial transactions typically relies on tabular models that demand heavy feature engineering to handle high-dimensional data and offer limited interpretability, making it difficult for humans to understand predictions. Large Language Models (LLMs), in contrast, can produce human-readable explanations and facilitate feature analysis, potentially reducing the manual workload of fraud analysts and informing system refinements. However, they perform poorly when applied directly to tabular fraud detection due to the difficulty of reasoning over many features, the extreme class imbalance, and the absence of contextual information. To bridge this gap, we introduce FinFRE-RAG, a two-stage approach that applies importance-guided feature reduction to serialize a compact subset of numeric/categorical attributes into natural language and performs retrieval-augmented in-context learning over label-aware, instance-level exemplars. Across four public fraud datasets and three families of open-weight LLMs, FinFRE-RAG substantially improves F1/MCC over direct prompting and is competitive with strong tabular baselines in several settings. Although these LLMs still lag behind specialized classifiers, they narrow the performance gap and provide interpretable rationales, highlighting their value as assistive tools in fraud analysis.

</details>


### [388] [Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments](https://arxiv.org/abs/2512.13060)
*Kangning Gao,Yi Hu,Cong Nie,Wei Li*

Main category: cs.LG

TL;DR: 提出基于深度Q学习的ETL智能调度优化框架，将调度过程建模为马尔可夫决策过程，通过强化学习智能体在高维状态空间中自适应决策，动态优化任务分配和资源调度，显著降低调度延迟、提高系统吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决异构数据环境下ETL流程存在的调度效率低、资源分配不均衡、适应性差等问题。传统调度方法难以应对复杂多变的数据环境，需要更智能、自适应的调度策略。

Method: 提出基于深度Q学习的智能调度优化框架：1) 将ETL调度过程形式化为马尔可夫决策过程；2) 构建包含状态表示模块、特征嵌入网络、Q值估计器和奖励评估机制的系统模型；3) 考虑任务依赖关系、节点负载状态和数据流特征；4) 设计多目标奖励函数平衡调度延迟、任务完成率、吞吐量和资源利用率等关键指标。

Result: 实验结果表明：该框架显著降低了调度延迟，提高了系统吞吐量，增强了多源异构任务条件下的执行稳定性。敏感性实验验证了模型在超参数变化、环境动态性和数据规模变化下的鲁棒性。

Conclusion: 深度Q学习调度框架展示了强化学习在复杂数据调度和资源管理中的强大潜力，为智能数据管道构建提供了高效、可扩展的优化策略，能够有效应对异构数据环境下的调度挑战。

Abstract: This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framework formalizes the ETL scheduling process as a Markov Decision Process and enables adaptive decision-making by a reinforcement learning agent in high-dimensional state spaces to dynamically optimize task allocation and resource scheduling. The model consists of a state representation module, a feature embedding network, a Q-value estimator, and a reward evaluation mechanism, which collectively consider task dependencies, node load states, and data flow characteristics to derive the optimal scheduling strategy in complex environments. A multi-objective reward function is designed to balance key performance indicators such as average scheduling delay, task completion rate, throughput, and resource utilization. Sensitivity experiments further verify the model's robustness under changes in hyperparameters, environmental dynamics, and data scale. Experimental results show that the proposed deep Q-learning scheduling framework significantly reduces scheduling delay, improves system throughput, and enhances execution stability under multi-source heterogeneous task conditions, demonstrating the strong potential of reinforcement learning in complex data scheduling and resource management, and providing an efficient and scalable optimization strategy for intelligent data pipeline construction.

</details>


### [389] [Multi-fidelity aerodynamic data fusion by autoencoder transfer learning](https://arxiv.org/abs/2512.13069)
*Javier Nieto-Centenero,Esther Andrés,Rodrigo Castellanos*

Main category: cs.LG

TL;DR: 提出一种结合自动编码器迁移学习和多分割保形预测的多保真度深度学习框架，用于数据稀缺条件下的空气动力学不确定性预测


<details>
  <summary>Details</summary>
Motivation: 高保真度空气动力学模拟计算成本过高，限制了数据驱动建模的应用。需要开发多保真度策略，利用低成本低保真度信息而不牺牲精度

Method: 结合自动编码器迁移学习和新开发的多分割保形预测策略。利用丰富的低保真度数据学习紧凑的潜在物理表示，作为冻结知识库，然后使用稀缺的高保真度样本微调解码器

Result: 在NACA翼型（2D）和跨音速机翼（3D）数据库的表面压力分布测试中，模型成功校正了低保真度偏差，使用极少的高保真度训练数据实现了高精度压力预测。MSCP框架产生稳健、可操作的不确定性带，点覆盖超过95%

Conclusion: 通过结合极端数据效率和不确定性量化，这项工作为数据稀缺环境中的空气动力学回归提供了可扩展且可靠的解决方案

Abstract: Accurate aerodynamic prediction often relies on high-fidelity simulations; however, their prohibitive computational costs severely limit their applicability in data-driven modeling. This limitation motivates the development of multi-fidelity strategies that leverage inexpensive low-fidelity information without compromising accuracy. Addressing this challenge, this work presents a multi-fidelity deep learning framework that combines autoencoder-based transfer learning with a newly developed Multi-Split Conformal Prediction (MSCP) strategy to achieve uncertainty-aware aerodynamic data fusion under extreme data scarcity. The methodology leverages abundant Low-Fidelity (LF) data to learn a compact latent physics representation, which acts as a frozen knowledge base for a decoder that is subsequently fine-tuned using scarce HF samples. Tested on surface-pressure distributions for NACA airfoils (2D) and a transonic wing (3D) databases, the model successfully corrects LF deviations and achieves high-accuracy pressure predictions using minimal HF training data. Furthermore, the MSCP framework produces robust, actionable uncertainty bands with pointwise coverage exceeding 95%. By combining extreme data efficiency with uncertainty quantification, this work offers a scalable and reliable solution for aerodynamic regression in data-scarce environments.

</details>


### [390] [LikeBench: Evaluating Subjective Likability in LLMs for Personalization](https://arxiv.org/abs/2512.13077)
*Md Awsafur Rahman,Adam Gabrys,Doug Kang,Jingjing Sun,Tian Tan,Ashwin Chandramouli*

Main category: cs.LG

TL;DR: LikeBench：首个将LLM个性化评估从记忆和应用扩展到"喜好度"的多维度动态评估框架，包含7个诊断指标，发现记忆准确性与喜好度不相关


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化基准主要关注记忆用户信息和应用记忆信息两个维度，但忽略了主观且对用户体验至关重要的"喜好度"维度，当前基准对此测量不足

Method: 提出LikeBench多会话动态评估框架，让LLM与模拟用户对话，仅从对话中学习偏好，并在每次交互后从7个维度评估喜好度：情感适应、正式度匹配、知识适应、引用理解、对话长度适应、幽默适应和回调。使用细粒度、心理学基础的人物描述而非粗糙的高/低特质评分

Result: 记忆性能强不代表喜好度高：DeepSeek R1记忆准确率较低（86%，17个事实/档案）但在喜好度得分上比Qwen3高28%，尽管Qwen3记忆准确率更高（93%，43个事实/档案）。即使是SOTA模型如GPT-5在短对话中适应良好，但在更长、更嘈杂的交互中表现有限

Conclusion: 喜好度是LLM个性化的重要维度，需要专门的评估框架。LikeBench提供了更全面、细粒度的评估方法，揭示了记忆准确性与喜好度之间的脱节，为未来个性化LLM研究提供了新方向

Abstract: A personalized LLM should remember user facts, apply them correctly, and adapt over time to provide responses that the user prefers. Existing LLM personalization benchmarks are largely centered on two axes: accurately recalling user information and accurately applying remembered information in downstream tasks. We argue that a third axis, likability, is both subjective and central to user experience, yet under-measured by current benchmarks. To measure likability holistically, we introduce LikeBench, a multi-session, dynamic evaluation framework that measures likability across multiple dimensions by how much an LLM can adapt over time to a user's preferences to provide more likable responses. In LikeBench, the LLMs engage in conversation with a simulated user and learn preferences only from the ongoing dialogue. As the interaction unfolds, models try to adapt to responses, and after each turn, they are evaluated for likability across seven dimensions by the same simulated user. To the best of our knowledge, we are the first to decompose likability into multiple diagnostic metrics: emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length fit, humor fit, and callback, which makes it easier to pinpoint where a model falls short. To make the simulated user more realistic and discriminative, LikeBench uses fine-grained, psychologically grounded descriptive personas rather than the coarse high/low trait rating based personas used in prior work. Our benchmark shows that strong memory performance does not guarantee high likability: DeepSeek R1, with lower memory accuracy (86%, 17 facts/profile), outperformed Qwen3 by 28% on likability score despite Qwen3's higher memory accuracy (93%, 43 facts/profile). Even SOTA models like GPT-5 adapt well in short exchanges but show only limited robustness in longer, noisier interactions.

</details>


### [391] [TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning](https://arxiv.org/abs/2512.13106)
*Shenzhi Yang,Guangcheng Zhu,Xing Zheng,Yingfan MA,Zhongqi Chen,Bowen Song,Weiqiang Wang,Junbo Zhao,Gang Chen,Haobo Wang*

Main category: cs.LG

TL;DR: TraPO提出了一种半监督RLVR方法，通过少量标注样本指导无标注样本的训练，有效解决了无监督RLVR中的模型崩溃问题，在数学推理任务上取得了显著的数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法依赖大量标注数据成本高，而无监督RLVR方法容易在训练后期出现模型崩溃，因为缺乏外部监督会强化错误的推理模式。需要一种既能减少标注成本又能保持训练稳定性的方法。

Method: 提出半监督RLVR范式TraPO，利用少量标注样本指导无标注样本的训练。核心是通过匹配无标注样本与标注样本的学习轨迹相似性来识别可靠的无标注样本，确保只有经过标注样本验证的推理模式被纳入强化学习训练。

Result: 在6个数学推理基准测试和3个分布外任务上表现出色。仅用1K标注+3K无标注样本达到42.6%平均准确率，超越使用45K无标注样本的最佳无监督方法（38.3%）。使用4K标注+12K无标注样本时，在所有基准测试上超越使用全部45K标注样本的完全监督模型，仅使用10%的标注数据。

Conclusion: TraPO通过半监督RLVR方法有效解决了无监督RLVR的模型崩溃问题，显著提高了数据效率和泛化能力，证明了少量标注样本对稳定一致性训练的重要性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.

</details>


### [392] [From Overfitting to Reliability: Introducing the Hierarchical Approximate Bayesian Neural Network](https://arxiv.org/abs/2512.13111)
*Hayk Amirkhanian,Marco F. Huber*

Main category: cs.LG

TL;DR: 提出分层近似贝叶斯神经网络，使用高斯-逆Wishart分布作为权重超先验，提高模型鲁棒性和性能，提供解析预测分布和权重后验，复杂度线性于权重数量。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络存在超参数调优和过拟合问题，贝叶斯神经网络通过纳入不确定性可提供更可靠的预测，尤其对于分布外数据。但现有方法仍有改进空间。

Method: 提出分层近似贝叶斯神经网络，使用高斯-逆Wishart分布作为网络权重的超先验。该方法提供预测分布和权重后验的解析表示，计算复杂度与权重数量呈线性关系。

Result: 实验结果表明HABNN不仅匹配且经常超越最先进模型，有效解决过拟合问题并提供可靠的分布外不确定性估计。

Conclusion: HABNN为贝叶斯神经网络提供了一种有前景的新方法，特别适用于安全关键环境，在保持高性能的同时提供可靠的预测不确定性。

Abstract: In recent years, neural networks have revolutionized various domains, yet challenges such as hyperparameter tuning and overfitting remain significant hurdles. Bayesian neural networks offer a framework to address these challenges by incorporating uncertainty directly into the model, yielding more reliable predictions, particularly for out-of-distribution data. This paper presents Hierarchical Approximate Bayesian Neural Network, a novel approach that uses a Gaussian-inverse-Wishart distribution as a hyperprior of the network's weights to increase both the robustness and performance of the model. We provide analytical representations for the predictive distribution and weight posterior, which amount to the calculation of the parameters of Student's t-distributions in closed form with linear complexity with respect to the number of weights. Our method demonstrates robust performance, effectively addressing issues of overfitting and providing reliable uncertainty estimates, particularly for out-of-distribution tasks. Experimental results indicate that HABNN not only matches but often outperforms state-of-the-art models, suggesting a promising direction for future applications in safety-critical environments.

</details>


### [393] [Quanvolutional Neural Networks for Spectrum Peak-Finding](https://arxiv.org/abs/2512.13125)
*Lukas Bischof,Rudolf M. Füchslin,Kurt Stockinger,Pavel Sulimov*

Main category: cs.LG

TL;DR: 量子卷积神经网络在NMR谱峰分析中超越经典CNN，F1分数提升11%，位置估计误差降低30%


<details>
  <summary>Details</summary>
Motivation: NMR等光谱的峰分析（去卷积）对专家和机器都具挑战性，量子计算有望增强现有机器学习技术，特别是受经典CNN成功启发，探索量子卷积神经网络在峰分析任务中的应用潜力

Method: 设计简单可解释的QuanvNN架构，可直接与经典CNN对比，在合成NMR数据集上评估多任务峰分析性能（峰计数和位置估计）

Result: QuanvNN在挑战性光谱上优于经典CNN：F1分数提升11%，峰位置估计的平均绝对误差降低30%，且在更困难问题上表现出更好的收敛稳定性

Conclusion: 量子卷积神经网络在光谱分析任务中展现出优于经典方法的潜力，特别是在复杂分子光谱的峰识别和定位方面，为量子机器学习在科学数据分析中的应用提供了实证支持

Abstract: The analysis of spectra, such as Nuclear Magnetic Resonance (NMR) spectra, for the comprehensive characterization of peaks is a challenging task for both experts and machines, especially with complex molecules. This process, also known as deconvolution, involves identifying and quantifying the peaks in the spectrum. Machine learning techniques have shown promising results in automating this process. With the advent of quantum computing, there is potential to further enhance these techniques. In this work, inspired by the success of classical Convolutional Neural Networks (CNNs), we explore the use of Quanvolutional Neural Networks (QuanvNNs) for the multi-task peak finding problem, involving both peak counting and position estimation. We implement a simple and interpretable QuanvNN architecture that can be directly compared to its classical CNN counterpart, and evaluate its performance on a synthetic NMR-inspired dataset. Our results demonstrate that QuanvNNs outperform classical CNNs on challenging spectra, achieving an 11\% improvement in F1 score and a 30\% reduction in mean absolute error for peak position estimation. Additionally, QuanvNNs appear to exhibit better convergence stability for harder problems.

</details>


### [394] [Enhancing Node-Level Graph Domain Adaptation by Alleviating Local Dependency](https://arxiv.org/abs/2512.13149)
*Xinwei Tai,Dongmian Zou,Hongfei Wang*

Main category: cs.LG

TL;DR: 该论文提出通过去相关节点特征来解决图域自适应中的条件偏移问题，并展示了该方法在性能提升和表示学习方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 图机器学习方法近年来取得显著进展，但如何有效地将知识从一个图迁移到另一个图仍然是一个关键挑战。无监督图域自适应（GDA）面临的主要困难是条件偏移，这会阻碍知识的可迁移性。

Method: 通过理论分析发现条件偏移仅存在于节点特征存在局部依赖性的情况下，因此提出通过去相关节点特征来改进GDA。具体实现包括去相关的GCN层和图变换器层。

Result: 实验结果表明该方法有效，不仅显著优于基线GDA方法，而且在学习到的表示中显示出较小的类内距离，可视化结果清晰。

Conclusion: 通过去相关节点特征可以有效解决图域自适应中的条件偏移问题，提高知识迁移效果，该方法具有理论支持和实验验证。

Abstract: Recent years have witnessed significant advancements in machine learning methods on graphs. However, transferring knowledge effectively from one graph to another remains a critical challenge. This highlights the need for algorithms capable of applying information extracted from a source graph to an unlabeled target graph, a task known as unsupervised graph domain adaptation (GDA). One key difficulty in unsupervised GDA is conditional shift, which hinders transferability. In this paper, we show that conditional shift can be observed only if there exists local dependencies among node features. To support this claim, we perform a rigorous analysis and also further provide generalization bounds of GDA when dependent node features are modeled using markov chains. Guided by the theoretical findings, we propose to improve GDA by decorrelating node features, which can be specifically implemented through decorrelated GCN layers and graph transformer layers. Our experimental results demonstrate the effectiveness of this approach, showing not only substantial performance enhancements over baseline GDA methods but also clear visualizations of small intra-class distances in the learned representations. Our code is available at https://github.com/TechnologyAiGroup/DFT

</details>


### [395] [SACn: Soft Actor-Critic with n-step Returns](https://arxiv.org/abs/2512.13165)
*Jakub Łyskawa,Jakub Lewandowski,Paweł Wawrzyński*

Main category: cs.LG

TL;DR: 提出SACn算法，将Soft Actor-Critic与n步回报结合，通过数值稳定的重要性采样和τ采样熵估计解决传统方法中的偏差和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: SAC是重要的离策略在线无模型强化学习方法，n步回报能提高收敛速度，但传统结合方式会因动作分布变化引入偏差，而重要性采样又可能导致数值不稳定。

Method: 1) 提出数值稳定的重要性采样方法并简化超参数选择；2) 在n步最大熵框架下分析SAC的熵估计，提出τ采样熵估计降低学习目标方差；3) 最终形成SACn算法。

Result: 在MuJoCo模拟环境中进行实验验证，表明SACn算法能有效结合n步回报的优势。

Conclusion: 成功将SAC与n步回报结合，解决了传统方法中的偏差和数值不稳定问题，提出了实用的SACn算法。

Abstract: Soft Actor-Critic (SAC) is widely used in practical applications and is now one of the most relevant off-policy online model-free reinforcement learning (RL) methods. The technique of n-step returns is known to increase the convergence speed of RL algorithms compared to their 1-step returns-based versions. However, SAC is notoriously difficult to combine with n-step returns, since their usual combination introduces bias in off-policy algorithms due to the changes in action distribution. While this problem is solved by importance sampling, a method for estimating expected values of one distribution using samples from another distribution, importance sampling may result in numerical instability. In this work, we combine SAC with n-step returns in a way that overcomes this issue. We present an approach to applying numerically stable importance sampling with simplified hyperparameter selection. Furthermore, we analyze the entropy estimation approach of Soft Actor-Critic in the context of the n-step maximum entropy framework and formulate the $τ$-sampled entropy estimation to reduce the variance of the learning target. Finally, we formulate the Soft Actor-Critic with n-step returns (SAC$n$) algorithm that we experimentally verify on MuJoCo simulated environments.

</details>


### [396] [PolySet: Restoring the Statistical Ensemble Nature of Polymers for Machine Learning](https://arxiv.org/abs/2512.13186)
*Khalid Ferji*

Main category: cs.LG

TL;DR: PolySet框架将聚合物表示为有限加权链集合，而非单一分子图，解决了传统机器学习模型无法处理聚合物统计分布特性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前聚合物机器学习模型通常将聚合物视为单一完美定义的分子图，而真实材料是由具有分布长度的链组成的统计集合，这种物理现实与数字表示之间的不匹配限制了模型捕捉聚合物行为的能力。

Method: 引入PolySet框架，将聚合物表示为从假定摩尔质量分布中采样的有限加权链集合。这种基于集合的编码独立于化学细节，兼容任何分子表示，在均聚物案例中使用最小语言模型进行说明。

Result: PolySet保留了高阶分布矩（如Mz、Mz+1），使机器学习模型能够以显著提高的稳定性和准确性学习对尾部敏感的性质。

Conclusion: 通过明确承认聚合物物质的统计性质，PolySet为未来聚合物机器学习建立了物理基础，自然可扩展到共聚物、嵌段结构和其他复杂拓扑结构。

Abstract: Machine-learning (ML) models in polymer science typically treat a polymer as a single, perfectly defined molecular graph, even though real materials consist of stochastic ensembles of chains with distributed lengths. This mismatch between physical reality and digital representation limits the ability of current models to capture polymer behaviour. Here we introduce PolySet, a framework that represents a polymer as a finite, weighted ensemble of chains sampled from an assumed molar-mass distribution. This ensemble-based encoding is independent of chemical detail, compatible with any molecular representation and illustrated here in the homopolymer case using a minimal language model. We show that PolySet retains higher-order distributional moments (such as Mz, Mz+1), enabling ML models to learn tail-sensitive properties with greatly improved stability and accuracy. By explicitly acknowledging the statistical nature of polymer matter, PolySet establishes a physically grounded foundation for future polymer machine learning, naturally extensible to copolymers, block architectures, and other complex topologies.

</details>


### [397] [WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory](https://arxiv.org/abs/2512.13190)
*Jin Sob Kim,Hyun Joon Park,Wooseok Shin,Dongil Park,Sung Won Han*

Main category: cs.LG

TL;DR: 提出WAY深度學習架構，用於處理AIS數據進行船舶目的地預測，通過重新構建軌跡為嵌套序列結構，並引入梯度丟棄技術提升性能。


<details>
  <summary>Details</summary>
Motivation: AIS系統雖然支持數據驅動的海事監控，但存在可靠性問題和數據間隔不規則的挑戰，需要準確預測船舶目的地以實現長期預警。

Method: 將長港口到港口軌跡重新構建為嵌套序列結構，使用空間網格減輕時空偏差。提出WAY架構，包含軌跡表示層和通道聚合序列處理塊，並引入梯度丟棄技術進行多對多訓練。

Result: 在5年AIS數據上的實驗顯示，WAY優於傳統空間網格方法，梯度丟棄技術帶來性能提升，並通過多任務學習展示了ETA估計的實際應用潛力。

Conclusion: WAY架構能有效處理AIS數據進行長期目的地預測，梯度丟棄技術改進了訓練效果，為海事監控提供了實用的深度學習解決方案。

Abstract: The Automatic Identification System (AIS) enables data-driven maritime surveillance but suffers from reliability issues and irregular intervals. We address vessel destination estimation using global-scope AIS data by proposing a differentiated approach that recasts long port-to-port trajectories as a nested sequence structure. Using spatial grids, this method mitigates spatio-temporal bias while preserving detailed resolution. We introduce a novel deep learning architecture, WAY, designed to process these reformulated trajectories for long-term destination estimation days to weeks in advance. WAY comprises a trajectory representation layer and Channel-Aggregative Sequential Processing (CASP) blocks. The representation layer generates multi-channel vector sequences from kinematic and non-kinematic features. CASP blocks utilize multi-headed channel- and self-attention for aggregation and sequential information delivery. Additionally, we propose a task-specialized Gradient Dropout (GD) technique to enable many-to-many training on single labels, preventing biased feedback surges by stochastically blocking gradient flow based on sample length. Experiments on 5-year AIS data demonstrate WAY's superiority over conventional spatial grid-based approaches regardless of trajectory progression. Results further confirm that adopting GD leads to performance gains. Finally, we explore WAY's potential for real-world application through multitask learning for ETA estimation.

</details>


### [398] [Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning](https://arxiv.org/abs/2512.13196)
*Chethana Prasad Kabgere,Sudarshan T S B*

Main category: cs.LG

TL;DR: NR-QFL是一种混合量子-经典联邦学习框架，通过变分量子电路在NISQ条件下实现安全、低延迟的模型聚合，专门用于车辆边缘计算环境中的ADAS系统。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在实时车辆网络中面临噪声、延迟和安全限制的问题，需要一种能够适应NISQ量子设备噪声特性，同时保证隐私、效率和稳定性的解决方案。

Method: 采用变分量子电路编码模型参数为量子态，通过自适应门重参数化确保有界误差收敛；使用量子熵基的客户端选择和多方服务器协调机制；在CPTP动力学下提供可证明的抗噪性。

Result: 经验验证显示NR-QFL能够实现一致收敛，减少梯度方差，降低通信开销，并在受限边缘条件下增强噪声容忍度，为量子增强的联邦学习建立了可扩展基础。

Conclusion: NR-QFL为车辆边缘计算中的ADAS智能提供了安全、高效且动态稳定的量子增强联邦学习框架，解决了传统FL在实时车辆网络中的关键限制。

Abstract: Advanced Driver Assistance Systems (ADAS) increasingly employ Federated Learning (FL) to collaboratively train models across distributed vehicular nodes while preserving data privacy. Yet, conventional FL aggregation remains susceptible to noise, latency, and security constraints inherent to real-time vehicular networks. This paper introduces Noise-Resilient Quantum Federated Learning (NR-QFL), a hybrid quantum-classical framework that enables secure, low-latency aggregation through variational quantum circuits (VQCs) operating under Noisy Intermediate-Scale Quantum (NISQ) conditions. The framework encodes model parameters as quantum states with adaptive gate reparameterization, ensuring bounded-error convergence and provable resilience under Completely Positive Trace-Preserving (CPTP) dynamics. NR-QFL employs quantum entropy-based client selection and multi-server coordination for fairness and stability. Empirical validation shows consistent convergence with reduced gradient variance, lower communication overhead, and enhanced noise tolerance under constrained edge conditions. The framework establishes a scalable foundation for quantum-enhanced federated learning, enabling secure, efficient, and dynamically stable ADAS intelligence at the vehicular edge.

</details>


### [399] [Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting](https://arxiv.org/abs/2512.13207)
*Karina Chichifoi,Fabio Merizzi,Michele Colajanni*

Main category: cs.LG

TL;DR: 研究探讨联邦学习在气象预报中的安全漏洞，发现即使少数恶意客户端也能通过数据投毒攻击显著扭曲区域温度预测，而基于剪裁均值的防御对空间相关数据效果有限。


<details>
  <summary>Details</summary>
Motivation: 深度学习与联邦学习结合为下一代天气预报提供了强大工具，但联邦学习的分布式特性引入了新的安全漏洞。特别是数据投毒攻击可能通过操纵训练数据来降低模型性能或引入系统性偏差，而气象数据的空间依赖性进一步放大了这种威胁。

Method: 使用Copernicus欧洲区域再分析数据集，模拟地理分布的客户端，评估基于补丁和全局偏置攻击对区域温度预测的影响。同时评估了剪裁均值聚合作为防御机制的有效性。

Result: 结果显示：1）单个恶意客户端的全局温度偏置攻击可使预测偏移达-1.7K；2）协调的补丁攻击使均方误差增加三倍以上，产生超过+3.5K的持续区域异常；3）剪裁均值聚合能有效防御全局偏置攻击（仅2-13%性能下降），但对补丁攻击无效（反而放大281-603%）。

Conclusion: 联邦学习在气象预报中存在严重安全漏洞，少数恶意客户端就能显著扭曲区域预测。基于异常值检测的防御机制对空间相关数据效果有限，需要开发更强大的防御策略来保护联邦气象预报系统。

Abstract: Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass traditional numerical models, while FL allows institutions in different locations to collaboratively train models without sharing raw data, addressing efficiency and security concerns. While FL has shown promise across heterogeneous regions, its distributed nature introduces new vulnerabilities. In particular, data poisoning attacks, in which compromised clients inject manipulated training data, can degrade performance or introduce systematic biases. These threats are amplified by spatial dependencies in meteorological data, allowing localized perturbations to influence broader regions through global model aggregation. In this study, we investigate how adversarial clients distort federated surface temperature forecasts trained on the Copernicus European Regional ReAnalysis (CERRA) dataset. We simulate geographically distributed clients and evaluate patch-based and global biasing attacks on regional temperature forecasts. Our results show that even a small fraction of poisoned clients can mislead predictions across large, spatially connected areas. A global temperature bias attack from a single compromised client shifts predictions by up to -1.7 K, while coordinated patch attacks more than triple the mean squared error and produce persistent regional anomalies exceeding +3.5 K. Finally, we assess trimmed mean aggregation as a defense mechanism, showing that it successfully defends against global bias attacks (2-13\% degradation) but fails against patch attacks (281-603\% amplification), exposing limitations of outlier-based defenses for spatially correlated data.

</details>


### [400] [ModSSC: A Modular Framework for Semi-Supervised Classification on Heterogeneous Data](https://arxiv.org/abs/2512.13228)
*Melvin Barbaux*

Main category: cs.LG

TL;DR: ModSSC是一个统一的半监督分类Python框架，支持多种算法、数据类型和硬件，通过YAML配置简化实验复现和比较研究。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督分类软件支持分散在不同方法和模态中，缺乏统一的框架来整合各种算法和数据类型。

Method: 开发了ModSSC开源框架，统一了归纳式和转导式半监督分类，实现了经典和最新算法，支持表格、图像、文本、音频和图数据，提供单一配置接口，支持CPU和GPU计算。

Result: 发布了ModSSC 1.0.0版本，采用MIT许可证，包含详细文档和测试，可在GitHub上获取。

Conclusion: ModSSC提供了一个统一的半监督分类框架，简化了实验复现和比较研究，填补了现有软件支持的碎片化问题。

Abstract: Semi-supervised classification leverages both labeled and unlabeled data to improve predictive performance, but existing software support is fragmented across methods and modalities. We introduce ModSSC, an open source Python framework that unifies inductive and transductive semi-supervised classification in a modular code base. ModSSC implements a broad range of classical and recent algorithms, provides loaders for tabular, image, text, audio and graph datasets, and exposes a single configuration interface for specifying datasets, models and evaluation protocols. It supports both lightweight classical methods on small datasets running on CPU and recent deep approaches that can exploit multiple GPUs within the same experimental framework. Experiments are described declaratively in YAML, which facilitates reproducing existing work and running large comparative studies. ModSSC 1.0.0 is released under the MIT license with extensive documentation and tests, and is available at https://github.com/ModSSC/ModSSC.

</details>


### [401] [CORE: Contrastive Masked Feature Reconstruction on Graphs](https://arxiv.org/abs/2512.13235)
*Jianyuan Bo,Yuan Fang*

Main category: cs.LG

TL;DR: 本文提出CORE框架，将对比学习整合到掩码特征重建中，在节点和图分类任务上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的图自监督学习领域，生成式和对比式方法是两大主流。研究发现掩码特征重建（MFR）和图对比学习（GCL）都旨在最大化相似元素之间的一致性，且在特定条件下目标函数会收敛。这表明两种方法是互补而非根本不同的，因此探索它们的整合以增强图自监督学习。

Method: 提出对比掩码特征重建（CORE）框架，将对比学习整合到MFR中。具体方法：1）仅使用掩码节点的原始特征和重建特征形成正样本对，促使编码器优先考虑上下文信息而非节点自身特征；2）利用掩码节点本身作为负样本，结合MFR的重建能力和GCL的判别能力，更好地捕获内在图结构。

Result: CORE在节点和图分类任务上显著优于MFR，取得SOTA结果。具体来说，在节点分类任务上比GraphMAE和GraphMAE2分别提升2.80%和3.72%，在图分类任务上分别提升3.82%和3.76%。

Conclusion: CORE框架成功整合了生成式和对比式自监督学习方法，证明了这两种方法的互补性。通过理论连接和实际整合，为图自监督学习提供了新的有效框架，在多个任务上取得了显著性能提升。

Abstract: In the rapidly evolving field of self-supervised learning on graphs, generative and contrastive methodologies have emerged as two dominant approaches. Our study focuses on masked feature reconstruction (MFR), a generative technique where a model learns to restore the raw features of masked nodes in a self-supervised manner. We observe that both MFR and graph contrastive learning (GCL) aim to maximize agreement between similar elements. Building on this observation, we reveal a novel theoretical insight: under specific conditions, the objectives of MFR and node-level GCL converge, despite their distinct operational mechanisms. This theoretical connection suggests these approaches are complementary rather than fundamentally different, prompting us to explore their integration to enhance self-supervised learning on graphs. Our research presents Contrastive Masked Feature Reconstruction (CORE), a novel graph self-supervised learning framework that integrates contrastive learning into MFR. Specifically, we form positive pairs exclusively between the original and reconstructed features of masked nodes, encouraging the encoder to prioritize contextual information over the node's own features. Additionally, we leverage the masked nodes themselves as negative samples, combining MFR's reconstructive power with GCL's discriminative ability to better capture intrinsic graph structures. Empirically, our proposed framework CORE significantly outperforms MFR across node and graph classification tasks, demonstrating state-of-the-art results. In particular, CORE surpasses GraphMAE and GraphMAE2 by up to 2.80% and 3.72% on node classification tasks, and by up to 3.82% and 3.76% on graph classification tasks.

</details>


### [402] [Learning to Retrieve with Weakened Labels: Robust Training under Label Noise](https://arxiv.org/abs/2512.13237)
*Arnab Sharma*

Main category: cs.LG

TL;DR: 提出标签弱化方法，通过生成一组可能的标签而非单一标签，在存在标签噪声的情况下训练更鲁棒的检索模型。


<details>
  <summary>Details</summary>
Motivation: 神经编码器在密集检索任务中广泛应用，但训练数据中的稀疏标注和标签噪声使得模型训练困难。现有方法要么需要调参，要么增加训练复杂度。

Method: 采用标签弱化方法，为每个查询-文档对生成一组可能的标签，这些标签基于观察到的监督信号和模型置信度分数。使用语义感知的噪声生成技术创建不同噪声比例的实验环境。

Result: 在四个不同的排序数据集上评估两个检索模型和一个重排序模型，结果显示标签弱化方法相比10种最先进的损失函数能提升检索任务性能。

Conclusion: 标签弱化是一种有效的方法，可以在存在标签噪声的情况下提高检索模型的鲁棒性和性能，且不需要复杂的训练设置或大量超参数调整。

Abstract: Neural Encoders are frequently used in the NLP domain to perform dense retrieval tasks, for instance, to generate the candidate documents for a given query in question-answering tasks. However, sparse annotation and label noise in the training data make it challenging to train or fine-tune such retrieval models. Although existing works have attempted to mitigate these problems by incorporating modified loss functions or data cleaning, these approaches either require some hyperparameters to tune during training or add substantial complexity to the training setup. In this work, we consider a label weakening approach to generate robust retrieval models in the presence of label noise. Instead of enforcing a single, potentially erroneous label for each query document pair, we allow for a set of plausible labels derived from both the observed supervision and the model's confidence scores. We perform an extensive evaluation considering two retrieval models, one re-ranking model, considering four diverse ranking datasets. To this end, we also consider a realistic noisy setting by using a semantic-aware noise generation technique to generate different ratios of noise. Our initial results show that label weakening can improve the performance of the retrieval tasks in comparison to 10 different state-of-the-art loss functions.

</details>


### [403] [BézierFlow: Bézier Stochastic Interpolant Schedulers for Few-Step Generation](https://arxiv.org/abs/2512.13255)
*Yunhong Min,Juil Koo,Seungwoo Yoo,Minhyuk Sung*

Main category: cs.LG

TL;DR: BézierFlow是一种轻量级训练方法，通过将随机插值调度器参数化为Bézier函数，学习采样轨迹的最优变换，在10步以内实现2-3倍性能提升，仅需15分钟训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级训练方法主要学习最优时间步长，但范围局限于ODE离散化。为了扩展这一范围，需要设计能够满足边界条件、可微性和SNR单调性等关键要求的参数化方法。

Method: 将随机插值调度器函数表示为Bézier函数，其中控制点自然强制执行所需属性。将问题简化为学习时间范围内的有序点集，同时将点的解释从ODE时间步长转变为Bézier控制点。

Result: 在多种预训练扩散和流模型中，BézierFlow始终优于先前的时间步长学习方法，在≤10步采样时实现2-3倍性能提升，仅需15分钟训练时间。

Conclusion: 通过将搜索空间从离散时间步长扩展到基于Bézier的轨迹变换，BézierFlow证明了扩展搜索空间的有效性，为少步生成提供了高效的轻量级训练方法。

Abstract: We introduce BézierFlow, a lightweight training approach for few-step generation with pretrained diffusion and flow models. BézierFlow achieves a 2-3x performance improvement for sampling with $\leq$ 10 NFEs while requiring only 15 minutes of training. Recent lightweight training approaches have shown promise by learning optimal timesteps, but their scope remains restricted to ODE discretizations. To broaden this scope, we propose learning the optimal transformation of the sampling trajectory by parameterizing stochastic interpolant (SI) schedulers. The main challenge lies in designing a parameterization that satisfies critical desiderata, including boundary conditions, differentiability, and monotonicity of the SNR. To effectively meet these requirements, we represent scheduler functions as Bézier functions, where control points naturally enforce these properties. This reduces the problem to learning an ordered set of points in the time range, while the interpretation of the points changes from ODE timesteps to Bézier control points. Across a range of pretrained diffusion and flow models, BézierFlow consistently outperforms prior timestep-learning methods, demonstrating the effectiveness of expanding the search space from discrete timesteps to Bézier-based trajectory transformations.

</details>


### [404] [No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction](https://arxiv.org/abs/2512.13300)
*Qinglin Jia,Zhaocheng Du,Chuhan Wu,Huifeng Guo,Ruiming Tang,Shuting Shi,Muyu Zhang*

Main category: cs.LG

TL;DR: 提出KAML框架解决广告系统中多任务学习面临的标签不完整和数据分布不匹配问题，通过属性驱动掩码策略、分层知识提取机制和排序损失来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实在线广告系统中，广告主通常有多样化的客户获取目标，但转化率预测面临标签不完整问题。许多广告主由于隐私等原因只提交部分用户转化行为，导致多任务数据标签不完整。如果模型在所有可用样本上训练，部署时服务于特定转化目标的广告主时会出现训练和部署数据分布不匹配的问题。

Method: 提出KAML框架，包含三个核心组件：1) 属性驱动掩码策略(ADM)更好地利用非对称多标签数据进行训练；2) 分层知识提取机制(HKE)在目标任务塔内建模样本差异，解决ADM引入的噪声问题；3) 结合排序损失策略进一步利用未标记样本。

Result: 在离线行业数据集和在线A/B测试中进行了全面评估，相比现有MTL基线模型，KAML显示出显著的性能提升。

Conclusion: KAML框架有效解决了多任务学习中标签不完整和数据分布不匹配的长期挑战，通过创新的掩码策略、知识提取机制和排序损失，在现实广告系统中实现了更好的性能。

Abstract: In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.

</details>


### [405] [ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning](https://arxiv.org/abs/2512.13316)
*Mayank Gulati,Benedikt Groß,Gerhard Wunder*

Main category: cs.LG

TL;DR: ALIGN-FL 提出了一种新颖的分布式学习方法，通过选择性共享生成组件来解决高度不相关数据分布的学习挑战，使用隐私保护机制在非IID场景下保持效用。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中高度不相关数据分布（Non-IID）的挑战，特别是在跨域协作场景中，同时保护隐私并支持异构客户端。

Method: 1. 选择性共享生成组件而非完整模型参数；2. 服务器使用合成样本进行全局训练；3. 结合DP-SGD自适应裁剪和Lipschitz正则化VAE解码器的隐私机制；4. 支持异构客户端的stateful架构。

Result: 在MNIST和Fashion-MNIST数据集上验证，隐私机制能有效将敏感异常值映射到典型数据点，在极端Non-IID场景下保持效用。

Conclusion: ALIGN-FL通过生成组件共享和互补隐私机制，成功解决了联邦学习中的Non-IID和隐私保护挑战，适用于跨域协作场景。

Abstract: We present ALIGN-FL, a novel approach to distributed learning that addresses the challenge of learning from highly disjoint data distributions through selective sharing of generative components. Instead of exchanging full model parameters, our framework enables privacy-preserving learning by transferring only generative capabilities across clients, while the server performs global training using synthetic samples. Through complementary privacy mechanisms: DP-SGD with adaptive clipping and Lipschitz regularized VAE decoders and a stateful architecture supporting heterogeneous clients, we experimentally validate our approach on MNIST and Fashion-MNIST datasets with cross-domain outliers. Our analysis demonstrates that both privacy mechanisms effectively map sensitive outliers to typical data points while maintaining utility in extreme Non-IID scenarios typical of cross-silo collaborations.
  Index Terms: Client-invariant Learning, Federated Learning (FL), Privacy-preserving Generative Models, Non-Independent and Identically Distributed (Non-IID), Heterogeneous Architectures

</details>


### [406] [KD-PINN: Knowledge-Distilled PINNs for ultra-low-latency real-time neural PDE solvers](https://arxiv.org/abs/2512.13336)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: KD-PINN框架通过知识蒸馏将高容量教师模型的预测精度转移到紧凑学生模型，在保持物理精度的同时实现4.8-6.9倍推理加速，达到亚10毫秒超低延迟实时性能。


<details>
  <summary>Details</summary>
Motivation: 开发准确且超低延迟的神经PDE求解器，解决传统物理信息神经网络推理延迟较高的问题，实现实时物理系统模拟。

Method: 提出知识蒸馏物理信息神经网络框架，通过连续调整Kullback-Leibler散度将高容量教师模型的预测能力转移到紧凑学生模型，在多种PDE系统上进行评估。

Result: 学生模型保持了教师模型的物理精度（平均RMSE增加低于0.64%），推理速度提升4.8-6.9倍，平均推理延迟5.3毫秒，达到超低延迟实时性能，蒸馏过程还显示出正则化效应。

Conclusion: KD-PINN框架成功实现了物理信息神经网络的超低延迟推理，为开发准确且实时的神经PDE求解器提供了有效途径，知识蒸馏在PINNs中具有显著的正则化和加速效果。

Abstract: This work introduces Knowledge-Distilled Physics-Informed Neural Networks (KD-PINN), a framework that transfers the predictive accuracy of a high-capacity teacher model to a compact student through a continuous adaptation of the Kullback-Leibler divergence. To confirm its generality for various dynamics and dimensionalities, the framework is evaluated on a representative set of partial differential equations (PDEs). In all tested cases, the student model preserved the teacher's physical accuracy, with a mean RMSE increase below 0.64%, and achieved inference speedups ranging from 4.8x (Navier-Stokes) to 6.9x (Burgers). The distillation process also revealed a regularizing effect. With an average inference latency of 5.3 ms on CPU, the distilled models enter the ultra-low-latency real-time regime defined by sub-10 ms performance. Finally, this study examines how knowledge distillation reduces inference latency in PINNs to contribute to the development of accurate ultra-low-latency neural PDE solvers.

</details>


### [407] [FROC: A Unified Framework with Risk-Optimized Control for Machine Unlearning in LLMs](https://arxiv.org/abs/2512.13337)
*Si Qi Goh,Yongsen Zheng,Ziyao Liu,Sami Hormi,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: FROC是一个用于大语言模型机器遗忘的统一风险控制框架，通过概率约束评估遗忘不足和效用损失风险，指导超参数选择以平衡安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前机器遗忘技术缺乏有效的风险评估和控制机制，难以在遗忘充分性和效用保持之间取得平衡，导致"被遗忘权"的信任问题。随着大语言模型广泛应用，管理遗忘不足和效用损失风险变得日益重要。

Method: FROC采用符合性风险控制框架，引入连续风险模型聚合遗忘不足和效用退化，计算符合性遗忘风险(CUR)和风险控制配置集，指导超参数选择以满足指定的风险预算。

Result: 实验表明FROC能产生稳定、可解释的风险景观，揭示遗忘配置、语义偏移和效用影响之间的一致关系，为大规模LLM部署中的遗忘行为管理提供实用基础。

Conclusion: FROC将机器遗忘重构为可控、风险感知的过程，通过统一的风险控制框架解决了当前MU技术缺乏风险评估机制的问题，为平衡遗忘充分性和模型效用提供了系统化方法。

Abstract: Machine unlearning (MU) seeks to eliminate the influence of specific training examples from deployed models. As large language models (LLMs) become widely used, managing risks arising from insufficient forgetting or utility loss is increasingly crucial. Current MU techniques lack effective mechanisms for evaluating and controlling these risks, hindering the selection of strategies that appropriately balance safety and utility, and raising trust concerns surrounding the "right to be forgotten." To address these issues, we propose FROC, a unified framework with Risk-Optimized Control for machine unlearning in LLMs. FROC is built around a conformal-style risk-control formulation that expresses a user-specified risk budget on unlearning behavior. This probability-based constraint enables FROC to compare MU strategies, identify feasible operating regions, and guide hyperparameter selection according to desired trade-offs between forgetting sufficiency and utility preservation. To operationalize this constraint, FROC introduces a smoothly varying continuous risk model that aggregates forgetting deficiency and utility degradation into a single configuration-level score. Building on conformal risk analysis, FROC computes (1) the Conformal Unlearning Risk (CUR), a data-driven estimated value on the probability that forgotten samples continue to influence model predictions, and (2) risk-controlled configuration sets, which identify unlearning hyperparameters that are valid under the specified risk budget. Experiments across multiple LLM MU methods demonstrate that FROC produces stable, interpretable risk landscapes and reveals consistent relationships between unlearning configurations, semantic shift, and utility impact. FROC reframes MU as a controllable, risk-aware process and offers a practical foundation for managing unlearning behavior in large-scale LLM deployments.

</details>


### [408] [Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks](https://arxiv.org/abs/2512.13340)
*Henrik C. M. Frederiksen,Junya Shiraishi,Cedomir Stefanovic,Hei Victor Cheng,Shashi Raj Pandey*

Main category: cs.LG

TL;DR: 提出事件驱动的通信框架，将持续学习集成到物联网网络中，用于节能的故障检测，通过自适应无线链路条件和能量预算来协同更新轻量级ML模型。


<details>
  <summary>Details</summary>
Motivation: 物联网设备上部署的轻量级机器学习模型在非平稳环境和有限初始训练数据下，推理精度会下降。虽然可以通过新数据更新模型，但这会消耗额外能量，对能量受限的物联网设备不利。

Method: 提出事件驱动的通信框架，使物联网设备和边缘服务器能够根据无线链路条件和可用能量预算，协同更新轻量级ML模型。该框架战略性地集成了持续学习技术。

Result: 在真实数据集上的评估显示，该方法在推理召回率方面优于周期性采样和非自适应持续学习方法，在严格的能量和带宽约束下实现了高达42.8%的改进。

Conclusion: 提出的框架通过事件驱动的通信和自适应持续学习，能够在能量受限的物联网环境中有效提高故障检测性能，平衡了模型更新需求与能量消耗之间的矛盾。

Abstract: The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limited initial training data. To counteract this, the deployed models can be updated occasionally with new observed data samples. However, this approach consumes additional energy, which is undesirable for energy constrained IoT devices. This letter introduces an event-driven communication framework that strategically integrates continual learning (CL) in IoT networks for energy-efficient fault detection. Our framework enables the IoT device and the edge server (ES) to collaboratively update the lightweight ML model by adapting to the wireless link conditions for communication and the available energy budget. Evaluation on real-world datasets show that the proposed approach can outperform both periodic sampling and non-adaptive CL in terms of inference recall; our proposed approach achieves up to a 42.8% improvement, even under tight energy and bandwidth constraint.

</details>


### [409] [On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models](https://arxiv.org/abs/2512.13352)
*Ali Al Sahili,Ali Chehab,Razane Tajeddine*

Main category: cs.LG

TL;DR: 该研究整合多种成员推理攻击技术到数据提取流程中，系统评估它们在真实数据提取场景中的有效性，并与传统基准测试结果对比。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易记忆训练数据，带来严重的隐私风险，特别是训练数据提取和成员推理攻击。现有研究表明这两种威胁相互关联，攻击者可以通过生成大量文本来提取数据，然后用MIA验证数据是否属于训练集。需要评估MIA技术在真实数据提取场景中的实际效果。

Method: 将多种成员推理攻击技术整合到数据提取流程中，构建系统化的基准测试框架。在集成设置中评估这些技术的性能，并与传统的MIA基准测试结果进行比较。

Result: 研究比较了不同MIA技术在数据提取场景中的表现，评估了它们在真实世界提取场景中的实际效用，揭示了与传统基准测试结果的差异。

Conclusion: 通过系统整合和基准测试，该研究为评估成员推理攻击在真实数据提取场景中的有效性提供了框架，有助于更好地理解MIA技术的实际隐私风险。

Abstract: Large Language Models (LLMs) are prone to memorizing training data, which poses serious privacy risks. Two of the most prominent concerns are training data extraction and Membership Inference Attacks (MIAs). Prior research has shown that these threats are interconnected: adversaries can extract training data from an LLM by querying the model to generate a large volume of text and subsequently applying MIAs to verify whether a particular data point was included in the training set. In this study, we integrate multiple MIA techniques into the data extraction pipeline to systematically benchmark their effectiveness. We then compare their performance in this integrated setting against results from conventional MIA benchmarks, allowing us to evaluate their practical utility in real-world extraction scenarios.

</details>


### [410] [SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy](https://arxiv.org/abs/2512.13458)
*Yici Liu,Qi Wei Oung,Hoi Leong Lee*

Main category: cs.LG

TL;DR: 提出一种通过源选择与对抗策略的跨被试EEG情绪识别方法，解决个体差异和负迁移问题


<details>
  <summary>Details</summary>
Motivation: 现有跨被试EEG情绪识别研究忽视了个体间差异和模型训练中的负迁移现象，需要解决这些问题以提高实际应用效果

Method: 提出包含源选择网络(SS)和对抗策略网络(AS)的双模块方法：SS通过破坏类别可分性和放大域间差异来学习域不变但情绪相关的表示；AS利用SS的源域选择结果和预训练域判别器，在对抗训练中增强域分类性能

Result: 在SEED和SEED-IV两个EEG情绪数据集上取得了优异性能

Conclusion: 提出的方法有效解决了跨被试EEG情绪识别中的个体差异和负迁移问题，为实际应用提供了有前景的解决方案

Abstract: Electroencephalographic (EEG) signals have long been applied in the field of affective brain-computer interfaces (aBCIs). Cross-subject EEG-based emotion recognition has demonstrated significant potential in practical applications due to its suitability across diverse people. However, most studies on cross-subject EEG-based emotion recognition neglect the presence of inter-individual variability and negative transfer phenomena during model training. To address this issue, a cross-subject EEG-based emotion recognition through source selection with adversarial strategy is introduced in this paper. The proposed method comprises two modules: the source selection network (SS) and the adversarial strategies network (AS). The SS uses domain labels to reverse-engineer the training process of domain adaptation. Its key idea is to disrupt class separability and magnify inter-domain differences, thereby raising the classification difficulty and forcing the model to learn domain-invariant yet emotion-relevant representations. The AS gets the source domain selection results and the pretrained domain discriminators from SS. The pretrained domain discriminators compute a novel loss aimed at enhancing the performance of domain classification during adversarial training, ensuring the balance of adversarial strategies. This paper provides theoretical insights into the proposed method and achieves outstanding performance on two EEG-based emotion datasets, SEED and SEED-IV. The code can be found at https://github.com/liuyici/SSAS.

</details>


### [411] [Dual-Phase Federated Deep Unlearning via Weight-Aware Rollback and Reconstruction](https://arxiv.org/abs/2512.13381)
*Changjun Zhou,Jintao Zheng,Leyou Yang,Pengfei Wang*

Main category: cs.LG

TL;DR: DPUL是一种新颖的服务器端联邦遗忘方法，通过深度移除所有影响权重来防止隐私泄露，相比现有方法在精度上提升1%-5%，时间成本降低高达12倍。


<details>
  <summary>Details</summary>
Motivation: 现有联邦遗忘方法存在高计算需求、复杂激励机制和客户端计算能力差异等问题，导致时间长、成本高。特别是服务器端知识蒸馏方法仅移除目标客户端的更新，忽略了其他客户端贡献中嵌入的隐私，可能导致隐私泄露。

Method: DPUL包含三个组件：(1)通过过滤客户端更新幅度识别高权重参数，并将其回滚以确保深度移除；(2)利用变分自编码器(VAE)重构和消除低权重参数；(3)使用基于投影的技术恢复模型。

Result: 在四个数据集上的实验结果表明，DPUL超越了最先进的基线方法，在精度上提供1%-5%的改进，时间成本降低高达12倍。

Conclusion: DPUL提出了一种有效的服务器端联邦遗忘方法，能够深度移除所有影响权重，防止隐私泄露，同时显著提高效率和准确性。

Abstract: Federated Unlearning (FUL) focuses on client data and computing power to offer a privacy-preserving solution. However, high computational demands, complex incentive mechanisms, and disparities in client-side computing power often lead to long times and higher costs. To address these challenges, many existing methods rely on server-side knowledge distillation that solely removes the updates of the target client, overlooking the privacy embedded in the contributions of other clients, which can lead to privacy leakage. In this work, we introduce DPUL, a novel server-side unlearning method that deeply unlearns all influential weights to prevent privacy pitfalls. Our approach comprises three components: (i) identifying high-weight parameters by filtering client update magnitudes, and rolling them back to ensure deep removal. (ii) leveraging the variational autoencoder (VAE) to reconstruct and eliminate low-weight parameters. (iii) utilizing a projection-based technique to recover the model. Experimental results on four datasets demonstrate that DPUL surpasses state-of-the-art baselines, providing a 1%-5% improvement in accuracy and up to 12x reduction in time cost.

</details>


### [412] [Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability](https://arxiv.org/abs/2512.13568)
*Leonard Bereska,Zoe Tzifa-Kratira,Reza Samavi,Efstratios Gavves*

Main category: cs.LG

TL;DR: 提出信息论框架测量神经网络表示的有效自由度，将叠加定义为有损压缩，揭示其与对抗鲁棒性的关系


<details>
  <summary>Details</summary>
Motivation: 神经网络通过叠加（多个特征作为激活空间中的重叠方向）实现卓越性能，但缺乏原则性方法来测量叠加现象，这给可解释性带来挑战

Method: 提出信息论框架，将香农熵应用于稀疏自编码器激活，计算有效特征数量作为无干扰编码所需的最小神经元数，等价于测量网络通过叠加模拟的"虚拟神经元"数量

Result: 度量在玩具模型中与真实情况强相关，在算法任务中检测到最小叠加，在dropout下显示系统性减少；层间模式反映Pythia-70M内在维度研究；捕捉到grokking期间的急剧特征整合；对抗训练可增加有效特征同时提高鲁棒性

Conclusion: 通过将叠加定义为有损压缩，这项工作能够原则性地测量神经网络在计算约束下如何组织信息，将叠加与对抗鲁棒性联系起来；效果取决于任务复杂性和网络容量：简单任务和充足容量允许特征扩展（丰富机制），复杂任务或有限容量迫使减少（稀缺机制）

Abstract: Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of freedom. We apply Shannon entropy to sparse autoencoder activations to compute the number of effective features as the minimum neurons needed for interference-free encoding. Equivalently, this measures how many "virtual neurons" the network simulates through superposition. When networks encode more effective features than actual neurons, they must accept interference as the price of compression. Our metric strongly correlates with ground truth in toy models, detects minimal superposition in algorithmic tasks, and reveals systematic reduction under dropout. Layer-wise patterns mirror intrinsic dimensionality studies on Pythia-70M. The metric also captures developmental dynamics, detecting sharp feature consolidation during grokking. Surprisingly, adversarial training can increase effective features while improving robustness, contradicting the hypothesis that superposition causes vulnerability. Instead, the effect depends on task complexity and network capacity: simple tasks with ample capacity allow feature expansion (abundance regime), while complex tasks or limited capacity force reduction (scarcity regime). By defining superposition as lossy compression, this work enables principled measurement of how neural networks organize information under computational constraints, connecting superposition to adversarial robustness.

</details>


### [413] [Multiclass Graph-Based Large Margin Classifiers: Unified Approach for Support Vectors and Neural Networks](https://arxiv.org/abs/2512.13410)
*Vítor M. Hanriot,Luiz C. B. Torres,Antônio P. Braga*

Main category: cs.LG

TL;DR: 本文提出基于Gabriel图(GG)的分类方法改进，包括更平滑的激活函数、结构支持向量(SSV)中心神经元、神经网络架构扩展，以及新的子图/距离成员函数和更高效的GG重计算算法。


<details>
  <summary>Details</summary>
Motivation: 虽然大间隔分类器源自优化框架，但支持向量可以从几何方法获得。本文旨在推进Gabriel图在二元和多类分类问题中的应用，改进现有GG分类器Chipclass的性能。

Method: 1) 提出更平滑的激活函数和结构支持向量(SSV)中心神经元；2) 扩展神经网络架构，可通过反向传播或线性方程组求解训练；3) 提出新的子图/距离成员函数用于图正则化；4) 开发计算效率更高的GG重计算算法。

Result: Friedman检验显示，该方法优于之前的GG分类器，且与基于树的模型在统计上等效。

Conclusion: 本文提出的GG改进方法在分类性能上取得了显著提升，计算效率更高，为基于几何图的分类方法提供了有效的改进方案。

Abstract: While large margin classifiers are originally an outcome of an optimization framework, support vectors (SVs) can be obtained from geometric approaches. This article presents advances in the use of Gabriel graphs (GGs) in binary and multiclass classification problems. For Chipclass, a hyperparameter-less and optimization-less GG-based binary classifier, we discuss how activation functions and support edge (SE)-centered neurons affect the classification, proposing smoother functions and structural SV (SSV)-centered neurons to achieve margins with low probabilities and smoother classification contours. We extend the neural network architecture, which can be trained with backpropagation with a softmax function and a cross-entropy loss, or by solving a system of linear equations. A new subgraph-/distance-based membership function for graph regularization is also proposed, along with a new GG recomputation algorithm that is less computationally expensive than the standard approach. Experimental results with the Friedman test show that our method was better than previous GG-based classifiers and statistically equivalent to tree-based models.

</details>


### [414] [DP-CSGP: Differentially Private Stochastic Gradient Push with Compressed Communication](https://arxiv.org/abs/2512.13583)
*Zehan Zhu,Heng Zhao,Yan Huang,Joey Tianyi Zhou,Shouling Ji,Jinming Xu*

Main category: cs.LG

TL;DR: 提出DP-CSGP算法，在定向图的去中心化学习中实现差分隐私、压缩通信和高模型效用


<details>
  <summary>Details</summary>
Motivation: 现有去中心化学习算法在保证差分隐私时通常忽略通信效率，或使用精确通信导致高通信成本。需要同时实现严格隐私保护、高效通信和高模型效用

Method: 提出差分隐私随机梯度推送压缩通信算法(DP-CSGP)，结合差分隐私机制、梯度压缩技术和去中心化优化框架，在定向图上进行高效隐私保护学习

Result: 对于一般非凸平滑目标函数，算法达到紧致的效用边界O(√(d log(1/δ))/(√nJε))，匹配精确通信的去中心化算法。实验显示在相同隐私预算下，DP-CSGP达到可比模型精度，通信成本显著降低

Conclusion: DP-CSGP成功解决了去中心化学习中隐私保护、通信效率和模型效用之间的权衡问题，为定向图上的隐私保护分布式学习提供了有效解决方案

Abstract: In this paper, we propose a Differentially Private Stochastic Gradient Push with Compressed communication (termed DP-CSGP) for decentralized learning over directed graphs. Different from existing works, the proposed algorithm is designed to maintain high model utility while ensuring both rigorous differential privacy (DP) guarantees and efficient communication. For general non-convex and smooth objective functions, we show that the proposed algorithm achieves a tight utility bound of $\mathcal{O}\left( \sqrt{d\log \left( \frac{1}δ \right)}/(\sqrt{n}Jε) \right)$ ($J$ and $d$ are the number of local samples and the dimension of decision variables, respectively) with $\left(ε, δ\right)$-DP guarantee for each node, matching that of decentralized counterparts with exact communication. Extensive experiments on benchmark tasks show that, under the same privacy budget, DP-CSGP achieves comparable model accuracy with significantly lower communication cost than existing decentralized counterparts with exact communication.

</details>


### [415] [XNNTab -- Interpretable Neural Networks for Tabular Data using Sparse Autoencoders](https://arxiv.org/abs/2512.13442)
*Khawla Elhadri,Jörg Schlötterer,Christin Seifert*

Main category: cs.LG

TL;DR: XNNTab是一种结合神经网络表达能力和可解释性的架构，通过学习非线性特征表示并使用稀疏自编码器分解为单语义特征，实现内在可解释性，在保持与不可解释模型相当性能的同时超越传统可解释模型。


<details>
  <summary>Details</summary>
Motivation: 在依赖表格数据且需要可解释性的应用中，虽然神经网络具有更高的预测性能，但由于其黑盒特性而未被采用。现有可解释模型（如决策树、线性回归）性能有限，需要一种既能保持神经网络表达能力又能提供可解释性的解决方案。

Method: XNNTab首先学习高度非线性的特征表示，然后使用稀疏自编码器（SAE）将这些表示分解为单语义特征。这些特征随后被赋予人类可解释的概念，使整个模型的预测具有内在可解释性。

Result: XNNTab在性能上超越了传统的可解释预测模型，同时达到了与其不可解释对应模型相当的性能水平。

Conclusion: XNNTab成功地将神经网络的表达能力和可解释性相结合，为需要可解释性的表格数据应用提供了一种有效的解决方案，填补了高性能黑盒模型与低性能可解释模型之间的空白。

Abstract: In data-driven applications relying on tabular data, where interpretability is key, machine learning models such as decision trees and linear regression are applied. Although neural networks can provide higher predictive performance, they are not used because of their blackbox nature. In this work, we present XNNTab, a neural architecture that combines the expressiveness of neural networks and interpretability. XNNTab first learns highly non-linear feature representations, which are decomposed into monosemantic features using a sparse autoencoder (SAE). These features are then assigned human-interpretable concepts, making the overall model prediction intrinsically interpretable. XNNTab outperforms interpretable predictive models, and achieves comparable performance to its non-interpretable counterparts.

</details>


### [416] [From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves](https://arxiv.org/abs/2512.13641)
*Gabriel Vitorino de Andrade,Saulo Roberto dos Santos,Itallo Patrick Castro Alves da Silva,Emanuel Adler Medeiros Pereira,Erick de Andrade Barboza*

Main category: cs.LG

TL;DR: 该研究提出了一种评估卷积神经网络在芒果叶病害诊断中鲁棒性的方法，通过创建包含19种人工损坏的数据集MangoLeafDB-C，比较了五种CNN架构在恶劣条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管芒果具有全球重要性，但缺乏针对芒果叶病害诊断模型鲁棒性的研究。AI模型需要通过鲁棒性评估来保证在现实挑战（如图像损坏）下的可靠性能，特别是在农业应用中。

Method: 1. 创建MangoLeafDB-C数据集：在原始MangoLeafDB基础上添加19种人工损坏类型，每种有5个严重程度等级；2. 比较五种CNN架构：ResNet-50、ResNet-101、VGG-16、Xception和专门为芒果叶诊断设计的轻量级架构LCNN；3. 使用F1分数、损坏错误率（CE）和相对平均损坏错误率（相对mCE）进行评估。

Result: LCNN在现实场景可能出现的损坏（如散焦模糊、运动模糊）中表现优于复杂模型，并获得了最低的mCE。现代架构（如ResNet-101）在理想条件下准确率高，但在损坏场景中性能显著下降。

Conclusion: 轻量级和专门化模型可能更适合边缘设备的实际应用，其中鲁棒性和效率至关重要。研究强调需要在农业智能系统开发中纳入鲁棒性评估，特别是在技术受限地区。

Abstract: The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutional neural networks (CNNs) under adverse conditions. We adapted the MangoLeafDB dataset, generating MangoLeafDB-C with 19 types of artificial corruptions at five severity levels. We conducted a benchmark comparing five architectures: ResNet-50, ResNet-101, VGG-16, Xception, and LCNN (the latter being a lightweight architecture designed specifically for mango leaf diagnosis). The metrics include the F1 score, the corruption error (CE) and the relative mean corruption error (relative mCE). The results show that LCNN outperformed complex models in corruptions that can be present in real-world scenarios such as Defocus Blur, Motion Blur, while also achieving the lowest mCE. Modern architectures (e.g., ResNet-101) exhibited significant performance degradation in corrupted scenarios, despite their high accuracy under ideal conditions. These findings suggest that lightweight and specialized models may be more suitable for real-world applications in edge devices, where robustness and efficiency are critical. The study highlights the need to incorporate robustness assessments in the development of intelligent systems for agriculture, particularly in regions with technological limitations.

</details>


### [417] [DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems](https://arxiv.org/abs/2512.13460)
*Chethana Prasad Kabgere,Shylaja S S*

Main category: cs.LG

TL;DR: DP-EMAR：一种差分隐私、基于错误模型的自修复框架，用于检测和重建联邦物联网中传输引起的模型权重失真，同时保持隐私保护


<details>
  <summary>Details</summary>
Motivation: 在资源受限的物联网网络中，联邦学习面临模型权重失真的挑战。多层级联邦物联网系统中，不稳定的连接和对抗性干扰会无声地改变传输参数，降低收敛性能

Method: 提出DP-EMAR框架，通过估计损坏模式并在添加隐私噪声前应用自适应校正，实现可靠的网络内修复。通过将差分隐私与安全聚合结合，区分DP噪声和真实传输错误

Result: 在异构物联网传感器和图数据集上的实验表明，DP-EMAR在通信损坏情况下保持收敛稳定性，维持接近基线性能，同时确保严格的(epsilon, delta)-DP保证

Conclusion: 该框架增强了联邦物联网学习的鲁棒性、通信效率和信任度，为隐私保护的联邦物联网学习提供了可靠的解决方案

Abstract: Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter transmitted parameters, degrading convergence. We propose DP-EMAR, a differentially private, error model based autonomous repair framework that detects and reconstructs transmission induced distortions during FL aggregation. DP-EMAR estimates corruption patterns and applies adaptive correction before privacy noise is added, enabling reliable in network repair without violating confidentiality. By integrating Differential Privacy (DP) with Secure Aggregation (SA), the framework distinguishes DP noise from genuine transmission errors. Experiments on heterogeneous IoT sensor and graph datasets show that DP-EMAR preserves convergence stability and maintains near baseline performance under communication corruption while ensuring strict (epsilon, delta)-DP guarantees. The framework enhances robustness, communication efficiency, and trust in privacy preserving Federated IoT learning.

</details>


### [418] [Element-wise Modulation of Random Matrices for Efficient Neural Layers](https://arxiv.org/abs/2512.13480)
*Maksymilian Szorc*

Main category: cs.LG

TL;DR: 提出参数化随机投影层，通过固定随机矩阵加可学习元素级参数，大幅减少全连接层参数，保持准确率的同时降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 全连接层是深度神经网络中内存和计算开销的主要来源，其密集且往往冗余的参数化导致效率低下。现有压缩技术通常引入复杂的工程权衡或降低模型性能。

Method: 提出参数化随机投影层，将特征混合与适应解耦：使用固定的随机矩阵，通过轻量级的可学习元素级参数进行调制。这种架构将可训练参数数量大幅减少到线性规模。

Result: 在各种基准测试中保持可靠的准确性，同时显著减少可训练参数数量。该设计为架构扩展和资源受限环境中的部署提供了稳定、计算高效的解决方案。

Conclusion: 参数化随机投影层是一种有效的全连接层压缩方法，通过创新的解耦设计，在保持性能的同时大幅降低参数复杂度和计算需求，适合资源受限的应用场景。

Abstract: Fully connected layers are a primary source of memory and computational overhead in deep neural networks due to their dense, often redundant parameterization. While various compression techniques exist, they frequently introduce complex engineering trade-offs or degrade model performance. We propose the Parametrized Random Projection (PRP) layer, a novel approach that decouples feature mixing from adaptation by utilizing a fixed random matrix modulated by lightweight, learnable element-wise parameters. This architecture drastically reduces the trainable parameter count to a linear scale while retaining reliable accuracy across various benchmarks. The design serves as a stable, computationally efficient solution for architectural scaling and deployment in resource-limited settings.

</details>


### [419] [On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing](https://arxiv.org/abs/2512.13497)
*Haoyu Ren,Kay Koehle,Kirill Dorofeev,Darko Anicic*

Main category: cs.LG

TL;DR: 本文提出了一种用于动态制造环境的设备端持续学习方法，用于无监督视觉异常检测与定位，通过轻量级特征提取器和增量核心集更新机制，在资源受限的边缘设备上实现快速、内存高效的模型适应。


<details>
  <summary>Details</summary>
Motivation: 现代制造业中，动态灵活的生产环境带来三大挑战：1) 小批量按需制造中产品频繁变更需要快速模型更新；2) 传统边缘硬件缺乏训练大型AI模型的资源；3) 异常和正常训练数据通常稀缺，特别是对新引入的产品变体。

Method: 基于PatchCore框架，提出设备端持续学习方法，采用轻量级特征提取器和基于k-center选择的增量核心集更新机制，支持从有限数据中进行快速、内存高效的适应，无需昂贵的云端重新训练。

Result: 在模拟灵活生产的工业用例测试中，方法相比基线实现了12%的AUROC提升，内存使用减少80%，训练速度比批量重新训练更快。

Conclusion: 该方法为动态智能制造提供了准确、资源高效且自适应的视觉异常检测解决方案，能够在资源受限的边缘设备上处理频繁的产品变更和数据稀缺问题。

Abstract: In modern manufacturing, Visual Anomaly Detection (VAD) is essential for automated inspection and consistent product quality. Yet, increasingly dynamic and flexible production environments introduce key challenges: First, frequent product changes in small-batch and on-demand manufacturing require rapid model updates. Second, legacy edge hardware lacks the resources to train and run large AI models. Finally, both anomalous and normal training data are often scarce, particularly for newly introduced product variations. We investigate on-device continual learning for unsupervised VAD with localization, extending the PatchCore to incorporate online learning for real-world industrial scenarios. The proposed method leverages a lightweight feature extractor and an incremental coreset update mechanism based on k-center selection, enabling rapid, memory-efficient adaptation from limited data while eliminating costly cloud retraining. Evaluations on an industrial use case are conducted using a testbed designed to emulate flexible production with frequent variant changes in a controlled environment. Our method achieves a 12% AUROC improvement over the baseline, an 80% reduction in memory usage, and faster training compared to batch retraining. These results confirm that our method delivers accurate, resource-efficient, and adaptive VAD suitable for dynamic and smart manufacturing.

</details>


### [420] [Learning under Distributional Drift: Reproducibility as an Intrinsic Statistical Resource](https://arxiv.org/abs/2512.13506)
*Sofiya Zaichyk*

Main category: cs.LG

TL;DR: 提出"可重复性预算"概念量化学习系统在分布漂移下的统计可重复性，建立基于Fisher-Rao路径长度的泛化误差界，证明该界是最优的


<details>
  <summary>Details</summary>
Motivation: 在分布漂移下，传统泛化界可能失效，需要新的理论框架来量化学习系统在分布变化下的统计可重复性

Method: 引入可重复性预算C_T作为统计原语，定义为耦合学习器-环境演化的累积Fisher-Rao路径长度，衡量学习过程中的总分布运动

Result: 推导出O(T^{-1/2} + C_T/T)阶的漂移-反馈泛化界，并证明匹配的最小最大下界，表明该速率是最优的

Conclusion: 建立了可重复性速度限制：任何算法的最坏情况泛化误差都不能低于数据生成过程的平均Fisher-Rao漂移率C_T/T，为外生漂移、自适应数据分析和执行预测提供了统一几何框架

Abstract: Statistical learning under distributional drift remains insufficiently characterized: when each observation alters the data-generating law, classical generalization bounds can collapse. We introduce a new statistical primitive, the reproducibility budget $C_T$, which quantifies a system's finite capacity for statistical reproducibility - the extent to which its sampling process can remain governed by a consistent underlying distribution in the presence of both exogenous change and endogenous feedback. Formally, $C_T$ is defined as the cumulative Fisher-Rao path length of the coupled learner-environment evolution, measuring the total distributional motion accumulated during learning. From this construct we derive a drift-feedback generalization bound of order $O(T^{-1/2} + C_T/T)$, and we prove a matching minimax lower bound showing that this rate is minimax-optimal. Consequently, the results establish a reproducibility speed limit: no algorithm can achieve smaller worst-case generalization error than that imposed by the average Fisher-Rao drift rate $C_T/T$ of the data-generating process. The framework situates exogenous drift, adaptive data analysis, and performative prediction within a common geometric structure, with $C_T$ emerging as the intrinsic quantity measuring distributional motion across these settings.

</details>


### [421] [Async Control: Stress-testing Asynchronous Control Measures for LLM Agents](https://arxiv.org/abs/2512.13526)
*Asa Cooper Stickland,Jan Michelfeit,Arathi Mani,Charlie Griffin,Ollie Matthews,Tomek Korbak,Rogan Inglis,Oliver Makins,Alan Cooney*

Main category: cs.LG

TL;DR: 研究LLM软件工程代理的异步监控方法，通过红蓝对抗游戏开发监控系统，在5个软件工程环境中实现6%漏报率（1%误报率），并评估部署时的破坏风险。


<details>
  <summary>Details</summary>
Motivation: LLM软件工程代理在实际开发任务中可能访问敏感数据或安全关键代码库，如果代理未对齐可能故意破坏代码库。需要监控系统来检测和防止此类破坏行为。

Method: 采用异步监控方法（事后审查代理行为），建立红蓝对抗游戏：蓝队设计监控器，红队创建破坏性代理。在5个多样化的软件工程环境中进行测试，开发集成监控器。

Result: 开发出集成监控器，在保留测试环境中达到6%的漏报率（假阴性率）和1%的误报率（假阳性率）。通过漏报率外推估计部署时的破坏风险。

Conclusion: 异步监控是可行的安全方法，不引入运行时延迟。通过对抗性游戏可以开发有效的监控系统，但需要谨慎评估风险外推模型的适用性。

Abstract: LLM-based software engineering agents are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such agents could intentionally sabotage these codebases if they were misaligned. We investigate asynchronous monitoring, in which a monitoring system reviews agent actions after the fact. Unlike synchronous monitoring, this approach does not impose runtime latency, while still attempting to disrupt attacks before irreversible harm occurs. We treat monitor development as an adversarial game between a blue team (who design monitors) and a red team (who create sabotaging agents). We attempt to set the game rules such that they upper bound the sabotage potential of an agent based on Claude 4.1 Opus. To ground this game in a realistic, high-stakes deployment scenario, we develop a suite of 5 diverse software engineering environments that simulate tasks that an agent might perform within an AI developer's internal infrastructure. Over the course of the game, we develop an ensemble monitor that achieves a 6% false negative rate at 1% false positive rate on a held out test environment. Then, we estimate risk of sabotage at deployment time by extrapolating from our monitor's false negative rate. We describe one simple model for this extrapolation, present a sensitivity analysis, and describe situations in which the model would be invalid. Code is available at: https://github.com/UKGovernmentBEIS/async-control.

</details>


### [422] [Image Diffusion Preview with Consistency Solver](https://arxiv.org/abs/2512.13592)
*Fu-Yun Wang,Hao Zhou,Liangzhe Yuan,Sanghyun Woo,Boqing Gong,Bohyung Han,Ming-Hsuan Yang,Han Zhang,Yukun Zhu,Ting Liu,Long Zhao*

Main category: cs.LG

TL;DR: 提出Diffusion Preview范式，通过快速低步采样生成预览供用户评估，满意后再进行全步精炼。为解决现有方法预览质量差和一致性不足的问题，提出了基于强化学习优化的轻量级高阶求解器ConsistencySolver。


<details>
  <summary>Details</summary>
Motivation: 图像扩散模型推理过程缓慢，严重影响交互体验。现有加速方法（如免训练求解器和后训练蒸馏）难以在低步数下提供高质量预览，且无法保证预览与最终输出的一致性。

Method: 提出Diffusion Preview范式，采用快速低步采样生成预览。开发ConsistencySolver，这是一种基于通用线性多步方法的轻量级可训练高阶求解器，通过强化学习进行优化，提升预览质量和一致性。

Result: ConsistencySolver在低步数场景下显著提升生成质量和一致性，比Multistep DPM-Solver减少47%步数达到相同FID分数，优于蒸馏基线。用户研究表明，该方法减少近50%的用户交互时间，同时保持生成质量。

Conclusion: Diffusion Preview范式结合ConsistencySolver能够有效提升交互效率，在保持生成质量的同时大幅减少用户等待时间，适用于高效的预览-精炼工作流程。

Abstract: The slow inference process of image diffusion models significantly degrades interactive user experiences. To address this, we introduce Diffusion Preview, a novel paradigm employing rapid, low-step sampling to generate preliminary outputs for user evaluation, deferring full-step refinement until the preview is deemed satisfactory. Existing acceleration methods, including training-free solvers and post-training distillation, struggle to deliver high-quality previews or ensure consistency between previews and final outputs. We propose ConsistencySolver derived from general linear multistep methods, a lightweight, trainable high-order solver optimized via Reinforcement Learning, that enhances preview quality and consistency. Experimental results demonstrate that ConsistencySolver significantly improves generation quality and consistency in low-step scenarios, making it ideal for efficient preview-and-refine workflows. Notably, it achieves FID scores on-par with Multistep DPM-Solver using 47% fewer steps, while outperforming distillation baselines. Furthermore, user studies indicate our approach reduces overall user interaction time by nearly 50% while maintaining generation quality. Code is available at https://github.com/G-U-N/consolver.

</details>


### [423] [Scalable Formal Verification via Autoencoder Latent Space Abstraction](https://arxiv.org/abs/2512.13593)
*Robert Reed,Morteza Lahijanian,Luca Laurenti*

Main category: cs.LG

TL;DR: 提出一种基于凸自编码器的形式化降维方法，在潜在空间构建有限抽象并保证包含原始系统行为，实现可扩展的形式验证。


<details>
  <summary>Details</summary>
Motivation: 有限抽象方法面临高维系统可扩展性挑战，基于学习的降维方法缺乏正确性保证，需要既能降维又能保证验证正确性的方法。

Method: 使用凸自编码器降维，通过核方法学习潜在空间动态，在潜在空间构建包含原始系统行为的有限抽象。

Result: 方法在多个系统上有效，包括26维神经网络控制系统，显著提升可扩展性而不损失严谨性，潜在空间验证结果可映射回原始系统。

Conclusion: 提出的凸自编码器降维与核方法学习相结合，为高维系统提供了可扩展且正确性保证的形式验证框架。

Abstract: Finite Abstraction methods provide a powerful formal framework for proving that systems satisfy their specifications. However, these techniques face scalability challenges for high-dimensional systems, as they rely on state-space discretization which grows exponentially with dimension. Learning-based approaches to dimensionality reduction, utilizing neural networks and autoencoders, have shown great potential to alleviate this problem. However, ensuring the correctness of the resulting verification results remains an open question. In this work, we provide a formal approach to reduce the dimensionality of systems via convex autoencoders and learn the dynamics in the latent space through a kernel-based method. We then construct a finite abstraction from the learned model in the latent space and guarantee that the abstraction contains the true behaviors of the original system. We show that the verification results in the latent space can be mapped back to the original system. Finally, we demonstrate the effectiveness of our approach on multiple systems, including a 26D system controlled by a neural network, showing significant scalability improvements without loss of rigor.

</details>


### [424] [LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification](https://arxiv.org/abs/2512.13617)
*Ankit Sharma,Sayan Roy Gupta*

Main category: cs.LG

TL;DR: LightTopoGAT：一种轻量级图注意力网络，通过拓扑增强（节点度和局部聚类系数）改进图表示学习，在保持参数效率的同时提升分类性能


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络需要大量计算资源且难以有效捕捉全局图属性，现有方法通常忽略结构信息

Method: 提出LightTopoGAT，通过节点度和局部聚类系数进行拓扑增强，采用简化的注意力机制保持参数效率

Result: 在MUTAG、ENZYMES和PROTEINS数据集上优于GCN、GraphSAGE和标准GAT，MUTAG准确率提升6.6%，PROTEINS提升2.2%

Conclusion: 拓扑特征能显著提升图神经网络性能，提供了一种简单有效的增强策略，不增加架构复杂度

Abstract: Graph Neural Networks have demonstrated significant success in graph classification tasks, yet they often require substantial computational resources and struggle to capture global graph properties effectively. We introduce LightTopoGAT, a lightweight graph attention network that enhances node features through topological augmentation by incorporating node degree and local clustering coefficient to improve graph representation learning. The proposed approach maintains parameter efficiency through streamlined attention mechanisms while integrating structural information that is typically overlooked by local message passing schemes. Through comprehensive experiments on three benchmark datasets, MUTAG, ENZYMES, and PROTEINS, we show that LightTopoGAT achieves superior performance compared to established baselines including GCN, GraphSAGE, and standard GAT, with a 6.6 percent improvement in accuracy on MUTAG and a 2.2 percent improvement on PROTEINS. Ablation studies further confirm that these performance gains arise directly from the inclusion of topological features, demonstrating a simple yet effective strategy for enhancing graph neural network performance without increasing architectural complexity.

</details>


### [425] [StutterFuse: Mitigating Modality Collapse in Stuttering Detection with Jaccard-Weighted Metric Learning and Gated Fusion](https://arxiv.org/abs/2512.13632)
*Guransh Singh,Md Shah Fahad*

Main category: cs.LG

TL;DR: StutterFuse：首个用于多标签口吃检测的检索增强分类器，通过结合临床案例记忆库解决重叠性言语不流畅的识别问题，并解决了模态崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有参数化模型难以区分复杂的重叠性言语不流畅（如"阻塞"与"延长"同时发生），因为训练数据中这些特定组合稀缺。虽然检索增强生成（RAG）在NLP领域取得了革命性进展，但在病理语音处理领域尚未探索。

Method: 提出StutterFuse，首个用于多标签口吃检测的检索增强分类器（RAC）。通过将Conformer编码器与临床案例的非参数记忆库相结合，使模型能够基于参考而非记忆进行分类。为解决"模态崩溃"问题，采用：（1）SetCon：基于Jaccard加权的度量学习目标，优化多标签集相似度；（2）门控专家混合融合策略，动态协调声学证据与检索上下文。

Result: 在SEP-28k数据集上，StutterFuse获得加权F1分数0.65，优于强基线模型，并展现出卓越的零样本跨语言泛化能力。

Conclusion: StutterFuse成功将检索增强范式引入病理语音处理，通过解决模态崩溃问题，有效提升了重叠性言语不流畅的检测性能，为临床口吃评估提供了新工具。

Abstract: Stuttering detection breaks down when disfluencies overlap. Existing parametric models struggle to distinguish complex, simultaneous disfluencies (e.g., a 'block' with a 'prolongation') due to the scarcity of these specific combinations in training data. While Retrieval-Augmented Generation (RAG) has revolutionized NLP by grounding models in external knowledge, this paradigm remains unexplored in pathological speech processing. To bridge this gap, we introduce StutterFuse, the first Retrieval-Augmented Classifier (RAC) for multi-label stuttering detection. By conditioning a Conformer encoder on a non-parametric memory bank of clinical examples, we allow the model to classify by reference rather than memorization. We further identify and solve "Modality Collapse", an "Echo Chamber" effect where naive retrieval boosts recall but degrades precision. We mitigate this using: (1) SetCon, a Jaccard-Weighted Metric Learning objective that optimizes for multi-label set similarity, and (2) a Gated Mixture-of-Experts fusion strategy that dynamically arbitrates between acoustic evidence and retrieved context. On the SEP-28k dataset, StutterFuse achieves a weighted F1-score of 0.65, outperforming strong baselines and demonstrating remarkable zero-shot cross-lingual generalization.

</details>


### [426] [A Scientific Reasoning Model for Organic Synthesis Procedure Generation](https://arxiv.org/abs/2512.13668)
*Guoqing Liu,Junren Li,Zihan Zhao,Eray Inanc,Krzysztof Maziarz,Jose Garrido Torres,Victor Garcia Satorras,Shoko Ueda,Christopher M. Bishop,Marwin Segler*

Main category: cs.LG

TL;DR: QFANG是一个科学推理语言模型，能够从反应方程式直接生成精确的结构化实验程序，通过化学引导推理和强化学习实现高质量合成程序生成。


<details>
  <summary>Details</summary>
Motivation: 解决计算机辅助合成规划中的关键挑战：弥合计算路线设计与实际实验室执行之间的差距，特别是准确预测每个合成步骤的可行实验程序。

Method: 1) 构建包含905,990个化学反应与结构化动作序列的高质量数据集；2) 引入化学引导推理框架生成基于化学知识的链式思维数据；3) 通过监督微调激发复杂化学推理；4) 应用可验证奖励强化学习进一步提升程序准确性。

Result: QFANG在传统NLP相似度指标和基于LLM-as-a-judge的化学感知评估中，优于先进的通用推理模型和最近邻检索基线，并能泛化到某些域外反应类别，适应实验室条件和用户特定约束的变化。

Conclusion: QFANG生成高质量合成程序的能力代表了向弥合计算合成规划与全自动实验室合成之间差距迈出的重要一步。

Abstract: Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly the accurate prediction of viable experimental procedures for each synthesis step. In this work, we present QFANG, a scientific reasoning language model capable of generating precise, structured experimental procedures directly from reaction equations, with explicit chain-of-thought reasoning. To develop QFANG, we curated a high-quality dataset comprising 905,990 chemical reactions paired with structured action sequences, extracted and processed from patent literature using large language models. We introduce a Chemistry-Guided Reasoning (CGR) framework that produces chain-of-thought data grounded in chemical knowledge at scale. The model subsequently undergoes supervised fine-tuning to elicit complex chemistry reasoning. Finally, we apply Reinforcement Learning from Verifiable Rewards (RLVR) to further enhance procedural accuracy. Experimental results demonstrate that QFANG outperforms advanced general-purpose reasoning models and nearest-neighbor retrieval baselines, measured by traditional NLP similarity metrics and a chemically aware evaluator using an LLM-as-a-judge. Moreover, QFANG generalizes to certain out-of-domain reaction classes and adapts to variations in laboratory conditions and user-specific constraints. We believe that QFANG's ability to generate high-quality synthesis procedures represents an important step toward bridging the gap between computational synthesis planning and fully automated laboratory synthesis.

</details>


### [427] [Directional Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2512.13672)
*Kunhee Kim,NaHyeon Park,Kibeom Hong,Hyunjung Shim*

Main category: cs.LG

TL;DR: DTI通过固定嵌入向量的模长并仅优化方向，解决了传统TI中嵌入模膨胀导致复杂提示失败的问题，在保持主体相似性的同时显著提升了文本保真度。


<details>
  <summary>Details</summary>
Motivation: 传统文本反演方法在复杂提示下常失败，研究发现这是由于学习到的token嵌入模长膨胀，导致在预归一化Transformer中提示条件化效果下降。

Method: 提出方向性文本反演：固定嵌入向量的模长为分布内尺度，仅通过黎曼SGD优化单位超球面上的方向；将方向学习建模为带冯·米塞斯-费希尔先验的MAP估计。

Result: DTI在个性化任务中比TI及其变体显著提升文本保真度，同时保持主体相似性；超球面参数化支持学习概念间的平滑语义插值。

Conclusion: 仅优化方向是实现提示忠实个性化的鲁棒且可扩展路径；嵌入模长膨胀是TI失败的关键原因，方向优化能有效解决此问题。

Abstract: Textual Inversion (TI) is an efficient approach to text-to-image personalization but often fails on complex prompts. We trace these failures to embedding norm inflation: learned tokens drift to out-of-distribution magnitudes, degrading prompt conditioning in pre-norm Transformers. Empirically, we show semantics are primarily encoded by direction in CLIP token space, while inflated norms harm contextualization; theoretically, we analyze how large magnitudes attenuate positional information and hinder residual updates in pre-norm blocks. We propose Directional Textual Inversion (DTI), which fixes the embedding magnitude to an in-distribution scale and optimizes only direction on the unit hypersphere via Riemannian SGD. We cast direction learning as MAP with a von Mises-Fisher prior, yielding a constant-direction prior gradient that is simple and efficient to incorporate. Across personalization tasks, DTI improves text fidelity over TI and TI-variants while maintaining subject similarity. Crucially, DTI's hyperspherical parameterization enables smooth, semantically coherent interpolation between learned concepts (slerp), a capability that is absent in standard TI. Our findings suggest that direction-only optimization is a robust and scalable path for prompt-faithful personalization.

</details>
