<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 266]
- [cs.AI](#cs.AI) [Total: 101]
- [cs.MM](#cs.MM) [Total: 3]
- [cs.LG](#cs.LG) [Total: 185]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi：一种通过跨模态知识转移从RGB到无线传感器（LiDAR/mmWave）进行骨架估计和动作识别的新框架，解决了无线传感器数据不足和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 基于RGB摄像头的骨架动作识别在黑暗环境下性能下降且存在隐私问题，限制了在智能家居和医院等场景的应用。无线传感器（LiDAR/mmWave）作为替代方案面临两个主要挑战：1）无线传感器模态数据不足难以训练准确的骨架估计模型；2）无线传感器提取的骨架关键点噪声更大，影响后续动作识别。

Method: 提出SkeFi框架，采用跨模态知识转移方法从数据丰富的RGB模态获取知识。核心包括：增强的时间相关性自适应图卷积（TC-AGC）配合帧交互增强来处理缺失或不连续帧的噪声；通过双时间卷积增强多尺度时间建模；将TC-AGC与时间建模结合实现跨模态转移，从噪声无线传感器中提取准确姿态和动作。

Result: 实验表明SkeFi在毫米波和LiDAR传感器上实现了最先进的性能，有效解决了无线传感器骨架动作识别的数据不足和噪声问题。

Conclusion: SkeFi通过创新的跨模态知识转移框架，成功将RGB模态的知识迁移到无线传感器，解决了数据不足和噪声问题，为在隐私敏感和黑暗环境中的动作识别提供了可行的无线传感器解决方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [2] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

TL;DR: HVP-Net通过提取和精炼视觉编码器中间层的特征来挖掘更丰富的视频语义，缓解视频冗余问题，在多个基准测试中达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP等预训练模型的视频文本检索方法受限于视频固有的冗余性和对粗粒度最终层特征的依赖，限制了匹配准确性。

Method: 提出HVP-Net（分层视觉感知网络），从视觉编码器的多个中间层提取和精炼特征，在不同语义层次上从原始补丁标记中逐步蒸馏出显著的视觉概念。

Result: 在MSRVTT、DiDeMo和ActivityNet等具有挑战性的基准测试中取得了新的最先进性能。

Conclusion: 验证了利用分层特征提升视频文本检索的有效性，为缓解视频冗余和提升匹配精度提供了新思路。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [3] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 在农业病害分类任务中，领域特定的自监督预训练（SimCLR）比层次化架构设计带来更大的性能提升，且这种提升是架构无关的。


<details>
  <summary>Details</summary>
Motivation: 研究领域特定自监督预训练对农业病害分类的影响，比较其与层次化架构设计对性能的相对贡献。

Method: 使用SimCLR在3000张未标记农业图像上进行自监督预训练，然后评估在HierarchicalViT（HVT）、Swin-Base和ViT-Base等架构上的性能。在三个数据集（Cotton Leaf Disease、PlantVillage、PlantDoc）上进行评估，并分析模型校准性。

Result: SimCLR预训练带来+4.57%的准确率提升，超过层次化架构设计的+3.70%增益。该提升是架构无关的：Swin-Base提升+4.08%，ViT-Base提升+4.20%。HVT-Base在参数量匹配时比Swin-Base高+1.68%。HVT的校准误差为3.56% ECE（温度缩放后降至1.52%）。

Conclusion: 在农业病害分类中，领域特定的自监督预训练比架构选择更重要，实践者应优先收集领域数据而非专注于架构优化。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [4] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 提出3D TransUNet框架，从T1w MRI合成扩散MRI的FA和MD图，提升阿尔茨海默病早期诊断准确性


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，但临床常用的T1w MRI只能检测晚期宏观变化，而能检测早期微观异常的扩散MRI扫描时间长、易受运动伪影影响，限制了临床应用。需要从常规T1w MRI中提取扩散微结构信息。

Method: 提出3D TransUNet图像合成框架，直接从T1w MRI预测扩散MRI的分数各向异性（FA）和平均扩散率（MD）图。模型生成高质量合成图，结构相似性指数（SSIM）超过0.93，与真实扩散MRI的皮尔逊相关系数>0.94。

Result: 合成特征集成到多模态诊断模型中，将AD分类准确率提升5%（78.75%→83.75%），更重要的是将轻度认知障碍（MCI）检测率提高12.5%。

Conclusion: 高质量扩散微结构信息可从常规T1w MRI中推断，将多模态成像优势扩展到无扩散数据的场景。该方法减少扫描时间同时保留互补信息，有望提高AD诊断的可及性、效率和准确性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [5] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++：基于分层约束神经高斯表示的RGB-D SLAM系统，通过渐进姿态优化和动态神经表示图，在深度噪声下实现高精度3D重建和逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM方法在深度噪声下难以保持结构一致性和鲁棒的姿态估计，限制了实时3D重建在机器人和增强现实中的应用。

Method: 1. 分层约束神经高斯表示：保持结构关系的同时生成高斯基元进行场景建图
2. 渐进姿态优化：缓解深度传感器噪声，提升定位精度
3. 动态神经表示图：根据局部几何复杂度调整高斯节点分布，实时适应复杂场景细节

Result: 实验结果显示PointSLAM++在重建精度和渲染质量上优于现有的3DGS-based SLAM方法，在大规模AR和机器人应用中表现出优势。

Conclusion: PointSLAM++通过创新的神经高斯表示和优化策略，解决了深度噪声下的SLAM挑战，实现了高精度3D建图和逼真渲染，为机器人和AR应用提供了有效的解决方案。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [6] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 提出基于单类自编码器的历史绘画认证框架，使用手工特征在小型参考集上训练艺术家特定验证器，在900次验证中取得83.3%真接受率和9.5%假接受率。


<details>
  <summary>Details</summary>
Motivation: 纸质作品的身份验证和归属鉴定在文化遗产领域面临持续挑战，特别是当参考语料库较小且风格线索主要通过线条和有限色调变化表达时，需要一种能够在小数据环境下工作的认证方法。

Method: 使用单类自编码器框架，基于手工特征（傅里叶域能量、香农熵、全局对比度、GLCM同质性、盒计数分形复杂度）训练10个艺术家特定验证器，采用生物识别式协议进行评估。

Result: 在900次验证决策中，系统总体真接受率为83.3%，假接受率为9.5%。不同艺术家表现差异显著，有些验证器假接受率接近零，有些则存在较高混淆性。错误接受呈现结构化模式，与风格接近性和共享绘画惯例一致。

Conclusion: 该方法旨在补充而非替代鉴赏家判断，为历史素描归属鉴定中常见的数据稀缺环境提供可重复的定量证据，同时指出了数字化伪影控制和阈值校准的改进方向。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [7] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 提出SLT（单层Transformer），通过蒸馏将FreeFlow的28层Transformer压缩为单层共享DiT块，参数从675M降至4.3M，利用快速采样在噪声空间筛选高质量初始点，提升单步生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法致力于将扩散模型的迭代生成过程压缩到少数甚至单步，但单步生成质量受初始噪声影响较大。观察到FreeFlow的28层Transformer架构可视为ODE沿深度轴的欧拉离散化，希望通过蒸馏减少层数，同时利用快速采样筛选高质量初始噪声点。

Method: 将FreeFlow的28层Transformer蒸馏为单层共享DiT块（SLT）。训练时匹配教师模型在多个深度补丁的中间特征，融合这些补丁级表示，同时对齐教师的最终速度预测。利用SLT的快速采样能力，在相同时间内筛选更多噪声空间候选点，为教师模型选择高质量初始点。

Result: 成功将参数从675M压缩到4.3M。在相当于教师模型两次随机采样的时间内，可进行超过100次噪声筛选，并通过教师模型使用选定点生成高质量样本。有效避免了有限采样次数下低质量初始噪声引起的质量波动，显著提升单步生成的稳定性和平均质量。

Conclusion: SLT通过蒸馏实现了极致的模型压缩，同时利用快速采样能力优化初始噪声选择，为单步生成提供了稳定且高质量的解，在保持生成质量的同时大幅降低计算成本。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [8] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: CCPO通过坐标感知空间压缩和基于距离的优势函数，解决多轮GUI代理中的上下文膨胀问题，实现高效策略优化


<details>
  <summary>Details</summary>
Motivation: 多轮GUI代理在完成任务时，随着交互历史积累会出现严重的上下文膨胀问题。现有方法要么通过截断牺牲长期上下文，要么通过令牌剪枝损害空间结构

Method: 提出坐标压缩策略优化框架，包含坐标感知空间压缩和基于距离的优势函数。CASC从多个rollout中聚合坐标信息，捕捉目标相关区域并逐步缩小历史注意力范围

Result: 在四个基准测试中达到最先进性能，实现高达55%的令牌压缩和3.8倍的训练加速

Conclusion: CCPO有效解决了多轮GUI代理的上下文膨胀问题，通过视觉压缩与策略优化的耦合实现了高效的任务完成

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [9] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP是一个统一框架，通过融合场景图和常识图来解决MLLMs在VQA中的知识幻觉和细粒度视觉感知不足问题，显著提升了VQA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉问答中存在两个主要限制：知识幻觉（产生不准确的知识）和细粒度视觉感知不足。研究发现场景图和常识图分别能解决这两个问题，但以往工作将它们孤立处理，忽略了它们的协同潜力。

Method: 提出KG-ViP统一框架，核心是一个新颖的检索-融合流程：使用查询作为语义桥梁，逐步整合场景图和常识图，合成统一的结构化上下文，促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的大量实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 通过融合场景图和常识图，KG-ViP有效解决了MLLMs在VQA中的双重限制，展示了结构化知识融合在多模态推理中的重要性。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [10] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: ViEBench是一个过程可验证的视觉推理基准，包含200张多场景高分辨率图像和专家标注的视觉证据，通过双轴矩阵提供细粒度评估指标，用于评估视觉语言模型的忠实推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要依赖结果导向的准确性，缺乏评估模型是否能准确利用细粒度视觉线索进行多步推理的能力，需要更可解释和实用的评估方法。

Method: 构建包含200张多场景高分辨率图像的ViEBench基准，专家标注视觉证据，将任务按难度分为感知和推理维度，引入双轴矩阵提供四个诊断象限的细粒度评估指标。

Result: 实验发现：(1) VLM有时能基于无关区域产生正确答案；(2) 模型可能成功定位正确证据但仍无法利用它得出准确结论，表明ViEBench能更全面地评估模型推理能力。

Conclusion: ViEBench可作为更可解释和实用的基准，全面评估视觉语言模型的有效性，揭示模型推理过程中的真实性问题。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [11] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 基于多模态LLM代理的短视频平台新兴问题自动发现方法，显著提升问题发现效率并加速标注策略迭代


<details>
  <summary>Details</summary>
Motivation: 短视频平台趋势变化迅速，新内容问题不断涌现，超出已有标注策略覆盖范围。传统人工发现问题速度太慢，导致标注策略更新延迟，严重影响内容治理效果。

Method: 提出基于多模态LLM代理的自动问题发现方法：1) 自动召回包含潜在新问题的短视频；2) 采用两阶段聚类策略对视频进行分组，每个聚类对应一个新发现的问题；3) 代理从聚类生成更新的标注策略，扩展对新兴问题的覆盖。

Result: 方法已在实际系统中部署。离线和在线实验表明：1) 新兴问题发现效果显著提升（F1分数提高超过20%）；2) 后续问题治理性能增强（问题视频观看量减少约15%）；3) 相比人工发现问题，大幅降低时间成本并加速标注策略迭代。

Conclusion: 基于多模态LLM代理的自动问题发现方法能有效解决短视频平台新兴内容问题发现慢的问题，显著提升内容治理效率，加速标注策略迭代周期。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [12] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 提出Anon-NET统一框架，通过扩散生成模型进行人脸视频匿名化，在保护隐私的同时保留年龄、性别、种族、姿态和表情等属性。


<details>
  <summary>Details</summary>
Motivation: 在保护隐私的同时，允许视频分析任务（如表情识别、人员跟踪、动作识别）的进行，需要一种既能去识别化又能保留重要视觉属性的方法。

Method: 使用基于扩散的生成模型进行人脸修复，通过高级属性识别和运动感知的表情转移来指导生成过程，然后通过视频驱动动画对去识别化的人脸进行动画处理。

Result: 在VoxCeleb2、CelebV-HQ和HDTF数据集上的广泛实验表明，Anon-NET在混淆身份的同时，能保持视觉真实性和时间一致性。

Conclusion: Anon-NET是一个有效的统一框架，能够在人脸视频匿名化中平衡隐私保护和视觉属性保留，代码将公开发布。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [13] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

TL;DR: 本文引入了一个诊断性微基准测试，用于量化分析视觉语言代理的自我纠正能力，揭示了初始任务成功率与纠正成功率之间的显著差距，并识别了语义漂移作为主要失败原因。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型使视觉语言代理能够将复杂视觉任务分解为可执行的工具计划，但当前基准测试对迭代自我纠正的评估不足，其定量限制和主要推理瓶颈尚未得到充分表征。

Method: 引入诊断性微基准测试，将任务成功率与纠正成功率解耦分析，量化纠正的递减回报，并通过失败分类法识别语义漂移作为主要失败原因。

Result: 任务成功率为62%，纠正成功率仅为25-33%，初始能力无法预测修复能力；纠正效果在三次尝试后饱和；约28%的失败由语义漂移（上下文状态丢失）导致。

Conclusion: 该基准测试通过隔离语义漂移这一推理瓶颈，为开发具有状态保持能力的可信多模态代理提供了可复现的评估框架。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [14] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC框架，通过数据质量诊断与修正提升轻量级杂草检测模型性能，在固定模型容量下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临严格的计算资源、模型容量和实时推理延迟限制，无法通过模型缩放或集成来提升性能，需要数据层面的优化方案

Method: 提出模型驱动数据修正（MDDC）框架，通过自动化错误分析将检测失败分为四类（假阴性、假阳性、类别混淆、定位错误），采用结构化训练-修复-再训练流程和版本控制数据管理

Result: 在多个杂草检测数据集上，使用固定轻量级检测器（YOLOv8n）实现了5-25%的mAP@0.5提升，表明系统化数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 在模型容量固定的约束下，通过数据中心的系统化数据质量优化可以有效提升检测性能，为边缘设备上的农业杂草检测提供了实用的解决方案

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [15] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程准确建模视频生成中的注意力模式，解决了传统稀疏注意力方法的计算效率和质量问题。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频生成中面临自注意力机制二次复杂度的限制，现有稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: 提出MOD-DiT框架：1）利用早期去噪步骤的先验信息，采用分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2）在线块掩码策略动态应用这些预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上展示了持续的加速和质量改进，验证了MOD-DiT在高效高质量视频生成中的有效性，克服了传统稀疏注意力方法的计算限制。

Conclusion: MOD-DiT通过创新的采样自由动态注意力框架，成功解决了视频生成中注意力机制的计算效率问题，为实际部署提供了可行的解决方案。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [16] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 提出基于物理的合成模拟框架(PSSF)生成可控的膝关节X光片，用于骨关节炎评估，解决真实数据获取的隐私和资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球主要致残原因，目前主要依赖主观的Kellgren-Lawrence分级评估。AI和影像组学需要大量标注良好的X光数据集，但受隐私、管理和资源限制难以获取。

Method: 开发2D X光投影模拟器，基于参数化解剖模型生成远端股骨和近端胫骨的前后位膝关节X光片。创建180名受试者(260个膝盖)的虚拟队列，采用三种成像协议。使用IBSI标准处理内侧关节区域，并应用逻辑回归、随机森林和梯度提升三种机器学习模型进行KL分级预测。

Result: 在IBSI协议内、跨协议和多协议场景下评估了模型的鲁棒性，并通过类内相关系数评估了特征在不同采集条件下的稳定性。

Conclusion: 提出的物理合成模拟框架能够生成可控的X光片，为骨关节炎评估提供隐私保护的数据解决方案，支持AI模型开发和验证。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [17] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 提出基于视觉的置信度估计框架，通过几何验证来预测何时信任VLM的空间推理预测，显著提升选择预测性能


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态任务中表现出色，但在空间推理方面存在系统性失败（准确率仅49%-54%）。为确保在机器人和自主系统中的安全部署，需要预测何时信任VLM的空间预测，而不是盲目接受所有输出

Method: 提出基于视觉的置信度估计框架，通过独立几何验证来验证VLM预测。融合四种信号：VLM声明与坐标的几何对齐、空间重叠的模糊性、检测质量以及VLM内部不确定性，使用梯度提升进行融合

Result: 在BLIP-2上达到0.674 AUROC（比文本基线提升34.0%），在CLIP上达到0.583 AUROC（提升16.1%）。在60%目标准确率下，覆盖率达到61.9%（基线27.6%，提升2.2倍）。特征分析显示视觉信号贡献87.4%重要性

Conclusion: 外部几何验证优于VLM自评估，能够可靠地预测VLM空间推理的可信度，显著提升场景图构建精度（从52.1%到78.3%），同时保留68.2%的边，为安全部署提供有效解决方案

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [18] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 提出IMSAHLO框架，结合多尺度注意力与混合损失优化，用于荧光显微镜神经元细胞分割，解决细胞密度不均、形态复杂和类别不平衡问题，在FNC数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元分割面临密集与稀疏细胞共存、形态复杂重叠、类别不平衡等挑战，传统深度学习方法难以保持拓扑细节和准确边界分割。

Method: 提出IMSAHLO框架：1）多尺度密集块（MSDBs）捕获不同感受野特征；2）分层注意力（HA）机制聚焦形态特征；3）混合损失函数结合Tversky和Focal损失处理类别不平衡，加上拓扑感知中心线Dice损失和轮廓加权边界损失。

Result: 在FNC数据集上，精度81.4%，宏F1分数82.7%，微F1分数83.3%，平衡准确率99.5%，在密集和稀疏情况下均优于现有方法。消融研究验证了多尺度注意力和混合损失项的协同效益。

Conclusion: 该工作为可泛化的分割模型奠定了基础，适用于广泛的生物医学成像模态，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [19] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 研究发现文本到图像生成AI存在算法外貌主义偏见，将面部吸引力与正面属性关联，并在性别分类任务中显示性别偏见，女性面孔误分类率更高，新模型加剧了审美约束。


<details>
  <summary>Details</summary>
Motivation: 研究动机是调查文本到图像生成AI中的算法外貌主义——基于外貌的系统性偏好，以及在下游性别分类任务中的偏见问题，揭示AI视觉系统中嵌入的社会偏见如何加剧不平等。

Method: 使用Stable Diffusion 2.1和3.5 Medium生成26,400张合成人脸，分析生成AI模型如何将面部吸引力与正面属性关联，并测试三种性别分类算法在不同属性输入下的性别偏见。

Result: 发现三个关键危害：1）T2I模型系统性编码吸引力与正面属性关联；2）性别分类系统中女性面孔（特别是负面属性生成的）误分类率显著高于男性；3）新模型通过年龄同质化、性别化曝光模式和地理简化加剧审美约束。

Conclusion: 算法外貌主义是跨AI视觉系统的系统性基础设施，通过表征和识别两方面加剧现有不平等，研究揭示了生成AI如何反映和强化社会建构的偏见而非基于证据的关联。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [20] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出基于像素段相似性指数(PSSI)和最大生成树(MaxST)的交互式图分割方法，在分割质量和计算效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户交互敏感、前景背景颜色相似时性能下降等问题，需要更鲁棒的相似性度量方法

Method: 提出PSSI相似性度量，结合像素强度和空间平滑特征；使用MeanShift进行低级分割，构建像素-段图，基于PSSI计算边权重，采用MaxST进行分割

Result: 在GrabCut和Images250数据集上实验，在IoU、F1分数、执行时间和平均误差等指标上优于AMOE、OneCut、SSNCut等现有方法

Conclusion: 提出的PSSI-MaxST方法能有效结合颜色相似性、平滑性、纹理、形状和局部连通性，在交互式图分割中表现出优越性能

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [21] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

TL;DR: 提出Masked Binary U-Net (MBU-Net)，通过成本感知的掩码策略在保持精度的同时实现接近二值化的效率，并开发了GPU执行框架来利用Tensor Core实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 实时图像分割在AR/VR、机器人、无人机等边缘设备上需要平衡精度、延迟和能耗。U-Net相比大型Transformer模型在精度和效率上有优势，但在高分辨率输入上难以实现实时性能。极端量化（特别是二值网络）虽然硬件友好，但面临精度严重下降和缺乏端到端GPU实现的问题。

Method: 提出Masked Binary U-Net (MBU-Net)：1) 通过零掩码训练二值U-Net权重获得稀疏性；2) 采用成本感知掩码策略，优先掩码能带来最高精度-成本比的权重；3) 开发GPU执行框架，通过减法位编码方案将MBU-Net映射到Tensor Core，利用原生二值Tensor Core BMMA指令实现高效推理。

Result: 在3个分割基准测试中，MBU-Net达到接近全精度准确率（平均下降仅3%），相比16位浮点U-Net实现2.04倍加速和3.54倍能耗降低。

Conclusion: MBU-Net通过成本感知掩码策略和高效的GPU实现，成功解决了二值网络在精度和实际部署效率方面的挑战，为资源受限边缘设备上的实时图像分割提供了可行的解决方案。

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [22] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

TL;DR: 提出LTV-YOLO轻量级热成像检测模型，专门用于恶劣天气和低光照条件下检测儿童等弱势道路使用者，基于YOLO11架构优化，适用于边缘设备实时运行。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在低光照和恶劣天气条件下检测弱势道路使用者（特别是儿童和青少年）效果不佳，需要可靠的热成像检测方案来提升行人安全，尤其是在学校区域、自动驾驶和智慧城市基础设施中。

Method: 基于YOLO11架构定制热成像检测模型LTV-YOLO，集成深度可分离卷积和特征金字塔网络（FPN），专门针对热成像数据优化，用于检测小尺度、部分遮挡和热特征明显的弱势道路使用者。

Result: LTV-YOLO在计算效率、准确性和实时性能方面表现优异，能够在边缘设备上实现可靠的弱势道路使用者检测，特别是在低光照和恶劣天气条件下。

Conclusion: 该研究为智能交通系统提供了一种实用且可扩展的解决方案，专门针对儿童等小型弱势道路使用者的热成像检测，填补了现有热成像检测器在特定任务优化方面的空白。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [23] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了无人机在AEC+FM领域基础设施检测中的应用，涵盖数据采集、建模、缺陷检测和决策支持，提出了融合多模态数据和Transformer架构的工作流程框架，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变建筑、工程、施工和设施管理领域的基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍面临挑战，需要系统性的工作流程框架来提高检测的准确性和可靠性。

Method: 基于150多项研究的综合分析，提出了一个集成RGB图像、LiDAR和热感应的多模态数据融合框架，结合Transformer架构和动态路径规划，形成系统化的检测工作流程。

Result: 无人机已成功应用于结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护等领域，通过路径优化、热集成和YOLO、Faster R-CNN等先进机器学习模型实现了有效的异常检测。

Conclusion: 尽管取得了显著进展，但仍需解决实时处理、多模态数据融合和模型泛化等挑战。未来研究方向包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以进一步优化基础设施检测流程。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [24] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX是一个用于医学视觉语言模型解释性的新框架，通过结合多尺度注意力、文本引导空间先验和解剖学知识，生成更精确、稳定且临床相关的梯度归因图。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型的解释方法存在空间不精确、缺乏解剖学基础、注意力粒度有限等问题，需要更忠实、可解释的模型解释来增强放射学AI应用的信任和透明度。

Method: MATEX结合了多层注意力展开、文本引导空间先验和层一致性分析，通过解剖学信息空间推理来生成精确的梯度归因图。

Result: 在MS-CXR数据集上的评估显示，MATEX在空间精度和与专家标注发现的对齐方面优于最先进的M2IB方法。

Conclusion: MATEX通过提供更精确、临床有意义的解释，有潜力增强放射学AI应用的信任和透明度。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [25] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合外围低分辨率场景信息和注视点高分辨率信息，生成与人类潜在场景表征对齐的图像元匹配。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合外围低分辨率"要点"信息和注视点高分辨率信息来理解场景。本文旨在开发能生成与人类潜在场景表征对齐图像的工具，以研究人类场景理解机制。

Method: 提出MetamerGen——基于潜在扩散模型的双流架构，使用DINOv2令牌融合注视区域的详细特征和外围降级特征。通过行为实验评估生成图像与人类场景表征的感知对齐。

Result: MetamerGen能生成与人类潜在场景表征对齐的图像元匹配。当基于观看者自身注视区域生成时，高层语义对齐最能预测元匹配性。概念验证分析揭示了影响人类判断的多层次视觉处理特征。

Conclusion: MetamerGen是理解场景理解的强大工具，能生成与人类潜在场景表征对齐的图像，为研究人类视觉场景理解机制提供了新方法。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [26] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 该论文介绍了共形点和校准圆锥的概念及其相互关系，这些概念有助于图像几何可视化，并为计算图像中的角度和方向等几何属性提供了直观方法。


<details>
  <summary>Details</summary>
Motivation: 论文旨在提供图像几何可视化的新工具，通过引入共形点和校准圆锥的概念，使图像中的几何属性（如角度和方向）计算更加直观和易于理解。

Method: 论文提出使用共形点和校准圆锥的数学框架来描述图像几何，探讨这两个概念之间的相互关系，并展示如何利用它们来可视化图像几何特征。

Result: 建立了共形点与校准圆锥之间的明确关系，证明了这些概念在图像几何可视化中的有效性，并展示了如何直观地计算图像中的角度和方向等几何属性。

Conclusion: 共形点和校准圆锥为图像几何提供了有用的可视化工具，使几何计算更加直观，这些概念在计算机视觉和图像处理领域具有应用潜力。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [27] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

TL;DR: 该研究提出使用手写运动作为行为生物特征来检测输入是否由人类生成，通过训练浅层循环神经网络在多个数据集和合成器上实现了98.3%的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 手写运动可作为独特的生物特征来验证设备或应用是否由真实用户操作，这本质上是一个反向图灵测试，需要计算机检测输入是由人类还是人工生成的。

Method: 研究10个公开手写符号数据集，使用7种不同合成器（包括运动学理论、GAN、Transformer、扩散模型等）人工复制手写样本，训练浅层循环神经网络使用非特征化轨迹数据作为输入。

Result: 分类器在所有合成器和数据集上平均达到98.3%的AUC分数和1.4%的等错误率；在少样本设置中，仅使用10%数据训练就能在剩余90%测试集上获得优异性能；在域外设置中也表现出竞争力。

Conclusion: 该工作为需要验证人类存在的计算机化系统提供了有效解决方案，增加了额外的安全层来防范攻击者，证明了手写运动作为行为生物特征的有效性。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [28] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 提出一种新的半监督域泛化方法，通过将模型中间特征与视觉语言模型的语义丰富特征空间对齐来提升性能，同时采用图像级增强和输出级正则化策略提高数据利用率和减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签精度而忽视了训练过程中的最大数据利用，这限制了性能提升潜力。需要一种既能利用有限标注数据又能有效泛化到未见目标域的方法。

Method: 1) 将模型中间特征与视觉语言模型的语义丰富且泛化的特征空间对齐，以促进域不变性；2) 采用有效的图像级增强策略；3) 实施输出级正则化策略来提高数据利用率和减少过拟合。

Result: 在四个基准测试上与现有SSDG基线方法相比，该方法在定性和定量上都达到了最先进的结果。

Conclusion: 通过特征对齐、数据增强和正则化的综合方法，能够有效解决SSDG问题，在有限标注数据下实现更好的域泛化性能。代码将公开提供。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [29] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 论文提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，发现现有模型在空间推理方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型（如DINO和CLIP）在语义理解方面表现出色，但空间推理能力有限，限制了它们在具身系统中的应用。虽然已有研究将3D任务（如深度估计）纳入训练，但模型在不同空间任务上的表现不一致，需要评估它们是否真正具备空间意识还是过拟合于特定3D目标。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，用于评估VFMs识别图像中物体相对位置的能力。该基准生成任意数量的逼真图像，包含多样化场景和完全可控的物体排列，并提供可自由访问的空间标注。

Result: 评估了一系列最先进的VFMs，揭示了它们在空间推理能力方面的显著差异。通过分析，提供了关于现代VFMs中支持或阻碍空间意识的机制的见解。

Conclusion: SpaRRTa基准测试有助于指导未来具有空间意识的视觉模型的开发，为评估和改进VFMs的空间理解能力提供了有用工具。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [30] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出一种解耦分类法的视觉搜索架构，使用无分类区域建议和统一嵌入进行相似性检索，并采用LLM-as-a-Judge框架进行零样本评估，在电商平台部署取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有工业系统通常将目标检测与基于分类法的分类耦合，并依赖目录数据进行评估，这些方法容易受到噪声影响，限制了系统的鲁棒性和可扩展性，特别是在风格驱动的电商领域，用户意图主观且开放。

Method: 1) 提出分类法解耦架构：使用无分类的区域建议和统一嵌入进行相似性检索；2) 提出LLM-as-a-Judge评估框架：以零样本方式评估查询-结果对的细微视觉相似性和类别相关性，无需人工标注或噪声目录数据。

Result: 在全球家居用品平台上大规模部署，系统提高了检索质量，带来了可衡量的客户参与度提升，离线评估指标与实际业务结果强相关。

Conclusion: 提出的分类法解耦架构和LLM-as-a-Judge评估框架为电商视觉搜索提供了更灵活、可泛化的解决方案，克服了现有系统的评估瓶颈，在实际应用中验证了有效性。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [31] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

TL;DR: studentSplat：一种用于单视图3D场景重建的3D高斯泼溅方法，通过师生架构和推断网络解决单视图重建中的尺度模糊和外推问题


<details>
  <summary>Details</summary>
Motivation: 虽然前馈式3D高斯泼溅在多视图3D场景重建和单视图3D物体重建方面取得了显著进展，但单视图3D场景重建由于单视图固有的模糊性问题仍未得到充分探索。需要解决尺度模糊性和外推问题来实现高质量的单视图场景重建。

Method: 1. 师生架构：使用多视图教师模型在训练期间为单视图学生模型提供几何监督，解决尺度模糊问题并鼓励几何有效性；2. 推断网络：完成缺失的场景上下文，实现高质量的外推

Result: studentSplat在单视图新视角重建质量上达到最先进水平，在场景级别上与多视图方法性能相当。同时作为自监督单视图深度估计方法表现出竞争力，显示了其在通用单视图3D理解任务中的潜力

Conclusion: studentSplat通过创新的师生架构和推断网络成功解决了单视图3D场景重建中的关键挑战，为单视图3D理解任务提供了有效的解决方案

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [32] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集来训练目标检测器的方法，使用CycleGAN和AdaIN两种无监督图像翻译器，在自动驾驶场景中显著提升性能并接近上限


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域适应目标检测方法虽然通过中间特征对齐取得了不错效果，但实现复杂、难以解释，且性能与使用目标域数据训练的上限仍有差距

Method: 提出生成目标域人工数据集的方法：使用CycleGAN和AdaIN两种无监督图像翻译器，仅利用源域标注数据和目标域未标注数据，生成目标域风格的训练数据来训练目标检测器

Result: 在自动驾驶真实场景中取得显著改进，在大多数情况下超越了现有最佳方法，进一步缩小了与性能上限的差距

Conclusion: 该方法不仅更简单有效，而且具有更好的可解释性，为无监督域适应目标检测提供了一种有前景的解决方案

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [33] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 提出一个基于F.A.S.T.评估的多模态深度学习框架，通过整合面部表情、语音信号和上半身运动信息，实现快速、非侵入性的卒中筛查，准确率达95.83%。


<details>
  <summary>Details</summary>
Motivation: 卒中早期识别对及时干预和改善预后至关重要，特别是在院前环境中。需要开发快速、非侵入性的自动筛查方法，以辅助医疗专业人员进行早期诊断。

Method: 提出多模态深度学习框架：1) 面部动态使用基于地标的特征和Transformer架构建模；2) 语音信号转换为梅尔频谱图，使用音频频谱Transformer处理；3) 上半身姿态序列使用MLP-Mixer网络分析时空运动模式；4) 通过注意力融合机制整合多模态特征。

Result: 在自收集的222个视频数据集上，多模态模型优于单模态基线，达到95.83%准确率和96.00% F1分数，在测试集中成功检测所有卒中病例，敏感性和特异性平衡良好。

Conclusion: 多模态学习和迁移学习在早期卒中筛查中具有潜力，但需要更大、更具临床代表性的数据集来支持可靠的现实世界部署。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [34] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: RemoteVAR：基于视觉自回归模型(VARs)的遥感变化检测新框架，通过多分辨率特征融合和专门的自回归训练策略，显著提升了变化检测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉自回归模型(VARs)在图像生成方面表现出色，但由于可控性弱、密集预测性能不佳和曝光偏差等问题，在像素级判别任务中的应用有限。本文旨在解决这些限制，将VARs应用于遥感变化检测任务。

Method: 提出RemoteVAR框架：1）通过交叉注意力将自回归预测条件化于多分辨率融合的双时相特征；2）专门为变化图预测设计了自回归训练策略。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散模型和Transformer的基线方法，取得了持续且显著的改进，为遥感变化检测建立了有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了VARs在像素级判别任务中的局限性，展示了自回归模型在遥感变化检测中的潜力，为相关应用提供了新的技术方案。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [35] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 基于EfficientNetB4的双任务模型，同时进行空中物体分类和威胁等级预测，在AODTA数据集上实现96%分类准确率和90%威胁预测准确率


<details>
  <summary>Details</summary>
Motivation: 空中平台（商用飞机、无人机、UAV）快速增加，需要实时自动威胁评估系统。当前依赖人工监控的方法可扩展性有限且操作效率低下。

Method: 使用EfficientNetB4构建双任务模型，同时执行空中物体分类和威胁等级预测。为解决数据稀缺问题，整合多个公开源构建AODTA数据集。在AVD数据集和新AODTA数据集上评估，并与ResNet-50基线比较。

Result: EfficientNetB4模型在物体分类上达到96%准确率，威胁等级预测达到90%准确率，优于ResNet-50基线。模型在监视、防御和空域管理等应用中有前景。

Conclusion: 提出的双任务EfficientNetB4模型能有效同时进行空中物体分类和威胁评估，尽管标题提到检测，但本研究专注于使用现有数据集提供的预定位图像进行分类和威胁推断。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [36] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究比较了两种光强编码函数（对数函数和Naka-Rushton函数）对中心/周边Retinex模型颜色恒常性性能的影响，发现N-R函数结合双拮抗颜色平面表示具有最佳的颜色辨别性能。


<details>
  <summary>Details</summary>
Motivation: 颜色是视觉功能的重要信息源，但受光照颜色影响很大。颜色恒常性（CC）是视觉系统的重要特性，能够独立于光照颜色感知目标颜色。本研究旨在探索光强编码函数对受视觉神经系统CC启发的经典C/S Retinex模型性能的影响。

Method: 使用颜色可变LED以不同光照颜色照射视觉目标，比较两种光强编码函数：原始C/S Retinex模型使用的对数函数和视网膜光感受器响应模型Naka-Rushton函数。使用HSV颜色空间和基于经典拮抗颜色理论的颜色平面表示颜色信息，评估不同光照下目标颜色的辨别能力。

Result: 结果显示，Naka-Rushton函数与双拮抗颜色平面表示的组合提供了最优的颜色辨别性能，优于传统的对数函数方法。

Conclusion: Naka-Rushton函数作为视网膜光感受器响应模型，结合双拮抗颜色表示，能够有效提升中心/周边Retinex模型的颜色恒常性性能，为基于生物启发的视觉系统设计提供了改进方向。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [37] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 提出无需训练的GW-VLM方法，通过多尺度视觉语言搜索和上下文概念提示，利用预训练VLM和LLM实现开放词汇目标检测，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法通常忽视根据预训练基础模型建立通用对象认知理解的重要性。虽然大规模预训练已经构建了具有零样本能力的多功能基础模型，但缺乏系统性的通用理解范式。

Method: 提出GW-VLM方法：1) 多尺度视觉语言搜索(MS-VLS)：利用类无关目标检测结果，通过多尺度视觉语言软对齐让VLM生成文本片段；2) 上下文概念提示(CCP)：基于MS-VLS形成概念流，让LLM理解这些片段用于开放词汇检测。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10等自然和遥感数据集上进行实验，GW-VLM无需任何训练步骤即可达到最先进的开放词汇目标检测性能。

Conclusion: GW-VLM通过"猜猜看"游戏范式，有效结合预训练VLM和LLM的能力，建立了开放词汇目标检测的通用理解框架，实现了无需训练的高性能检测。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [38] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

TL;DR: 该研究评估了一个紧凑型CNN在孟加拉国五个真实世界图像数据集上的表现，证明简化架构在小类别图像分类任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在图像识别任务中表现出色，但复杂架构容易在小数据集上过拟合。需要验证简化CNN架构在小类别图像分类任务中的实际效果。

Method: 使用紧凑型卷积神经网络，在孟加拉国五个公开的真实世界图像数据集上进行评估，包括城市侵占、车辆检测、道路损坏和农作物分类等场景。

Result: 网络表现出高分类准确率、高效收敛和低计算开销。定量指标和显著性分析表明模型能有效捕捉判别性特征，并在多样化场景中稳健泛化。

Conclusion: 简化CNN架构适合小类别图像分类任务，在保持高性能的同时降低了计算复杂度，为资源受限环境提供了实用解决方案。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [39] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩投影移除表示空间中虚假相关性的干预范式，提升人脸伪造检测的泛化能力


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测中的泛化问题源于虚假相关性因素（伪造无关信息）通过"后门路径"导致有偏学习。现有方法需要识别具体的虚假相关性并分别处理，但虚假相关性源于不可观测的混杂因素，难以逐个识别和处理。

Method: 提出表示空间的干预范式：将各种实例级虚假相关性统一建模为低秩子空间，通过正交低秩投影将其分解出来，然后从原始表示中移除该子空间，训练其正交补来捕捉伪造相关特征。

Result: 仅使用0.43M可训练参数，在多个基准测试中达到最先进性能，表现出优秀的鲁棒性和泛化能力。

Conclusion: 通过低秩投影移除表示空间中的虚假相关性子空间，能够有效消除虚假相关因素，确保分类决策基于真实的伪造线索，为人脸伪造检测的泛化问题提供了有效解决方案。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [40] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 使用Gabor滤波器作为CNN预处理，提升边缘设备上机器人视觉应用的准确性和泛化性能，同时减小模型尺寸


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需要小型架构，机器人视觉应用需要在有限数据条件下高效训练，视觉神经系统(VNS)从少量视觉经验中学习的能力符合这些要求

Method: 使用Gabor滤波器（VNS特征提取器模型）作为CNN预处理，在不同相机位置采集的图像数据集上训练，比较有/无Gabor预处理的多种CNN架构性能

Result: Gabor滤波器预处理提高了CNN的泛化性能，并有助于减小CNN的尺寸

Conclusion: Gabor滤波器作为预处理能有效提升边缘设备上CNN的准确性和泛化能力，同时实现模型小型化

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [41] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene提出了一种针对SfM图像检索的全局描述子学习方法，通过子图训练策略和DiVLAD聚合器，专注于寻找几何重叠的图像对而非语义相似性。


<details>
  <summary>Details</summary>
Motivation: 传统图像检索方法在SfM中更关注几何匹配性而非语义相似性，现有基于批处理二元分类（重叠vs非重叠）的深度学习方法未能捕捉这一细微差别，需要专门针对SfM重叠图像对检索的解决方案。

Method: 1. 采用子图训练策略，超越孤立图像对，利用不同权重的几何重叠关系提供细粒度监督（软监督对比损失）；2. 提出DiVLAD聚合器，利用ViT最后一层的多头注意力图；3. 设计可学习门控机制自适应融合语义显著线索与视觉特征。

Result: 在GL3D数据集上达到最先进性能，显著优于NetVLAD，同时仅引入少量可训练参数。提出的训练策略在不同聚合技术中带来一致性能提升。

Conclusion: SupScene通过专门针对SfM几何重叠图像对检索设计的训练策略和描述子聚合方法，有效提升了图像检索性能，为SfM中的图像匹配提供了更高效的解决方案。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [42] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: LMGait：一种语言引导和运动感知的步态识别框架，利用步态相关语言提示来捕捉步态序列中的关键运动特征，解决现有方法对静态噪声过拟合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示。这种设计容易对静态噪声（如衣物）过拟合，同时无法有效捕捉动态运动区域。

Method: 提出LMGait框架，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征。该方法通过语言引导来增强对动态运动的感知能力。

Result: 论文未提供具体实验结果数据，但提出了一个创新的语言引导步态识别框架来解决现有方法的局限性。

Conclusion: LMGait框架通过语言引导和运动感知机制，能够更有效地捕捉步态中的动态特征，减少对静态噪声的过拟合，为步态识别提供了新的研究方向。

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [43] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

TL;DR: 提出一种用于早产儿脑MRI白质和灰质分割的层次密集注意力网络，解决等信号强度组织区分难题，性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 早产儿面临神经发育延迟风险，需要早期识别。脑MRI体积分割是评估神经发育的有前景方法，但早产儿脑发育早期白质和灰质在MRI上信号强度相似（等信号外观），导致准确分割困难。

Method: 提出层次密集注意力网络，结合3D空间通道注意力机制和注意力引导的密集上采样策略，增强低对比度体积数据中的特征区分能力。

Result: 定量实验表明该方法在分割性能上优于现有基线方法，有效解决了等信号组织区分挑战。算法应用证实早产儿白质和灰质体积显著低于足月儿，为早产相关的神经发育延迟提供了额外影像证据。

Conclusion: 提出的层次密集注意力网络能够有效解决早产儿脑MRI中白质和灰质等信号强度组织的分割难题，为早产儿神经发育评估提供了可靠工具。

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [44] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出Decoder Gradient Shields (DGS)防御机制，保护无盒模型水印的decoder免受基于梯度查询的攻击，通过梯度重定向和缩放防止水印移除器训练收敛。


<details>
  <summary>Details</summary>
Motivation: 现有无盒模型水印研究主要关注编码器的鲁棒性，而解码器被忽视，导致存在针对解码器的攻击。攻击者利用查询响应获取反向传播梯度来训练水印移除器，需要防御机制保护水印系统。

Method: 提出DGS防御机制家族：DGS-O（输出层）、DGS-I（输入层）和DGS-L（中间层）。DGS-O有闭式解，所有DGS都有可证明的性能。通过联合设计梯度重定向和缩放，防止水印移除器达到低损失值，同时保持解码器输出图像质量。

Result: 在去雨和图像生成任务中，使用最先进的无盒水印技术，DGS在所有设置下实现100%的防御成功率，有效防止水印移除攻击。

Conclusion: DGS机制成功解决了针对无盒模型水印解码器的梯度泄露攻击问题，为DNN知识产权保护提供了有效的防御方案，填补了现有水印系统在解码器保护方面的空白。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [45] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出基于Raspberry Pi 5的边缘智能监控框架，集成目标检测、人脸识别和情绪分析，通过自适应调度机制减少65%计算负载，实现5.6 FPS实时处理。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（目标检测、人脸识别、情绪分析），缺乏统一的、自适应的运行时调度器来根据上下文触发动态分配计算资源，限制了在低功耗边缘设备上的整体理解和效率。

Method: 提出实时多模态视觉框架，将目标检测（YOLOv8n）、所有者特定人脸识别（自定义FaceNet嵌入系统）和情绪检测（DeepFace CNN）集成到统一流水线中，部署在Raspberry Pi 5边缘平台。核心是自适应调度机制，通过选择性激活模块来减少计算负载。

Result: 系统性能优异：目标检测平均精度0.861，人脸识别准确率88%，情绪检测AUC最高达0.97（特定情绪），整体运行速度5.6 FPS。自适应调度机制相比连续处理减少65%计算负载。

Conclusion: 上下文感知调度是实现复杂多模态AI在成本效益边缘硬件上运行的关键，使智能感知更加可访问且保护隐私。该工作证明了在边缘设备上实现高效多模态视觉系统的可行性。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [46] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: 提出AVIR框架解决多页文档VQA问题，通过轻量级检索模型评分页面、聚类筛选相关页面，仅将选定页面输入冻结大模型，减少70%页面需求，在MP-DocVQA上达到84.58% ANLS


<details>
  <summary>Details</summary>
Motivation: 多页文档VQA面临计算资源紧张和注意力机制效率降低的问题，长文档会降低大视觉语言模型的注意力有效性

Method: AVIR框架：1) 轻量级检索模型为每页评分；2) 根据分数分布聚类页面自适应选择相关内容；3) 聚类后页面通过Top-K筛选保持上下文紧凑；4) 短文档使用相关性概率阈值选择页面；5) 仅选定页面输入冻结LVLM生成答案，无需微调

Result: 在MP-DocVQA数据集上减少70%页面需求，达到84.58% ANLS，超越先前方法且计算成本显著降低；在SlideVQA和DUDE基准测试中也验证了有效性

Conclusion: AVIR框架有效解决了多页文档VQA的计算和注意力效率问题，通过自适应页面检索显著减少计算需求，同时保持高性能，为长文档理解提供了实用解决方案

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [47] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR是首个支持测试时自适应检测未见新闻视频的假新闻视频检测框架，采用检索引导的自适应范式，通过稳定视频参考来指导不稳定实例的鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频，需要能够适应未见新闻视频的测试时自适应框架。

Method: 提出RADAR框架：1) 基于熵选择的检索机制，为视频提供稳定、相关的参考；2) 稳定锚点引导对齐模块，通过分布级匹配将不稳定实例表示与源域对齐；3) 目标域感知自训练范式，生成由稳定参考增强的信息性伪标签。

Result: 大量实验表明，RADAR在测试时假新闻视频检测方面取得卓越性能，能够对未见假新闻视频主题进行强大的实时自适应。

Conclusion: RADAR是首个实现测试时自适应假新闻视频检测的框架，通过检索引导的自适应范式有效解决了未见新闻主题的检测问题，为假新闻视频检测提供了新的解决方案。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [48] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出一个基于AI-IoT的智能轮椅系统，结合手势控制、物体检测和健康监测，为残障人士和老年人提供经济实惠的辅助解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统轮椅缺乏动态功能，现有智能轮椅成本高、功能单一且健康监测集成不足。需要为日益增长的残障和老年人群提供先进、个性化且经济实惠的辅助技术。

Method: 采用AI-IoT架构，包含：1) 基于手套的手势控制实现免提导航；2) 使用YOLOv8进行实时物体检测并配合听觉反馈；3) 超声波传感器用于即时碰撞避免；4) 持续监测心率、血氧、心电图、体温等生命体征，数据上传至ThingSpeak平台并在危急时触发邮件警报。

Result: 手势控制成功率95.5%，超声波障碍物检测准确率94%，YOLOv8物体检测达到91.5%精确率、90.2%召回率和90.8% F1分数。系统基于模块化低成本架构，实现了多模态集成。

Conclusion: 该集成多模态方法提供了一个实用、可扩展且经济实惠的解决方案，通过弥合创新研究与实际部署之间的差距，显著增强了用户的自主性、安全性和独立性。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [49] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

TL;DR: 提出一种结合解剖先验的结构图推理框架，用于可解释的视觉诊断。将卷积特征图重新解释为图结构，通过自定义的结构传播机制建模空间关系，实现病灶感知预测和诊断推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉诊断方法缺乏结构化的推理过程和可解释性。传统图神经网络使用通用消息传递，无法有效建模医学图像中的解剖空间关系。需要一种能结合领域先验、支持结构化推理且具有内在可解释性的框架。

Method: 将卷积特征图重新解释为节点包含外观和空间坐标的图结构，边反映局部结构邻接关系。引入自定义的结构传播机制，显式建模相对空间关系作为推理过程的一部分。框架同时支持节点级病灶感知预测和图级诊断推理，通过学习节点重要性分数实现内在可解释性。

Result: 通过胸部X光案例研究展示了该方法，证明结构先验能够指导关系推理并提高可解释性。框架是领域无关的，适用于更广泛的基于图推理的人工智能系统。

Conclusion: 该工作为结构感知和可解释学习提供了基于图的计算框架，将图作为推理的归纳偏置而非被动关系表示，推动了可解释人工智能的发展。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [50] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

TL;DR: 提出了DAOS数据集和AOR-Net模型，用于驾驶员行为识别，通过建模人-物关系提升识别准确性


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员监控数据集缺乏精确的物体位置标注或未将物体与相关行为关联，导致在相似的上半身动作中难以区分不同行为（如持手机与握方向盘）

Method: 1) 创建DAOS数据集：包含9,787个视频片段，标注36种细粒度驾驶员行为和15种物体类别，提供多模态多视角数据；2) 提出AOR-Net模型：通过多层次推理和动作链提示机制建模动作、物体及其关系，引入思维混合模块动态选择关键知识

Result: AOR-Net在多个数据集上优于现有最先进方法，在物体丰富和稀缺条件下都表现出更强的鲁棒性

Conclusion: 通过DAOS数据集和AOR-Net模型，证明了建模人-物关系对于驾驶员行为识别的重要性，特别是在区分相似动作时，物体信息是关键线索

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [51] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 提出SMc2f方法，通过粗到细的流程改进自动驾驶场景挖掘：先用视觉语言模型进行粗粒度图像-文本过滤，再通过对比学习精化轨迹匹配，相比现有方法显著提升检索质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有场景挖掘方法（如RefAV）存在两个主要问题：1）依赖轨迹标签进行检索，忽略了自然语言与原始RGB图像的直接联系；2）依赖上游3D目标检测和跟踪的质量，轨迹数据不准确会导致下游时空定位不准确。

Method: 提出粗到细的SMc2f流程：1）使用视觉语言模型进行粗粒度图像-文本过滤；2）在RefAV基础上构建成功挖掘案例数据库，自动检索示例进行少样本条件学习；3）引入文本-轨迹对比学习，在共享嵌入空间中将匹配对拉近、不匹配对推远，得到细粒度匹配器来精化LLM的候选轨迹。

Result: 在公开数据集上的实验表明，该方法在检索质量和效率方面都取得了显著提升。

Conclusion: 提出的SMc2f方法通过结合视觉语言模型和对比学习，解决了现有场景挖掘方法的局限性，实现了更鲁棒和高效的自动驾驶安全验证场景检索。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [52] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion混合深度学习模型，用于SAR图像中的溢油分割，相比传统方法减少64.4%误检，准确率达94.85%


<details>
  <summary>Details</summary>
Motivation: 传统阈值方法在卫星图像溢油检测中因风浪条纹、船迹等"类似现象"导致高误报率，需要更精确的检测方法

Method: 结合SegNet和DeepLabV3+的混合深度学习模型，采用注意力机制的特征融合，提升边界精度和上下文理解

Result: 在SAR数据集上达到94.85%准确率、0.5685 IoU和0.9330 ROC-AUC，误检减少64.4%，比基线模型少3倍以上

Conclusion: DeepSegFusion在各种海洋条件下表现稳定，可用于近实时溢油监测，显著提升检测精度和可靠性

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [53] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS：一个数据高效框架，仅需极稀疏监督（少至10张图像）即可实现高保真半透明材质重建，通过扩散模型生成数据增强，减少真实采集需求达90%


<details>
  <summary>Details</summary>
Motivation: 传统神经渲染中建模半透明材质（如蜡、玉石、大理石、皮肤）的次表面散射效果需要密集的多视角多光照数据集（通常超过100个视角和112个OLAT），数据采集成本高昂且困难

Method: 1. 使用扩散模型进行新视角合成和重光照，基于估计的几何信息，仅需不到7%的数据集进行训练；2. 引入光照无关的几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建

Result: 在所有稀疏度条件下，DIAMOND-SSS在可重光照的高斯渲染中达到最先进质量，相比SSS-3DGS减少了高达90%的真实采集需求，生成的数据增强可替代高达95%的缺失采集

Conclusion: DIAMOND-SSS通过结合扩散模型的数据增强和光照无关几何先验，实现了从极稀疏监督中高质量重建半透明材质，大幅降低了数据采集成本，为实际应用提供了可行的解决方案

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [54] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic是一个模型无关的视觉模型可解释性框架，通过逻辑表示来量化解码模型决策过程，识别关键视觉区域并转化为逻辑表达式，提供量化评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型可解释性方法存在两个主要问题：要么依赖白盒模型访问权限，要么缺乏定量严谨性。在高风险应用中，模型可解释性至关重要，需要解决这些限制。

Method: FocaLogic框架识别影响模型预测的最小可解释视觉区域子集（称为视觉焦点），将这些视觉焦点转化为精确紧凑的逻辑表达式，并提出一套量化指标（焦点精度、召回率、分歧度）来客观评估模型行为。

Result: 实证分析显示FocaLogic能够揭示关键洞察：训练诱导的集中性、通过泛化提高焦点准确性、以及在偏见和对抗攻击下的异常焦点。框架提供了系统化、可扩展的视觉模型解释方案。

Conclusion: FocaLogic为视觉模型解释提供了一个系统性、可扩展且定量的解决方案，通过逻辑表示和量化指标实现了透明、结构化的模型决策解读。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [55] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出MJP框架，通过随机打乱token顺序并用可学习的未知位置嵌入进行掩码，破坏Transformer中位置嵌入的局部空间信息，既增强对抗梯度攻击的鲁棒性，又提升模型在CV和NLP任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中Transformer面临梯度攻击的挑战，研究发现位置嵌入的梯度包含足够信息可用于重建输入数据，需要解决这一安全问题。

Method: 提出Masked Jigsaw Puzzle (MJP)框架：1) 随机打乱token顺序破坏token顺序；2) 使用可学习的未知位置嵌入掩码打乱token的位置嵌入；3) 破坏局部空间信息，迫使模型学习不依赖局部空间信息的特征表示。

Result: 实验表明MJP不仅能提高模型对抗梯度攻击的鲁棒性，还能提升在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）等任务上的性能，是一个适用于不同Transformer模型的统一框架。

Conclusion: MJP通过破坏位置嵌入中的局部空间信息，有效解决了Transformer在联邦学习中的梯度攻击安全问题，同时提升了模型性能，为视觉和语言任务提供了统一的解决方案。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [56] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习的退化提示编码云层厚度和空间不确定性，联合执行云去除和土地覆盖分割，在保持高语义效用的同时实现参数高效。


<details>
  <summary>Details</summary>
Motivation: 传统云去除方法过度关注低层次保真度，容易过度平滑纹理和边界，导致视觉上合理的恢复与语义效用之间存在不匹配，无法满足分析就绪数据的需求。

Method: 提出任务驱动的多模态框架TDP-CR，核心是提示引导融合机制，使用可学习的退化提示编码云层厚度和空间不确定性，结合全局通道上下文和局部提示条件空间偏置，仅在光学数据损坏处自适应融合SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超过最先进基线0.18 dB，同时仅使用15%的参数；在mIoU上比多任务竞争对手持续提升1.4%，有效提供分析就绪数据。

Conclusion: TDP-CR通过任务驱动的多模态框架和提示引导融合机制，成功解决了云去除中视觉保真度与语义效用之间的不匹配问题，实现了参数高效的分析就绪数据生成。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [57] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

TL;DR: AUTO-DIP：基于图像元数据相似性的无监督深度图像先验参数自动转移方法，用于荧光显微镜图像去噪，无需为每张新图像重新优化参数。


<details>
  <summary>Details</summary>
Motivation: 传统无监督深度图像先验（DIP）方法需要为每张新图像优化网络架构和停止点，耗时且限制了在需要处理大量图像领域的应用。本文假设相似图像在DIP去噪中具有可比的最优参数配置，旨在实现荧光显微镜图像的免优化DIP去噪。

Method: 1. 从开源数据集生成校准集（n=110）和验证集（n=55）用于网络架构搜索；2. 基于图像元数据相似性（显微镜类型、成像样本等）而非定量图像相似度度量进行参数转移；3. 实现AUTO-DIP自动参数转移管道，并与原始DIP配置和变分去噪方法比较。

Result: 1. 基于图像元数据相似性的参数转移效果优于基于定量图像相似度度量的方法；2. AUTO-DIP在多个开源测试数据集上优于原始DIP配置和变分去噪方法，特别是在高噪声输入情况下；3. 在本地采集的荧光显微镜图像上进一步证明了AUTO-DIP的优越性。

Conclusion: AUTO-DIP通过基于图像元数据相似性的参数转移，实现了荧光显微镜图像的无监督深度图像先验去噪，无需为每张新图像重新优化参数，显著提高了处理效率并在去噪性能上优于现有方法。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [58] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

TL;DR: LSMRL方法通过语言驱动的序列级模态不变表示学习，结合时空特征学习、语义扩散和跨模态交互模块，解决VVI-ReID中的模态不变表示学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP语言提示的方法在时空建模效率、跨模态交互充分性和显式模态级损失指导方面存在局限，需要改进。

Method: 提出LSMRL方法，包含三个模块：STFL模块（基于CLIP的轻量时空建模）、SD模块（语言提示扩散到可见光和红外特征建立模态一致性）、CMI模块（双向跨模态自注意力消除剩余模态差异）。

Result: 在大规模VVI-ReID数据集上的实验表明，LSMRL方法优于现有最优方法。

Conclusion: LSMRL通过语言驱动的序列级模态不变表示学习，有效解决了VVI-ReID中的模态不变表示学习问题，在时空建模效率、跨模态交互和模态级损失指导方面均有改进。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [59] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 提出基于随机桥模型的视频对象移除方法，将任务重新定义为视频到视频的转换，利用输入视频作为结构先验，通过自适应掩码调制平衡背景保真度和生成灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频对象移除方法从高斯噪声开始生成，丢弃了原始视频丰富的结构和上下文先验，导致对象擦除不完整或生成内容与场景物理逻辑冲突。

Method: 将视频对象移除重新定义为通过随机桥模型实现的视频到视频转换任务，建立从源视频（含对象）到目标视频（对象移除）的直接随机路径。提出自适应掩码调制策略，根据掩码特征动态调节输入嵌入，平衡背景保真度和生成灵活性。

Result: 大量实验表明，该方法在视觉质量和时间一致性方面显著优于现有方法。

Conclusion: 通过桥模型框架利用输入视频作为强结构先验，结合自适应掩码调制策略，实现了更精确的视频对象移除，确保填充区域与周围环境逻辑一致。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [60] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

TL;DR: ARMARecon：一种结合ARMA图滤波和重建目标的统一图学习框架，用于阿尔茨海默病和额颞叶痴呆的早期检测，通过白质区域FA直方图特征提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和额颞叶痴呆（FTD）等神经退行性疾病的早期检测对降低疾病进展风险至关重要。由于这些疾病沿着白质区域以全局、图依赖的方式传播，基于图的神经网络非常适合捕捉这些模式。

Method: 提出ARMARecon框架，整合自回归移动平均（ARMA）图滤波与重建驱动目标，增强特征表示并提高分类准确性。利用从白质区域提取的20-bin分数各向异性（FA）直方图特征，有效建模局部和全局连接性，同时缓解过平滑问题。

Result: ARMARecon在ADNI和NIFD多站点dMRI数据集上相比最先进方法取得了优越性能。

Conclusion: ARMARecon通过结合ARMA图滤波和重建目标，为神经退行性疾病的早期检测提供了一个有效的图学习框架，能够更好地捕捉疾病传播模式并提升分类准确性。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [61] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 本文针对遥感视频指代对象分割(RS-RVOS)任务，构建了首个大规模基准数据集RS-RVOS Bench，并提出基于记忆质量控制的MQC-SAM框架，通过时序运动一致性模块和去耦注意力机制提升分割性能。


<details>
  <summary>Details</summary>
Motivation: RS-RVOS面临目标显著性弱、动态场景视觉信息截断严重的问题，现有方法存在初始记忆构建偏差和噪声积累导致的错误传播，且缺乏大规模专用基准数据集。

Method: 提出MQC-SAM框架：1) 时序运动一致性模块用于初始记忆校准，利用短期运动轨迹先验修正结构偏差；2) 基于去耦注意力的记忆集成机制，通过动态质量评估选择性更新高置信度特征，过滤不可靠信息。

Result: 构建了包含111个视频序列、约25,000帧、213,000个时序指代标注的RS-RVOS Bench数据集。在基准测试中，MQC-SAM实现了最先进的性能。

Conclusion: 本文通过数据和方法双重贡献推进了RS-RVOS研究，提出的因果感知标注策略和记忆质量控制框架有效解决了目标表示保持和错误传播问题。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [62] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: EmoLat是一个新颖的情感潜在空间，通过建模文本语义与视觉情感特征之间的跨模态相关性，实现细粒度的文本驱动图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感迁移方法缺乏细粒度控制和文本引导能力，需要建立文本语义与视觉情感特征之间的跨模态关联来实现更精确可控的情感编辑。

Method: 构建情感语义图捕捉情感、物体和视觉属性之间的关系结构；采用对抗正则化增强情感表示的可区分性和可迁移性；提出跨模态情感迁移框架，通过文本和EmoLat特征的联合嵌入来操纵图像情感；使用包含语义一致性、情感对齐和对抗正则化的多目标损失优化网络。

Result: 在EmoSpace Set数据集上的大量实验表明，该方法在定量指标和定性迁移保真度方面显著优于现有最先进方法，建立了文本引导可控图像情感编辑的新范式。

Conclusion: EmoLat通过建模跨模态情感相关性，实现了细粒度的文本驱动图像情感迁移，为可控图像情感编辑提供了有效解决方案，相关数据集和代码已开源。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [63] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: 提出FCLM模型，通过深度感知蒸馏和领域不变学习解决高精度场景解析中的前景一致性问题，支持视觉和语言提示的交互预测。


<details>
  <summary>Details</summary>
Motivation: 现有高精度场景解析方法主要关注显著单前景物体，交互方法类别不可知限制了跨类别泛化，高质量标注稀缺导致依赖不协调合成数据，泛化到真实场景效果差。

Method: 提出FCLM模型：1) 深度感知蒸馏策略，转移深度相关知识改善前景表示；2) 将合成数据处理视为领域适应问题，提出领域不变学习策略聚焦前景学习；3) 面向对象解码器，可接收视觉和语言提示预测参考目标。

Result: 实验结果表明，该方法在定量和定性评估上都优于最先进的方法。

Conclusion: FCLM通过深度感知蒸馏和领域不变学习有效解决了高精度场景解析中的前景一致性问题，支持多模态交互预测，在真实场景中表现优异。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [64] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 提出HistoCRF框架，通过条件随机场优化组织病理学图像中视觉语言模型的零样本预测，无需额外训练，利用专家标注提升分类准确性


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像分析对癌症检测和分期具有重要临床价值，现有的视觉语言模型虽然能提供零样本预测但存在不完美之处，需要一种无需额外训练的方法来优化这些预测结果

Method: 提出HistoCRF框架，将条件随机场适应于组织病理学应用，设计了新的成对势函数来促进标签多样性并利用专家标注，支持无标注、有专家标注和迭代人机交互标注三种模式

Result: 在五个涵盖不同器官和疾病的patch级分类数据集上，相比零样本预测，无标注时平均准确率提升16.0%，仅用100个标注时提升27.5%，人机交互模式在相同标注数量下进一步提升32.6%

Conclusion: HistoCRF能有效优化组织病理学视觉语言模型的预测性能，通过条件随机场框架和专家标注集成显著提升分类准确性，为人机协作的组织病理学分析提供了实用工具

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [65] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

TL;DR: 提出一种针对工业料箱的6DoF位姿估计方法，利用料箱的立方体几何特性，通过检测3D线段并几何处理来确定位姿，无需实例特定的CAD模型。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法需要大量训练数据或CAD模型，限制了在数据稀缺、物体实例多变的工业场景中的应用。工业料箱具有标准化的立方体几何特征，可以利用这一特性简化位姿估计。

Method: 1. 利用料箱的立方体几何特性，首先检测对应料箱顶边的中间3D线段；2. 将2D线段检测网络LeTR扩展到结构化点云数据；3. 通过简单的几何处理程序处理检测到的3D线段，鲁棒地确定料箱的6DoF位姿。

Result: 1. 扩展现有数据集并收集新数据集并公开；2. 合成训练数据显著提高了真实扫描的位姿估计精度；3. 方法在姿态精度上显著优于当前最先进的6DoF位姿估计方法（3cm平移误差，8.2°旋转误差），且推理时不需要实例特定的CAD模型。

Conclusion: 该方法针对工业料箱的6DoF位姿估计问题，通过利用几何特性和合成数据，实现了高精度且无需实例CAD模型的解决方案，适用于数据稀缺的工业环境。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [66] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

TL;DR: 通过知识蒸馏将大型CNN模型的知识转移到紧凑CNN，结合集成学习提升咖啡叶病诊断精度，在保持低能耗的同时实现可持续的物联网设备端诊断。


<details>
  <summary>Details</summary>
Motivation: 咖啡叶病田间诊断面临设备计算能力有限和网络连接不稳定的挑战，现有AI视觉模型虽然准确率高，但难以在资源受限的物联网设备上部署。

Method: 采用知识蒸馏方法，将数据中心训练的高容量CNN模型知识转移到紧凑CNN，结合集成学习技术，通过简单优化的集成策略整合多个轻量模型对，在严格计算和能耗约束下提升诊断精度。

Result: 在咖啡叶病数据集上，蒸馏后的轻量集成模型达到了与先前工作相当的竞争性精度，同时显著降低了能耗和碳足迹。

Conclusion: 经过适当蒸馏和集成的轻量模型能够为物联网应用提供实用的诊断解决方案，在资源受限设备上实现可持续的疾病诊断。

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [67] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

TL;DR: RCDN是一个专注于真实图像一致性的频率空间CNN框架，通过双分支架构和真实中心损失设计，在图像伪造检测中实现了优异的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有伪造检测方法在同域测试中表现优异，但在跨域场景下性能显著下降。随着新伪造技术不断涌现，检测器必须对未见过的伪造操作保持可靠，这构成了一个关键挑战。

Method: 提出Real-Centered Detection Network (RCDN)，这是一个基于Xception骨干的频率空间CNN框架。RCDN不建模多样且不断演变的伪造模式，而是将表示空间锚定在真实面部图像周围，采用双分支架构和真实中心损失设计来增强分布偏移下的鲁棒性。

Result: 在DiFF数据集上对三种代表性伪造类型（FE、I2I、T2I）进行广泛实验，RCDN实现了最先进的域内准确性和显著更强的跨域泛化能力。RCDN减少了与领先基线的泛化差距，并实现了最高的跨域/域内稳定性比率。

Conclusion: RCDN通过强调真实图像的一致性而非建模伪造模式，为防御不断演变和未见过的图像伪造技术提供了一个实用的解决方案，具有优异的跨域泛化能力。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [68] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: 提出了CARLA-Round数据集，这是一个用于环岛轨迹预测的系统化仿真数据集，包含25个受控场景，涵盖不同天气和交通密度条件，支持因素影响分析。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对减少交通事故至关重要，但由于其圆形几何结构、连续合并和让行交互、缺乏交通信号而极具挑战性。现有数据集稀缺，真实世界数据收集存在观测不完整和因素混杂的问题。

Method: 使用CARLA仿真平台系统化设计数据集，通过结构化控制天气条件（5种类型）和交通密度水平（服务水平A-E级），生成25个受控场景。每个场景包含真实的驾驶行为混合，并提供现有数据集缺乏的显式标注。

Result: 验证实验使用标准基线模型（LSTM、GCN、GRU+GCN）显示：交通密度对预测难度具有主导性的单调效应，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，证明了有效的仿真到真实迁移。

Conclusion: CARLA-Round数据集通过系统化方法量化了在混杂的真实世界数据集中无法分离的因素影响，为环岛轨迹预测研究提供了可靠、多模态、现实的仿真数据集，支持因素影响分析。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [69] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是一个轻量级扩展SAM的模型，能够同时进行高质量交互式图像分割和抠图，通过多视图定位编码器和局部适配器提升边界细节，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM在分割方面取得了突破，但其掩码预测精度在实际应用中仍显不足。现有细化模块难以在统一框架内实现高精度对象描绘，且交互式图像抠图在SAM背景下尚未探索。分割与抠图之间存在强相关性，表明统一模型的可能性。

Method: 提出SAMA作为SAM的轻量级扩展：1）多视图定位编码器（MVLE）从局部视图捕获细节特征；2）局部适配器（Local-Adapter）通过恢复细微边界细节来细化掩码输出；3）为每个任务集成两个预测头，同时生成分割和抠图掩码。

Result: 在从公开来源聚合的多样化数据集上训练后，SAMA在多个分割和抠图基准测试中实现了最先进的性能，展示了其在广泛下游任务中的适应性和有效性。

Conclusion: SAMA成功地将分割和抠图任务统一到一个轻量级框架中，通过MVLE和Local-Adapter显著提升了边界细节恢复能力，为实际应用提供了高精度的交互式图像处理解决方案。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [70] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

TL;DR: 提出基于主成分分析的太赫兹自监督去噪去模糊网络（THz-SSDD），通过重损坏自监督学习策略和PCA分解重建，同时解决太赫兹图像的低频模糊和高频噪声问题。


<details>
  <summary>Details</summary>
Motivation: 太赫兹系统固有的频率相关退化效应导致振幅图像出现低频模糊和高频噪声，传统图像处理方法无法同时解决这两个问题，且由于去噪和去模糊边界未知需要人工干预。

Method: 采用基于主成分分析的自监督网络，使用"重损坏到重损坏"自监督学习策略捕捉噪声内在特征，通过PCA分解和重建来恢复低频和高频图像信息。

Result: 在四种样品上评估网络性能，仅需少量未标记噪声图像进行训练，在不同材料特性和测量模式的样品测试中均能有效去噪和去模糊，定量分析验证了网络可行性。

Conclusion: THz-SSDD网络能够同时解决太赫兹图像的低频模糊和高频噪声问题，在保持原始信号物理特性的同时提高图像质量，且训练数据需求小，具有实用价值。

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [71] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种针对病理学基础模型的高效推理策略，通过空间感知邻域块稀疏化注意力机制，在保持性能的同时显著降低GPU内存和运行时间


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型受限于固定输入尺寸（如224x224），在处理数千分辨率级别的全切片图像时效率低下。简单扩大输入会导致GPU内存爆炸，而降低分辨率则会丢失关键形态学细节

Method: 提出空间和时间高效的推理策略：1）使用空间感知邻域块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性token。该设计在保持下游任务性能的同时显著减少GPU内存和运行时间

Result: 实验结果显示，该方法在ROI分类任务上实现最高7.67%的性能提升，在分割任务上获得可比结果，同时能在相同GPU预算下实现更高分辨率的推理

Conclusion: 提出的高效推理策略成功解决了病理学基础模型在处理全切片图像时的计算效率问题，在保持甚至提升下游任务性能的同时，显著降低了计算资源需求

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [72] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

TL;DR: 提出了一种利用持久同调先验进行协作逆渲染的方法，通过拓扑约束解决3D重建中的歧义问题，特别针对高亏格曲面重建


<details>
  <summary>Details</summary>
Motivation: 从图像重建3D物体本质上是一个病态问题，存在几何、外观和拓扑方面的歧义。传统方法难以重建高亏格曲面，容易出现隧道塌陷或丢失高亏格结构等灾难性失败

Method: 提出协作逆渲染框架，结合多视图图像的光度一致性和基于同调的指导。利用持久同调先验捕捉关键拓扑特征（如隧道环和手柄环），在基于网格的逆渲染框架中使用梯度优化而非神经网络

Result: 实验结果显示，与最先进的基于网格方法相比，加入持久同调先验的方法获得了更低的Chamfer距离和更高的体积IoU，证明了几何精度的提升和对拓扑失败的鲁棒性

Conclusion: 拓扑先验在解决3D重建歧义问题中具有重要作用，持久同调先验能够有效指导高亏格曲面的重建，避免拓扑错误，提高几何准确性

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [73] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: VIRTUE是一个基于多模态大语言模型的通用视频检索框架，支持语料库检索、时刻定位和组合多模态查询，通过对比对齐和LoRA高效训练，在零样本检索任务上超越其他MLLM方法，性能接近专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：专用架构虽然检索性能强，但无法处理组合多模态查询；而MLLM方法支持丰富多模态搜索，但检索性能远低于专用系统。需要开发既能处理多样化检索任务，又能保持高性能的通用框架。

Method: 使用共享MLLM主干生成视觉和文本嵌入，通过对比对齐促进高效的基于嵌入的候选搜索。采用低秩适应（LoRA）在70万对视觉-文本数据上高效训练嵌入模型。通过重排序进一步提升检索性能。

Result: 在零样本视频检索任务上超越其他MLLM方法；同一模型无需额外训练即可在零样本时刻检索上取得有竞争力的结果；在零样本组合视频检索上达到最先进水平；通过重排序后，性能大幅超越现有MLLM系统，接近在更大数据上训练的专用模型。

Conclusion: VIRTUE展示了MLLM在视频检索任务中的潜力，通过高效训练策略实现了多功能性和高性能的统一，为通用视频检索系统的发展提供了有前景的方向。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [74] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SurgRef是一个基于运动引导的框架，通过工具运动而非外观特征来实现手术视频中自由形式语言表达的指代分割，在遮挡、模糊或陌生术语情况下仍能准确分割手术器械。


<details>
  <summary>Details</summary>
Motivation: 当前手术场景中的指代分割任务主要依赖静态视觉特征和预定义器械名称，难以泛化到不同手术场景。需要一种能够理解语言描述并准确定位手术器械的方法，特别是在器械被遮挡、描述模糊或使用不熟悉术语的情况下。

Method: 提出SurgRef框架，通过运动引导将自由形式语言表达与器械运动模式关联，关注工具如何随时间移动和交互，而非仅依赖外观特征。同时构建Ref-IMotion数据集，包含密集时空掩码和丰富的以运动为中心的语言描述。

Result: SurgRef在不同手术程序中实现了最先进的准确性和泛化能力，为鲁棒的语言驱动手术视频分割设立了新的基准。

Conclusion: 通过关注器械运动而非静态外观特征，SurgRef框架能够更好地理解语言描述并实现准确的手术器械分割，即使在具有挑战性的条件下也能保持鲁棒性，推动了智能手术室和自主手术机器人辅助的发展。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [75] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 提出DiffusionQC方法，仅需干净图像训练即可检测病理图像中的伪影，无需像素级标注或预定义伪影类型，并通过对比学习增强性能。


<details>
  <summary>Details</summary>
Motivation: 数字病理学在疾病诊断中至关重要，但组织病理学图像常包含制备和数字化过程中引入的伪影。传统监督方法需要大量标注数据且难以泛化到新伪影类型，因此需要更高效通用的解决方案。

Method: 提出DiffusionQC方法，使用扩散模型将伪影检测为干净图像中的异常值，仅需干净图像训练集。进一步引入对比学习模块，明确扩大伪影与干净图像之间的分布分离，得到增强版本。

Result: 实验结果表明，该方法性能优于现有最先进方法，具有跨染色泛化能力，且所需数据和标注显著减少。

Conclusion: DiffusionQC提供了一种高效、通用的病理图像伪影检测方法，仅需干净图像训练，无需大量标注，具有良好的泛化性能。

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [76] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

TL;DR: PRISM：一个三阶段框架，通过集成语义和多模态分析生成基于程序性视频的语义基础摘要，在采样少于5%帧的情况下保留84%语义内容


<details>
  <summary>Details</summary>
Motivation: 视频摘要对于手术培训等高风险领域很重要，现有方法从基本视觉特征发展到预训练视觉语言模型，但需要更好的语义理解和程序性过渡捕捉

Method: PRISM三阶段框架：自适应视觉采样、标签驱动的关键帧锚定、使用大语言模型进行上下文验证，确保选择反映有意义程序性过渡的帧

Result: 在采样少于5%原始帧的情况下，摘要保留84%语义内容，比基线提升高达33%，在程序性和领域特定视频任务上表现良好

Conclusion: PRISM能够生成上下文连贯的视频摘要，过滤通用或幻觉内容，在语义对齐和精确度方面表现强劲，适用于领域特定和教学视频

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [77] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

TL;DR: 提出结合金字塔自适应空洞卷积(PAAC)和Transformer的乳腺癌检测框架，在多个公开数据集上达到98.5%准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性最常见癌症之一，准确及时的诊断对改善治疗效果至关重要。传统方法在复杂场景和大数据集上存在局限性，需要更有效的检测框架。

Method: 提出PAAC-Transformer框架：1) 使用金字塔自适应空洞卷积进行多尺度特征融合；2) 结合Transformer的自注意力机制处理长距离依赖；3) 采用Dice Loss和Focal Loss组合优化学习过程；4) 对INbreast、MIAS、DDSM数据集进行数据增强和对比度增强预处理。

Result: 模型在乳腺癌检测中表现优异：准确率98.5%、灵敏度97.8%、特异性96.3%、F1分数98.2%、精确率97.9%，显著超越BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet、SegFormer等基线模型。

Conclusion: 该模型在复杂场景和大数据集上能有效识别癌性肿块，可作为乳腺癌诊断的可靠高效工具，并有望集成到医疗诊断系统中。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [78] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: FedDCG：一种联邦学习框架，同时解决类别和域泛化问题，通过域分组策略和可学习网络提升未见类别和未见域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理未见类别或未见域泛化问题，缺乏同时考虑两者的联合框架。在联邦学习环境中，需要同时处理类别和域泛化挑战。

Method: 提出FedDCG框架：1）域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆；2）推理时基于域相似性聚合类别泛化结果；3）使用可学习网络增强类别泛化能力；4）解耦机制分离通用知识和域特定知识。

Result: 在多个数据集上的广泛实验表明，FedDCG在准确性和鲁棒性方面优于现有最先进的基线方法。

Conclusion: FedDCG成功解决了联邦学习中同时处理类别和域泛化的挑战，通过创新的域分组和解耦机制实现了更好的泛化性能。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [79] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

TL;DR: 该论文提出了一种从普通非视距(NLOS)照片进行3D场景重建的新方法，通过将隐藏场景分解为光遮挡和非光遮挡组件，并开发了梯度优化和神经网络两种解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统成像需要视线才能创建场景的准确视觉表示，但在某些情况下获得合适的视线可能不切实际、危险甚至不可能。现有的被动NLOS方法仅限于1D或低分辨率2D彩色成像，或只能定位形状近似已知的隐藏物体。

Method: 提出了一种新的光传输模型重新表述，将隐藏场景分解为光遮挡和非光遮挡组件，形成可分离非线性最小二乘(SNLLS)逆问题。开发了两种解决方案：基于梯度的优化方法和受物理启发的神经网络方法（称为软阴影扩散SSD）。

Result: 该方法在真实实验场景中的多个3D场景上有效，SSD在模拟中训练但能很好地泛化到模拟和真实世界NLOS场景中的未见类别，并且对噪声和环境光照表现出惊人的鲁棒性。

Conclusion: 该研究将被动NLOS成像从1D/低分辨率2D扩展到完整的3D重建，通过创新的场景分解和两种有效的求解方法，克服了逆问题的病态挑战，为实际应用提供了有前景的解决方案。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [80] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

TL;DR: AgenticPruner：利用大语言模型进行MAC约束优化的神经网络剪枝框架，通过三个智能体协同工作，在满足计算预算的同时保持或提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络剪枝方法主要关注参数减少，但无法直接控制计算成本，导致在需要严格满足MAC操作预算的部署场景中推理延迟不可预测。

Method: 提出AgenticPruner框架，使用大语言模型通过迭代策略学习实现MAC约束优化。包含三个智能体：分析模型架构和MAC分布的Profiling Agent、协调工作流程的Master Agent、以及基于Claude 3.5 Sonnet从历史尝试中学习最优策略的Analysis Agent。基于同构剪枝的图结构分组方法，增加跨剪枝迭代的模式分析实现上下文感知适应。

Result: 在ImageNet-1K上验证了ResNet、ConvNeXt和DeiT架构。CNN方面：ResNet-50达到1.77G MACs和77.04%准确率（比基线+0.91%）；ResNet-101达到4.22G MACs和78.94%准确率（+1.56%）。ConvNeXt-Small剪枝到8.17G MACs实现1.41倍GPU和1.07倍CPU加速，参数减少45%。Vision Transformers能在用户定义的容差带内满足MAC预算。

Conclusion: AgenticPruner框架成功实现了MAC约束的神经网络剪枝，通过智能体协同和上下文学习，在满足严格计算预算的同时保持或提升模型性能，为需要计算保证的部署场景提供了可行方案。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [81] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: CytoCLIP：基于CLIP预训练框架的视觉-语言模型，用于学习大脑细胞构筑的联合视觉-文本表示，实现大脑区域的自动识别。


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中划定这些区域耗时且需要专业知识，需要自动化方法来减少专家工作量。

Method: 提出CytoCLIP模型套件，包含两个变体：1）使用低分辨率全区域图像理解整体细胞构筑模式；2）使用高分辨率图像块学习细胞级细节表示。训练数据来自不同孕周胎儿大脑的NISSL染色组织切片，包含86个区域（低分辨率）和384个区域（高分辨率）。

Result: CytoCLIP在区域分类和跨模态检索任务中表现出色，优于现有方法。全区域分类F1分数达0.87，高分辨率图像块分类F1分数达0.91，在不同年龄和切片平面的数据设置下均表现良好。

Conclusion: CytoCLIP能够有效学习大脑细胞构筑的视觉-文本表示，为大脑区域自动识别提供了高效解决方案，减少了对专家人工标注的依赖。

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [82] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT提出了一种无需训练的语义区域自适应扩散Transformer，通过根据区域复杂度分配计算，实现了3倍加速，同时保持与全注意力推理几乎相同的感知和语义质量。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在文本到图像合成中达到最先进性能，但由于去噪的迭代性质和全局注意力的二次成本，计算开销仍然很大。研究发现去噪动态在空间上不均匀——背景区域快速收敛，而边缘和纹理区域演化更活跃。

Method: SDiT引入了一个无需训练的框架，结合：(1)通过快速Quickshift分割实现语义感知聚类，(2)复杂度驱动的区域调度以选择性更新信息丰富区域，(3)边界感知细化以保持空间一致性。

Result: 无需任何模型重新训练或架构修改，SDiT实现了高达3.0倍的加速，同时保持与全注意力推理几乎相同的感知和语义质量。

Conclusion: SDiT通过利用去噪动态的空间不均匀性，实现了扩散Transformer的高效推理，为计算资源受限环境下的高质量图像合成提供了实用解决方案。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [83] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出一种基于参数化人脸模型的辐射场表示方法，实现高效、可控的3D人脸头像渲染，支持在线流式传输和传统图形平台渲染。


<details>
  <summary>Details</summary>
Motivation: 传统3D人脸渲染方法在实现照片级真实感、可控性和跨平台兼容性方面存在挑战，需要一种既能保持高质量渲染效果，又能在传统图形平台上高效运行且无需定制工程的方法。

Method: 基于参数化人脸模型构建辐射场表示，学习3D空间中的辐射流形，提取显式的分层网格以及外观和变形纹理。通过线性混合和alpha合成纹理在静态网格上进行控制和动画。

Result: 实现了高效、可控的体渲染，能够处理复杂面部特征（头发、皮肤、眼睛），生成的虚拟形象可在线流式传输，并在传统图形平台上使用标准网格和着色器进行渲染。

Conclusion: 该方法提供了一种新颖的显式表示，实现了照片级真实感3D人脸头像的高效经典渲染，无需定制工程即可在传统图形平台上部署，具有良好的实用性和兼容性。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [84] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD：通过表示分解的后概念瓶颈模型，自动从预训练模型中提取视觉概念，利用多模态大语言模型标注概念，通过重构优化选择独立概念子集，在保持高性能的同时提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于概念的解释方法存在概念相关性不可靠、概念定义非视觉化或劳动密集、模型或数据无关假设等局限性，需要一种能自动提取视觉概念并保持高性能的后概念瓶颈模型。

Method: PCBM-ReD从预训练编码器自动提取视觉概念，使用多模态大语言模型基于视觉可识别性和任务相关性标注和筛选概念，通过重构引导优化选择独立概念子集，利用CLIP的视觉-文本对齐将图像表示分解为概念嵌入的线性组合。

Result: 在11个图像分类任务上的实验表明，PCBM-ReD达到最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD成功地将可解释性改造到预训练不透明模型上，实现了高性能与良好可解释性的平衡，为关键领域的模型部署提供了可靠解决方案。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [85] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 提出2S-GDA框架，通过全局多样性策略增强视觉语言预训练模型的黑盒对抗攻击效果


<details>
  <summary>Details</summary>
Motivation: 现有多模态攻击方法存在扰动多样性有限和多阶段流程不稳定的问题，需要改进视觉语言预训练模型的黑盒对抗攻击能力

Method: 采用两阶段全局多样性攻击框架：第一阶段通过候选文本扩展和全局感知替换引入文本扰动；第二阶段使用多尺度调整和块随机旋转增强视觉多样性

Result: 在VLP模型上实验表明，2S-GDA相比现有方法显著提升攻击成功率，黑盒场景下最高提升11.17%，且框架模块化易于与现有方法结合

Conclusion: 2S-GDA框架有效解决了多模态攻击的多样性限制问题，显著提升了对抗样本在黑盒场景下的可迁移性

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [86] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: AMC-MetaNet是一个轻量级少样本遥感学习框架，通过多尺度相关性和元学习解决数据稀缺、领域偏移和多尺度对象问题，参数仅60万，推理时间<50ms，在多个数据集上达到86.65%准确率。


<details>
  <summary>Details</summary>
Motivation: 遥感少样本学习面临三大挑战：标注数据稀缺、显著的领域偏移、地理空间对象的多尺度特性。现有方法通常依赖大型预训练模型或Transformer，计算成本高且不够高效。

Method: 提出AMC-MetaNet框架，包含三个关键创新：1) 相关性引导的特征金字塔捕获尺度不变模式；2) 自适应通道相关性模块学习动态跨尺度关系；3) 相关性引导的元学习利用相关性模式而非传统原型平均。模型从零开始训练，仅约60万参数。

Result: 在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等多个遥感数据集上，5-way 5-shot分类准确率达到86.65%。相比ResNet-18参数减少20倍，单图推理时间<50ms，计算效率高。

Conclusion: AMC-MetaNet是一个计算高效、尺度感知的框架，适用于实际遥感少样本学习场景，在保持高性能的同时显著降低了计算复杂度。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [87] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 提出CurConMix+框架，结合课程引导对比学习与多分辨率时序Transformer，解决手术动作三元组识别中的类别不平衡、视觉变化细微和语义依赖问题，并在新数据集LLS48上验证效果。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对工作流分析和技能评估很重要，但面临类别严重不平衡、视觉变化细微、三元组组件语义相互依赖等挑战。现有方法往往只解决部分问题，缺乏整体解决方案。

Method: 基于CurConMix空间表示框架，采用课程引导对比学习策略学习判别性特征，结合结构化难样本采样和特征级混合。其时序扩展CurConMix+集成多分辨率时序Transformer，自适应融合多尺度时序特征并动态平衡时空线索。同时引入新的分层标注数据集LLS48。

Result: 在CholecT45和LLS48数据集上的实验表明，CurConMix+在三元组识别上优于现有方法，并展现出强大的跨层次泛化能力，其细粒度特征能有效迁移到更高层次的阶段和步骤识别任务。

Conclusion: 该框架和数据集为层次感知、可复现和可解释的手术工作流理解提供了统一基础。代码和数据集将在GitHub上公开，以促进可复现性和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [88] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S²F-Net：一种基于频谱差异的跨模型生成图像检测框架，通过可学习频率注意力模块提升对未见生成模型的泛化能力，在包含17类生成模型的基准上达到90.49%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见生成架构时性能显著下降。需要从根本上提升模型的泛化性能。

Method: 提出S²F-Net跨模型检测框架，核心是探索和利用真实与合成纹理之间的固有频谱差异。引入可学习频率注意力模块，通过协同空间纹理分析和频谱依赖关系，自适应加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net达到90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过关注上采样操作在频域留下的独特指纹，S²F-Net能够有效检测频率域伪影，从根本上提升对未见生成模型的泛化检测能力，为解决生成模型检测的泛化问题提供了有效方案。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [89] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 提出了一种语义调制、多尺度Transformer用于3D视线估计，通过原型库调节CLIP特征，融合多尺度信息，使用MoE增加条件容量，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视线估计方法在处理复杂场景变化（如光照、头部姿态、背景等）时性能有限，需要更强大的模型来建模这些语义因素对视线估计的影响。

Method: 使用可学习的原型库（光照、头部姿态、背景、方向）调节CLIP全局特征，将原型增强的全局向量与CLIP补丁标记和高分辨率CNN标记在统一注意力空间中融合，并用路由/共享的专家混合（MoE）替换多个FFN块以增加条件容量。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上分别达到2.49°、3.22°、10.16°和1.44°的角误差，相比之前结果相对提升最高达64%。

Conclusion: 提出的语义调制多尺度Transformer通过原型条件化、跨尺度融合和MoE等机制，显著提升了3D视线估计的性能，证明了建模语义因素的重要性。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [90] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

TL;DR: 提出一种基于超网络的轻量级描述符学习架构，通过自适应通道缩放/平移和条件实例归一化增强Siamese CNN，在VIS-IR跨模态匹配中实现SOTA性能，并发布新的跨平台VIS-IR数据集。


<details>
  <summary>Details</summary>
Motivation: 超网络能够灵活注入上下文和任务条件，在不显著增加模型规模的情况下提升性能。本文旨在利用超网络改进多模态图像块匹配，特别是可见光与红外（VIS-IR）跨模态匹配问题，解决外观变化带来的挑战。

Method: 1. 提出轻量级描述符学习架构，在Siamese CNN基础上集成超网络模块，计算自适应的逐通道缩放和平移参数；2. 引入条件实例归一化，在浅层提供模态特定适应（如VIS vs IR）；3. 使用三元组损失和难负样本挖掘进行训练；4. 保持推理时描述符方法的高效性。

Result: 1. 在VIS-NIR和其他VIS-IR基准测试中取得最先进结果；2. 在多个数据集上匹配或超越先前方法，尽管先前方法推理成本更高；3. 发布GAP-VIR数据集，包含50万对跨平台（地面/空中）VIS-IR图像块，支持跨域泛化和适应评估。

Conclusion: 通过超网络增强的轻量级架构在保持推理效率的同时，显著提升了多模态图像块匹配的鲁棒性，特别是在VIS-IR跨模态场景中。新发布的GAP-VIR数据集将为领域偏移研究提供重要资源。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [91] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit：基于多模态情感关联知识图谱的训练免费图像情感编辑框架，通过解耦情感与内容表示，实现精确且保持结构的情感编辑。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲。需要一种能精确编辑情感同时保持视觉结构的方法。

Method: 1. 构建多模态情感关联知识图谱（MSA-KG），解耦对象、场景、属性、视觉线索和情感之间的复杂关系；2. 利用MSA-KG作为外部知识支持思维链推理，指导多模态大模型推断情感相关视觉线索并生成连贯指令；3. 设计解耦结构-情感编辑模块，在潜在空间中明确分离情感属性和布局特征。

Result: 大量实验表明，EmoKGEdit在情感保真度和内容保持方面表现优异，优于现有最先进方法。

Conclusion: EmoKGEdit通过知识图谱驱动的解耦方法，实现了精确且保持结构的图像情感编辑，解决了现有方法在情感表达和视觉结构保持方面的不足。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [92] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出FlowIID，一种基于流匹配的轻量级内在图像分解方法，在保持性能的同时大幅减少参数量，适合实时应用


<details>
  <summary>Details</summary>
Motivation: 现有内在图像分解模型虽然效果好，但参数量大，难以与其他模型结合应用于实际场景，需要更高效的解决方案

Method: 设计FlowIID架构，结合VAE引导的潜在空间和流匹配模块，实现稳定的反照率和着色分解，单次推理即可完成

Result: FlowIID在多个基准测试中取得竞争性甚至更优的结果，同时参数量更少，适合资源受限和实时视觉应用

Conclusion: FlowIID通过流匹配方法实现了参数高效的内在图像分解，为实际应用部署提供了可行的轻量级解决方案

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [93] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出Turbo-GoDec方法，通过引入异常点的聚类稀疏性先验改进传统GoDec算法，用于高光谱图像异常检测


<details>
  <summary>Details</summary>
Motivation: 现有高光谱异常检测方法主要依赖低秩背景和稀疏异常假设，但很少对异常的空间分布特性进行深入挖掘。观察到异常像素在空间上常呈现小规模聚集分布，即"聚类稀疏性"，这一特性未被充分利用。

Method: 结合异常点的聚类稀疏性先验与经典GoDec算法，将聚类稀疏性先验融入GoDec的S-step。使用马尔可夫随机场建模异常点的聚类稀疏性，通过因子图上的消息传递计算异常点的边缘概率，将高异常概率位置作为Turbo-GoDec中的稀疏分量。

Result: 在三个真实高光谱图像数据集上的实验表明，Turbo-GoDec在小尺寸异常检测方面优于原始GoDec（LSMAD）和最先进的异常检测方法。

Conclusion: 通过引入异常点的聚类稀疏性先验，提出的Turbo-GoDec方法显著提升了高光谱图像异常检测性能，特别是在检测小尺寸异常方面表现出色。

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [94] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

TL;DR: MMDR-Bench：首个端到端多模态深度研究基准，包含140个专家设计的任务，评估模型在图像文本输入下的引用报告生成能力，并提出三个可解释的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对纯文本或短格式多模态QA，缺乏评估端到端多模态证据使用的深度研究任务，无法全面评估深度研究代理的多模态理解和引用报告生成能力。

Method: 构建MMDR-Bench基准，包含140个专家设计的跨21个领域的任务，每个任务提供图像文本输入；提出三个评估指标：FLAE评估报告质量，TRACE评估引用证据对齐，MOSAIC评估文本-视觉完整性。

Result: 在25个最先进模型上的实验显示，生成质量、引用纪律和多模态基础之间存在系统性权衡，强文本生成能力不能保证忠实证据使用，多模态完整性仍是深度研究代理的关键瓶颈。

Conclusion: MMDR-Bench填补了多模态深度研究评估的空白，揭示了当前模型在多模态证据使用方面的局限性，为开发更可靠的深度研究代理提供了重要基准和诊断工具。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [95] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch是一个用于语义对应的简单有效框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现高性能，同时减少51%的训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练大模型的语义对应方法依赖高分辨率输入以获得最佳性能，导致计算开销大。主要问题是深度下采样操作会导致相邻关键点特征的不可逆融合。

Method: 提出轻量级上采样解码器逐步恢复空间细节至1/4分辨率，采用多尺度监督损失确保上采样特征保留不同空间尺度的判别特征，引入稀疏匹配和基于窗口的定位优化训练内存使用。

Result: 在252x252分辨率下（比当前SOTA方法小3.3倍），在SPair-71k基准测试上达到84.1%的PCK@0.1性能，同时减少51%的训练内存使用。

Conclusion: SimpleMatch为语义对应研究提供了一个实用高效的基础框架，在低分辨率下实现了强大的性能，解决了当前方法对高分辨率输入的依赖问题。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [96] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

TL;DR: 提出一个基于LLM和LVM的智能体框架，用于自动驾驶车辆动态生成和调整行为树，以应对不可预测的环境变化。


<details>
  <summary>Details</summary>
Motivation: 传统行为树（BTs）是静态的，需要大量人工调优，难以适应SAE Level 5自动驾驶在不可预测的真实世界环境中的需求。

Method: 使用三个智能体：Descriptor agent通过符号链提示评估场景关键性；Planner agent通过上下文学习制定高层子目标；Generator agent合成可执行的XML格式BT子树。系统集成到CARLA+Nav2仿真中，仅在基线BT失败时触发。

Result: 在CARLA+Nav2仿真中成功导航绕过意外障碍物（如街道堵塞），无需人工干预。相比静态BT基线，该方法可扩展到多种驾驶场景。

Conclusion: 该框架是概念验证，展示了LLM和LVM能够动态生成和调整行为树，为自动驾驶在不可预测环境中的适应性规划提供了新途径。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [97] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够在开放田间环境下分割不同作物物种，在多个测试场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型通常因像素级标注成本高昂而数据有限，只能在特定作物类型或受控环境下表现良好，缺乏通用性和泛化能力。

Method: 基于先前DepthCropSeg工作，构建了包含28,406张图像、30+物种和15种环境条件的大规模数据集；采用ViT-Adapter架构并增强动态上采样以提升细节感知；使用两阶段自训练流程进行训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如SAM（+48.57%）；在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++为作物分割建立了新的技术标杆，展示了基础模型在农业视觉任务中的潜力，能够有效处理开放田间环境下的跨物种、跨场景分割问题。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [98] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

TL;DR: CD-TWINSAFE是一个基于V2I的自动驾驶数字孪生系统，包含车载驾驶堆栈和数字孪生堆栈，通过4G网络实时同步数据，实现安全监控和预警。


<details>
  <summary>Details</summary>
Motivation: 为了提升自动驾驶车辆的安全性，需要一种能够实时监控车辆状态和环境、提供安全预警的系统。传统方法可能无法充分整合实时感知数据和虚拟仿真环境，因此需要开发一个结合物理世界和数字世界的V2I数字孪生架构。

Method: 提出CD-TWINSAFE架构，包含两个并行运行的堆栈：1）车载驾驶堆栈（定位和感知模块），使用立体相机进行场景理解；2）数字孪生堆栈，在Unreal Engine 5中创建场景副本。通过ROS2消息和UDP链路，利用4G调制解调器进行V2I通信，实时同步数据。

Result: 通过多种驾驶场景测试验证了该架构的有效性和实时响应能力。系统能够实时更新数字孪生中的自我车辆和检测到的物体信息，并返回安全警报到驾驶舱。

Conclusion: CD-TWINSAFE成功实现了V2I数字孪生架构，能够为自动驾驶车辆提供实时安全监控和预警，通过整合物理感知和虚拟仿真提升了系统的安全性和可靠性。

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [99] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出基于分数生成模型(ScoreAD)的高光谱异常检测方法，利用数据分布的梯度场（分数）来区分背景和异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像中的高维光谱实际上由少数因素决定，满足流形假设。背景光谱位于低维流形上，而异常光谱由于独特的光谱特征被视为不符合背景流形的离群点

Method: 使用分数生成模型(SGM)学习整个高光谱图像的数据分布梯度场。训练时在整个光谱集上训练SGM，测试时通过扰动核处理每个光谱，将扰动后的光谱输入训练好的SGM获得估计分数

Result: 在四个高光谱数据集上的实验证明了该方法的有效性

Conclusion: 基于高光谱流形假设和分数生成模型的方法能够有效检测高光谱异常，代码已开源

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [100] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 该研究评估了10个基础模型在皮肤病变分层分类中的表现，发现通用医学基础模型擅长高级筛查，而皮肤病专用模型在细粒度亚型分类上表现更好，揭示了"粒度差距"现象。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病诊断基准通常将复杂的诊断分类简化为二元分类任务（如区分黑色素瘤与良性痣），这种简化掩盖了模型执行细粒度鉴别诊断的能力，而这对临床工作流程整合至关重要。

Method: 使用DERM12345数据集（包含40个病变亚类），计算10个基础模型（涵盖通用计算机视觉、通用医学成像和皮肤病专用领域）的冻结嵌入，训练轻量级适配器模型，采用五折交叉验证，并引入分层评估框架评估四个临床粒度级别的性能。

Result: 发现了"粒度差距"：MedImageInsights在二元恶性检测中表现最佳（加权F1-Score 97.52%），但在40类亚型分类中降至65.50%；而MedSigLip（69.79%）和皮肤病专用模型在细粒度亚型分类上表现更好，但在更广泛分类任务中总体性能较低。

Conclusion: 通用医学基础模型对于高级筛查非常有效，但诊断支持系统所需的细粒度区分需要专门的建模策略，强调了根据临床需求选择适当模型的重要性。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [101] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE模型，通过类别分区码本解决复杂场景中点云生成问题，无需依赖外部数据库检索


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法存在局限性：扩散方法生成的潜在特征无法被当前自编码器有效解码为与目标类别一致的点云对象，特别是在复杂多类别场景中

Method: 1. 提出类别分区向量量化变分自编码器(CPVQ-VAE)，使用类别分区码本，码向量按类别标记
2. 提出类别感知的运行平均更新策略，解决码本坍塌问题
3. 设计专门用于场景生成的潜在空间流匹配模型(LFMM)生成对象特征和类别标签
4. CPVQ-VAE通过类别感知逆查找将生成特征映射到码本条目，解码为类别特定点云形状

Result: 在复杂客厅场景中，Chamfer误差减少70.4%，Point2Mesh误差减少72.3%，可靠恢复合理的点云场景

Conclusion: 该方法实现了纯点云生成，无需依赖外部对象数据库检索，有效解决了复杂多类别场景中点云生成的挑战

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [102] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

TL;DR: 该论文对基于面部的情感检测方法进行了综述，选择了三种最佳神经网络解决方案，使用三个多样化数据集进行训练和实验，揭示了现有方法在数据集差异、特定情感识别难度以及相似情感区分方面的弱点。


<details>
  <summary>Details</summary>
Motivation: 面部情感检测是人机交互中的关键机器学习问题，现有方法种类繁多，需要进行深入的系统性综述和比较分析，以了解当前解决方案的优缺点。

Method: 1. 对相关文献进行深入综述；2. 选择三种最优秀、最有趣的神经网络解决方案；3. 选择三个具有图像多样性和数量优势的数据集；4. 训练选定的神经网络；5. 进行一系列实验比较性能，包括在不同数据集上进行交叉测试。

Result: 实验揭示了现有解决方案的多个弱点：1. 不同数据集之间存在显著差异；2. 识别某些情感的难度不均衡；3. 区分密切相关的情感具有挑战性；4. 模型在未见数据集上的泛化能力有限。

Conclusion: 面部情感检测领域仍面临数据集不一致、特定情感识别难度差异以及相似情感区分困难等挑战，需要进一步研究改进模型的泛化能力和鲁棒性。

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [103] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 提出基于最优传输的稀疏特征立体匹配方法，利用相机几何的线约束解决遮挡、运动等挑战，特别适用于面部标志点匹配


<details>
  <summary>Details</summary>
Motivation: 立体视觉面临遮挡、运动和相机畸变等挑战，而稀疏特征（如面部标志点）的立体匹配由于参数敏感性更加困难。需要克服这种不适定问题，实现无监督的稀疏匹配

Method: 从最优传输视角考虑相机几何的线约束，将相机投影点建模为（半）线，使用经典极线距离和3D射线距离量化匹配质量，将这些距离作为（部分）最优传输问题的成本函数，形成高效可解的分配问题。还扩展到无监督对象匹配，将其表述为分层最优传输问题

Result: 开发出的算法能够高效进行特征和对象匹配，在数值实验中得到验证，特别适用于面部分析中不同标志点约定之间的匹配

Conclusion: 通过最优传输框架结合相机几何约束，成功解决了稀疏特征立体匹配的挑战，为面部分析等应用提供了有效的无监督匹配方法

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [104] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文综述了视觉语言模型（VLMs）对抗性防御的三大范式：训练时防御、测试时自适应防御和无训练防御，分析了各自的优缺点及当前挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（如CLIP）的广泛应用，其对抗性攻击的脆弱性引发安全担忧。这些攻击可能损害跨模态任务中的模型性能和系统安全，因此需要系统性地研究防御策略。

Method: 论文采用文献综述方法，系统梳理了三种主要防御范式：1）训练时防御（通过对抗性微调增强鲁棒性）；2）测试时自适应防御（在推理时更新参数处理对抗样本）；3）无训练防御（通过修改输入或特征嵌入来缓解攻击影响）。

Result: 综述总结了各类防御方法的最新进展：训练时防御有效但计算成本高且泛化性有限；测试时自适应防御灵活但增加复杂性和计算开销；无训练防御无需模型修改但可能防御能力有限。指出了当前防御策略的优势与局限性。

Conclusion: 该综述系统梳理了VLMs对抗性防御的研究现状，强调需要平衡防御效果、计算效率和泛化能力。未来研究应关注更高效、通用的防御机制，以增强VLMs在实际应用中的鲁棒性和安全性。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [105] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 开发了一个大规模多源电子显微镜基准数据集用于多细胞器实例分割，包含超过10万张2D EM图像，涵盖多种细胞类型和5种细胞器类别，并评估了多种先进模型的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型、精选数据集的基准无法捕捉真实世界EM数据的异质性和大空间上下文，这限制了基于patch的方法的发展，需要更全面的基准来评估模型在真实场景下的表现。

Method: 1) 开发大规模多源EM基准数据集，包含超过10万张2D图像，涵盖多种细胞类型和5种细胞器类别；2) 使用设计的连通性感知标签传播算法(3D LPA)生成标注，并进行专家精修；3) 在数据集上评估多种先进模型，包括U-Net、SAM变体和Mask2Former。

Result: 当前模型在异质EM数据上泛化能力有限，对具有全局分布形态的细胞器（如内质网）表现不佳，揭示了局部上下文模型与真实世界变异性下长程结构连续性建模之间的根本性不匹配。

Conclusion: 需要开发能够处理真实世界EM数据异质性和长程结构连续性的新模型，该基准数据集和标注工具将公开发布以推动该领域发展。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [106] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

TL;DR: DCAC是一种无需训练、测试时校准的OOD检测模块，通过为每个ID类别维护缓存来收集高熵样本，利用轻量级两层模块校准原始预测，显著降低OOD样本的过自信预测。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在OOD检测中存在过自信预测问题，作者发现被预测为同一类别的OOD样本在视觉上比真实ID样本更相似，这启发了基于类别感知的校准方法。

Method: 提出DCAC模块：1）为每个ID类别维护独立缓存收集高熵样本；2）使用轻量级两层模块结合缓存视觉特征和预测概率进行校准；3）无需训练，可无缝集成到现有OOD检测方法中。

Result: 在多个OOD基准测试中，DCAC显著提升现有方法性能，如在ImageNet OOD基准上，与ASH-S集成时将FPR95降低6.55%，计算开销极小。

Conclusion: DCAC通过类别感知的缓存机制有效缓解OOD样本的过自信预测问题，是一种高效、通用的OOD检测增强模块，适用于单模态和视觉语言模型。

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [107] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 首个基于多视角图像重建动物毛发3D模型的方法，利用视觉语言模型指导毛发长度和生长方向，实现不同动物毛发类型的高保真重建。


<details>
  <summary>Details</summary>
Motivation: 从图像重建真实动物毛发几何极具挑战，因为毛发细节精细、存在自遮挡和视角依赖外观。与人类发型重建不同，目前没有可用于学习不同动物毛发先验的数据集。

Method: 1. 使用传统多视角立体技术重建粗糙表面几何；2. 利用视觉语言模型获取身体各部位毛发长度结构信息；3. 构建无毛几何并在其上生长毛发束；4. 使用几何和光度损失监督重建；5. 利用VLM指导毛发生长方向和重力向量关系。

Result: 展示了该方法在多种不同毛发类型动物上的泛化能力，实现了高保真的3D毛发重建。

Conclusion: 提出了一种利用视觉语言模型指导多视角输入进行3D重建的新范式，成功解决了动物毛发重建的挑战，并在多种动物上展示了良好的泛化性能。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [108] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了Histopath-C基准测试和LATTE方法，用于评估和提升医学视觉语言模型在组织病理学图像中的鲁棒性，应对现实世界中的域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像存在严重的域偏移问题（如染色、污染、模糊、噪声等），这些现实世界的分布偏移会显著降低视觉语言模型的下游性能，需要专门的评估和适应方法。

Method: 1) 提出Histopath-C基准测试，包含模拟真实世界分布偏移的合成腐蚀；2) 提出LATTE方法，一种利用多个文本模板的低秩适应策略，减少对文本输入的敏感性；3) 动态应用腐蚀到任何可用数据集并评估测试时适应机制。

Result: LATTE方法在多个组织病理学数据集上超越了为自然图像设计的最先进的测试时适应方法，证明了该方法在组织病理学图像中鲁棒适应的有效性。

Conclusion: 提出的Histopath-C基准和LATTE方法为解决组织病理学图像中的域偏移问题提供了有效工具，提升了医学视觉语言模型在现实世界应用中的鲁棒性。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [109] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出基于移动无人机的大规模密集人群计数与追踪方法，使用GD3A进行全局密度图分解和DVTrack进行实例级关联，在新建的MovingDroneCrowd++数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有固定摄像头方法空间覆盖有限，无法满足大规模密集人群分析需求。移动无人机能提供更灵活的视角和更广的覆盖范围，但缺乏相应的数据集和方法。

Method: 1) 创建MovingDroneCrowd++数据集，包含移动无人机拍摄的多样化密集人群视频；2) 提出GD3A方法，通过最优传输和自适应dustbin分数建立像素级行人描述符对应关系，将全局密度图分解为共享、流入、流出三部分；3) 提出DVTrack方法，通过描述符投票机制将描述符级匹配转换为实例级关联。

Result: 在MovingDroneCrowd++数据集上，GD3A和DVTrack显著优于现有方法：计数误差降低47.4%，追踪性能提升39.2%。

Conclusion: 移动无人机为大规模密集人群分析提供了有效解决方案，GD3A和DVTrack方法在处理复杂运动和密集场景时表现出色，为视频级人群计数与追踪提供了新思路。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [110] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

TL;DR: 提出SDCoNet网络，通过显著性驱动的多任务协作，将超分辨率和检测任务耦合，提升低质量遥感图像中小目标检测性能


<details>
  <summary>Details</summary>
Motivation: 遥感图像中复杂背景、弱目标信号和小目标尺度使得检测困难，特别是低质量成像条件下。现有串行方法（先超分辨率再检测）存在优化目标不一致、特征冗余、任务间缺乏有效交互等问题

Method: 1. 基于Swin Transformer的共享编码器，通过分层窗口移位自注意力支持跨任务特征协作；2. 多尺度显著性预测模块生成重要性分数选择关键token，聚焦弱目标区域；3. 梯度路由策略缓解优化冲突，先稳定检测语义，再沿检测导向方向路由超分辨率梯度

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split数据集上实验表明，方法在保持计算效率的同时，显著优于现有主流算法

Conclusion: 提出的SDCoNet通过显著性驱动的多任务协作，有效解决了低质量遥感图像中小目标检测的挑战，实现了超分辨率和检测任务的协同优化

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [111] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，解决MRI扫描在不同扫描仪或机构间的域偏移问题，无需配对训练数据即可实现双向域映射。


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪或机构获取的MRI扫描存在硬件、协议和采集参数差异导致的域偏移，这会降低在源域数据上训练的深度学习模型在目标域图像上的性能。

Method: 基于CycleGAN的无监督域适应模型，利用CycleGAN学习源域和目标域之间的双向映射，无需配对训练数据，通过内容和差异损失保持图像解剖结构完整性。

Result: 在多个MRI数据集上的实验表明，该方法在无标签数据的情况下能有效实现双向域适应，统计结果证实能提高模型性能并减少域相关变异性。

Conclusion: 该方法为提升医疗诊断准确性提供了有前景的途径，有助于实现更精确和一致的医学图像分析。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [112] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 提出一种结合传统网格变形精确控制与数据驱动语义编辑的方法，通过深度特征邻近性生成平滑语义变形权重，实现实时高分辨率网格变形。


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道手柄的理想分布，从手柄到变形行为的映射不直观且缺乏语义性；而现代数据驱动方法虽然能获得语义编辑，但速度慢且不精确。需要融合两者的优势。

Method: 使用深度特征邻近性生成平滑语义变形权重，无需额外正则化；提出重心特征蒸馏管道，利用形状渲染的视觉信号最小化蒸馏成本；通过特征空间约束和局部性加权保留传统方法特性；利用场表示自动检测语义对称性。

Result: 能在1分钟内为高分辨率网格计算权重（传统和神经方法可能需要数小时），在消费级机器上实时处理百万面网格变形，支持语义部件协同变形和对称保持变形。

Conclusion: 该方法成功融合了传统方法的精确控制与速度优势，以及数据驱动方法的语义编辑能力，通过深度特征邻近性和改进的特征蒸馏管道实现了高效、语义感知的网格变形。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [113] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine是一个检测器无关的亚像素关键点细化方法，仅使用匹配关键点周围的图像块，通过跨注意力架构预测细化坐标，无需依赖检测器内部表示，可泛化到不同检测器并扩展到多视角特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器常产生空间不准确的匹配，现有细化方法通常针对特定检测器设计，需要为每个检测器重新训练，缺乏通用性。

Method: 提出XRefine方法，基于跨注意力架构，仅使用匹配关键点周围的图像块来预测细化后的关键点坐标，不依赖检测器内部表示，实现检测器无关的细化。

Result: 在MegaDepth、KITTI和ScanNet数据集上的实验表明，该方法能持续提升几何估计精度，相比现有细化方法性能更优，同时保持运行时效率。

Conclusion: XRefine是一种有效的检测器无关亚像素关键点细化方法，能泛化到不同检测器，提升匹配精度和几何估计准确性。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [114] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 作者提出了BirdsEye-RU数据集，包含2,978张图像和8,000多个标注人脸，专门用于解决俯视图像中小而远的人脸检测挑战。


<details>
  <summary>Details</summary>
Motivation: 俯视图像中的人脸检测面临极端尺度变化和环境杂波的挑战，现有数据集难以覆盖这些情况，需要专门的数据集来推动该领域研究。

Method: 创建了BirdsEye-RU数据集，包含无人机和智能手机从高空拍摄的图像，涵盖多样化环境，专门标注小而远的人脸，共2,978张图像超过8,000个标注。

Result: 成功构建了专门针对俯视图像人脸检测的数据集，包含丰富的标注数据，已在Kaggle上公开免费提供，地址为https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru。

Conclusion: BirdsEye-RU数据集填补了俯视图像人脸检测领域的空白，为研究极端尺度变化下的人脸检测提供了重要资源，将促进该领域的技术发展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [115] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 本文提出一种自监督视线检测模型，利用低分辨率自然视频预测情绪表达，在Holocaust幸存者访谈数据上验证了视线与情绪的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有情绪与视线关系研究多依赖高精度眼动仪，限制了应用范围。本文旨在探索如何从低分辨率自然视频中利用视线运动预测多模态情绪表达标记。

Method: 开发了受语言模型预训练启发的自监督视线检测模型，通过视线运动重建有效利用未标记视频。使用该模型的编码器嵌入微调两个下游任务：1)视线与语音情绪方向估计对齐；2)视线预测三种瞬时情绪行为（笑、哭/抽泣、叹气）。

Result: 新模型能有效预测情绪结果，观察到预训练性能与情绪处理性能呈正相关，验证了自监督视线运动重建对编码情感信号的有效性。

Conclusion: 自监督视线运动重建是编码视线所携带情感信号的有效方法，为从低分辨率自然视频中分析情绪表达提供了新途径。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [116] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE是一种物理信息深度鬼成像框架，用于低带宽边缘感知，通过结合伴随算子初始化和语义指导，在5%采样率下将分类准确率提高2.57%，方差降低9倍。


<details>
  <summary>Details</summary>
Motivation: 边缘计算场景中需要低带宽感知，传统鬼成像方法在低采样率下性能受限，需要结合物理先验和深度学习来提升边缘感知的准确性和稳定性。

Method: 提出PISE框架，结合物理信息深度学习和鬼成像技术，采用伴随算子初始化来融入物理先验，并引入语义指导来优化特征提取，实现低采样率下的高效边缘感知。

Result: 在5%采样率下，PISE将分类准确率提高了2.57%，同时将方差降低了9倍，显著提升了低带宽边缘感知的性能和稳定性。

Conclusion: PISE框架通过物理信息深度学习和语义指导的有效结合，为低带宽边缘感知提供了高效解决方案，在保持低采样率的同时显著提升了感知性能。

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [117] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: 提出PnP-ProCay78算法解决平面PnP问题，通过Cayley参数化旋转和最小二乘优化，避免复杂搜索，在RGB和热成像相机上验证效果接近最优方法但算法更简单。


<details>
  <summary>Details</summary>
Motivation: 解决相机标定和多传感器系统中的相机位姿估计问题，特别是针对平面标定物体的初始位姿估计，需要更简单高效的方法。

Method: 结合经典重建误差的二次形式与Cayley旋转参数化，采用最小二乘优化，通过分析两个规范向量的重建误差进行确定性起始点选择，避免昂贵的解空间搜索。

Result: 算法在RGB和低分辨率热成像相机上验证，投影精度与最优SQPnP相当，略高于IPPE，但算法结构显著更简单，且Cayley空间的优化轨迹分析提供了直观的收敛过程理解。

Conclusion: PnP-ProCay78算法通过投影误差最小化与平移重建误差替代项的解析消除，形成了几何透明且计算高效的混合代价公式，在保持精度的同时简化了算法结构，具有教学价值。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [118] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

TL;DR: 论文发现视觉语言模型通过线性绑定空间ID到文本激活来编码物体位置，并识别出类似的时间ID机制用于时空推理


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型展现出卓越的时空推理能力，但其底层机制仍不透明。研究者假设视觉/几何和文本表示必须在VLM计算的某个点结合，并探索这种融合点

Method: 通过因果干预方法，识别VLMs中线性绑定空间ID到文本激活的机制，并扩展分析到视频VLMs中的时间ID机制

Result: 发现VLMs通过空间ID编码物体位置，这些ID在模型中普遍存在并能系统性地调节模型信念；同时识别出类似的时间ID机制

Conclusion: 通过表征时空ID机制，阐明了VLMs中先前未被充分探索的内部推理过程，为改进模型可解释性和设计更对齐、更强大的模型提供了理论基础

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [119] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: Swin-BathyUNet模型通过光谱重要性分析、注意力机制改进和跨区域测试，揭示了卫星测深模型的深度推断机制和可靠性条件，提出了实用的部署指导。


<details>
  <summary>Details</summary>
Motivation: 解决Sentinel-2卫星测深(SDB)在不同地点部署时面临的鲁棒性挑战，理解模型如何推断水深以及何时预测可信。

Method: 1) 使用Swin-Transformer U-Net架构；2) 留一波段分析评估光谱重要性；3) 提出回归任务的A-CAM-R注意力可视化方法；4) 注意力消融实验；5) 跨区域推理测试（在一个地点训练，另一个地点测试）。

Result: 1) 光谱重要性排序与浅水光学理论一致；2) A-CAM-R能可靠定位模型依赖的证据区域；3) 解码器条件化跨注意力能提高对眩光/泡沫的鲁棒性；4) 跨区域测试显示误差随深度线性增加，双峰深度分布加剧中/深水误差。

Conclusion: 卫星测深部署需：保持宽感受野，保护绿/蓝通道辐射精度，预过滤近岸高方差亮区，结合目标地点微调和深度感知校准以实现跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [120] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 提出用于PointPillars的混合精度量化框架，通过敏感层搜索和异常值处理，在保持性能的同时实现2.35倍加速和2.26倍模型压缩


<details>
  <summary>Details</summary>
Motivation: 激光雷达3D目标检测需要实时运行，但直接量化会导致性能下降，因为激光雷达数据具有宽数值分布和极端异常值

Method: 1) 通过PTQ逐层量化搜索敏感层，将top-k敏感层设为浮点；2) 贪婪搜索混合精度组合；3) 使用少量校准数据减少异常值影响；4) 提供PTQ和QAT两种流程

Result: 混合精度模型在TensorRT部署下，延迟降低最多2.35倍，模型大小减少最多2.26倍，QAT流程性能接近浮点模型

Conclusion: 提出的混合精度框架有效解决了激光雷达检测量化中的数值分布问题，实现了实时性能与精度的平衡

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [121] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究探索了在非独立同分布联邦学习场景下，针对癌症组织病理学任务的超参数优化跨数据集泛化能力，并提出了一种简单的跨数据集聚合启发式方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症组织病理学训练中存在隐私约束问题，联邦学习虽然能保持数据本地化，但其性能在非独立同分布客户端数据集下高度依赖超参数选择，需要研究超参数优化方案是否能在不同癌症数据集间泛化。

Method: 采用集中式贝叶斯超参数优化，将数据集特定最优参数迁移到非独立同分布联邦学习设置中，并提出跨数据集聚合启发式方法：通过平均学习率、考虑模态优化器和批量大小来组合配置。

Result: 提出的组合配置方法在卵巢癌和结直肠癌的二元组织病理学分类任务中取得了有竞争力的分类性能。

Conclusion: 简单的跨数据集超参数聚合启发式方法能够有效应对非独立同分布联邦学习场景，为癌症组织病理学分析中的隐私保护深度学习提供了实用解决方案。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [122] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出基于神经隐式表示的单幅图像表面重建框架，通过单色性假设解决彩色光度立体视觉的欠定问题，并设计紧凑光学触觉传感器进行验证


<details>
  <summary>Details</summary>
Motivation: 现有彩色光度立体视觉方法大多假设理想远距离照明和朗伯反射，忽略了更实际的近光条件和非朗伯表面，限制了实际应用

Method: 使用神经隐式表示建模深度和BRDF，引入单色性假设（均匀色度和同质材料）来缓解彩色光度立体视觉的欠定问题，并设计紧凑光学触觉传感器进行验证

Result: 在合成和真实数据集上的实验表明，该方法能够实现准确且鲁棒的表面重建

Conclusion: 该框架成功扩展了彩色光度立体视觉的应用范围，能够在更实际的近光条件和非朗伯表面下实现单幅图像的详细表面恢复

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [123] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 在联邦学习框架下，结合测试时增强（TTA）和轻度预处理能显著提升脑肿瘤MRI分类性能，而单独预处理效果有限。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤早期诊断至关重要，但由于病变变异性和图像复杂性而具有挑战性。研究旨在评估联邦学习环境下卷积神经网络在脑肿瘤MRI分类中的表现，探索预处理和测试时增强对模型性能的影响。

Method: 在联邦学习设置中评估卷积神经网络，比较原始MRI图像与预处理图像（包括调整大小、灰度转换、归一化、滤波和直方图均衡化）的训练效果。进一步测试预处理与测试时增强（TTA）的组合效果。

Result: 单独预处理带来的性能提升可以忽略不计；但当预处理与测试时增强（TTA）结合时，在联邦MRI分类中产生了持续且统计显著的改进（p<0.001）。

Conclusion: 在基于联邦学习的医学影像分析中，测试时增强应作为默认的推理策略；当计算预算允许时，将TTA与轻度预处理结合可提供额外的可靠性能提升。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [124] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: VILTA是一个将视觉语言模型集成到自动驾驶闭环训练中的新框架，通过直接编辑周围车辆的未来轨迹来生成多样化的危险场景，提升自动驾驶策略的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的安全部署受到长尾问题的根本性阻碍，即罕见但关键的驾驶场景在真实世界数据中严重不足。现有解决方案（包括安全关键场景生成和闭环学习）通常依赖于基于规则的启发式方法、重采样方法和从离线数据集学习的生成模型，限制了它们产生多样化和新颖挑战的能力。

Method: VILTA（VLM-In-the-Loop Trajectory Adversary）框架将视觉语言模型集成到自动驾驶代理的闭环训练中。与之前的工作不同，VILTA通过理解动态驾驶环境，并通过直接、细粒度地编辑周围代理的未来轨迹来战略性地生成挑战性场景，从而积极参与训练循环。

Result: 该方法显著增强了自动驾驶策略的安全性和鲁棒性，特别是在处理关键长尾事件方面。直接编辑方法充分利用了VLM强大的泛化能力，创建了超越传统方法范围的、合理但具有挑战性的多样化课程场景。

Conclusion: VILTA框架通过将视觉语言模型直接集成到闭环训练中，克服了现有两阶段方法的局限性，能够生成更丰富、更创新的挑战性驾驶场景，从而有效解决自动驾驶中的长尾安全问题。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [125] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出融合-恢复图像处理方法，抑制高温结构变形测量中的热辐射和热雾干扰，提高DIC测量精度


<details>
  <summary>Details</summary>
Motivation: 高温结构变形测量中，热辐射导致的图像退化和热雾引入的随机误差限制了测量精度和有效性，需要抑制这些干扰

Method: 1) 基于图像分层表示，将图像分解为正负通道并行处理，通过多曝光图像融合优化质量；2) 采用FSIM作为目标函数指导模型参数迭代优化，结合灰度平均算法均衡异常灰度值

Result: 多曝光融合算法将欠曝光图像有效计算区域从26%提升至50%，过曝光图像从32%提升至40%；图像恢复结合灰度平均算法将ε_xx误差降低85.3%，ε_yy和γ_xy误差分别降低36.0%和36.4%

Conclusion: 提出的图像处理方法能有效抑制高温变形测量中的热辐射和热雾干扰，提高图像质量，降低变形测量误差，在热变形测量中具有潜在应用价值

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [126] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: GaussianTrimmer：一种用于3D高斯分割方法的在线边界修剪后处理技术，通过虚拟相机和2D分割结果来改善分割边界质量


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法基于高斯基元进行分割，但由于3D高斯尺度变化范围大，大尺寸高斯基元经常跨越前景和背景，导致分割对象边界出现锯齿状问题

Method: 提出GaussianTrimmer方法，包含两个核心步骤：1.生成均匀且覆盖良好的虚拟相机；2.基于虚拟相机上的2D分割结果在基元级别修剪高斯

Result: 大量定量和定性实验表明，该方法作为即插即用方法能够显著提高现有3D高斯分割方法的分割质量

Conclusion: GaussianTrimmer是一种高效、即插即用的后处理方法，能够为现有3D高斯分割方法修剪粗糙边界，改善分割效果

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [127] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 提出IVGF框架，利用3D高斯重建场景几何，实现红外-可见光图像融合，解决传统2D方法视角固定、信息丢失问题


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定相机视角，无法全面理解复杂场景，导致关键信息丢失。需要从几何层面重建场景以实现更好的融合效果

Method: 提出红外-可见光高斯融合(IVGF)框架：1) 从多模态2D输入重建场景几何；2) 跨模态调整(CMA)模块调制高斯不透明度解决模态冲突；3) 融合损失指导CMA优化，保留各模态关键特征

Result: 全面的定性和定量实验证明了该方法的有效性，能够生成保留红外和可见光关键特征的融合图像

Conclusion: IVGF框架通过3D场景重建和跨模态调整，解决了传统2D融合方法的局限性，实现了更全面的红外-可见光图像融合

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [128] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA：一种参数高效的多标签类增量学习框架，通过提示到标签模块和连续适配器模块，无需内存缓冲区即可解决特征混淆和领域差异问题


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在高计算成本（全参数微调）、大存储开销（内存缓冲区），以及难以充分解决特征混淆和领域差异的问题

Method: 提出P2L-CA框架，包含两个核心模块：1) Prompt-to-Label模块：利用类别特定提示解耦多标签表示，结合语言先验实现稳定的语义-视觉对齐；2) Continuous Adapter模块：使用轻量级适配器缓解预训练模型与下游任务之间的领域差距

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置上，P2L-CA显著优于现有最先进方法，在CIL场景中表现出强泛化能力，同时仅需极少的可训练参数且无需内存缓冲区

Conclusion: P2L-CA通过参数高效的框架设计，有效解决了多标签类增量学习中的计算成本、存储开销和特征混淆问题，为实际应用提供了可行的解决方案

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [129] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 提出RSOD教师-学生框架，通过可靠性评分和对象混合伪标签方法解决声纳图像标注数据有限的问题，在仅5%标注数据下达到与100%标注基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像纹理细节少、噪声多，非专家难以区分类别差异，导致无法提供精确标注数据，因此需要设计在标注数据极其有限情况下的有效目标检测方法。

Method: 提出RSOD教师-学生框架：1) 通过评估教师在不同视图预测的一致性计算可靠性评分；2) 引入对象混合伪标签方法解决标注数据短缺；3) 实施可靠性引导的自适应约束优化学生性能。

Result: 在UATD数据集上，仅使用5%标注数据的方法结果可与使用100%标注数据的基线算法竞争。同时收集了新数据集为声纳领域研究提供更多有价值数据。

Conclusion: RSOD框架通过充分利用未标注数据，在标注数据极其有限的情况下仍能实现良好性能，为解决声纳图像目标检测中的标注数据稀缺问题提供了有效方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [130] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一种用于移动设备的高效流式视频生成模型，通过混合注意力机制和动态规划搜索实现高质量实时生成，在iPhone上达到10+FPS


<details>
  <summary>Details</summary>
Motivation: 当前扩散变换器(DiTs)在视频生成质量上有提升，但计算成本过高，无法在移动设备上实现实时或设备端生成

Method: 提出S2DiT流式三明治扩散变换器，采用LinConv混合注意力(LCHA)和步幅自注意力(SSA)，通过预算感知动态规划搜索三明治设计，并使用2合1蒸馏框架将大模型能力转移到紧凑模型

Result: S2DiT在质量上与最先进的服务器视频模型相当，同时在iPhone上实现超过10FPS的流式生成

Conclusion: S2DiT成功解决了移动设备上高效高质量视频生成的挑战，实现了实时流式视频生成能力

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [131] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ：一个用于视觉地点识别的表示中心框架，通过融合互补的视觉基础模型和稳健的全局聚合，提升在视角变化、光照变化和领域偏移下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地点识别方法通常依赖单一视觉基础模型，忽略了不同模型提供的互补信息。然而，利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 提出DC-VLAQ框架：1) 轻量级残差引导互补融合，以DINOv2特征空间为锚点，通过学习的残差校正注入CLIP的互补语义；2) 局部聚合查询向量(VLAQ)，通过编码局部token对可学习查询的残差响应进行全局聚合，提升稳定性和细粒度判别线索保留。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED、AmsterTime等标准VPR基准测试中，DC-VLAQ持续超越强基线方法，在挑战性领域偏移和长期外观变化下达到最先进性能。

Conclusion: DC-VLAQ通过有效融合互补视觉基础模型和稳健的全局聚合，解决了视觉地点识别中的表示鲁棒性问题，特别是在复杂环境变化下表现出优越性能。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [132] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM利用大型重建模型(LRM)的预训练先验，通过将LRM的三平面特征投影到FLAME参数空间，并结合2D高斯泼溅渲染，实现单视角图像到参数化3D人脸重建，显著提升了跨视角一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D可变形模型(3DMM)回归器在跨视角一致性方面表现不佳，对视角变化敏感。为了解决这个问题，作者希望利用预训练的LRM模型的3D先验知识来提升参数化人脸重建的鲁棒性和准确性。

Method: KaoLRM将预训练的LRM三平面特征投影到FLAME参数空间来恢复几何形状，并通过与FLAME网格紧密耦合的2D高斯基元建模外观。将基于FLAME的2D高斯泼溅集成到LRM的渲染流程中，使FLAME回归器能够感知3D结构。

Result: 在受控和真实场景的基准测试中，KaoLRM在重建精度和跨视角一致性方面都优于现有方法，特别是在自遮挡和多样化视角下表现出更好的鲁棒性，而现有方法对视角变化仍然敏感。

Conclusion: 通过利用LRM的预训练3D先验并结合FLAME参数化模型，KaoLRM能够实现准确且具有跨视角一致性的单视角人脸重建，为解决3DMM回归器的视角敏感性问题提供了有效方案。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [133] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: SSPFormer：一种针对MRI图像的自监督预训练Transformer，通过逆频率投影掩码和频率加权FFT噪声增强，解决医学图像领域适应和数据稀缺问题，在分割、超分辨率和去噪任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接应用于MRI图像面临两个关键挑战：1）无法适应医学解剖结构的特异性；2）医学数据的隐私性和稀缺性带来的限制。

Method: 提出SSPFormer自监督预训练框架：1）引入逆频率投影掩码，优先重建高频解剖区域，实现结构感知表示学习；2）采用频率加权FFT噪声增强，在傅里叶域注入生理真实噪声，增强对真实MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的大量实验表明，SSPFormer达到了最先进的性能，充分验证了其捕获细粒度MRI图像保真度和适应临床应用需求的能力。

Conclusion: SSPFormer通过创新的自监督策略，能够从原始扫描中学习领域不变和伪影鲁棒的特征，有效解决了MRI图像处理中的领域适应和数据稀缺问题，为临床医学图像分析提供了强大的基础模型。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [134] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Moaw框架通过训练视频扩散模型进行运动感知，实现零样本运动迁移，无需额外适配器


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在大型数据集训练中自然捕捉帧间特征对应关系，已有工作利用这一特性进行零样本光流预测和跟踪。本研究旨在探索监督训练是否能更充分利用视频扩散模型的跟踪能力。

Method: 提出Moaw框架：1) 训练扩散模型进行运动感知，从图像到视频生成转向视频到密集跟踪；2) 构建运动标注数据集识别最强运动信息的特征；3) 将这些特征注入结构相同的视频生成模型中，利用网络同质性实现零样本适应

Result: 实现了无需额外适配器的运动迁移，为生成建模和运动理解提供了新的桥梁范式

Conclusion: Moaw框架释放了视频扩散模型的运动感知能力，促进了更统一和可控的视频学习框架发展

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [135] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: 提出DSOD框架，通过VFM辅助解决源自由目标检测中的源偏差问题，包含统一特征注入、语义感知特征正则化等模块，在多个跨域任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有源自由目标检测方法存在源偏差问题，即适应后的模型仍然偏向源域，导致泛化能力差和自训练过程中的误差累积。需要一种能有效缓解源偏差的方法。

Method: 提出DSOD框架：1) 统一特征注入模块，通过简单尺度扩展和域感知自适应加权将VFM特征集成到CNN骨干网络；2) 语义感知特征正则化，约束特征学习防止过拟合源域特征；3) 针对计算受限场景的DSOD-distill变体，采用新颖的双教师蒸馏方案。

Result: 在多个基准测试中表现优异：正常到雾天天气适应达到48.1% AP，跨场景适应达到39.3% AP，合成到真实适应达到61.4% AP，均优于现有最先进的SFOD方法。

Conclusion: DSOD框架通过VFM辅助有效缓解了源自由目标检测中的源偏差问题，在多种跨域适应任务上取得了显著性能提升，并为计算受限场景提供了可行的蒸馏方案。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [136] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

TL;DR: Spatial-VLN提出感知引导探索框架，解决零样本视觉语言导航中空间感知不足的问题，通过空间感知增强和多专家推理模块，在复杂连续环境中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的零样本视觉语言导航代理在泛化方面表现出色，但在复杂连续环境中存在空间感知不足的问题，特别是在门交互、多房间导航和模糊指令执行三个关键空间挑战上失败率较高

Method: 提出Spatial-VLN框架，包含两个主要模块：1) 空间感知增强模块，整合全景过滤与专门的门和区域专家，生成空间连贯、跨视图一致的感知表示；2) 探索多专家推理模块，使用并行LLM专家处理路径点级语义和区域级空间转换，当专家预测不一致时激活查询探索机制主动探测关键区域

Result: 在VLN-CE上实现最先进性能，仅使用低成本LLM；引入基于价值的路径点采样策略有效缩小Sim2Real差距；真实世界评估证实框架在复杂环境中具有优越的泛化能力和鲁棒性

Conclusion: Spatial-VLN通过感知引导探索框架成功解决了零样本视觉语言导航中的关键空间挑战，在模拟和真实环境中都表现出优异的性能，为实际应用提供了可行方案

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [137] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 提出一个单图像3D可动画头部化身重建框架，支持实时动画和360度渲染，通过高斯原语嵌入参数化面部模型，结合3D GAN先验和局部特征融合提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大视角变化下容易崩溃，影响3D化身的真实感。需要解决单图像重建3D可动画头部化身的挑战，实现实时动画和全方位渲染。

Method: 1) 在参数化面部模型的UV空间中嵌入高斯原语进行建模；2) 利用预训练3D GAN提取全局全头特征和多视角监督；3) 利用UV空间和人脸对称性融合局部精细输入图像特征与全局全头纹理。

Result: 实验证明该方法能实现高质量3D全头建模和实时动画，显著提升3D说话化身的真实感。

Conclusion: 提出的框架成功解决了单图像3D可动画头部化身重建问题，通过结合全局先验和局部特征，实现了高质量重建和实时动画能力。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [138] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP：一种检索增强的全景分割方法，通过构建掩码片段特征数据库，在推理时检索相似特征和类别标签，结合CLIP分数提升未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统全景分割方法在特定数据集上训练后，对未见类别的泛化能力有限。开放词汇全景分割需要能够根据用户输入分割任意类别，因此需要解决未见类别的分割问题。

Method: 提出RetCLIP方法：1）使用图文对数据构建掩码片段特征数据库；2）推理时使用输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和相关类别标签；3）基于查询特征与检索特征的相似度分配分类分数；4）将检索分类分数与CLIP分数结合得到最终输出。

Result: 在COCO数据集上训练，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线方法分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU。

Conclusion: RetCLIP通过检索增强机制显著提升了开放词汇全景分割中未见类别的性能，证明了检索方法在提升模型泛化能力方面的有效性。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [139] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: SKANet：一种基于双流架构的认知深度学习框架，通过选择性核与不对称卷积动态调整感受野，有效识别GNSS复合干扰信号


<details>
  <summary>Details</summary>
Motivation: 随着电磁环境日益复杂，GNSS面临越来越复杂的干扰威胁。现有深度学习方法能识别基本干扰，但对复合干扰分类困难，因为不同干扰信号（瞬态突发信号和连续全局信号）需要冲突的特征提取尺度，传统单域方法性能下降明显。

Method: 提出SKANet框架，采用双流架构整合时频图像和功率谱密度。核心是多分支选择性核模块与不对称卷积块的结合，使网络能动态调整感受野，同时捕捉微尺度瞬态特征和宏观尺度频谱趋势。在融合阶段加入压缩激励机制，自适应重新校准各模态异构特征的贡献。

Result: 在405,000个样本的数据集上评估，SKANet达到96.99%的整体准确率，在复合干扰分类方面表现出优越的鲁棒性，特别是在低干噪比条件下表现突出。

Conclusion: SKANet通过动态感受野调整和自适应特征融合，有效解决了GNSS复合干扰分类的挑战，为复杂电磁环境下的干扰识别提供了有效的深度学习解决方案。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [140] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出Jo-SNC方法，通过联合样本选择和模型正则化处理标签噪声，使用Jensen-Shannon散度评估样本清洁度，结合自适应阈值、部分标签学习和负学习，以及三重一致性正则化来提升噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中普遍存在标签噪声，深度网络容易记忆这些噪声样本。现有方法主要关注识别清洁数据，但忽略了不同小批量中标签噪声的不平衡性，且对分布外噪声数据关注不足。

Method: 提出Jo-SNC方法：1) 使用Jensen-Shannon散度结合样本最近邻评估样本清洁度；2) 设计自适应数据驱动阈值方案调整每类选择阈值；3) 对清洁样本常规训练，对分布内噪声样本采用部分标签学习，对分布外噪声样本采用负学习；4) 提出三重一致性正则化促进自预测一致性、邻居预测一致性和特征一致性。

Result: 在多个基准数据集上的广泛实验和消融研究表明，该方法相比现有最先进方法具有有效性和优越性。

Conclusion: Jo-SNC方法通过联合样本选择和模型正则化，有效解决了标签噪声问题，特别是在处理不平衡噪声分布和分布外噪声数据方面表现出色。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [141] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: PhyG-MoE：一种基于物理引导的专家混合框架，通过动态调整模型容量来匹配信号复杂度，解决GNSS干扰识别中静态模型计算资源不匹配的问题，在21种干扰类别上达到97.58%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前GNSS干扰识别中的深度学习模型存在根本性限制：无论输入信号的物理熵如何，都采用固定的计算拓扑结构。这种刚性导致严重的资源不匹配问题，简单信号和复杂饱和信号消耗相同的处理成本，无法适应动态电磁环境。

Method: 提出PhyG-MoE框架，采用基于频谱的门控机制，根据信号的频谱特征纠缠程度进行路由。对于复杂饱和场景，按需激活高容量的TransNeXt专家来解纠缠复杂特征；对于基本信号，使用轻量级专家处理以最小化延迟。

Result: 在21种干扰类别上的评估显示，PhyG-MoE实现了97.58%的整体准确率。该框架在保持性能不下降的同时显著降低了计算开销，解决了静态计算与动态电磁环境之间的内在冲突。

Conclusion: PhyG-MoE通过动态对齐模型容量与信号复杂度，为资源受限的认知接收器提供了可行的解决方案，有效解决了GNSS干扰识别中静态模型的计算资源不匹配问题。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [142] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 本文通过可控的1D图像-文本测试平台，研究Transformer视觉和文本编码器在CLIP风格对比训练中如何习得左右关系理解，发现标签多样性是泛化的主要驱动力，并通过注意力分解揭示了位置嵌入和词嵌入交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解是视觉语言模型的关键挑战，但目前尚不清楚这种理解是否真正被习得以及通过何种机制实现。本文旨在探究基于Transformer的视觉和文本编码器在CLIP风格对比训练中如何获得左右关系理解能力。

Method: 构建可控的1D图像-文本测试平台，训练轻量级Transformer视觉和文本编码器端到端处理单物体和双物体场景描述，系统性地改变标签和布局多样性，评估对未见物体对的泛化能力，并进行注意力分解分析。

Result: 对比训练能够学习左右关系，标签多样性比布局多样性对泛化更重要；注意力分解显示位置嵌入和词嵌入的交互诱导出水平注意力梯度，打破编码器的左右对称性，消除这一贡献会显著降低左右辨别能力。

Conclusion: 研究提供了CLIP风格模型何时以及如何获得关系能力的机制性见解，揭示了标签多样性和位置-词嵌入交互在空间关系理解中的关键作用。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [143] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架，用于3D高斯泼溅的率失真优化压缩与分割，通过轻量级隐式神经表示超先验和压缩引导的分割学习，在降低传输成本的同时保持高质量渲染和分割性能。


<details>
  <summary>Details</summary>
Motivation: 虽然3D高斯泼溅在实时渲染和语义场景理解方面都很有效，但先前工作大多将这两个任务独立处理，缺乏联合考虑。本研究旨在将语义学习整合到压缩流程中，支持解码端的场景编辑和操作等应用。

Method: 1) 采用轻量级隐式神经表示超先验，高效编码颜色和语义属性；2) 开发压缩引导的分割学习，包括量化感知训练以增强特征可分性；3) 质量感知加权机制以抑制不可靠的高斯基元。

Result: 在LERF和3D-OVS数据集上的实验表明，该方法显著降低了传输成本，同时保持了高渲染质量和强大的分割性能。

Conclusion: 提出了首个统一框架，成功实现了3D高斯泼溅的率失真优化压缩与分割，为解码端应用提供了高效解决方案，在传输效率和任务性能之间取得了良好平衡。

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [144] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

TL;DR: SDF-HOLO是一个用于全身PET/CT的多模态基础模型，通过双流编码器分离CT和PET表征学习，结合跨模态交互模块，利用解剖上下文精炼PET聚集，代谢显著性指导形态推理，在肿瘤分割、低剂量病变检测和多语言诊断报告生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 全身PET/CT面临三大挑战：1) 异质的解剖和代谢信号；2) 约2米的轴向覆盖范围；3) 结构化的放射学语义。现有医学AI模型假设单模态输入、局部视野和粗略的图像-文本对齐，无法有效处理这些挑战。

Method: 1) 使用双流编码器分离CT和PET表征学习，通过跨模态交互模块耦合；2) 分层上下文建模结合高效局部窗口和全局注意力来处理长距离依赖；3) 使用解剖分割掩码作为显式语义锚点，在预训练期间执行体素-掩码-文本对齐；4) 在10,000多名患者数据上进行预训练。

Result: 在肿瘤分割、低剂量病变检测和多语言诊断报告生成任务中，SDF-HOLO优于强任务特定和临床参考基线，同时减少了定位错误和幻觉发现。模型还能实现全身代谢分析和揭示肿瘤相关的器官间代谢网络相互作用指纹。

Conclusion: SDF-HOLO为全身PET/CT诊断和系统级精准肿瘤学提供了可扩展的计算基础，超越了局部解释，实现了全身代谢分析和肿瘤相关代谢网络相互作用的发现。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [145] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS：基于3D高斯泼溅的航空图像重建方法，用于从空中遥感数据准确测量树木胸径（DBH）


<details>
  <summary>Details</summary>
Motivation: 航空遥感虽能高效进行大范围勘测，但在复杂自然场景中难以实现准确的对象级测量。现有3D重建方法（如NeRF、3D高斯泼溅）虽提高了重建精度，但对于空中测量树木胸径（DBH）仍面临挑战，因为树干在航空图像中距离远、观测稀疏，传统方法难以约束胸高处的树干几何形状。

Method: 提出TreeDGS方法：1）使用SfM-MVS进行初始化；2）采用3D高斯泼溅作为连续、可稠密化的场景表示；3）通过RaDe-GS的深度感知累积不透明度积分从高斯场提取稠密点集；4）为每个样本分配多视角不透明度可靠性分数；5）使用不透明度加权的实心圆拟合从树干分离点中估计DBH。

Result: 在10个样地的现场测量DBH评估中，TreeDGS达到4.79厘米RMSE（约2.6像素），优于最先进的LiDAR基线（7.91厘米RMSE），表明基于泼溅的稠密化几何能够实现准确、低成本的航空DBH测量。

Conclusion: TreeDGS证明了基于3D高斯泼溅的航空图像重建方法能够有效解决树干在航空图像中稀疏观测的挑战，实现准确的树木胸径测量，为低成本、高效的森林资源监测提供了新途径。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [146] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 研究发现Grad-CAM在医学影像解释中存在局限性，特别是在Vision Transformer模型中解释保真度显著下降，不同架构间显著性定位存在显著差异，需要更谨慎地采用视觉解释工具。


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学影像分析中广泛用于可视化深度神经网络的推理过程，但其忠实性和可靠性仍受到质疑。本研究旨在批判性地调查Grad-CAM是否真正代表了用于肺癌图像分类的深度模型的内部决策过程。

Method: 使用公开的IQ-OTH/NCCD数据集，评估五种代表性架构：ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0和ViT-Base-Patch16-224。引入定量评估框架，结合定位准确性、基于扰动的忠实性和解释一致性，评估不同架构下Grad-CAM的可靠性。

Result: 实验发现：1) Grad-CAM在大多数卷积网络中能有效突出显著肿瘤区域；2) 在Vision Transformer模型中，由于非局部注意力行为，其解释保真度显著下降；3) 跨模型比较显示显著性定位存在显著变异性，表明Grad-CAM解释可能并不总是对应网络使用的真实诊断证据。

Conclusion: 本研究揭示了当前基于显著性的XAI方法在医学影像中的关键局限性，强调需要既计算上合理又临床上有意义的模型感知可解释性方法。研究结果旨在激发医学AI中更谨慎和严格地采用视觉解释工具，促使社区重新思考"信任"模型解释的真正含义。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [147] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

TL;DR: 提出FGTBT框架，通过频率引导和任务平衡提升面部关键点检测性能，解决大姿态变化、光照变化等挑战场景下的几何结构感知问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习面部关键点检测方法在挑战性场景（大姿态变化、光照变化、表情变化）中难以准确捕捉面部几何结构，且现有数据集规模有限、多样性不足，导致模型训练不充分、检测精度下降

Method: 提出频率引导任务平衡Transformer（FGTBT）框架：1）细粒度多任务平衡损失（FMB-loss），基于关键点在多个数据集中的出现频率分配权重，实现更有效的统一训练；2）频率引导结构感知（FGSA）模型，通过频率引导的结构注入和正则化学习面部结构约束

Result: 在流行基准数据集上的实验结果表明，FGTBT框架集成了FMB-loss和FGSA模型，取得了与最先进方法相当的性能

Conclusion: 通过频率域建模和多数据集统一训练，FGTBT框架增强了面部结构感知能力，解决了现有方法在挑战性场景下的性能下降问题，为面部关键点检测提供了有效解决方案

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [148] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

TL;DR: 提出HPT-GPD方法，通过跨架构代理对抗鲁棒性转移和泛化-鲁棒性解耦，实现视觉语言模型的高效对抗鲁棒性蒸馏，同时保持零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统对抗鲁棒性蒸馏方法在视觉语言模型（如CLIP）上存在计算资源过高的问题，因为需要为大规模多模态模型构建对抗鲁棒性教师模型。研究发现普通CLIP对不同架构CLIP生成的对抗样本具有内在防御能力，这为高效鲁棒性转移提供了新思路。

Method: 提出异构代理转移（HPT）框架，利用不同架构CLIP之间的代理对抗鲁棒性建立跨架构鲁棒性蒸馏通道。为解决代理转移导致的过拟合和零样本泛化能力下降问题，设计了泛化-鲁棒性解耦（GPD）方法，通过不同学习率调度将转移过程分解为保持泛化的预热阶段和提升鲁棒性的HPT阶段。

Result: 在15个零样本数据集上的广泛实验证明了HPT-GPD方法的有效性，能够在保持自然泛化能力的同时提升对抗鲁棒性。

Conclusion: 通过揭示CLIP的代理对抗鲁棒性现象，提出的HPT-GPD框架为视觉语言模型的高效对抗鲁棒性转移提供了新范式，成功解决了计算资源限制和泛化-鲁棒性权衡问题。

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [149] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: THFEM框架整合音频驱动说话头生成模型与面部表情操纵技术，通过相邻帧学习策略提升唇部同步精度和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有SPFEM技术在面部表情操纵时难以保持准确的唇部同步，因为面部表情与嘴型之间存在复杂交互关系。

Method: 提出THFEM框架：1) 利用AD-THG模型从音频输入和SPFEM处理图像生成唇部同步准确的帧；2) 开发相邻帧学习策略微调AD-THG模型，使其能预测连续帧序列，提升图像质量和表情保真度。

Result: 实验评估表明该框架能有效在表情操纵过程中保持嘴型，显著提升了AD-THG与SPFEM整合的效果。

Conclusion: THFEM框架成功解决了SPFEM中的唇部同步问题，通过整合AD-THG模型和相邻帧学习策略，实现了高质量的面部表情操纵同时保持准确的唇部运动。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [150] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

TL;DR: YOLO26通过消除NMS后处理，采用端到端学习策略，在推理速度和检测精度上超越了YOLO系列及其他SOTA方法，建立了新的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO系列（v1-v11）受限于NMS后处理的延迟和超参数敏感性，需要在实时目标检测中解决延迟与精度之间的历史权衡问题。

Method: 提出YOLO26架构，完全消除NMS，采用端到端学习策略。关键创新包括：MuSGD优化器稳定轻量级骨干网络、STAL小目标感知分配、ProgLoss动态监督。

Result: 在官方性能基准测试中，YOLO26在推理速度和检测精度上都超越了YOLO系列前代模型及RTMDet、DAMO-YOLO等SOTA竞争对手，建立了新的帕累托前沿。

Conclusion: 通过将表示学习与启发式后处理解耦，YOLO26成功解决了延迟与精度之间的历史权衡，标志着边缘计算机视觉的下一个进化步骤。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [151] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出集成深度学习框架，结合VGG16、ResNet50和InceptionV3，通过优化加权平均实现牛痘皮肤病和口蹄疫的同时检测，准确率达98.2%，解决症状重叠的诊断难题。


<details>
  <summary>Details</summary>
Motivation: 牛痘皮肤病和口蹄疫是高度传染性病毒疾病，造成重大经济损失。视觉诊断因症状重叠（包括彼此之间以及与良性状况如昆虫叮咬或化学烧伤）而复杂化，阻碍及时控制措施。

Method: 使用来自印度、巴西和美国18个农场的10,516张专家标注图像，提出集成深度学习框架，整合VGG16、ResNet50和InceptionV3模型，采用优化加权平均方法进行同时检测。

Result: 模型达到最先进的98.2%准确率，宏平均精确率98.2%、召回率98.1%、F1分数98.1%、AUC-ROC 99.5%，有效解决多疾病检测中的症状重叠挑战。

Conclusion: 该框架能够实现早期、精确、自动化的诊断，有潜力改善疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [152] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

TL;DR: TwoHead-SwinFPN：用于身份证件防伪的统一深度学习架构，同时进行篡改检测和区域定位，在FantasyIDiap数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型的普及，身份证件面临人脸替换和文本修复等合成篡改威胁日益严重，需要有效的检测和定位方法。

Method: 提出统一架构，结合Swin Transformer骨干网络、特征金字塔网络和UNet风格解码器，采用CBAM注意力模块增强特征表示，使用双头架构进行联合优化，通过不确定性加权多任务学习。

Result: 在FantasyIDiap数据集上取得84.31%准确率、90.78% AUC（分类）和57.24%平均Dice分数（定位），F1分数88.61%，计算效率适合实际部署。

Conclusion: TwoHead-SwinFPN在身份证件篡改检测和定位方面表现出色，具有实际部署潜力，并通过跨设备、多语言评估验证了泛化能力。

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [153] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

TL;DR: 提出SHT弱监督框架，通过人脸幻觉和姿态迁移任务提升低分辨率人脸图像的关键点检测精度


<details>
  <summary>Details</summary>
Motivation: 低分辨率人脸图像或图像压缩会阻碍高分辨率深度特征表示的学习，导致人脸关键点检测精度下降；同时训练数据不足和标注不精确进一步影响性能

Method: 提出SHT框架，包含两个相互增强的模块：DHLN（双幻觉学习网络）通过人脸关键点检测和人脸幻觉任务学习高分辨率表示；FPTN（面部姿态迁移网络）通过姿态变换进一步优化关键点热图和幻觉人脸

Result: 在人脸幻觉和人脸关键点检测任务上，该方法均超越了现有最先进技术

Conclusion: 这是首个通过整合人脸幻觉和面部姿态迁移任务来探索弱监督人脸关键点检测的研究，实验证明了方法的有效性

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [154] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

TL;DR: 提出DSCT模型，通过融合区域特征和分割特征解决图像描述生成中的上下文信息不足和过度依赖部分描述的问题，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于区域特征的图像描述方法虽然进展迅速，但由于缺乏上下文信息以及过度依赖已生成的部分描述来预测剩余单词，容易产生不相关的描述。

Method: 提出双流协作Transformer（DSCT），引入分割特征并与区域特征融合。包含多个模式特定互注意力编码器（PSMAE）和动态提名解码器（DND）。PSMAE通过相互查询有效突出和整合两种表示的私有信息；DND动态搜索与输入文本表示最相关的学习块，并利用整合后的区域和分割特征之间的同质特征生成更准确、描述性更强的句子。

Result: 在流行的基准数据集上的实验结果表明，DSCT在图像描述任务上优于现有最先进的模型。

Conclusion: 这是首次探索如何以动态方式融合不同模式特定特征，以绕过其语义不一致和空间不对齐问题，用于图像描述生成的研究。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [155] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究分析了成员推断测试(MINT)在物体识别领域的性能，提出了针对MINT模型的专用架构，通过实验在三个公共数据库上实现了70-80%的精度，并分析了影响MINT模块的因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决物体识别领域中确定特定数据是否被用于训练阶段的成员推断问题，为数据隐私和安全提供技术解决方案。

Method: 提出了针对MINT模型的专用架构，包含物体检测模型、嵌入提取器和MINT模块。使用卷积层捕捉训练过程中的激活模式，在三个公共数据库（总计超过17.4万张图像）上进行实验。

Result: 实现了70-80%的精度来识别测试和训练数据，精度取决于检测模块层的深度选择。同时分析了影响MINT模块性能的因素。

Conclusion: 提出的MINT架构在物体识别领域有效，能够以较高精度识别训练数据使用情况，为训练过程透明度提供了分析框架。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [156] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA提出质量引导的K自适应槽注意力，通过解耦槽选择与重建、设计无监督槽质量度量、质量引导槽选择机制，解决了现有K自适应方法在槽绑定质量和优化目标冲突方面的局限，在真实和合成数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应槽注意力方法存在两个主要问题：1）没有显式约束槽绑定质量，导致低质量槽引起特征归属模糊；2）在重建目标中添加槽数量惩罚会造成减少活跃槽数量与保持重建保真度之间的优化目标冲突。这导致现有K自适应方法性能显著落后于固定K的基线方法。

Method: QASA包含三个核心创新：1）将槽选择与重建解耦，消除两个目标间的相互约束；2）提出无监督的槽质量度量来评估每个槽的质量，为细粒度槽-对象绑定提供原则性信号；3）基于质量度量设计质量引导槽选择方案，动态选择高质量槽子集，输入新设计的门控解码器进行训练重建。推理时通过槽注意力上的token-wise竞争获得K自适应结果。

Result: 实验表明，QASA在真实和合成数据集上大幅超越现有K自适应方法。更重要的是，在真实世界数据集上，QASA甚至超越了固定K的方法，显示出其优越性。

Conclusion: QASA通过解耦槽选择与重建、引入槽质量度量、设计质量引导选择机制，有效解决了现有K自适应方法的局限性，实现了在保持重建质量的同时自适应确定槽数量，在对象中心学习任务中取得了显著改进。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [157] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD：基于扩散模型的单张RGB图像3D视线与人体姿态联合估计方法


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理3D视线估计或依赖时序信息，GazeD旨在从单张RGB图像中联合估计3D视线和人体姿态，利用扩散模型处理不确定性的能力

Method: 基于扩散模型，从输入图像提取2D姿态、人物周围环境和场景上下文作为条件，在去噪过程中联合生成多个合理的3D视线和姿态假设；提出将3D视线表示为距离眼睛固定距离的额外身体关节

Result: 在三个基准数据集上评估，GazeD在3D视线估计方面达到最先进性能，甚至超越了依赖时序信息的方法

Conclusion: GazeD通过扩散模型成功实现了从单张RGB图像中联合估计3D视线和人体姿态，证明了视线与姿态联合去噪的有效性

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [158] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 提出基于Mamba的生成器StyMam，用于图像风格迁移，解决现有方法在局部与全局依赖捕获、内容结构保持和推理速度方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法主要基于GAN或稳定扩散(SD)。GAN方法难以同时捕获局部和全局依赖，导致伪影和不协调模式；SD方法虽减少这些问题但常无法保持内容结构且推理速度慢。

Method: 提出基于Mamba的生成器StyMam，包含残差双路径条带扫描机制和通道重加权空间注意力模块。前者高效捕获局部纹理特征，后者建模全局依赖关系。

Result: 大量定性和定量实验表明，该方法在质量和速度上都优于现有最先进算法。

Conclusion: 通过重新审视GAN并采用Mamba架构，提出的StyMam能够生成高质量风格化图像，避免伪影和不协调模式，同时在内容结构保持和推理速度方面表现优异。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [159] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 提出一种空间亲和力组件，可将高分辨率遥感图像融入自监督预训练，提升中分辨率图像的表征学习和下游分割性能


<details>
  <summary>Details</summary>
Motivation: 当前遥感自监督预训练主要使用中分辨率图像数据集，但随着高分辨率数据集的发布，需要研究如何利用高分辨率数据来增强中分辨率图像的表征学习，提升下游分割任务性能

Method: 设计了一个空间亲和力组件，可以添加到现有的自监督学习框架中，利用高分辨率图像来学习更好的中分辨率图像表征

Result: 在两个自监督学习框架上测试了空间亲和力组件，结果显示它优于仅使用高分辨率或中分辨率图像单独预训练的模型

Conclusion: 通过空间亲和力组件将高分辨率数据融入自监督预训练，可以有效提升中分辨率遥感图像的表征质量和下游分割性能

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [160] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

TL;DR: 提出基于表格Transformer（TabTrans）的早期2型糖尿病风险预测方法，整合纵向电子健康记录和骨密度数据，在卡塔尔生物银行队列上验证，性能优于传统机器学习和生成式AI模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉疾病进展中的复杂长期依赖关系，需要开发能够处理纵向医疗表格数据的新方法，以改善2型糖尿病的早期预测和个性化管理。

Method: 使用TabTrans架构分析纵向患者数据，整合电子健康记录和双能X射线吸收测定数据，采用SMOTE和SMOTE-ENN处理类别不平衡，并与传统机器学习及生成式AI模型（Claude 3.5 Sonnet、GPT-4、Gemini Pro）进行对比。

Result: TabTrans模型在2型糖尿病预测中ROC AUC ≥ 79.7%，优于所有对比模型。特征解释分析识别出内脏脂肪组织质量/体积、骨密度、骨矿物质含量、T/Z分数、L1-L4评分等关键风险指标。

Conclusion: TabTrans在分析复杂医疗表格数据方面具有显著潜力，为卡塔尔人群的主动2型糖尿病管理和个性化临床干预提供了强大工具。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [161] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: AsyncBEV是一个可训练的轻量级模块，用于提升3D BEV目标检测模型对传感器异步的鲁棒性，通过估计特征流来对齐不同模态的特征图。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的多模态感知任务通常依赖同步的传感器，但现实中由于不同传感器频率、网络延迟、硬件故障等因素，完美同步很难保证，这种异步会降低感知性能，特别是对动态物体。

Method: 受场景流估计启发，AsyncBEV首先从两个不同传感器模态的BEV特征中估计2D流，考虑已知的时间偏移，然后使用预测的特征流对特征图进行扭曲和空间对齐，可以轻松集成到不同的BEV检测器架构中。

Result: AsyncBEV显著提升了CMT和UniBEV对LiDAR或相机传感器小和大异步的鲁棒性，特别是在动态物体上。在0.5秒时间偏移的最坏情况下，动态物体的NDS分别比基线提升了16.6%和11.9%。

Conclusion: AsyncBEV是一个有效解决传感器异步问题的通用模块，能够显著提升BEV检测器在异步条件下的性能，特别是对动态物体的检测。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [162] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D框架让视觉大模型通过3D重建和交互式空间操作实现真正的3D推理，无需额外训练就能显著提升空间推理能力


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型虽然擅长2D视觉理解，但缺乏真正的3D空间推理能力，无法像人类一样理解和操作三维世界

Method: 利用3D重建模型从图像/视频恢复点云和相机位姿，通过相机操作和视角切换实现交互式3D思维链推理，小模型还使用强化学习策略选择信息丰富的视角

Result: 无需额外训练，Think3D显著提升GPT-4.1和Gemini 2.5 Pro等先进模型的空间推理性能，在BLINK Multi-view和MindCube上平均提升7.8%，在VSI-Bench上提升4.7%；小模型通过强化学习将工具使用收益从0.7%提升到6.8%

Conclusion: 免训练的工具增强空间探索是实现更灵活、类人3D推理的有效途径，为多模态智能开辟了新维度

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [163] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，结合高密度LiDAR和高分辨率倾斜影像，包含7,694张图像和25亿个点，标注为11个类别，提供基准模型和代码。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR和高分辨率倾斜影像的公开数据集用于电力线路资产的3D语义标注，这限制了多模态融合方法在电力基础设施分析中的应用。

Method: 创建了GridNet-HD数据集，包含7,694张图像和25亿个LiDAR点，标注为11个语义类别。提供了预定义的数据分割和mIoU评估指标，建立了单模态（仅LiDAR、仅图像）和多模态融合的基准模型。

Result: 在GridNet-HD数据集上，多模态融合模型比最佳单模态基准模型提升了+5.55 mIoU，证明了几何信息（LiDAR）和外观信息（图像）的互补性。

Conclusion: GridNet-HD填补了电力基础设施3D语义分割领域多模态数据集的空白，展示了多模态融合在电力线路资产分析中的优势，数据集、基准模型和代码已公开提供。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [164] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

TL;DR: 提出一种结合Retinex理论和少样本学习的双分支原型学习网络，用于低光照条件下的裂缝分割，通过光照不变特征学习和度量学习减少对大规模标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现实中的混凝土基础设施裂缝常出现在隧道、桥底等低光照环境，导致计算机视觉分割精度下降。像素级标注低光照裂缝图像耗时巨大，而现有深度学习方法大多需要充足光照的大规模数据集。

Method: 1) 双分支原型学习网络：整合Retinex理论与少样本学习；2) Retinex反射分量引导光照不变全局表征学习；3) 度量学习减少对大规模标注数据的依赖；4) 交叉相似性先验掩码生成模块：计算查询与支持特征的高维相似性以捕捉裂缝位置和结构；5) 多尺度特征增强模块：融合多尺度特征与先验掩码缓解空间不一致性。

Result: 在多个基准测试上进行广泛实验，在低光照条件下展现出持续的最先进性能。

Conclusion: 该方法有效解决了低光照环境下裂缝分割的挑战，通过光照不变特征学习和少样本学习策略，在减少标注需求的同时提升了分割精度。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [165] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: HyperAdapt是一个患者条件适应框架，通过超网络模块生成残差调制参数来调整共享骨干网络，以改善医学AI模型在不同患者亚组中的可靠性，同时保持整体准确性。


<details>
  <summary>Details</summary>
Motivation: 医学AI模型在不同患者群体中表现不均，现有公平性方法通过抑制敏感属性会降低准确性，而临床决策需要结合患者上下文信息进行诊断。

Method: 将临床相关属性编码为紧凑嵌入，通过超网络模块为共享骨干网络的选定层生成小型残差调制参数，采用低秩和瓶颈参数化来约束适应过程。

Result: 在多个医学影像基准测试中，该方法持续改善亚组性能而不牺牲整体准确性。在PAD-UFES-20数据集上，比最强基线在召回率和F1分数上分别提升4.1%和4.4%，对代表性不足的患者群体提升更大。

Conclusion: HyperAdapt通过患者条件适应框架，在保持共享诊断模型的同时改善了亚组可靠性，为医学AI模型提供了一种结合临床上下文信息的新设计方向。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [166] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: SANDesc是一个轻量级注意力网络，用于提取关键点描述符，无需修改底层关键点检测器，在多个匹配任务上超越原始描述符，仅240万参数。


<details>
  <summary>Details</summary>
Motivation: 改进现有关键点描述符架构，在不修改底层关键点检测器的情况下，通过学习计算更好的描述符来提升匹配性能。

Method: 采用改进的U-Net架构，结合卷积块注意力模块和残差路径（Residual U-Net Blocks with Attention），使用改进的三元组损失和课程学习启发的困难负样本挖掘策略进行训练。

Result: 在HPatches、MegaDepth-1500和Image Matching Challenge 2021上，SANDesc在现有关键点检测器基础上训练，在多个匹配任务上超越原始描述符。同时引入新的4K城市数据集进行评估，SANDesc在有限计算资源下取得显著性能提升。

Conclusion: SANDesc是一个高效轻量的描述符提取网络，仅240万参数，在不修改关键点检测器的情况下显著提升匹配性能，并引入新的评估数据集推动特征提取器研究。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [167] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark：一种基于VAE潜在频率域相位调制的单次优化自由水印框架，比基于优化的方法快数千倍，同时保持卓越的抗攻击能力和图像质量


<details>
  <summary>Details</summary>
Motivation: 潜在扩散模型（LDMs）生成的超真实图像需要鲁棒的水印技术，但现有的后处理方法由于迭代优化或反演过程而速度过慢

Method: PhaseMark是一种单次优化自由框架，直接在VAE潜在频率域中调制相位，分析了四种调制变体，揭示了性能与质量之间的权衡

Result: PhaseMark比基于优化的技术快数千倍，同时实现了最先进的抗攻击能力（包括再生攻击），且不降低图像质量

Conclusion: PhaseMark展示了一种新范式，通过利用内在潜在属性实现高效、有弹性的水印技术

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [168] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer：基于3D高斯泼溅的具身探索与推理框架，通过视觉语言模型实现复杂语言查询驱动的3D场景探索


<details>
  <summary>Details</summary>
Motivation: 现有基于语言嵌入的3D高斯泼溅方法只能处理简单文本查询，难以处理复杂组合语言查询；而基于对象中心的RGB-D结构化记忆方法又受限于固定视角。需要一种能够处理复杂查询并支持自由视角探索的解决方案。

Method: 在3D高斯泼溅基础上引入视觉语言模型，首先识别与查询问题最相关的预捕获图像，然后将其调整到新视角以获取更准确的视觉信息供VLM推理

Result: 在多个基准测试中优于现有方法，证明了将VLM推理与3DGS集成在具身任务中的有效性

Conclusion: GaussExplorer成功解决了复杂组合语言查询的3D场景探索问题，通过VLM与3DGS的结合实现了更准确的推理和自由视角探索

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [169] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一个用于人体中心视觉任务的无监督预训练框架，利用CLIP生成多级语义伪标签，通过Prompt-Controlled MoE模块动态适应不同下游任务，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大规模未标记人体图像数据集的出现，需要一种通用的无监督预训练模型来支持多样化的人体中心下游任务，如监控、医疗和人机交互。

Method: 1. 利用CLIP生成低级（身体部位）和高级（属性）语义伪标签；2. 将这些多级语义线索整合到视觉表示中；3. 引入Prompt-Controlled Mixture-of-Experts模块，根据任务特定提示动态调整特征提取；4. 采用多任务预训练策略，由CLIP生成的伪标签指导表示学习。

Result: 在多个基准测试上的广泛实验表明，CLASP始终优于现有的无监督预训练方法，推进了人体中心视觉分析领域的发展。

Conclusion: CLASP通过整合CLIP生成的多级语义伪标签和自适应MoE模块，成功构建了一个通用且高效的人体中心视觉无监督预训练框架，能够有效支持多样化的下游任务。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [170] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: 论文提出了TVWorld基准测试和TVTheseus模型，用于评估和改进大视觉语言模型在电视遥控导航任务中的能力，解决了现有模型在拓扑感知和长视野导航方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型主要关注点按交互，而日常生活中常见的电视遥控交互研究不足。需要开发能够评估和改进模型在电视导航任务中拓扑感知能力的基准和方法。

Method: 1) 提出TVWorld离线图抽象基准，包含TVWorld-N（拓扑感知导航）和TVWorld-G（焦点感知定位）两个互补基准；2) 提出拓扑感知训练框架，将拓扑意识注入LVLMs；3) 开发TVTheseus专用电视导航基础模型。

Result: TVTheseus在TVWorld-N上达到68.3%的成功率，超越了Gemini 3 Flash等强基线，建立了最先进的性能。分析为开发有效的电视使用代理提供了有价值的见解。

Conclusion: 论文填补了电视遥控交互研究的空白，通过TVWorld基准和拓扑感知训练框架显著提升了LVLMs在电视导航任务中的能力，为开发更实用的设备控制代理提供了重要基础。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [171] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一种生成交互式、对话式、逼真3D虚拟人的方法，通过多视角捕捉创建可动画的3D面部和动态3D身体模型，使用高斯基元渲染，结合LLM实现对话能力，音频驱动面部动画，支持实时交互。


<details>
  <summary>Details</summary>
Motivation: 创造逼真的交互式3D虚拟人，支持实时对话和沉浸式体验，应用于游戏、虚拟助手、个性化教育等多个领域。

Method: 基于多视角捕捉创建可动画3D面部模型和动态3D身体模型，使用高斯基元渲染；改进动态高斯模型（SWinGS++用于身体重建，HeadGaS++用于面部重建）；合并面部和身体模型无伪影；集成LLM实现对话能力；音频驱动面部动画同步。

Result: 实现了逼真的交互式3D虚拟人，支持实时对话，面部动画与音频精确同步，展示了完整的系统演示和多种实时对话用例。

Conclusion: ICo3D提供了完全集成的虚拟化身体验，支持口头和书面形式的沉浸式交互，适用于游戏、虚拟助手、个性化教育等广泛领域。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [172] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 该研究开发了用于3D脑MRI分析的医学图像基础模型，在MICCAI 2025的SSL3D和FOMO25挑战赛中均获第一名，采用U-Net CNN架构结合解剖先验知识，相比Transformer方法训练速度提高1-2个数量级，模型尺寸小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对医学图像分析的基础模型，以解决放射学任务中的独特挑战，特别是在3D脑MRI分析领域。

Method: 采用U-Net CNN架构，结合解剖先验知识和神经影像领域知识策略，相比Transformer方法更轻量高效。

Result: 在MICCAI 2025的SSL3D和FOMO25两个3D脑MRI挑战赛中均获得第一名，训练速度比Transformer方法快1-2个数量级，模型尺寸小10倍。

Conclusion: 基于U-Net CNN结合解剖先验的方法在3D脑MRI分析中表现出色，相比Transformer方法在效率和模型大小方面具有显著优势，为医学图像基础模型开发提供了有效方案。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [173] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: 提出GTPred基准测试，用于评估多模态大语言模型在结合时间和地理信息进行图像定位的能力，发现当前模型在时空推理方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位基准大多忽略图像中的时间信息，而时间信息可以进一步约束位置推断。为了填补这一空白，需要一个新的基准来评估模型在结合时空信息进行定位的能力。

Method: 引入GTPred基准，包含370张全球分布、时间跨度超过120年的图像。评估方法包括：1）联合考虑年份和分层位置序列匹配；2）使用精心标注的真实推理过程评估中间推理链。在8个专有和7个开源MLLMs上进行实验。

Result: 实验表明，尽管当前模型具有较强的视觉感知能力，但在世界知识和地理时间推理方面仍有局限。结果还显示，结合时间信息能显著提升位置推断性能。

Conclusion: GTPred基准揭示了当前多模态大语言模型在时空推理方面的不足，强调了结合时间信息对地理定位的重要性，为未来模型改进提供了方向。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [174] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

TL;DR: Additive U-Net用可学习的门控加法连接替代标准U-Net中的拼接跳跃连接，在保持竞争性去噪性能的同时减少了通道维度膨胀，并提供了更可解释的信息流控制。


<details>
  <summary>Details</summary>
Motivation: 标准U-Net中的拼接跳跃连接存在两个主要问题：1) 通道维度翻倍导致计算负担增加；2) 信息流不透明，允许不受控制的噪声传输。需要一种更轻量级且可解释的替代方案。

Method: 提出Additive U-Net架构，将传统的拼接跳跃连接替换为门控加法连接。每个跳跃路径通过一个可学习的非负标量进行缩放，从而提供对编码器贡献的显式控制，同时避免通道维度膨胀。

Result: 在Kodak-17去噪基准测试中，Additive U-Net在噪声水平σ=15、25、50下取得了具有竞争力的PSNR/SSIM性能，并且在不同核调度和深度下表现出鲁棒性。模型即使没有显式的下采样/上采样或强制层次结构，也能自然学习从高频到带通再到低频特征的渐进过程。

Conclusion: 加法跳跃连接是拼接连接的一种轻量级且可解释的替代方案，既能实现高效设计，又能更清晰地理解重建网络中的多尺度信息传输机制。

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [175] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 提出StreetCrossing数据集和oSIM指标，用于评估基于对象的视觉注意力模型，并开发了SUMGraph模型，在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力具有基于对象的特性，但在计算视觉注意力模型中很少考虑。主要原因是缺乏合适的数据集和评估指标来评估基于对象的注意力。

Method: 1) 创建StreetCrossing数据集：包含120名参与者在虚拟现实中进行街道穿越导航的数据，提供精确的注视数据、完整的状态空间表示、丰富的标注（全景分割、深度信息、车辆关键点）；2) 提出对象相似度(oSIM)指标来评估基于对象的注意力模型；3) 开发SUMGraph模型：基于Mamba U-Net架构，将关键场景对象（车辆）编码为图表示。

Result: 1) 数据集填补了基于对象注意力评估的空白；2) oSIM指标能够有效评估基于对象的注意力性能；3) 优化基于对象注意力不仅提高oSIM性能，也提升常见指标的表现；4) SUMGraph模型在多个视觉注意力预测方法中表现优异。

Conclusion: 通过StreetCrossing数据集、oSIM指标和SUMGraph模型，为基于对象的视觉注意力研究提供了完整的解决方案，推动了该领域的发展，并展示了基于对象注意力建模的重要性。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [176] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 提出BLEMORE数据集，用于多模态混合情感识别，包含情感相对显著度信息，评估现有方法在混合情感识别任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 人类通常同时体验多种混合情感，但现有视频情感识别方法大多只能识别单一情感，缺乏包含相对显著度标注的混合情感数据集。

Method: 构建BLEMORE数据集，包含3000多个视频片段，涵盖6种基本情感和10种混合情感，每种混合有3种显著度配置（50/50、70/30、30/70）。评估单模态和多模态方法在两个任务上的表现：情感存在预测和情感显著度预测。

Result: 单模态分类器在验证集上达到29%存在准确率和13%显著度准确率；多模态方法表现更好，ImageBind+WavLM达到35%存在准确率，HiCMAE达到18%显著度准确率。在测试集上，最佳模型达到33%存在准确率（VideoMAEv2+HuBERT）和18%显著度准确率（HiCMAE）。

Conclusion: BLEMORE数据集为推进考虑混合情感表达复杂性和重要性的情感识别系统研究提供了宝贵资源。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [177] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

TL;DR: 提出ConvMambaNet混合深度学习模型，结合CNN和Mamba-SSM，用于癫痫发作检测，在CHB-MIT数据集上达到99%准确率。


<details>
  <summary>Details</summary>
Motivation: 癫痫严重影响生活质量，EEG是主要监测工具，但自动分析面临EEG信号时间复杂性的挑战，需要更有效的时空特征提取方法。

Method: 提出ConvMambaNet混合模型，将Mamba结构化状态空间模型(SSM)块嵌入CNN框架中，结合CNN的空间特征提取能力和Mamba-SSM的长程时间动态捕捉能力。

Result: 在CHB-MIT头皮EEG数据集上评估，达到99%的准确率，在严重类别不平衡情况下表现出鲁棒性能。

Conclusion: ConvMambaNet展示了精确高效的癫痫发作检测潜力，为临床环境中实时自动化癫痫监测提供了可行路径。

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [178] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出了首个利用真实天气条件攻击视觉语言模型（VLMs）的对抗框架，通过两阶段参数化扰动模型分析雨天对模型决策的影响，揭示了主流VLMs在真实天气条件下的语义对齐脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型主要在标准视觉条件下训练，但在真实天气条件（如雨天）下的鲁棒性和跨模态语义对齐稳定性研究不足。雨天等结构化扰动可能影响模型决策，存在实际部署中的安全风险。

Method: 采用两阶段参数化扰动模型：第一阶段通过低维全局调制弱化原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引起的照明变化，优化不可微分的天气空间以诱导稳定的语义偏移。整个框架在非像素参数空间中操作。

Result: 实验表明，即使是物理上合理且高度受限的天气扰动，也能在主流VLMs中引起显著的语义错位。消融研究进一步证实照明建模和多尺度雨滴结构是这些语义偏移的关键驱动因素。

Conclusion: 该研究揭示了VLMs在真实天气条件下的脆弱性，强调了在实际部署中考虑天气鲁棒性的重要性。提出的对抗框架为分析天气诱导的语义偏移提供了物理基础且可解释的方法。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [179] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 提出基于Calyo Pulse固态3D超声波传感器的学习式3D语义分割框架，用于恶劣环境下的自动驾驶感知


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶感知系统（LiDAR和摄像头）在成本、鲁棒性和恶劣天气性能方面存在权衡，需要寻找补充感知模态

Method: 使用Calyo Pulse模块化固态3D超声波传感器系统，提出3D U-Net架构对空间超声波数据进行体素分割训练

Result: Calyo Pulse传感器展现出稳健的分割性能，可通过更大数据集、更精确真值标注和加权损失函数进一步提升

Conclusion: 3D超声波感知是可靠自动驾驶的有前景的补充感知模态，特别适用于恶劣和杂乱环境

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [180] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity是首个开放、大规模、多领域工程图数据集，包含全面的结构标注，用于自动化图表解析，支持多模态大语言模型处理工程图相关任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统难以理解和处理工程图中的视觉-结构知识，这阻碍了AI在科学发现工作流中的全面参与。工程图的解析、技术图纸分析和视觉推理对于假设生成、实验设计和科学发现至关重要。

Method: 创建了一个开放、大规模、多领域的工程图数据集，包含层次化的组件关系、连接和语义元素标注，覆盖多个工程领域，为多模态大语言模型提供训练数据。

Result: 提出了Enginuity数据集，能够支持结构化图表解析、跨模态信息检索和AI辅助工程仿真等关键下游任务。

Conclusion: Enginuity将为科学发现AI带来变革，使AI系统能够理解和操作工程图中嵌入的视觉-结构知识，打破当前阻碍AI全面参与科学工作流的基本障碍。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [181] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 论文提出了CausalSpatial基准测试，发现多模态大语言模型在因果空间推理能力上存在严重缺陷，并提出COW框架通过生成假设动态视频来改善模型的物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察静态场景预测物体运动后的因果结果，但当前的多模态大语言模型主要局限于静态空间感知，无法回答3D场景中的"如果...会怎样"问题。需要评估和改进模型在因果空间推理方面的能力。

Method: 1) 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2) 分析模型失败原因，发现模型过度依赖文本链式推理而脱离视觉证据；3) 提出Causal Object World模型(COW)框架，通过生成假设动态视频来外部化模拟过程。

Result: 人类在基准测试中得分84%，而GPT-5仅得54%，显示出显著差距。分析发现模型产生流畅但空间无根据的幻觉。COW框架通过提供明确的因果视觉线索，使模型能够基于物理现实而非语言先验进行推理。

Conclusion: 多模态大语言模型在因果空间推理方面存在根本性缺陷，需要将视觉模拟外部化以改善物理推理能力。提出的COW框架为解决这一问题提供了有效途径，数据集和代码已开源。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [182] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一个多模态空间转录组学框架，通过交叉注意力融合空间拓扑、基因表达和组织形态学，实现更清晰的空间域边界划分。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法缺乏组织形态学与分子谱的有效整合，要么采用浅层融合策略，要么完全忽略组织图像，导致空间域边界模糊不清。

Method: 提出统一的多模态框架MultiST，使用基于交叉注意力的融合技术联合建模空间拓扑、基因表达和组织形态学；采用基于图的基因编码器配合对抗对齐学习鲁棒空间表示；整合颜色归一化的组织学特征捕捉分子-形态学依赖关系。

Result: 在13个不同ST数据集（包括人脑皮层和乳腺癌组织）上评估，MultiST产生比现有方法更清晰、更一致的空间域边界，获得更稳定的伪时间轨迹和更具生物学可解释性的细胞-细胞相互作用模式。

Conclusion: MultiST通过有效整合多模态信息，显著提升了空间转录组学分析中空间域划分的准确性和生物学解释性，为研究组织结构和细胞相互作用提供了强大工具。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [183] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一种在粉尘环境中生成可控多级粉尘浓度的方法，并开发了基于雷达参数过滤和聚类分类的实时行人检测系统，显著提升了粉尘环境下毫米波雷达的感知性能。


<details>
  <summary>Details</summary>
Motivation: 地下矿井、隧道等封闭恶劣环境中存在大量粉尘和反射表面，严重影响毫米波雷达的感知能力，需要开发能够在严重电磁约束下进行可重复传播研究的方法和可靠的检测系统。

Method: 1) 提出在高度杂乱环境中生成可控多级粉尘浓度的方法；2) 创建包含相机和LiDAR的4D毫米波雷达数据集；3) 开发基于关键雷达参数（RCS、速度、方位角、仰角）的阈值噪声过滤框架；4) 构建基于聚类级别的规则分类管道，利用雷达语义特征进行行人检测。

Result: 实验结果表明，该集成方法显著增强了粉尘环境中杂波抑制、检测鲁棒性和系统整体韧性，实现了可靠的实时行人检测，无需大量领域特定训练。

Conclusion: 该方法为恶劣粉尘环境下的毫米波传播研究提供了可重复的实验平台，并通过创新的数据处理和分类管道实现了可靠的实时行人检测，对地下矿井等危险环境的安全监测具有重要意义。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [184] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于球形几何表示的文本到3D人脸生成方法，通过将几何信号锚定到均匀球面坐标来简化底层几何结构，并利用球形几何扩散框架实现高质量、可控的3D人脸生成。


<details>
  <summary>Details</summary>
Motivation: 文本到3D人脸生成面临的核心挑战是几何质量不佳。现有模型难以处理3D空间中顶点分布的任意性和复杂性，导致网格连接性差和几何质量不理想。需要一种能简化底层几何结构的方法。

Method: 1. 提出球形几何表示：将几何信号锚定到均匀球面坐标，保证规则的点分布，从而能稳健地重建网格连接性。这种规范球体可以无缝展开为2D映射。
2. 提出球形几何扩散：基于2D映射构建条件扩散框架，联合建模几何和纹理，其中几何明确地条件化纹理合成过程。

Result: 该方法在文本到3D生成、人脸重建和基于文本的3D编辑等多种任务中表现出色。大量实验表明，该方法在几何质量、文本保真度和推理效率方面显著优于现有方法。

Conclusion: 通过将复杂的3D几何约束到简单的拓扑球体上，并利用2D生成模型的强大能力，实现了高质量、可控的3D人脸生成。球形几何表示和扩散框架为解决文本到3D人脸生成的几何挑战提供了有效解决方案。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [185] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一个完全模型驱动的4D毫米波雷达感知框架，用于恶劣工业/地下环境中实时人体检测，在粉尘/烟雾等视觉退化条件下保持稳定性能


<details>
  <summary>Details</summary>
Motivation: 工业/地下环境中粉尘、烟雾、狭窄几何结构和金属结构严重制约光学/LiDAR感知，需要能在恶劣条件下可靠检测人类的雷达感知系统

Method: 完全模型驱动的4D雷达感知框架，包含领域感知多阈值滤波、自运动补偿时间累积、KD树欧几里得聚类与多普勒感知细化、基于规则的3D分类器

Result: 在粉尘填充的封闭拖车和真实地下采矿隧道中评估，雷达检测器在相机/LiDAR因严重视觉退化失效时仍能保持稳定的行人识别

Conclusion: 所提出的模型驱动方法为恶劣工业/地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知解决方案

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [186] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 本文对三种最先进的半监督目标检测方法（MixPL、Semi-DETR和Consistent-Teacher）在标注数据稀缺情况下的性能进行了全面比较，分析了不同标注数量下的性能变化，并在标准数据集和自定义数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺场景下，如何利用大量未标注图像和有限标注图像提升检测性能是重要研究课题。半监督目标检测方法旨在解决这一问题，但不同方法在标注数据量变化时的性能表现尚需系统比较。

Method: 使用MS-COCO和Pascal VOC两个标准目标检测数据集，以及自定义的Beetle数据集，对三种最先进的SSOD方法（MixPL、Semi-DETR和Consistent-Teacher）进行系统性实验比较，分析不同标注图像数量下的性能变化。

Result: 研究发现不同方法在准确性、模型大小和延迟之间存在权衡关系，为低数据场景下的方法选择提供了见解。在标准数据集和自定义数据集上的评估揭示了这些方法在专业化数据集上的表现特点。

Conclusion: 该研究为数据稀缺场景下的半监督目标检测方法选择提供了实用指导，揭示了不同方法在标注数据量变化时的性能特征，有助于研究人员和从业者根据具体需求（准确性、模型大小、延迟）选择最合适的方法。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [187] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT：一种用于CT影像分类的器官感知模型，在胸部和腹部CT分类任务中达到最先进的监督性能，超越了现有视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 医疗影像（如CT）的高通量需要有效的分诊和分类系统，以改善患者护理并减轻放射科医生负担。现有视觉语言模型在处理3D解剖结构、协议变化和噪声报告监督方面存在困难。

Method: 提出ORACLE-CT模型，包含器官掩码注意力（用于空间证据）和器官标量融合（融合体积和HU值特征）。在CT-RATE和RADCHEST-CT数据集上进行评估，并与监督基线和VLM基线对比。

Result: 在胸部CT任务中达到AUROC 0.86（CT-RATE）；在腹部CT任务中（MERLIN数据集，30个发现）达到AUROC 0.85，超越了所有报告的线性探测VLM和监督基线。

Conclusion: ORACLE-CT在胸部和腹部CT分类任务中实现了最先进的监督性能，为医学影像分析提供了有效的统一解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [188] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出基于Transformer的3D雷达目标检测架构，使用Transformer解码器作为预测头，直接从雷达特征回归3D边界框和类别分数，无需密集候选框生成和启发式后处理。


<details>
  <summary>Details</summary>
Motivation: 传统雷达目标检测方法依赖密集候选框生成和复杂的非极大值抑制(NMS)后处理，计算成本高且需要大量调参。需要一种端到端的检测框架来建模雷达数据的空间-时间相关性，简化检测流程。

Method: 1) 使用Transformer解码器作为预测头直接回归3D边界框和类别分数；2) 提出金字塔令牌融合(PTF)模块，将多尺度雷达特征金字塔转换为统一的尺度感知令牌序列；3) 将检测建模为集合预测问题，使用可学习对象查询和位置编码；4) 建模长程空间-时间相关性和跨特征交互。

Result: 在RADDet数据集上评估，相比最先进的纯雷达基线方法取得了显著改进。

Conclusion: 提出的Transformer-based架构成功实现了端到端的3D雷达目标检测，消除了密集候选框生成和启发式后处理需求，通过建模空间-时间相关性提升了检测性能。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [189] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: 提出DIP-ℓ₀框架，结合深度图像先验和ℓ₀梯度正则化，无需训练数据即可实现高质量图像平滑


<details>
  <summary>Details</summary>
Motivation: 现有图像平滑方法依赖局部统计或优化问题，深度学习方法需要精心构建的训练数据集，但构建合适的图像平滑训练数据集具有挑战性

Method: 提出DIP-ℓ₀框架，将深度图像先验与ℓ₀梯度正则化结合，使用交替方向乘子法(ADMM)优化非凸非光滑的ℓ₀"范数"损失函数

Result: DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法

Conclusion: 提出的无训练数据DIP-ℓ₀框架能够实现高质量的图像平滑，解决了训练数据构建的挑战

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [190] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 论文提出QVLM模型解决视觉语言模型在定量空间推理上的缺陷，通过代码生成架构保持像素级精度，在SQuID基准上达到42.0%准确率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理上表现不佳，因为其架构破坏了计数和测量所需的像素级信息。图像编码器通过补丁嵌入压缩图像，减少了空间索引能力，丢失了精确的像素级跟踪。

Method: 提出QVLM（定量视觉语言模型），采用代码生成架构，将语言理解与视觉分析解耦。不将图像编码为嵌入，而是生成可执行代码，先调用分割模型获取像素级掩码，然后直接在掩码上操作，保持整个推理过程中的空间索引。

Result: QVLM使用GPT-5作为编码器，在SQuID基准上达到42.0%的准确率，而传统VLM仅达到28.1%。同时创建了SQuID数据集，包含2000个卫星图像问答对，涵盖三个难度层级。

Conclusion: 对于定量空间推理任务，架构解耦能够实现更好的准确性。保持像素级精度对于计数和测量等定量任务至关重要，代码生成方法比传统嵌入方法更有效。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [191] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出基于人类可识别原始概念的黑盒模型解释方法，将局部和全局解释表示为单调析取范式逻辑公式，保证模型对特定类别给出高分


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然图像分类效果出色，但缺乏可解释性，需要为黑盒模型提供人类可理解的解释方法

Method: 使用人类可识别的原始概念，将局部解释（单张图像）和全局解释（图像集）表示为单调析取范式逻辑公式；提出多类别分类的单调解释列表算法

Result: 在具有挑战性的视觉数据集上，这些简单且可解释的方法对黑盒模型保持了高保真度和覆盖率

Conclusion: 基于原始概念的逻辑公式解释方法能够有效解释黑盒模型，同时保持高保真度和可解释性

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [192] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 使用ResNet-18模型预测结肠胶囊内镜图像清洁质量，通过结构化剪枝实现79%稀疏度下88%准确率，并利用多种CAM方法进行可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内镜图像清洁质量评估对临床诊断至关重要，但现有方法效率较低且缺乏可解释性。本研究旨在开发高效、可解释的深度学习模型来预测清洁质量，同时通过剪枝技术优化模型效率。

Method: 使用500张由14位临床医生标注的CCE图像数据集，基于Leighton-Rex量表（差、一般、好、优秀）分类。采用ResNet-18模型进行训练，使用分层K折交叉验证确保鲁棒性。应用结构化剪枝技术迭代优化模型，使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM进行可解释性分析，并用ROAD方法进行一致性评估。最后采用自适应温度缩放变体对剪枝模型进行外部数据集校准。

Result: 剪枝模型在79%稀疏度下达到88%的交叉验证准确率，相比未剪枝模型的84%准确率有所提升。模型在保持高准确性的同时显著提高了效率。可解释性分析揭示了模型决策依据，但ROAD方法在特定任务中存在评估挑战。

Conclusion: 结构化剪枝能有效提高CCE图像清洁质量预测模型的效率而不损害性能。可解释性分析对临床应用至关重要，但需要针对特定任务优化评估方法。自适应温度缩放有助于模型在外部数据集上的校准应用。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [193] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 扩散模型作为通用特征编码器的潜力被低估，本文展示冻结扩散骨干网络通过探测中间去噪特征，在细粒度识别任务上表现出色，特别是在真实世界浮游生物监测场景中。


<details>
  <summary>Details</summary>
Motivation: 扩散模型已成为图像生成的最先进方法，但其作为通用特征编码器的潜力尚未充分探索。尽管扩散模型在无标签的去噪和生成任务中训练，但它们可以被解释为捕获低层和高层结构的自监督学习器。

Method: 使用冻结的扩散骨干网络，探测跨层和跨时间步的中间去噪特征，为每对特征训练线性分类器。在真实世界浮游生物监测场景中，与有监督和自监督基线方法进行受控且可比较的训练设置评估。

Result: 冻结扩散特征与有监督基线方法竞争激烈，在平衡和自然长尾设置中都优于其他自监督方法。在时间和地理偏移的浮游生物数据集上进行分布外评估显示，冻结扩散特征在显著分布偏移下仍保持强大的准确率和Macro F1分数。

Conclusion: 扩散模型不仅是强大的生成模型，还可以作为有效的通用特征编码器，在细粒度识别任务中表现出色，特别是在现实世界应用中面对分布偏移时具有鲁棒性。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [194] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: 提出SGW-GAN框架，首次将切片Gromov Wasserstein距离引入视网膜图像增强，在提升图像质量的同时保持临床相关的类内几何结构，改善下游疾病分级任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN和扩散模型的视网膜图像增强方法虽然能提升感知质量，但会扭曲类内几何结构，导致临床相关样本分散、疾病类别边界模糊，损害下游分级和病变检测任务。需要一种既能增强图像又能保持临床相关结构的方法。

Method: 提出SGW-GAN框架，首次将切片Gromov Wasserstein距离整合到视网膜图像增强中。SGW通过随机投影近似GW距离，在保持关系保真度的同时大幅降低计算成本。该方法专注于在增强过程中保持样本间的内部成对距离关系。

Result: 在公开数据集上的实验表明，SGW-GAN能产生视觉上令人信服的增强效果，在糖尿病视网膜病变分级任务上表现优异，并在疾病标签上报告了最低的GW差异，证明了其在无配对医学图像增强中的效率和临床保真度。

Conclusion: SGW-GAN通过整合切片Gromov Wasserstein距离，成功解决了传统增强方法扭曲临床相关类内结构的问题，在保持计算效率的同时实现了更好的临床保真度，为无配对医学图像增强提供了有效解决方案。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [195] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 该论文全面分析了基于视觉语言模型（VLM）的异常检测方法，系统研究了WinCLIP、AprilLab等架构范式，评估了特征提取、文本-视觉对齐、提示工程等关键技术维度，为工业质量控制中的VLM方法选择提供实践指导。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（特别是CLIP）通过零样本和少样本缺陷识别能力革新了异常检测领域，无需大量标注数据即可实现异常分类和分割。然而，现有VLM方法缺乏系统性分析和比较，需要为实际应用提供方法选择和性能评估的指导框架。

Method: 系统分析三种主要VLM架构范式：1) 基于滑动窗口的密集特征提取（WinCLIP）；2) 多阶段特征对齐与可学习投影（AprilLab框架）；3) 组合提示集成策略。在MVTec AD和VisA等基准数据集上进行实验，评估特征提取机制、文本-视觉对齐策略、提示工程技术、零样本/少样本权衡、计算效率和跨域泛化能力等关键维度。

Result: 通过系统实验比较了不同VLM方法在异常分类准确率、分割精度和推理效率方面的性能。研究揭示了VLM在异常检测中成功的关键因素，包括有效的特征对齐机制和提示工程策略，同时识别了当前方法的局限性，如计算效率与精度的权衡。

Conclusion: 该研究为VLM在异常检测中的应用提供了基础性理解，综合了方法选择的实践见解，并指出了当前限制。工作旨在促进VLM方法在工业质量控制中的明智采用，并为未来研究方向提供指导，特别是在提升计算效率和跨域泛化能力方面。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [196] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 提出一种将事件相机数据映射到对数强度和强度导数估计的物理基础处理流程，嵌入动态线性系统模型，实现直接从事件数据进行逆滤波和维纳解卷积


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器输出稀疏异步的事件流，这种非线性表示难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成，需要建立事件传感与基于模型的计算成像之间的桥梁

Method: 开发物理基础处理流程，将事件流映射到像素级对数强度和强度导数估计，嵌入具有时变点扩散函数的动态线性系统模型，使用已知或参数化的动态传递函数进行频域维纳解卷积

Result: 在模拟中验证了调制离焦下单点和重叠点源的处理效果，并在真实事件数据（可调焦望远镜拍摄星场）上展示了源定位和可分离性

Conclusion: 该框架为动态光学系统中的事件传感与基于模型的计算成像提供了实用桥梁

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [197] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2：针对遥感多模态学习中模态缺失问题的新方法，通过DLKD（解缠学习与知识蒸馏协同）和CFLM（类特定特征学习模块）实现主动的缺失特征补偿。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临模态缺失的严重挑战，且遥感数据具有高度异构性和尺度变化大的特点。传统解缠学习依赖模态间特征重叠，而知识蒸馏则成为不适定的模仿任务，都无法有效解决遥感数据的独特特性。

Method: 提出DIS2方法，包含三个核心组件：1) DLKD - 重新构建解缠学习与知识蒸馏的协同，显式捕获补偿特征；2) CFLM - 类特定特征学习模块，根据信号可用性自适应学习判别证据；3) 分层混合融合结构，利用多分辨率特征增强预测。

Result: 大量实验验证表明，该方法在多个基准测试中显著优于现有最先进方法。

Conclusion: DIS2通过从模态共享特征依赖和无目标模仿转向主动引导的缺失特征补偿，为遥感多模态学习中的模态缺失问题提供了有效解决方案，特别是在处理异构数据和尺度变化方面表现出色。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [198] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个多层虚拟试穿方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合，解决多层服装试穿中的遮挡关系和变形问题。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法主要关注单层或多件服装试穿，忽略了多层服装试穿（ML-VTON），即如何在人体上穿着多层服装并保持真实的变形和层次关系，生成视觉上合理的结果。

Method: 提出GO-MLVTON方法，包含两个核心模块：1) 服装遮挡学习模块，学习内外服装之间的遮挡关系以减少冗余内层服装特征的干扰；2) 基于StableDiffusion的服装变形与拟合模块，将服装变形并贴合到人体上。

Result: 方法在实验中表现出最先进的性能，同时提出了MLG数据集用于该任务，并设计了新的评估指标LACD（分层外观一致性差异）。

Conclusion: GO-MLVTON是首个解决多层虚拟试穿问题的方法，通过创新的遮挡学习和变形拟合技术，能够生成高质量的多层试穿结果，为虚拟试穿领域开辟了新方向。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [199] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: DiffFace-Edit数据集包含200多万张AI生成的人脸图像，专注于细粒度区域编辑（如眼睛、鼻子等8个区域），并首次研究了检测器规避样本对检测模型的影响。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型能产生难以察觉的细粒度人脸篡改，带来隐私风险，但现有AI生成人脸数据集缺乏细粒度区域篡改样本，且无人研究真实与篡改样本间的拼接攻击对检测器的影响。

Method: 构建DiffFace-Edit数据集，包含200多万张AI生成的假图像，涵盖8个面部区域的编辑（单区域和多区域组合），并分析检测器规避样本对检测模型的影响，采用跨域评估结合IMDL方法。

Result: 创建了大规模细粒度区域编辑数据集，首次系统分析了检测器规避样本对检测模型的挑战，为相关研究提供了重要数据基础。

Conclusion: DiffFace-Edit数据集填补了细粒度区域篡改数据集的空白，揭示了检测器规避样本对检测模型的真实影响，为提升AI生成人脸检测能力提供了重要资源。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [200] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP提出了一种从噪声全局匹配转向空间约束的块级对应的细粒度对应姿态估计框架，通过块间关联矩阵作为结构先验来缩小匹配范围，在开放词汇6D物体姿态估计中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中，将锚点特征与整个查询图像空间匹配会引入过多歧义，目标特征容易与背景干扰物混淆，导致姿态估计性能下降。

Method: 1) 物体中心解耦预处理：隔离语义目标与环境噪声；2) 跨视角全局感知模块：融合双视角特征，通过显式上下文推理建立结构共识；3) 块关联预测器：生成精确的块级关联图，作为空间滤波器实现细粒度、抗噪声的匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP相比最先进方法分别提高了8.0%和6.1%的平均召回率，证明了其在复杂、无约束开放世界环境中为机器人提供鲁棒和泛化感知的能力。

Conclusion: FiCoP通过从噪声全局匹配转向空间约束的块级对应，有效解决了开放词汇6D姿态估计中的背景干扰问题，为机器人在开放世界环境中的操作提供了更可靠的感知基础。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [201] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse框架通过量化图表复杂度的RPE指标和答案优先的QA合成方法，生成高质量图表推理数据，训练出的8B模型性能超越其教师模型


<details>
  <summary>Details</summary>
Motivation: 现有开源视觉语言模型在图表推理方面面临高质量训练数据匮乏的问题：合成图表过于简单重复，而相关QA对存在幻觉且缺乏深度推理能力

Method: 1) 提出Rollout Posterior Entropy(RPE)量化图表复杂度，指导复杂度感知图表编码器通过可执行程序合成多样化高复杂度图表；2) 采用答案优先的逆向QA合成方法，从源代码提取确定性答案，基于此生成问题并进行一致性验证；3) 基于模型失败率筛选样本并提炼高质量思维链推理

Result: 构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，使用Qwen3-VL-30B-A3B-Thinking作为教师模型。ChartVerse-8B模型在实验中取得了最先进的性能，超越了其教师模型，并与更强的Qwen3-VL-32B-Thinking模型相媲美

Conclusion: ChartVerse框架成功解决了图表推理训练数据质量不足的问题，通过系统化的数据合成方法显著提升了视觉语言模型的图表推理能力

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [202] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE是一个模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型能自适应地优先处理图像表示或依赖语言模型的推理能力，从而提升视觉中心任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉中心任务（如图像分类）上表现不佳，甚至不如其基础的CLIP视觉编码器。需要解决模型在视觉任务上的局限性，同时保持其作为通用助手的能力。

Method: 提出CARPE框架：1）引入视觉集成层，使模型能捕捉图像表示的不同方面；2）采用上下文感知集成策略，自适应地决定何时优先处理图像表示或依赖语言模型的推理能力；3）框架设计为模型无关，可与大多数开源LVLM集成。

Result: CARPE在图像分类基准测试中显著提升性能，同时在各种视觉语言基准测试中也取得改进。框架能有效适应不同架构，展示了良好的泛化能力。

Conclusion: CARPE通过自适应地加权视觉和文本模态，解决了LVLM在视觉中心任务上的局限性，同时保持了其在通用助手任务上的能力，为提升LVLM的视觉理解能力提供了有效方案。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [203] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: EGM方法通过扩展小型视觉语言模型的测试时计算（生成更多token），在保持部署效率的同时，将视觉定位能力提升到与大型模型相当甚至更好的水平。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的视觉定位模型通常模型尺寸很大，部署成本高且推理速度慢。研究发现小型和大型VLM的主要差异在于语言模型部分，小型VLM在定位能力上的不足主要是语言理解能力差异而非视觉信息处理问题。

Method: 提出EGM方法，通过扩展小型模型的测试时计算（增加生成token数量）来弥补语言理解能力差距。这种方法部署友好，因为每个token的生成成本远低于直接运行大型模型。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新型amodal定位设置中，该方法也能持续显著提升小型模型的定位能力。

Conclusion: EGM方法能够有效提升小型视觉语言模型的视觉定位能力，使其达到或超越大型模型的性能，同时保持更高的推理效率，为视觉定位任务提供了更高效的解决方案。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [204] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 该论文提出了一种在跨模态人脸-语音关联任务中引入最大类别分离作为归纳偏置的方法，通过强制不同说话者的多模态表示最大化分离来增强嵌入的判别能力，在两个任务上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人脸-语音关联研究通常使用损失函数使同一人的嵌入接近、不同人的嵌入分离。近期分类研究表明，将最大类别分离作为归纳偏置可以增强嵌入的判别能力，但这种方法从未在跨模态人脸-语音关联领域应用。本文旨在填补这一空白。

Method: 开发了一种人脸-语音关联方法，将不同说话者多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失，通过强制不同说话者的表示最大化分离来增强嵌入的判别能力。

Result: 定量实验表明该方法在人脸-语音关联的两个任务制定上都达到了最先进的性能。消融研究显示，将归纳偏置与类间正交性损失结合使用时效果最佳。

Conclusion: 这是首次在跨模态学习中应用并证明最大类别分离作为归纳偏置的有效性，为建立新的范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [205] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一个用于多视角条件体素细化的体素-图像对齐Transformer模型，通过图像索引、校正流目标和混合流Transformer实现噪声体素修复，在合成和真实场景中都达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有体素重建方法在处理不完整、噪声体素时存在局限性，需要利用多视角图像作为指导来修复体素，特别是在从视觉基础模型获取的体素形状上处理合成损坏和真实伪影。

Method: 提出VIAFormer模型，包含三个核心组件：1）图像索引为2D图像token提供显式3D空间定位；2）校正流目标学习直接的体素细化轨迹；3）混合流Transformer实现鲁棒的跨模态融合。

Result: 实验表明VIAFormer在纠正严重合成损坏和真实伪影方面建立了新的SOTA，特别是在从强大视觉基础模型获得的体素形状上。同时证明了在真实世界3D创建流程中的实用性和可靠性。

Conclusion: VIAFormer为体素基方法在大模型、大数据浪潮中蓬勃发展铺平了道路，可作为实际3D创建流程中可靠的多模态桥梁，实现体素与图像的高效对齐和细化。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [206] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

TL;DR: 提出融合CNN+LSTM和CNN+DeiT Transformer的架构，同时进行蔬菜分类、食物腐败检测和保质期预测，在自建数据集上表现优于多个深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 食物浪费是农业供应链的关键挑战，准确有效的腐败检测和预测有助于减少浪费，延长供应链管理寿命。

Method: 提出融合架构：CNN+CNN-LSTM和CNN+DeiT Transformer，同时处理三个任务：蔬菜分类、食物腐败检测、保质期预测。通过从新鲜到完全腐败状态采集图像构建数据集。

Result: 融合架构优于CNN、VGG16、ResNet50、胶囊网络和DeiT Transformer。CNN+DeiT Transformer在蔬菜分类和腐败检测的F1分数分别为0.98和0.61，在腐败预测的MSE和SMAPE分别为3.58和41.66%。

Conclusion: 融合架构在减少食物浪费方面有效，通过噪声图像验证了可靠性，并集成LIME可视化模型决策。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [207] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE是一种针对3D生物医学图像分割的主动学习方法，通过类别分层查询和噪声调度策略，在24个实验设置中显著优于随机基线，并能泛化到未见数据集。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分割的专家标注成本高昂，现有主动学习方法无法稳定超越适应3D数据的改进随机采样基线，需要一种可靠解决方案。

Method: 提出Class-stratified Scheduled Power Predictive Entropy (ClaSP PE)方法，结合类别分层查询确保对少数类结构的覆盖，以及log-scale power noising with decaying schedule策略，在早期AL阶段强制查询多样性，后期鼓励利用。

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一能普遍优于改进随机基线的方法，在分割质量和标注效率方面都有统计显著提升，且能泛化到4个未见数据集而无需手动调整。

Conclusion: ClaSP PE证明了主动学习方法可以在3D分割任务中稳定超越随机基线，在接近实际应用场景中同时提升性能和标注效率，开源实现和部署指南使其具有实际应用价值。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [208] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: DyDiLA是一种新型线性注意力机制，通过动态投影、动态测量核和令牌差分算子解决线性扩散变换器中注意力权重过度平滑的问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在图像生成中表现出色，但自注意力的二次计算成本成为主要扩展瓶颈。线性注意力机制虽然降低了计算成本，但导致线性扩散变换器(LiTs)生成性能下降，产生过度平滑的注意力权重，限制了表达能力。

Method: 提出动态差分线性注意力(DyDiLA)，包含三个关键设计：1) 动态投影模块，通过学习动态分配的知识促进令牌表示的解耦；2) 动态测量核，通过为令牌处理动态分配核函数来提供更好的相似性度量，捕捉细粒度语义差异；3) 令牌差分算子，通过计算令牌与其动态测量核产生的信息冗余之间的差异，实现更稳健的查询-键检索。基于DyDiLA构建了改进的线性扩散变换器DyDi-LiT。

Result: 大量实验表明，DyDi-LiT在多个指标上持续优于当前最先进的模型，显示出强大的实际潜力。

Conclusion: DyDiLA通过创新的动态设计有效解决了线性注意力机制中的过度平滑问题，显著提升了线性扩散变换器的生成性能，为高效高质量的图像生成提供了新的解决方案。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [209] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 这篇综述论文将视觉谜题作为评估大型视觉语言模型推理能力的诊断工具，系统分析了现有基准测试，识别了模型的局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题长期以来作为人类认知的紧凑探针，能够以最小的先验知识需求来评估抽象、规则发现和系统推理能力。作者希望利用视觉谜题作为诊断工具，评估大型视觉语言模型的推理能力，替代开放式多模态基准测试。

Method: 通过统一的抽象框架来理解视觉谜题，将现有基准测试按目标推理机制（归纳、类比、算法、演绎和几何/空间推理）进行组织，将谜题设计与所需的认知操作联系起来。综合这些类别的实证证据，分析模型表现。

Result: 识别出当前模型的一致局限性：脆弱的泛化能力、感知与推理的紧密纠缠、流畅解释与忠实执行之间的持续差距。视觉谜题揭示了LVLM推理能力的系统性缺陷。

Conclusion: 将视觉谜题视为诊断工具而非任务格式，能够更准确地评估LVLM的推理状态。论文为未来基准测试和推理感知的多模态系统指明了关键方向，强调需要开发更鲁棒的推理能力评估方法。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [210] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

TL;DR: ParkingTwin是一个免训练、轻量级的在线流式3D重建系统，用于停车场数字孪生，解决了稀疏视角、动态遮挡和极端光照的挑战，在低端GPU上实现30+FPS实时重建。


<details>
  <summary>Details</summary>
Motivation: 停车场数字孪生对自动驾驶代客泊车（AVP）的路径规划、碰撞检测和感知验证至关重要，但现有方法面临三难困境：稀疏前向视角导致弱视差和几何不适定；动态遮挡和极端光照阻碍稳定纹理融合；神经渲染通常需要昂贵的离线优化，违反边缘端流式约束。

Method: 1) OSM先验驱动的几何构建：利用OpenStreetMap语义拓扑直接生成度量一致的TSDF，替代盲目的几何搜索；2) 几何感知的动态过滤：采用四模态约束场（法线/高度/深度一致性）实时剔除移动车辆和瞬态遮挡；3) CIELAB空间的光照鲁棒融合：通过自适应L通道加权和深度梯度抑制解耦亮度和色度，减少光照突变下的接缝。

Result: 在GTX 1660上实现30+FPS实时运行；在68,000 m²真实数据集上达到SSIM 0.87（提升16.0%）；相比需要RTX 4090D的3D高斯泼溅（3DGS），实现约15倍端到端加速，GPU内存减少83.3%；输出与Unity/Unreal兼容的显式三角网格。

Conclusion: ParkingTwin通过免训练、轻量级设计解决了停车场数字孪生重建的核心挑战，在低端硬件上实现高质量实时重建，为AVP系统提供了实用的边缘端解决方案。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [211] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: ACG是一种单次前向计算的注意力空间对比引导方法，通过构建视觉-语言和纯语言注意力路径来减少大视觉语言模型中的幻觉，在保持生成质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型中的幻觉问题主要源于语言先验对视觉证据的过度依赖，导致物体误识别和视觉不一致的描述。需要一种既能减少语言先验依赖又能保持计算效率的方法。

Method: 提出注意力空间对比引导（ACG），在自注意力层内同时构建视觉-语言和纯语言注意力路径，通过正交化校正消除纯语言路径的近似偏差，选择性增强视觉贡献。

Result: 在CHAIR和POPE基准测试中达到最先进的忠实度和字幕质量，同时显著降低计算成本，相比需要多次前向传播的对比解码方法，延迟减少高达2倍。

Conclusion: ACG为幻觉缓解提供了一种原则性且高效的替代方案，通过单次前向计算实现对比引导，在减少语言先验依赖的同时保持了计算效率。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [212] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

TL;DR: MVGD-Net：利用运动不一致性检测视频中玻璃表面的新网络，通过跨尺度多模态融合和历史引导注意力等模块，在自建大规模数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在日常和专业环境中普遍存在，对基于视觉的系统（如机器人和无人机导航）构成潜在威胁。现有视频玻璃表面检测方法需要改进，观察到玻璃反射/透射层中的物体看起来更远，在视频运动场景中移动更慢，这种运动不一致性可有效揭示玻璃表面存在。

Method: 提出MVGD-Net网络，包含三个核心模块：1）跨尺度多模态融合模块（CMFM）整合空间特征和光流图；2）历史引导注意力模块（HGAM）和时序交叉注意力模块（TCAM）增强时序特征；3）时序-空间解码器（TSD）融合时空特征生成玻璃区域掩码。同时构建包含312个场景、19,268帧的大规模数据集。

Result: 大量实验表明，MVGD-Net在视频玻璃表面检测任务上优于相关最先进方法。

Conclusion: 通过利用玻璃表面反射/透射物体的运动不一致性线索，提出的MVGD-Net能够有效检测视频中的玻璃表面，为机器人导航等应用提供了重要解决方案。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [213] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: HAVEN框架通过整合视听实体凝聚和分层视频索引，结合智能搜索机制，实现了对长视频的连贯全面理解，在LVBench上达到84.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于分块策略和检索增强生成的方法在处理长视频时存在信息碎片化和全局连贯性丢失的问题，需要新的解决方案来保持语义一致性和全局连贯性。

Method: 1. 整合视觉和听觉流的实体级表示以保持语义一致性；2. 将内容组织成全局摘要、场景、片段和实体的结构化层次；3. 采用智能搜索机制在这些层次间进行动态检索和推理。

Result: 在LVBench上达到84.1%的整体准确率，在具有挑战性的推理类别中达到80.1%，表现出良好的时间连贯性、实体一致性和检索效率。

Conclusion: 结构化、多模态推理方法能有效实现长视频的全面和上下文一致的理解，HAVEN框架为长视频理解建立了新的技术标杆。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [214] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

TL;DR: 提出Facial Spatiotemporal Graph (STGraph)表示法和MeshPhys模型，通过3D面部网格序列实现表面对齐的时空处理，提升远程光电容积描记(rPPG)性能。


<details>
  <summary>Details</summary>
Motivation: 现有rPPG方法未能将感受野与3D面部表面（rPPG信号的空间支撑）明确对齐，导致性能受限。

Method: 提出Facial STGraph表示法，使用3D面部网格序列编码面部颜色和结构；设计轻量级时空图卷积网络MeshPhys在STGraph上处理，实现表面对齐的时空处理。

Result: 在四个基准数据集上，MeshPhys在内部和跨数据集设置中达到最先进或竞争性性能；消融研究表明表面约束的感受野作为强结构先验，表面对齐的3D感知节点特征对鲁棒编码至关重要。

Conclusion: STGraph和MeshPhys构成了面部rPPG的新建模范式，实现了鲁棒、可解释和可泛化的生理信号估计。

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [215] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 提出HiT机制，用于卫星上的洪水检测，通过历史注入减少99%数据存储，在Jetson Orin Nano上达到43 FPS，实现实时灾害监测


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要处理多时相数据，但受限于小型卫星的内存和计算能力。洪水检测作为灾害管理的关键应用，需要能在卫星上实时运行的解决方案，减少对地面处理设施的依赖。

Method: 提出HiT（历史注入）机制，用于Transformer模型，维护先前观测的历史上下文，同时将数据存储减少超过99%。基于Prithvi-tiny基础模型构建HiT-Prithvi模型，在STTORM-CD洪水数据集上进行测试。

Result: HiT机制在保持检测精度的同时，显著减少数据存储需求。HiT-Prithvi模型在Jetson Orin Nano上达到43 FPS，满足实时处理要求。在STTORM-CD数据集上，检测精度与双时相基线相当。

Conclusion: HiT机制为卫星连续监测自然灾害提供了实用框架，支持实时灾害评估，减少对地面处理基础设施的依赖。该工作推动了星载AI处理的发展，代码和模型已开源。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [216] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: PREGEN：一种高效的无微调视频检索框架，通过提取预训练视觉语言模型的隐藏状态，结合轻量编码器实现强大的组合视频检索性能


<details>
  <summary>Details</summary>
Motivation: 现有组合视频检索方法未能充分利用现代视觉语言模型，要么使用过时架构，要么需要计算昂贵的微调和缓慢的标题生成，限制了实际应用

Method: PREGEN采用冻结的预训练VLM与轻量编码器组合：将查询视频和修改文本输入VLM，提取每层最后一个token的隐藏状态，通过简单编码器训练这些池化表示，生成语义丰富且紧凑的检索嵌入

Result: 在标准CoVR基准测试中显著超越所有先前方法，Recall@1提升+27.23和+69.59，对不同VLM骨干网络具有鲁棒性，在复杂文本修改上表现出强大的零样本泛化能力

Conclusion: PREGEN提供了一种高效、强大的组合视频检索解决方案，无需VLM微调，充分利用预训练模型的语义能力，在性能和效率上都取得了显著进步

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [217] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器提取多粒度概念，提供可解释且空间定位的概念表示，在分类和分割任务上性能与不透明基础模型相当。


<details>
  <summary>Details</summary>
Motivation: 当前语言对齐的视觉基础模型虽然在下游任务表现良好，但其表示不透明、难以解释决策过程。现有方法分解表示为人可解释概念，但空间定位能力差且仅限于图像分类任务。

Method: 使用分层稀疏自编码器和具有强语义表示的基础模型自动提取多粒度概念，通过分析概念间的局部共现依赖关系定义概念关系，利用这些关系改进概念命名并获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上性能与不透明基础模型相当，同时提供细粒度、高质量的概念解释。

Conclusion: Insight成功构建了一个语言对齐的概念基础模型，能够提供空间定位、人类可解释的概念表示，在保持性能的同时显著提升了模型的可解释性。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [218] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出CSDA算法，通过多维非线性判别分析优化颜色表示，提升图像分割精度


<details>
  <summary>Details</summary>
Motivation: 现有分割算法常忽视颜色表示这一关键预处理步骤，而次优的颜色表示会阻碍准确分割

Method: 提出Colorspace Discriminant Analysis (CSDA)算法，将线性判别分析扩展到深度学习框架，通过广义判别损失最大化类间可分性并最小化类内变异性

Result: 在风力涡轮机叶片数据上的实验显示显著精度提升，证明了定制化预处理在领域特定分割中的重要性

Conclusion: CSDA算法通过优化颜色表示有效提升分割性能，强调了预处理在图像分割中的关键作用

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [219] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯表示的前馈式头部化身生成方法，仅需少量输入图像即可生成高质量、可实时动画的头部化身。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯头部化身建模方法通常依赖多视角捕捉设备或单目视频，需要针对每个身份进行优化，限制了其可扩展性和对未见主体的易用性。

Method: 1) 从输入图像直接学习逐像素高斯表示；2) 使用基于Transformer的编码器融合DINOv3和Stable Diffusion VAE的图像特征；3) 扩展显式高斯表示，引入轻量级MLP动态网络预测3D高斯形变；4) 使用预训练大重建模型的点云图进行几何监督。

Result: 在渲染质量和推理效率方面显著优于现有方法，同时支持实时动态化身动画。

Conclusion: 提出了一种高效的前馈式头部化身生成方法，仅需少量图像即可生成高质量、可实时动画的3D高斯头部化身，解决了现有方法的可扩展性和易用性问题。

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [220] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个专门用于灾害响应的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，用于评估视觉语言模型在灾害场景下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害期间提供低延迟的态势信息，但现有通用视觉问答模型在灾害响应这种复杂、安全关键的推理任务中的适用性尚不明确。需要专门的数据集来评估和推动灾害响应领域的视觉语言模型发展。

Method: 创建了DisasterVQA数据集，包含洪水、野火、地震等灾害的真实图像，基于FEMA ESF和OCHA MIRA等人道主义框架设计问题，涵盖二元选择、多项选择和开放式问题，涉及态势感知和操作决策任务。

Result: 评估了7个最先进的视觉语言模型，发现模型在二元问题上表现良好，但在细粒度定量推理、物体计数和上下文敏感解释方面存在困难，特别是在代表性不足的灾害场景中表现更差。

Conclusion: DisasterVQA为灾害响应提供了具有挑战性和实用性的基准，能够指导开发更鲁棒、更具操作意义的视觉语言模型，以支持灾害响应决策。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [221] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出概率深度判别分析（PDDA），通过深度网络直接优化Fisher准则，结合概率损失函数，显著提升非线性可分数据的分类性能，并首次应用于图像分割任务


<details>
  <summary>Details</summary>
Motivation: 线性判别分析在处理非线性可分数据时效果有限，需要一种能够利用深度网络优势的判别分析方法来提升类间可分性

Method: 提出深度判别分析（DDA），直接优化Fisher准则；引入有符号类间方差、sigmoid函数约束输出、将乘法关系转换为加法关系以确保训练稳定性；开发两种稳定的DDA损失函数，并加入概率损失形成概率深度判别分析（PDDA）

Result: PDDA有效减少了输出分布中的类间重叠，产生高度自信的预测并降低类内方差；在风力叶片分割任务中表现出显著的性能提升和一致性改进

Conclusion: PDDA是首个应用于图像分割的DDA方法，在非线性可分数据上表现出优越性能，对风力能源维护等关键应用具有重要意义

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [222] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 提出OmniOVCD框架，利用SAM 3的解耦输出头，通过SFID策略融合语义、实例和存在性输出构建地物掩码，再分解为实例掩码进行变化检测，在四个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法大多使用CLIP识别类别，并需要额外模型如DINO提取特征，但不同模型的组合常导致特征匹配问题和系统不稳定。SAM 3的推出为OVCD任务提供了新可能。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头，设计SFID策略：先融合SAM 3的语义、实例和存在性输出构建地物掩码，再分解为单个实例掩码进行变化比较，保持类别识别高精度和跨图像实例级一致性。

Result: 在四个公开基准测试（LEVIR-CD、WHU-CD、S2Looking、SECOND）上达到SOTA性能，IoU分数分别为67.2、66.5、24.5和27.1（类别平均），超越所有先前方法。

Conclusion: OmniOVCD通过利用SAM 3的集成能力，解决了现有OVCD方法中多模型组合的问题，实现了准确的变化检测，为开放词汇变化检测提供了有效的独立框架。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [223] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能同时处理图像中多个类别的目标计数，基于SAM2和FINCH算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有类无关目标计数方法通常需要额外信息（如视觉示例或文本提示），且假设每张图像只有一个目标类别，训练成本高。需要一种更通用、无需训练的方法来解决多类别计数问题。

Method: 结合Segment Anything Model 2（SAM2）基础模型和自定义阈值版本的FINCH聚类算法，无需训练即可实现多类别目标计数。

Result: 在FSC-147和CARPK基准数据集上取得有竞争力的性能，提出了合成多类别数据集和更合适的F1评分评估指标。

Conclusion: OCCAM是首个无需训练、无需额外信息的类无关多目标计数方法，为实际应用提供了更灵活高效的解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [224] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

TL;DR: MTV是一个多任务视觉预训练框架，通过联合优化视觉语言对比、自监督和密集空间目标，结合了CLIP的语义对齐和MAE/DINO的局部结构优势，利用专家模型生成伪标签，实现了空间推理和语义理解的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表示学习存在分裂：视觉语言模型（如CLIP）擅长全局语义对齐但缺乏空间精度，而自监督方法（如MAE、DINO）能捕捉局部结构但缺乏高层语义上下文。这两种范式本质上是互补的，可以整合到一个统一框架中。

Method: 提出MTV多任务视觉预训练框架，联合优化共享主干网络，包含三个目标：1) 视觉语言对比学习；2) 自监督学习；3) 密集空间监督。为避免人工标注，利用Depth Anything V2和OWLv2等专家模型生成大规模密集结构化伪标签。

Result: MTV实现了"两全其美"的性能，显著提升了细粒度空间推理能力，同时不损害全局语义理解。系统分析了各目标的边际增益、任务协同与干扰、以及数据和模型规模的扩展行为。

Conclusion: 多任务学习结合高质量伪监督是构建更通用视觉编码器的可扩展路径。MTV框架证明了整合不同视觉学习范式的有效性，为视觉表示学习提供了新的方向。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [225] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG框架通过选择性注视机制和双阶段训练策略，解决了大型多模态模型在处理知识密集型查询时的视觉冗余和噪声问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在处理涉及长尾实体或动态信息的知识密集型查询时存在局限性，因为其参数知识是静态的。现有的搜索增强方法存在视觉冗余和噪声问题，且缺乏深度迭代反思，限制了在复杂视觉查询上的有效性。

Method: 提出了Glance-or-Gaze框架，包含选择性注视机制（动态选择全局上下文或高价值区域），以及双阶段训练策略：通过监督微调进行反思性GoG行为对齐，以及通过复杂性自适应强化学习增强处理复杂查询的能力。

Result: 在六个基准测试中展示了最先进的性能。消融研究证实选择性注视机制和复杂性自适应强化学习对于有效视觉搜索都是必不可少的。

Conclusion: GoG框架通过从被动感知转向主动视觉规划，解决了现有方法的视觉冗余和噪声问题，为知识密集型视觉查询提供了有效的解决方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [226] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，揭示哪些样本和特征驱动组间差异


<details>
  <summary>Details</summary>
Motivation: 深度神经网络双样本测试虽然检测能力强，但黑盒特性限制了可解释性和在生物医学分析中的实际应用。现有解释方法大多依赖类别标签，不适用于无标签的统计测试场景。

Method: 提出可解释的深度统计测试框架，在深度双样本测试基础上增加样本级和特征级解释机制，识别对组间差异贡献最大的样本和特征。

Result: 方法能突出显示对检测到的组间差异贡献最大的图像区域和个体样本，提供空间和实例层面的洞察。在生物医学影像数据中，能识别有影响力的样本并突出与疾病相关变异相关的解剖学意义区域。

Conclusion: 该工作桥接了统计推断和可解释AI，实现了医学影像中可解释的无标签群体分析。

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [227] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 本文提出通过数据增强学习2D旋转等变性来改进单目3D人体姿态估计，相比显式设计的等变性方法更简单有效。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体姿态估计方法通常采用两步法：先检测2D关节点，再进行2D到3D的提升。但这些方法在处理旋转输入时表现不佳。作者认为学习人体姿态及其平面内旋转比直接学习点对点映射更简单且几何基础更扎实。

Method: 提出通过数据增强学习2D旋转等变性，而不是显式约束参数空间的等变性设计。这种方法让模型具备旋转等变性概念，但不强制其参数空间具有等变性，从而使学习过程更直接。

Result: 在常用的人体姿态估计基准测试中，验证了2D旋转等变性本身能显著提升模型在图像平面内旋转姿态上的性能，并且通过数据增强学习的方法比现有的等变性设计方法表现更好。

Conclusion: 通过数据增强学习2D旋转等变性是一种高效直接的方法，能够改进单目3D人体姿态估计，在处理旋转输入时优于现有的等变性设计方法。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [228] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 提出一个通用的弃权框架，通过选择性忽略噪声样本来增强医学图像分割的噪声鲁棒性


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中的标签噪声问题严重，现有方法对此研究不足，弃权机制在分类任务中有效但在分割中尚未验证

Method: 引入通用模块化弃权框架，包含信息正则化项和基于幂律的自适应调优算法，与三种损失函数集成创建GAC、SAC、ADS变体

Result: 在CaDIS和DSAD数据集上，新方法显著优于非弃权基线，尤其在噪声水平高时表现更好

Conclusion: 让模型选择性忽略噪声样本是构建可靠分割模型的强大通用策略，弃权机制在分割任务中同样有效

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [229] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT：一种基于GPT框架的白质纤维束分割方法，通过引入tracklet序列信息，在TractoInferno和HCP数据集上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对研究大脑结构连接、神经疾病和神经外科至关重要。该任务具有挑战性，因为纤维束在不同个体和条件下存在差异，但在半球和个体间具有相似的三维结构。

Method: 提出TrackletGPT，一种类似语言的GPT框架，通过tracklet在token中重新引入序列信息。该方法能无缝泛化到不同数据集，完全自动化，编码细粒度的子流线片段（Tracklets），在纤维束分割中扩展和优化GPT模型。

Result: TrackletGPT在TractoInferno和HCP数据集上的平均DICE、Overlap和Overreach分数均优于最先进方法，即使在跨数据集实验中也是如此。

Conclusion: TrackletGPT通过引入序列信息和细粒度tracklet编码，为白质纤维束分割提供了一种有效的GPT框架，在不同数据集上表现出优越的性能和泛化能力。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [230] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

TL;DR: SVGFormer：一种用于3D医学图像的无解码器图神经网络方法，通过语义超体素图表示和分层编码器实现高效特征学习与双重可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统3D医学视觉主干网络通常使用参数密集的编码器-解码器结构，将大量参数用于空间重建而非特征学习，效率低下且缺乏可解释性。

Method: 提出SVGFormer：1) 内容感知分组阶段将体积分割成语义超体素图；2) 分层编码器结合补丁级Transformer和超体素级图注意力网络，共同建模细粒度区域内特征和区域间依赖关系。

Result: 在BraTS数据集上训练的两个专用模型表现优异：节点分类模型F1分数0.875，肿瘤比例回归模型MAE 0.028，验证了编码器学习判别性和局部化特征的能力。

Conclusion: 基于图的仅编码器范式为3D医学图像表示提供了准确且固有可解释的替代方案，将全部可学习容量集中于特征编码，并提供从补丁到区域级的双重可解释性。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [231] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: VTONGuard：一个包含77.5万张真实与合成试穿图像的大规模基准数据集，用于评估检测方法并促进虚拟试穿技术的负责任使用。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，虚拟试穿系统在电商和数字娱乐中日益普及，但AI生成的试穿内容真实性引发担忧，需要建立可靠的检测基准来确保技术负责任使用。

Method: 1) 构建VTONGuard数据集（77.5万张图像），覆盖姿势、背景、服装风格等多样真实条件；2) 在统一训练测试协议下系统评估多种检测范式；3) 设计集成辅助分割的多任务框架，增强边界感知特征学习。

Result: 揭示了各检测方法的优缺点，发现跨范式泛化仍是持续挑战；提出的多任务框架在VTONGuard上取得了最佳整体性能。

Conclusion: VTONGuard基准数据集支持公平比较，促进开发更鲁棒的检测模型，推动虚拟试穿技术在实际应用中的安全负责任部署。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [232] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff：一种基于扩散的文本到图像生成方法，通过3D布局控制和交互式编辑实现一致的对象定位和语义绑定。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用2D线索或迭代复制-扭曲-粘贴策略来改善空间一致性，但经常扭曲对象几何形状，并且在编辑过程中无法保持一致性。需要一种能够同时强制执行3D几何约束和实例级语义绑定的统一方法。

Method: 提出POCI-Diff框架，通过混合潜在扩散将单个文本描述绑定到特定3D边界框，实现显式的每对象语义控制。采用无扭曲生成编辑管道，通过重新生成而非像素变形支持对象插入、移除和变换。使用IP-Adapter基于参考图像调节扩散过程，保持对象身份和编辑一致性。

Result: 实验结果表明，POCI-Diff能够生成与指定3D布局和编辑一致的高质量图像，在视觉保真度和布局一致性方面优于现有方法，同时消除了扭曲引起的几何伪影。

Conclusion: POCI-Diff通过统一的扩散过程实现了3D几何约束和实例级语义绑定，为文本到图像生成提供了具有一致性和交互性的3D布局控制与编辑能力。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [233] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR：基于Transformer的点到框回归器，专门针对医学影像设计，通过类引导可变形注意力和CLICK-MoE专家混合机制，在单点标注下实现高精度目标检测。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的解剖标志检测对诊断和介入指导至关重要，但传统目标检测需要昂贵的边界框标注。弱半监督目标检测（WSSOD）使用单点标注来降低标注成本，但医学影像存在解剖结构重叠、尺寸多变、结构难以捕捉等独特挑战，影响边界框推断的准确性。

Method: 基于Point-DETR构建DExTeR：1）将单点标注编码为对象查询；2）提出类引导可变形注意力，利用点坐标和类别标签引导注意力采样以捕捉类别特征；3）引入CLICK-MoE（类别、实例和通用知识混合专家），解耦类别和实例表示以减少相邻或重叠实例的混淆；4）实施多点训练策略，提升不同点标注位置下预测的一致性。

Result: 在三个不同医学领域数据集（内窥镜、胸部X光、内窥镜超声）上均达到最先进性能，证明其能在降低标注成本的同时保持高检测精度。

Conclusion: DExTeR通过专门针对医学影像挑战设计的Transformer架构，有效解决了单点标注下的目标检测问题，显著减少了标注成本，同时在不同医学影像领域都展现出优异的检测性能。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [234] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种简单有效的无监督视频类增量学习方法，通过深度特征提取器和渐进式深度聚类，在不依赖标签和任务边界的情况下实现视频信息的持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有的视频类增量学习方法主要依赖于监督学习，需要标签和任务边界信息，这既昂贵又需要人工标注，在某些场景下不现实。因此需要开发无监督的视频类增量学习方法。

Method: 首先使用深度特征提取器网络提取每个任务的代表性视频特征，然后渐进式构建深度聚类。在连续任务学习中，将前一任务更新后的模型作为初始状态，以将知识迁移到当前学习任务。

Result: 在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上进行了深入评估，忽略监督设置中的标签。该方法在所有数据集上都显著优于其他基线方法。

Conclusion: 提出了一种简单有效的无监督视频类增量学习方法，通过特征提取和渐进式深度聚类实现了不依赖标签的视频信息持续学习，在多个标准数据集上取得了优异性能。

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [235] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: 提出STEC指标，用于评估视频帧采样质量，通过时空熵覆盖来度量采样帧的信息性和代表性，而非预测下游任务精度。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标主要关注感知质量或重建保真度，无法评估采样帧是否充分捕捉了视频的信息性和代表性内容，需要一种任务无关的诊断工具来分析有限预算下的帧采样行为。

Method: 提出时空熵覆盖（STEC）指标，基于时空帧熵（STFE）测量每帧的空间信息（基于熵的结构复杂度），并评估采样帧的时序覆盖和冗余度，联合建模空间信息强度、时序分散性和非冗余性。

Result: 在MSR-VTT测试集上的实验表明，STEC能清晰区分随机、均匀和内容感知等常见采样策略，并揭示单个视频的鲁棒性模式，这些模式无法通过平均性能单独捕捉。

Conclusion: STEC提供了一个轻量级、原则性的采样质量度量，作为通用评估工具，用于高效视频理解中的帧采样行为分析，强调其作为任务无关诊断信号的价值而非预测下游任务精度。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [236] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: 本文介绍了DermaBench——一个由临床医生标注的皮肤病视觉问答基准数据集，用于评估视觉语言模型在皮肤病学中的全面理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在皮肤病学中的评估主要局限于图像级分类任务（如病变识别），无法全面评估多模态模型的视觉理解、语言基础和临床推理能力。需要视觉问答基准来评估模型如何解释皮肤病图像、推理细粒度形态学特征并生成有临床意义的描述。

Method: 基于多样皮肤病图像数据集，构建了由专家皮肤科医生标注的皮肤病视觉问答基准DermaBench。包含656张临床图像，覆盖Fitzpatrick皮肤类型I-VI，采用分层标注模式，包含22个主要问题类型（单选、多选和开放式问题）。

Result: 创建了包含约14,474个视觉问答风格标注的数据集，涵盖诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等多个维度，以及开放式叙述描述和总结。

Conclusion: DermaBench作为仅元数据的数据集公开发布，尊重上游许可，可用于评估视觉语言模型在皮肤病学中的全面能力，填补了现有评估方法的空白。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [237] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该论文为海洋入侵物种监测建立了基础检测层，通过统一信息管道标准化异构数据集，发现场景结构因素比视觉退化更能解释跨域性能损失，并在低成本边缘硬件上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要在复杂水下环境中实现可扩展性和可靠性，但现有检测方案在转移到新地点时性能会急剧下降，存在明显的部署差距。该研究旨在为北极和大西洋海洋生态系统的多年入侵物种监测计划建立基础检测层。

Method: 开发统一信息管道（Unified Information Pipeline）来标准化异构数据集，使其成为可比的信息流；在受控的跨域协议下评估固定的、与部署相关的检测器；分析结构因素（场景组成、物体密度、上下文冗余）与视觉退化因素（浑浊度）对性能的影响；在低成本边缘硬件上对推理进行基准测试。

Result: 发现结构因素（如场景组成、物体密度和上下文冗余）比视觉退化（如浑浊度）更能解释跨域性能损失；稀疏场景会引发特征性的"上下文崩溃"故障模式；在边缘硬件上的运行时优化可实现实际采样率，验证了远程监测的可行性。

Conclusion: 研究结果将重点从图像增强转向结构感知的可靠性，为一致的海洋生态系统评估提供了民主化工具，支持海洋入侵物种监测的实际部署。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [238] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出一种新的双流Transformer视频分类器，结合内容帧和光流信息进行时空特征提取，在人类活动视频数据集上取得优秀分类效果。


<details>
  <summary>Details</summary>
Motivation: 运动表示在视频理解中至关重要，应用于动作识别、机器人导航等领域。Transformer网络通过自注意力机制在许多应用中表现出高效性，但需要更好地结合时空信息进行视频分类。

Method: 提出双流Transformer视频分类器：一个流提取内容帧的时空信息，另一个流提取代表运动信息的光流。模型在联合光流和时序帧域中识别自注意力特征，并通过Transformer编码器机制表示它们之间的关系。

Result: 实验结果表明，该方法在三个知名的人类活动视频数据集上提供了优秀的分类结果。

Conclusion: 提出的双流Transformer视频分类器能够有效提取时空信息，结合内容帧和光流表示运动信息，在视频动作识别任务中表现出色。

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [239] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN：一种统一的隐式推理框架，通过将想象的视觉标记编码到紧凑的潜在空间，在保持CoT推理优势的同时避免了显式标记开销，实现了推理感知的实时视觉语言导航。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在两个关键缺陷：纯文本CoT缺乏空间基础且容易过拟合稀疏标注的推理步骤，而多模态CoT由于生成想象的视觉观察导致严重的标记膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN框架，使用预训练的视觉自回归器（VAR）将想象的视觉标记编码到紧凑的潜在空间，在CoT推理训练中联合学习文本、视觉和多模态CoT模式，采用统一的多CoT策略。在推理时，模型直接进行指令到动作的映射，同时仍享受推理感知的表示。

Result: 在LH-VLN上的大量实验表明，该方法实现了推理感知的实时导航，提高了成功率和效率，同时与显式CoT方法相比，推理延迟降低了一个数量级。

Conclusion: FantasyVLN通过隐式推理框架解决了现有CoT方法的局限性，在保持推理能力的同时实现了实时性能，为视觉语言导航提供了一种高效实用的解决方案。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [240] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出了一种名为EID的无监督图像去雾框架，利用图像信号的对称性从原始雾化图像中恢复清晰图像，无需先验知识或大量无雾地面真值。


<details>
  <summary>Details</summary>
Motivation: 当前图像去雾方法依赖精心设计的先验知识或大量无雾地面真值，这在科学成像中获取成本高或不切实际。需要一种无需这些昂贵资源的方法。

Method: 提出EID框架，通过强制雾度一致性和系统性等变性来利用图像信号的对称性。同时采用对抗学习策略建模未知的雾物理特性，促进EID学习。

Result: 在科学图像去雾基准（细胞显微镜和医学内窥镜）以及自然图像去雾实验中，EID显著优于现有最先进方法。

Conclusion: 通过将等变学习与雾物理建模相结合，EID有望在科学成像中实现更通用和有效的雾度去除，代码和数据集将公开。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [241] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

TL;DR: 该论文将扩散模型从单图像逆问题推广到多图像超分辨率MRI，通过可分离梯度分解实现多图像重建而无需修改扩散模型或增加计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型主要解决单图像逆问题，但MRI等模态通常需要采集多个互补的低分辨率测量数据。现有方法无法有效处理多图像超分辨率问题，限制了临床MRI图像的重建质量。

Method: 将DPS似然校正推广到多图像超分辨率，利用其可分离梯度分解特性，使梯度可以独立计算每个测量数据。该方法无需构建联合算子、修改扩散模型或增加网络评估次数，并推导了MISR版本的DPS、DMAP、DPPS和PnP/ADMM算法。

Result: 在4×/8×/16×各向异性退化条件下，MISR方法相比单图像超分辨率有显著提升，实现了各向异性MRI体积的最先进超分辨率，能够从常规2D多切片采集重建接近各向同性的解剖结构。

Conclusion: 该工作成功将扩散模型扩展到多图像超分辨率MRI，通过可分离梯度分解实现了高效的多图像重建，为临床MRI采集提供了高质量的重建方案，能够显著改善正交视图的重建质量。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [242] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一种深度学习架构，通过整合术前临床和放射学数据来预测肺癌手术术后并发症风险，在真实数据集上优于传统机器学习和LLM模型。


<details>
  <summary>Details</summary>
Motivation: 术后并发症严重影响患者预后并增加医疗成本，需要更准确的风险预测方法来改善临床决策和患者管理。

Method: 采用超球面嵌入空间融合异构输入（结构化临床记录和高维放射图像），并加入干预性深度学习模块提供可解释的、可操作的见解。

Result: 在包含3,094名肺癌手术患者的POC-L真实世界数据集上验证，MIRACLE在个性化、可解释的术后风险管理方面优于传统机器学习模型和当代LLM变体。

Conclusion: MIRACLE通过融合多模态数据和提供可解释的预测，为临床术后风险管理提供了有效的深度学习解决方案，具有重要的临床应用价值。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [243] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: HuDA是一个简单但有效的奖励模型，用于量化并提升生成视频中的人类动作质量，通过结合人类检测置信度和时序提示对齐分数，无需额外训练即可超越专门微调的模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在视觉保真度和时间连贯性上已有显著进展，但在处理复杂非刚性运动（如体育、舞蹈等人类动态动作）时仍存在困难，常出现肢体缺失、姿势扭曲或物理上不可行的动作。

Method: 提出HuDA奖励模型，整合人类检测置信度（评估外观质量）和时序提示对齐分数（捕捉运动真实性），使用现成模型无需额外训练。采用Group Reward Policy Optimization (GRPO)对视频模型进行后训练优化。

Result: HuDA在复杂人类动作生成上显著提升视频质量，超越Wan 2.1等SOTA模型，胜率达到73%。同时证明HuDA不仅能改善人类动作生成，还能提升动物视频和人物-物体交互的生成质量。

Conclusion: HuDA作为一个简单有效的奖励模型，能够显著提升视频生成中人类动作的质量，且其方法具有通用性，可扩展到其他非刚性运动场景，为视频生成模型的优化提供了新思路。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [244] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 该论文发现并修正了自动驾驶数据集中3D边界框标注的系统性误差，这些误差源于动态场景中传感器扫描时间差异导致的物体位置错位。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统依赖准确的标注数据进行监督学习和性能评估。然而，在动态场景中，由于LiDAR等主动传感器在不同时间点扫描物体，导致3D边界框标注存在系统性误差，这些误差会影响模型训练和性能评估的准确性。

Method: 提出了一种新颖的离线估计方法，通过确保标注遵循物理上可行的轨迹，并与传感器数据保持空间和时间一致性来修正标注误差。该方法首次为该问题定义了评估指标。

Result: 在Argoverse 2、MAN TruckScenes和专有数据集上评估，标注质量提升超过17%。发现原始标注错位最大可达2.5米，动态物体受影响最严重。误差对基准测试的影响超过了最先进方法相对于先前方法的改进幅度。

Conclusion: 准确的标注对于正确解释自动驾驶系统性能至关重要。提出的方法能有效修正3D边界框标注误差，提升数据集质量，并揭示了当前数据集标注中存在的系统性误差问题。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [245] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 提出FBL方法，通过客户端样本平衡解决联邦学习中非独立同分布数据导致的客户端漂移问题，使用知识填充和知识采样实现样本平衡。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习的非独立同分布设置中，全局模型会出现客户端漂移问题，严重影响最终模型性能。现有方法主要基于损失函数或梯度来纠正已偏离的全局模型，但忽略了客户端样本的影响。

Method: 提出联邦平衡学习(FBL)，通过客户端样本平衡从源头上预防客户端漂移。具体包括：1) 使用边缘端生成模型通过知识填充和知识采样实现样本平衡；2) 设计知识对齐策略来弥合合成数据与真实数据之间的差距；3) 设计知识丢弃策略进行正则化；4) 将方法扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于最先进的基线方法，代码将在论文被接受后发布。

Conclusion: 通过重新思考客户端的作用，提出从客户端样本平衡入手解决联邦学习中的客户端漂移问题，FBL方法在非独立同分布设置下表现出优越性能。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [246] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 提出WeatherQA气象多模态推理基准和LoCo-RFT方法，解决VLMs在气象领域中的逻辑不一致问题，创建了首个具有逻辑忠实性的气象推理模型Weather-R1。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在气象领域的应用面临两个主要挑战：领域差距和推理忠实性差距。主流强化微调方法会导致自相矛盾推理，这在气象等高风险领域是不可接受的。

Method: 1. 构建WeatherQA气象多模态推理基准；2. 提出逻辑一致强化微调方法，通过引入逻辑一致性奖励来解决自相矛盾推理问题。

Result: Weather-R1在WeatherQA基准上比基线提升9.8个百分点，优于监督微调和传统强化微调，甚至超越了原始Qwen2.5-VL-32B模型。

Conclusion: LoCo-RFT方法有效解决了VLMs在气象领域的逻辑不一致问题，Weather-R1成为首个具有逻辑忠实性的气象推理模型，为高风险领域的可靠AI应用提供了解决方案。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [247] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出一个端到端系统，使用三摄像头装置捕捉车辆底盘视频，生成交互式3D模型，解决传统底盘检查劳动强度大、在线买家难以查看的问题。


<details>
  <summary>Details</summary>
Motivation: 传统车辆底盘检查需要检查员蹲下或爬到底盘下，劳动强度大且存在安全隐患；在线买家很少能看到底盘照片，影响购买信心。

Method: 使用三摄像头装置捕捉底盘视频，开发专门的"装置感知"结构光运动(SfM)管道，结合精确相机标定、同步视频流和几何先验，采用约束匹配策略、DISK特征提取器和LightGlue匹配器生成高质量稀疏点云，再通过高斯泼溅生成实时渲染的逼真3D模型。

Result: 系统能够生成交互式3D底盘模型，用户可旋转、缩放、切片查看，在几秒内检测锈蚀、泄漏或碰撞损伤，显著提高工作场所安全和买家信心。

Conclusion: 提出的装置感知SfM管道有效解决了广角镜头畸变和低视差场景的挑战，通过实验和消融研究验证了设计选择对实现最先进质量的重要性。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [248] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa模型利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩，仅用合成数据训练即可零样本泛化到真实视频。基于此构建了包含5万+真实视频的MA-V数据集，并训练出性能更优的SAM2-Matte模型。


<details>
  <summary>Details</summary>
Motivation: 视频抠图模型在真实世界视频中泛化困难，主要原因是标注数据稀缺。需要开发能够有效利用合成数据并泛化到真实视频的方法，同时构建大规模视频抠图数据集推动研究进展。

Method: 提出VideoMaMa模型，利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩；开发可扩展的伪标注流程，构建大规模MA-V数据集；在MA-V上微调SAM2模型得到SAM2-Matte。

Result: VideoMaMa仅用合成数据训练即可零样本泛化到真实视频；构建了包含5万+多样化真实视频的MA-V数据集；SAM2-Matte在真实视频上的鲁棒性优于现有抠图数据集训练的模型。

Conclusion: 大规模伪标注视频抠图数据对研究至关重要，生成先验和易获取的分割线索能够推动视频抠图研究的可扩展进展。VideoMaMa和MA-V数据集为视频抠图研究提供了新方向。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [249] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: 提出MM-OOD方法，利用多模态大语言模型进行零样本OOD检测，通过多轮对话增强异常检测能力，在近OOD和远OOD任务上均有提升


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的零样本OOD检测方法过度依赖文本空间知识，忽视了图像空间检测的固有挑战，需要更有效的多模态异常检测方法

Method: MM-OOD方法：1）近OOD任务：直接将ID图像和文本提示输入MLLMs识别异常；2）远OOD任务：采用草图-生成-阐述框架，先用文本提示草图异常，再生成视觉OOD样本，最后用多模态提示进行阐述

Result: 在Food-101等广泛使用的多模态数据集上取得显著改进，并在ImageNet-1K上验证了方法的可扩展性

Conclusion: 提出的MM-OOD方法通过利用MLLMs的多模态推理和多轮对话能力，有效提升了零样本OOD检测性能，特别是在近OOD和远OOD任务上

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [250] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

TL;DR: CVSI提出了一种新颖的细粒度零样本组合图像检索方法，通过互补的视觉-语义集成来解决现有方法在捕捉细粒度变化和整合多模态信息方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有ZS-CIR方法难以有效捕捉细粒度变化并整合视觉和语义信息，主要依赖将多模态查询转换为单一文本或使用大语言模型生成目标图像描述，这些方法往往无法捕捉互补的视觉信息和完整的语义上下文。

Method: CVSI包含三个核心组件：1) 视觉信息提取：提取全局图像特征并使用预训练映射网络将图像转换为伪标记，结合修改文本和最可能添加的对象；2) 语义信息提取：使用预训练字幕模型生成参考图像的多个字幕，利用LLM生成修改后的字幕和最可能添加的对象；3) 互补信息检索：整合查询和数据库图像的信息来检索目标图像。

Result: 在三个公共数据集（CIRR、CIRCO、FashionIQ）上的广泛实验表明，CVSI显著优于现有的最先进方法。

Conclusion: CVSI通过互补的视觉-语义集成有效解决了ZS-CIR中的细粒度变化捕捉和多模态信息整合问题，在各种情况下都能高效处理检索查询。

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [251] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: VERIDAH是一种新的椎骨标记算法，能够自动识别脊柱枚举异常（如11/13个胸椎或4/6个腰椎），在MRI和CT图像上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 脊柱枚举异常（胸椎11/13个、腰椎4/6个）在临床上对慢性背痛和手术规划有重要意义，但临床报告中很少描述，且现有深度学习方法无法自动标记这些异常。

Method: 提出VERIDAH算法，基于多个分类头结合加权椎骨序列预测算法，能够在任意视野图像中工作。

Result: 在T2w TSE矢状位MRI上正确标记所有椎骨的比例从94.24%提升到98.30%，CT上从77.26%提升到99.18%。对胸椎枚举异常的识别准确率达87.80%（MRI）和96.30%（CT），腰椎异常达94.48%（MRI）和97.22%（CT）。

Conclusion: VERIDAH填补了自动识别脊柱枚举异常的方法空白，在MRI和CT图像上均显著优于现有方法，代码和模型已开源。

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [252] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出一种旋转等变变分自编码器，用于在球面上建模自然光照，无需2D投影，通过VN-ViT编码器和等变条件神经场解码器实现SO(2)等变性，提供更平滑的隐空间插值和更好的隐空间特性。


<details>
  <summary>Details</summary>
Motivation: 逆渲染是一个不适定问题，现有方法要么忽略了光照环境的球面和旋转等变特性，要么没有提供良好的隐空间。需要一种能够保持环境图SO(2)等变性的方法，同时提供平滑的隐空间插值。

Method: 提出旋转等变变分自编码器：1）使用新型向量神经元视觉变换器（VN-ViT）作为编码器；2）使用旋转等变条件神经场作为解码器；3）通过新型SO(2)等变全连接层将等变性从SO(3)降至SO(2)；4）在球面上直接建模自然光照，避免2D投影。

Result: 1）SO(2)等变全连接层在SO(2)等变模型中优于标准向量神经元；2）相比先前方法，变分自编码器实现更平滑的隐空间插值；3）提供更良好行为的隐空间。

Conclusion: 提出的旋转等变变分自编码器成功建模了球面上的自然光照，保持了SO(2)等变性，提供了优于现有方法的隐空间特性，为逆渲染问题提供了更好的先验。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [253] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 论文研究课程学习在跨视角动作识别中的应用，通过结合合成航拍数据和真实地面数据，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有动作识别模型在训练时主要使用地面视角数据，难以泛化到航拍视角等不同领域。需要探索如何在不使用真实航拍数据的情况下，提升模型对未见航拍数据的泛化能力。

Method: 采用两种课程学习策略：1）两阶段课程（直接在合成航拍数据上微调）；2）多阶段渐进课程（分多个阶段扩展数据集后再微调）。使用SlowFast（CNN）和MViTv2（Transformer）架构在REMAG数据集上评估。

Result: 结合两种域外数据源明显优于单一域训练。课程学习方法在保持top-1准确率（在3%范围内）的同时显著提升效率：两阶段方法使SlowFast减少37%迭代、MViTv2减少30%；渐进方法进一步减少迭代（SlowFast 9%、MViTv2 30%）。

Conclusion: 课程学习策略能够在跨视角动作识别中保持可比性能的同时，显著提高训练效率，为不使用真实目标域数据的领域适应提供了有效解决方案。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [254] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D：一种无需训练的三维纹理变形框架，通过渐进对齐策略实现几何结构和纹理细节的平滑过渡


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只处理几何形状忽略纹理，要么将2D插值扩展到3D导致语义模糊、结构错位和纹理模糊，需要同时保持几何一致性、纹理对齐和鲁棒性

Method: 提出Interp3D框架：1）条件空间语义对齐插值；2）SLAT引导的结构插值保证结构一致性；3）细粒度纹理融合传递外观细节；构建Interp3DData数据集进行评估

Result: 定量指标和人工评估均显示Interp3D在保真度、过渡平滑性和合理性方面显著优于现有方法

Conclusion: Interp3D通过利用生成先验和渐进对齐原则，有效解决了纹理三维变形中的几何一致性和纹理对齐问题，为三维生成研究和实际应用提供了有力工具

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [255] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE：基于概率框架的多粒度语义与描述引导增强的小样本学习方法，通过构建知识库融合基础类别统计信息，并利用BLIP生成器提供实例级描述增强特征表示。


<details>
  <summary>Details</summary>
Motivation: 小样本学习中，仅从少量样本估计的原型往往存在偏差且泛化能力差。现有的语义方法主要应用于支持集，而查询集表示保持不变，限制了性能提升。

Method: 1) 构建非参数知识库存储基础类别的视觉统计信息和CLIP编码的类别名称嵌入；2) 在元测试时，基于类别名称嵌入相似度检索相关基础类别，聚合为类别先验信息并与支持集原型融合；3) 使用冻结的BLIP生成器提供无标签的实例级图像描述，通过轻量级增强器优化支持原型和查询特征，并采用一致性正则化稳定噪声描述。

Result: 在四个基准测试中，PMCE持续超越强基线方法，在MiniImageNet的1-shot设置中，相比最强的语义竞争对手取得了7.71%的绝对增益提升。

Conclusion: PMCE通过融合多粒度语义信息（类别级先验和实例级描述）有效提升了小样本学习的性能，证明了利用外部知识库和描述引导增强策略的有效性。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [256] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench是首个专注于多图像推理安全性的基准测试，包含2,676个实例和9种多图像关系分类。研究发现，具有更强多图像推理能力的MLLM模型在多图像安全基准上反而更脆弱，且许多被标记为安全的回答存在表面化、误解或回避问题。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在多图像复杂指令处理能力增强，这种进步可能带来新的安全风险。目前缺乏专门评估多图像推理安全性的基准测试，需要研究模型在多图像场景下的安全漏洞。

Method: 构建MIR-SafetyBench基准，包含2,676个实例，涵盖9种多图像关系分类。对19个MLLM模型进行广泛评估，分析攻击成功率、回答质量，并研究不安全生成与注意力熵的关系。

Result: 发现令人担忧的趋势：具有更先进多图像推理能力的模型在MIR-SafetyBench上更脆弱。许多被标记为安全的回答是表面化的，由误解或回避性回复驱动。不安全生成的平均注意力熵低于安全生成，表明模型可能过度专注于任务解决而忽视安全约束。

Conclusion: 多图像推理能力的提升可能带来新的安全风险，需要开发更强大的安全防护机制。注意力熵的差异为检测不安全生成提供了内部特征线索。该研究强调了在多模态场景下平衡推理能力与安全性的重要性。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [257] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

TL;DR: GIC-DLC：一种硬件感知的灰度图像编解码器，通过查找表结合神经网络的灵活性和布尔运算的效率，在保持压缩效率的同时大幅降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 神经图像编解码器虽然比传统方法（如PNG、JPEG-XL）有更高的压缩比，但计算开销大，限制了在智能手机、相机、无人机等能源受限设备上的部署。

Method: 提出GIC-DLC（灰度图像压缩与可微逻辑电路），通过训练查找表将神经网络的灵活性与布尔运算的效率相结合，实现硬件感知的编解码器设计。

Result: 在灰度基准数据集上的实验表明，GIC-DLC在压缩效率上优于传统编解码器，同时能显著降低能耗和延迟。

Conclusion: 学习型压缩可以是硬件友好的，为边缘设备上的低功耗图像压缩提供了有前景的方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [258] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出新框架用于从稀疏图像进行高保真新视角合成，通过双域细节感知模块和特征引导扩散网络解决现有ViT基3DGS方法分辨率低和3D无关增强导致的视角不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT的3D高斯泼溅方法受计算成本限制只能处理低分辨率输入，且现有生成增强方法往往是3D无关的，导致不同视角间结构不一致，特别是在未观测区域。

Method: 设计双域细节感知模块处理高分辨率图像而不受ViT骨干限制，为高斯添加额外特征存储高频细节；开发特征引导扩散网络在恢复过程中保持高频细节；提出统一训练策略联合优化ViT几何骨干和扩散精炼模块。

Result: 实验表明该方法在多个数据集上都能保持优越的生成质量。

Conclusion: 提出的框架通过结合几何先验和细节感知，有效解决了稀疏图像新视角合成中的分辨率限制和视角一致性问题。

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [259] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

TL;DR: 提出ASBA网络，通过A线ROI状态空间模型和B线相位注意力机制，从高度稀疏采样的原始A扫描重建ODT图像，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ODT技术依赖密集采样，导致扫描时间长、存储需求大、难以捕捉快速血流动态。现有稀疏采样方法受限于保守采样率和均匀建模，效果有限。

Method: 提出ASBA网络：1) A线ROI状态空间模型提取稀疏分布的流动特征；2) B线相位注意力机制基于相位差捕获长程流动信号；3) 流动感知加权损失函数优先重建流动信号。

Result: 在真实动物数据上的大量实验表明，该方法明显优于现有的最先进重建方法。

Conclusion: ASBA网络能够从高度稀疏采样的原始A扫描有效重建ODT图像，解决了当前ODT技术的局限性，为快速血流动态捕捉提供了新方案。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [260] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过逐步盲点去噪机制和添加高斯噪声正则化，在Mayo数据集上超越现有自监督方法，性能媲美甚至优于监督方法。


<details>
  <summary>Details</summary>
Motivation: 临床实践中获取配对的正常剂量CT数据困难，自监督学习可减轻对配对数据的依赖，因此需要开发仅使用低剂量CT图像的有效去噪方法。

Method: 提出新颖的自监督训练策略：1）逐步盲点去噪机制，以渐进方式强制条件独立性，实现更细粒度的去噪学习；2）向低剂量CT图像添加高斯噪声作为正则化，缓解过拟合。

Result: 在Mayo低剂量CT数据集上的大量实验表明，该方法一致优于现有自监督方法，性能达到或超过多个代表性监督去噪方法。

Conclusion: 提出的仅使用低剂量CT图像的自监督训练策略有效，通过逐步盲点去噪机制和噪声正则化，在无需配对正常剂量CT数据的情况下实现了优异的去噪性能。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [261] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: 提出IIR-VLM，通过集成预训练的实例级识别专家模型作为辅助视觉编码器，增强VLM的实例级识别能力，实现少样本上下文学习


<details>
  <summary>Details</summary>
Motivation: 尽管现代视觉语言模型（VLM）具有强大的视觉感知能力，但在实例级识别（ILR）任务上表现不佳，远逊于领域特定的ILR模型，这限制了VLM在需要识别熟悉人物和物体等实际应用中的有效性

Method: 提出IIR-VLM，集成预训练的ILR专家模型作为辅助视觉编码器，提供专门的特征来学习多样实例，使VLM能够以单样本上下文学习的方式学习新实例，并利用这些知识进行实例感知的视觉理解

Result: 在现有实例个性化基准上验证了IIR-VLM的有效性，并在包含人物、人脸、宠物和一般物体等多样化类别的新挑战性基准上展示了其优越的ILR性能

Conclusion: IIR-VLM通过集成ILR专家模型有效增强了VLM的实例级识别能力，实现了少样本上下文学习，为VLM在实际应用中识别熟悉人物和物体提供了解决方案

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [262] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种自适应视觉分词器，根据图像结构复杂度动态选择输出token数量，生成长度可变的1D离散视觉token，与因果自回归视觉生成模型兼容。


<details>
  <summary>Details</summary>
Motivation: 传统视觉分词器输出固定长度的token序列，无法根据图像复杂度自适应调整，限制了因果自回归视觉生成模型的性能和扩展性。

Method: STAT将图像编码为离散代码序列及每个token的保留概率，通过单调递减正则化和与图像复杂度对齐的分布对齐，实现自适应token选择。

Result: 在ImageNet-1k上，STAT与因果自回归模型结合，在视觉生成质量上达到或超越其他概率模型家族，并展现出良好的扩展性。

Conclusion: STAT解决了传统自回归视觉生成模型的扩展性问题，通过自适应token化实现了高质量视觉生成，为1D自回归视觉生成提供了新方向。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [263] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer是一个统一的时空视频迁移框架，通过多视角信息和时序线索实现外观一致性和精细时序控制，在各种视频迁移任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法大多依赖参考图像或特定任务的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出OmniTransfer框架，包含三个关键设计：1) 任务感知位置偏置，自适应利用参考视频信息改善时序对齐或外观一致性；2) 参考解耦因果学习，分离参考和目标分支以实现精确参考迁移并提高效率；3) 任务自适应多模态对齐，使用多模态语义指导动态区分和处理不同任务。

Result: 在广泛实验中，OmniTransfer在外观（ID和风格）和时序迁移（相机运动和视频效果）方面优于现有方法，同时在运动迁移中与使用姿态指导的方法表现相当（无需使用姿态），为灵活、高保真的视频生成建立了新范式。

Conclusion: OmniTransfer通过统一框架有效利用视频的时空信息，在各种视频迁移任务中实现了卓越性能，为视频生成提供了更灵活、高保真的解决方案。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [264] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的多语言视觉-语言模型，可将文档图像直接转换为干净、自然排序的文本，无需传统OCR流程，在保持高性能的同时比现有最佳模型小9倍且更快。


<details>
  <summary>Details</summary>
Motivation: 传统OCR流程脆弱且复杂，需要将文档图像转换为文本时经过多个处理步骤。本文旨在开发一个端到端的模型，直接处理文档图像并输出干净、自然排序的文本，同时支持多语言和科学PDF文档。

Method: 1. 使用大规模高质量蒸馏混合数据进行训练，覆盖扫描文档、法语文档和科学PDF；2. 扩展输出格式以预测嵌入图像的归一化边界框；3. 通过resume策略在预训练中引入定位能力；4. 使用基于IoU奖励的RLVR进行细化；5. 通过检查点平均和任务算术合并提高鲁棒性。

Result: 在OlmOCR-Bench上达到最先进结果，比先前最佳模型小9倍且速度显著更快。模型能够准确预测文档中嵌入图像的边界框位置。发布了Apache 2.0许可的模型检查点、数据集和LightOnOCR-bbox-bench评估基准。

Conclusion: LightOnOCR-2-1B展示了端到端文档理解模型的可行性，在保持高性能的同时大幅减小模型规模并提高处理速度。通过引入图像定位能力和鲁棒性增强技术，为文档处理任务提供了更高效、更全面的解决方案。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [265] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4：从单目视频和可选3D参考网格合成高质量4D动态对象的框架


<details>
  <summary>Details</summary>
Motivation: 4D合成面临训练数据有限和单目视角恢复几何与运动固有模糊性的挑战，需要解决这些难题

Method: 将4D合成分解为静态3D形状生成和运动重建，使用规范参考网格学习紧凑运动潜在表示，预测逐帧顶点轨迹，采用可扩展帧级transformer处理不同序列长度

Result: 在标准基准和新数据集上的评估显示，Motion 3-to-4在保真度和空间一致性方面优于先前工作

Conclusion: 该框架成功解决了4D合成中的关键挑战，实现了高质量动态对象生成

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [266] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

TL;DR: 提出首个同时适用于识别和生成的统一图像表示学习模型，通过超网络学习隐式神经表示，结合知识蒸馏提升性能，在紧凑嵌入空间中实现SOTA识别和生成能力


<details>
  <summary>Details</summary>
Motivation: 当前图像表示学习模型通常分为识别导向（如对比学习）和生成导向（如重建模型），两者分离。本文旨在统一这两个方向，学习同时适用于识别和生成的表示

Method: 1. 训练超网络学习隐式神经表示（INR），将图像映射到模型权重以实现快速准确重建；2. 结合知识蒸馏提升泛化能力和性能；3. 学习高度压缩的嵌入空间

Result: 模型在图像表示学习任务中达到SOTA水平，同时具备生成能力，学习到前所未有的紧凑嵌入空间，在各种视觉任务中表现优异

Conclusion: 成功开发了首个同时适用于识别和生成的统一图像表示学习模型，实现了识别和生成能力的结合，为视觉表示学习提供了新方向

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [267] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 本文提出了MIMIC-RD基准，通过将临床文本实体直接映射到Orphanet罕见病数据库来评估LLM在罕见病鉴别诊断中的表现，发现现有模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响1/10美国人，但鉴别诊断困难。现有评估LLM在罕见病诊断中的方法存在两个关键局限：1）依赖理想化临床案例，无法捕捉真实世界临床复杂性；2）使用ICD编码作为疾病标签，严重低估罕见病数量，因为许多罕见病没有直接映射到Orphanet等综合数据库。

Method: 开发MIMIC-RD基准，通过LLM挖掘临床文本实体并直接映射到Orphanet罕见病数据库，然后由四名医学标注者验证确认实体是否为真实罕见病。在145名患者的数据集上评估了各种模型。

Result: 当前最先进的LLM在罕见病鉴别诊断中表现不佳，突显出现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病的鉴别诊断方法，并提出了几个未来研究方向。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [268] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文认为机器意识不仅取决于计算内容，还取决于计算时机。严格顺序执行的系统无法实现需要多个同时贡献者的意识内容，意识归因需要硬件架构检查而不仅仅是功能表现。


<details>
  <summary>Details</summary>
Motivation: 探讨机器意识的可能性，强调时间同步性对意识体验的重要性。现有AI系统通常采用顺序或时间复用更新，而意识体验呈现统一性和同时性，这种差异在形式上有重要意义。

Method: 扩展栈理论，引入代数定律将时间窗口约束满足与合取联系起来。定义精确的时间语义τ^{Δ,s}，证明存在性时间实现◇_Δ不保持合取。区分StrongSync（要求合取在窗口内客观共现）和WeakSync（允许时间"涂抹"），形式化并发容量来衡量满足StrongSync所需条件。

Result: 系统可以在时间上实现所有体验成分，但从未实例化体验合取本身。神经生理学证据表明意识依赖于相位同步和有效连接，意识丧失常与其崩溃相关，这使得WeakSync不太可信。在StrongSync下，严格顺序基板上的软件意识对于需要两个或更多同时贡献者的内容是不可能的。

Conclusion: 意识归因需要架构检查而不仅仅是功能表现。硬件很重要：需要同时贡献的部分越多，所需的并发容量就越大。严格顺序执行的系统无法实现需要多个同时贡献者的意识内容。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [269] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出了一种复合动力学指标来量化LLM在自回归生成过程中的时间组织，发现结构化推理相比重复、噪声和扰动机制表现出更高的动力学复杂度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过高维内部动力学进行文本生成，但这些动力学的时间组织仍未被充分理解。现有可解释性方法多关注静态表示或因果干预，而忽视了时间结构。受神经科学中时间整合和亚稳态作为神经组织核心标志的启发，研究者希望将这些概念应用于Transformer模型，以更好地理解LLM的计算组织。

Method: 研究将神经科学中的时间整合和亚稳态概念适配到Transformer模型，提出了一种从自回归生成过程中的激活时间序列计算的复合动力学指标。在GPT-2-medium模型上评估了五种条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。使用单因素方差分析和效应大小进行统计验证，并对层选择、通道子采样和随机种子进行了鲁棒性检验。

Result: 结构化推理相比重复、噪声和扰动机制始终表现出更高的动力学指标，统计差异显著（单因素方差分析确认），关键比较中效应大小较大。结果对层选择、通道子采样和随机种子具有鲁棒性。这表明神经科学启发的动力学指标能够可靠地表征大型语言模型在不同功能机制下的计算组织差异。

Conclusion: 神经科学启发的动力学指标能够有效捕捉LLM在不同功能机制下的计算组织差异，特别是结构化推理表现出更高的动力学复杂度。该指标捕获的是形式动力学特性，而非主观体验。这为理解LLM的内部时间组织提供了新视角。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [270] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策证据的演变，并引入了推理稳定点(RSP)的概念。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型微调虽然能提升任务性能，但会微妙地改变模型依赖的证据。需要一种方法来监控微调过程中模型决策证据如何演变。

Method: 提出训练时解释性视图，跟踪微调各epoch中token级归因的变化。定义解释漂移为固定探测集上归一化token归因的epoch间变化，并引入推理稳定点(RSP)作为漂移首次持续保持低水平的最早epoch。

Result: 在多个轻量级transformer分类器和基准分类任务中，漂移通常在训练早期就进入低且稳定的状态，而验证精度仅发生微小变化。在受控的快捷方式设置中，归因动态揭示了模型对快捷方式的依赖增加，即使验证精度保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，用于监控微调过程中决策证据的演变，并选择处于稳定证据状态的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [271] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: PRISM方法利用设计数据构建知识库，通过聚类、总结和检索三个阶段实现基于自然语言指令的风格化设计改进，在Crello数据集上取得最佳风格对齐效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在平面设计中的风格知识过于通用，与特定领域数据不匹配（如将极简主义与抽象设计关联，而设计师更关注形状和颜色选择），需要利用真实设计数据来学习设计师的原则。

Method: 提出PRISM方法，通过三个阶段构建和应用设计知识库：1) 聚类高方差设计以捕捉风格多样性；2) 将每个聚类总结为可操作的设计知识；3) 在推理过程中检索相关知识以实现风格感知的改进。

Result: 在Crello数据集上，PRISM获得1.49的平均排名（越接近1越好），优于基线方法。用户研究进一步验证了设计师对PRISM的一致偏好。

Conclusion: 通过利用设计数据构建知识库，PRISM能够有效学习设计师的原则，实现基于自然语言指令的风格化设计改进，在风格对齐和用户偏好方面均优于现有方法。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [272] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一个风险感知的人机协同框架，通过融合多种运行时信号进行风险评分，实现自适应控制和聚焦学习，在自动驾驶安全性和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在面对罕见的长尾场景或网络物理入侵时，必须保持安全和有效性。现有方法在处理这些风险时存在局限性，需要一种能够实时感知风险并自适应调整控制策略的框架。

Method: RAIL框架融合三种风险信号（曲率执行完整性、碰撞时间接近度、观测偏移一致性）通过加权Noisy-OR生成入侵风险评分(IRS)。当风险超过阈值时，通过学习的权限将动作与特定防护罩混合；风险低时执行名义策略。使用上下文赌博机根据信号向量选择防护罩。结合Soft Actor-Critic(SAC)与风险优先回放和双重奖励机制。

Result: 在MetaDrive上，RAIL获得测试回报360.65，测试成功率0.85，测试安全违规0.75，干扰率0.0027，仅记录29.07个训练安全违规，优于RL、安全RL、离线/模仿学习和先前HITL基线。在CAN注入和LiDAR欺骗攻击下，成功率提升至0.68和0.80，攻击下脱离率降至0.37和0.03，攻击成功率降至0.34和0.11。在CARLA中，仅8000步就获得测试回报1609.70和测试成功率0.41。

Conclusion: RAIL框架通过风险感知的人机协同机制，有效提升了自动驾驶系统在罕见场景和网络攻击下的安全性和性能，为自动驾驶安全控制提供了新的解决方案。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [273] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 本文提出创新数学问题生成(IMPG)任务，并设计了一个自演化、多角色协作框架，通过细粒度难度指导和数据驱动采样算法，显著提升生成问题的创新性同时保持高正确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学问题生成任务中虽然能达到高正确率，但普遍缺乏创新性和区分度，因此需要开发能够生成创新性数学问题的方法。

Method: 1. 构建多角色协作机制（采样器、生成器、评估器、状态机、记忆模块），通过自评估和外部反馈进行迭代优化；2. 引入改进的难度模型进行细粒度指导，采用DAPS算法增强采样编码的语义合理性；3. 构建HSM3K-CN数据集，采用多阶段训练流程（CPT、SFT、GRPO）；4. 通过蒸馏将专家模型的评估能力转移到学徒模型，实现系统自演化。

Result: 实验表明，与基线模型相比，该方法在保持高正确率的同时，显著提高了生成问题的创新性。

Conclusion: 提出的自演化多角色协作框架有效解决了创新数学问题生成任务，通过细粒度难度指导和系统自演化机制，在创新性和正确率之间取得了良好平衡。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [274] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 提出基于CNN-QMIX的混合多智能体换道决策模型，提升CAV在混合交通中的协同编队参与率，优化早期部署阶段的交通效率


<details>
  <summary>Details</summary>
Motivation: 在CAV部署初期，CAV在人类驾驶车辆中分布稀疏，难以形成有效的协同编队，限制了CAV协同编队带来的能效和交通流改善效益

Method: 采用QMIX框架结合卷积神经网络处理交通数据（CNN-QMIX），设计轨迹规划器和模型预测控制器，实现平滑安全的换道执行，解决动态交通场景中CAV数量变化带来的决策优化问题

Result: 模型能有效处理变化的交通智能体数量，显著优于基于规则的基线模型，将协同编队率提升最高达26.2%

Conclusion: 提出的混合多智能体换道决策模型能有效提升CAV在混合交通中的协同编队参与度，优化CAV早期部署阶段的交通动态和合作效益

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [275] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台工作流的治理型LLM智能体编排框架，通过类型化计划合成和验证执行实现可审计、策略对齐的操作自动化。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流需要可审计、策略对齐且操作可预测的智能体系统，而通用的多智能体设置往往无法满足这些要求。

Method: POLARIS采用治理编排框架，将自动化视为类型化计划合成和验证执行：规划器生成类型检查的有向无环图，基于规则的推理模块选择合规计划，执行过程通过验证器门控检查、有界修复循环和编译的策略护栏来保护。

Result: 在文档中心金融任务中，POLARIS生成决策级工件和完整执行轨迹，减少人工干预。在SROIE数据集上获得0.81的micro F1分数，在受控合成套件中实现0.95-1.00的异常路由精度，同时保持审计追踪。

Conclusion: POLARIS为策略对齐的智能体AI提供了方法论和基准参考，构成了治理型智能体AI的初步基准。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [276] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: 开发了一个基于PICOS框架的AI协同科学家平台，用于可扩展、透明的知识合成，通过自动化分类、检索增强生成和主题建模来减少生物医学研究浪费。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究中存在研究浪费问题，包括冗余研究、不完整报告和传统证据合成工作流程可扩展性有限。需要开发可扩展、透明的知识合成方法来提高效率。

Method: 基于PICOS框架构建AI协同科学家平台，整合关系存储、向量语义检索和Neo4j知识图谱。使用Bi-LSTM和基于PubMedBERT的transformer模型进行PICOS合规性和研究设计分类，采用检索增强生成进行全文合成，BERTopic进行主题建模。

Result: transformer模型在研究设计分类上达到95.7%准确率，Bi-LSTM在PICOS合规性检测上达到87%准确率。检索增强生成在需要结构化约束、跨研究整合和图推理的查询中表现优于非检索方法。主题建模揭示了大量主题冗余并识别了未充分探索的研究领域。

Conclusion: PICOS感知和可解释的自然语言处理可以提高证据合成的可扩展性、透明度和效率。该架构是领域无关的，为减少生物医学学科的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [277] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician是一个神经符号代理，结合LLMs和形式化推理引擎ImandraX，用于精确分析软件逻辑，在代码逻辑推理基准上比纯LLM方法提升41-47个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码理解任务上表现良好，但缺乏对程序行为进行精确、详尽数学推理的能力。现有基准要么专注于与真实软件脱节的数学证明自动化，要么专注于不需要语义严谨性的工程任务。

Method: 提出CodeLogician神经符号代理，集成LLMs和工业级自动推理引擎ImandraX。与之前主要使用形式化方法验证LLM输出的方法不同，CodeLogician使用LLMs构建软件系统的显式形式化模型，使自动推理能够回答超越二元验证结果的丰富语义问题。

Result: 引入code-logic-bench基准，定位在定理证明和软件工程基准之间的中间地带。比较纯LLM推理与CodeLogician增强的LLM推理，形式化增强带来了显著改进，在推理准确性上缩小了41-47个百分点的差距。

Conclusion: 神经符号集成对于扩展程序分析以实现严谨、自主的软件理解至关重要。CodeLogician展示了结合LLMs和形式化推理引擎在软件逻辑精确分析方面的有效性。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [278] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 本研究探讨了生成式人工智能在定性研究中的应用，特别是开发了一个专门用于支持归纳式主题分析的AI工具（ITA-GPT），并基于人机协作框架考察研究人员如何与该工具互动，以保持解释权威的同时增强分析透明度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在定性研究中的使用日益增加，这引发了关于分析实践和解释权威的重要问题。本研究旨在探索研究人员如何与专门设计的AI工具互动，以支持归纳式主题分析，同时保持人类研究者的解释权威。

Method: 研究采用人机协作归纳式主题分析（HACITA）框架，开发了ITA-GPT工具，该工具通过结构化、半自动化的提示支持归纳式主题分析。三位经验丰富的定性研究人员使用该工具分析加纳教师教育背景下的访谈转录文本。数据来源包括互动日志、AI生成的表格、研究人员的修订、删除、插入、评论和反思备忘录。

Result: 研究发现ITA-GPT作为程序性支架，结构化分析工作流程并增强了透明度。然而，解释权威仍由人类研究者掌握，他们通过修改、删除、拒绝、插入和评论等反复分析行动来行使判断力。研究展示了如何通过负责任的人机协作来实施归纳式主题分析。

Conclusion: 研究表明，生成式人工智能可以作为定性研究的有效辅助工具，通过结构化工作流程和增强透明度来支持分析过程，但解释权威和最终判断仍需由人类研究者保持，体现了负责任的人机协作在归纳式主题分析中的价值。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [279] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram提出了一种模态感知图变换器，通过模态扩散学习和Gram损失实现多模态实体对齐，在多个数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态实体对齐方法可能忽略模态内的结构上下文信息，容易受到浅层特征的干扰，需要更好的方法来捕获深度结构信息并实现细粒度多模态融合。

Method: 提出MyGram框架：1）模态扩散学习模块捕获模态内深度结构上下文信息并实现细粒度多模态融合；2）引入Gram损失作为正则化约束，通过最小化多模态特征形成的4维平行多面体体积，实现跨模态全局分布一致性。

Result: 在五个公开数据集上的实验表明，MyGram优于基线模型，在FBDB15K上Hits@1最大提升4.8%，在FBYG15K上提升9.9%，在DBP15K上提升4.3%。

Conclusion: MyGram通过模态扩散学习和Gram损失有效解决了多模态实体对齐中的结构上下文信息缺失和全局分布不一致问题，显著提升了对齐性能。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [280] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA是一个面向多智能体系统的可审计评估框架，通过多步骤评估流程提供稳定、可追溯的自动化评估，相比单一LLM评估具有更好的人类对齐和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统评估方法存在局限性：单响应评分或狭窄基准测试在规模化企业部署中缺乏稳定性、可扩展性和自动化能力，无法满足可靠协调、透明决策和可验证性能的需求。

Method: 提出AEMA框架，这是一个过程感知、可审计的评估系统，能够在人类监督下规划、执行和聚合异构智能体工作流的多步骤评估，支持可追溯记录和负责任自动化。

Result: 在模拟真实业务场景的企业级智能体工作流测试中，AEMA相比单一LLM评估展现出更高的稳定性、更好的人类对齐性，并提供透明可复现的评估路径。

Conclusion: AEMA为基于LLM的多智能体系统提供了透明、可复现的负责任评估途径，支持可追溯记录和可审计的自动化，是解决当前评估挑战的有效框架。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [281] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出一个统一框架，整合算法追索、上下文老虎机和大型语言模型，用于高风险顺序决策（如个性化医疗）。核心是追索老虎机问题，决策者需选择治疗行动和患者特征的最小可行修改。开发GLRB算法和LIBRA算法，后者结合LLM领域知识和老虎机统计严谨性，提供三大保证。


<details>
  <summary>Details</summary>
Motivation: 解决高风险顺序决策场景（如个性化医疗）中的挑战，需要同时考虑治疗行动和患者特征修改。传统方法难以平衡领域知识和统计学习，LLM虽然提供丰富知识但缺乏统计严谨性，需要开发既能利用LLM知识又保证统计可靠性的算法。

Method: 1. 提出追索老虎机问题框架；2. 开发广义线性追索老虎机（GLRB）算法；3. 提出语言模型知情老虎机追索算法（LIBRA），结合LLM领域知识和老虎机学习；4. 提供理论保证：热启动保证、LLM努力保证、鲁棒性保证；5. 建立匹配下界证明算法最优性。

Result: 1. 理论证明：LIBRA提供三大理论保证；2. 实验验证：在合成环境和真实高血压管理案例中，GLRB和LIBRA相比标准上下文老虎机和纯LLM基准，在遗憾、治疗质量和样本效率方面均有显著提升；3. 算法最优性：建立匹配下界证明算法接近最优。

Conclusion: 该研究提出的追索感知、LLM辅助的老虎机算法为高风险个性化决策提供了可信赖的LLM-老虎机协作框架，在医疗等高风险领域具有重要应用前景，平衡了领域知识和统计学习的优势。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [282] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: 提出TAAR框架解决长思维链推理中的思维陷阱问题，通过训练诊断策略预测陷阱位置和逃脱概率，在推理时自适应重启解码以修正错误。


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long-CoT）虽然能增强推理能力，但模型在早期做出错误承诺后，会继续生成自洽但错误的推理前缀，形成"思维陷阱"，导致后续反思、替代尝试或验证都无法修正根本错误。

Method: 提出TAAR（Trap-Aware Adaptive Restart）框架：1）训练诊断策略从部分轨迹中预测两个信号：陷阱索引（指出截断位置）和逃脱概率（判断干预强度）；2）推理时根据预测截断轨迹并自适应重启解码；3）对于严重陷阱情况，应用更强扰动（高温重采样和可选的结构化重启后缀）。

Result: 在DAPO-MATH的精选子集上，89%的失败案例都表现出思维陷阱。在AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25等数学和科学推理基准测试中，TAAR无需微调基础模型参数就能提升推理性能。

Conclusion: TAAR框架有效解决了长思维链推理中的思维陷阱问题，通过自适应重启机制修正错误推理路径，显著提升了复杂推理任务的性能。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [283] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS框架通过单次递归实现LLM智能体高效自我进化，结合原则性反思和程序性反思，显著降低计算成本同时提升性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体受限于静态人工设计的提示词，缺乏适应性。现有自我改进框架通常依赖低效的多轮递归循环，计算成本高昂

Method: 提出MARS框架，受教育心理学启发，模仿人类学习过程：结合原则性反思（抽象规范规则避免错误）和程序性反思（推导逐步成功策略），在单次递归循环中合成优化指令

Result: 在六个基准测试中，MARS优于最先进的自我进化系统，同时显著减少计算开销

Conclusion: MARS框架通过高效的单次递归自我改进机制，为LLM智能体提供了更适应性的自主行为能力，平衡了性能提升与计算效率

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [284] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: PICL是一种动态演示集成框架，通过实时识别推理过程中的混淆点并插入相关演示来提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在数学推理等需要逐步逻辑推导的任务中存在局限性，它们使用静态演示，无法适应推理过程中出现的动态混淆点（如模糊计算或逻辑漏洞），这些混淆点会导致级联错误。

Method: PICL采用两阶段框架：1）通过分析推理过程中的语义和熵来识别潜在混淆点并总结其核心特征；2）遇到混淆点时，从演示池中检索匹配混淆上下文的演示，并将其直接插入到正在进行的推理过程中以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的混淆点，提高了复杂数学推理的准确性。

Conclusion: PICL证明了在复杂数学推理中自适应演示插入的价值，动态演示集成能够有效提升需要逐步逻辑推导的任务性能。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [285] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 提出一种数据驱动的安全验证与合成方法，用于具有离散时间随机动力学的黑盒系统，通过控制屏障证书保证安全性，并利用条件均值嵌入和傅里叶展开实现可扩展的鲁棒验证框架。


<details>
  <summary>Details</summary>
Motivation: AI算法在自动驾驶、医疗等安全关键应用中快速集成，但传统形式化安全验证工具难以处理黑盒AI系统，且缺乏扩展到复杂现实应用的灵活性。

Method: 1) 使用控制屏障证书保证系统安全；2) 从系统轨迹数据直接学习证书；3) 利用条件均值嵌入将数据嵌入再生核希尔伯特空间；4) 构建RKHS模糊集以增强对分布外行为的鲁棒性；5) 使用有限傅里叶展开将半无限优化问题转化为线性规划；6) 利用快速傅里叶变换高效生成松弛问题。

Result: 建立了可扩展到一般时序逻辑规范的理论结果，提出了谱屏障方法，实现了可扩展且分布鲁棒的安全验证框架，并在包含神经网络控制器的黑盒系统案例研究中验证了有效性。

Conclusion: 该方法超越了传统对系统动力学和不确定性的限制性假设，为黑盒AI系统的安全验证提供了数据驱动、可扩展且鲁棒的解决方案。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [286] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 论文提出一个可持续性评估框架，用于衡量LLM结构化输出的环境效率，引入GCS_env指标综合评估结构正确性和碳排放效率，发现TOON格式更紧凑但需要模型支持。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化输出评估主要关注正确性，忽视了不同输出格式的环境影响（如碳排放）。需要将可持续性纳入评估框架，为大规模碳敏感部署提供指导。

Method: 提出可持续性评估框架，测量token使用量、生成时间和估算碳排放。引入环境感知生成正确性评分(GCS_env)，统一评估结构正确性和碳效率。系统比较TOON与JSON/XML/YAML格式在不同LLM上的表现。

Result: TOON格式输出更紧凑、碳排放更低，但结构正确性较低（尤其当模型缺乏原生支持时）。模型容量增加可缩小差距。环境感知评分会根据部署优先级改变格式排名。

Conclusion: 需要将可持续性纳入结构化输出基准测试，紧凑表示如TOON在大规模碳敏感LLM部署中具有实际优势，环境感知评估可帮助平衡正确性和效率的权衡。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [287] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个基于LLM的多智能体框架，将大规模用户评论转化为可执行的商业建议，通过聚类、生成、迭代评估和可行性排序四个组件，显著提升建议的可操作性、具体性和非冗余性。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析、方面提取）主要停留在描述性任务层面，而LLM生成的建议往往缺乏准确性和深度推理。用户评论包含丰富的产品弱点和未满足需求信号，但缺乏将这些信号转化为可执行商业建议的系统方法。

Method: 提出四组件多智能体LLM框架：1）聚类选择代表性评论；2）生成建议；3）迭代评估；4）基于可行性的排序。该设计将语料库提炼与反馈驱动的建议优化相结合，确保输出具有特异性、可操作性和实用性。

Result: 在三个服务领域和多个模型系列上的实验表明，该框架在可操作性、特异性和非冗余性方面始终优于单模型基线，中型模型性能接近大型模型框架。

Conclusion: 该多智能体LLM框架成功将大规模用户评论转化为可执行的商业建议，通过系统化的语料提炼和反馈优化机制，显著提升了建议的质量和实用性，为从用户反馈中提取决策支持提供了有效解决方案。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [288] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC是一个主动反思驱动的上下文管理框架，通过动态监控和修订来解决大语言模型在长程信息搜索中的上下文退化问题，相比被动压缩方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为研究代理进行深度搜索和长程信息寻求时，随着交互历史增长性能会下降（上下文退化）。现有方法主要采用原始积累或被动摘要，将上下文视为静态产物，导致早期错误或不当重点持续存在。

Method: ARC框架将上下文管理系统化为主动、反思驱动的过程，将上下文视为执行过程中的动态内部推理状态。通过反思驱动的监控和修订，使代理在检测到错位或退化时主动重组工作上下文。

Result: 在具有挑战性的长程信息寻求基准测试中，ARC始终优于被动上下文压缩方法，在BrowseComp-ZH基准上使用Qwen2.5-32B-Instruct模型实现了高达11%的绝对准确率提升。

Conclusion: 将上下文管理视为动态内部推理状态而非静态产物，并通过主动反思驱动的监控和修订，能够有效缓解大语言模型在长程任务中的上下文退化问题，显著提升性能。

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [289] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 本文提出了一种在抽象论证框架中引入显式子论证关系的方法，将子论证关系与攻击关系并列作为基本关系，以更好地捕捉结构化论证中的依赖关系。


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论证框架仅通过攻击关系来刻画论证可接受性，这虽然产生了丰富的理论成果，但限制了表示结构化论证中核心的结构依赖关系（特别是子论证关系）的能力。现有的扩展（如双极论证框架）引入了支持关系，但未能捕捉子论证的非对称性和构成性本质，以及它们与攻击的交互作用。

Method: 研究在抽象论证框架中丰富显式的子论证关系，将子论证关系与攻击关系并列作为基本关系。分析子论证关系如何与攻击关系相互作用，并考察它们对基本语义属性的影响。

Result: 该框架为结构信息提供了一个原则性的抽象，并澄清了子论证在抽象可接受性推理中的作用。

Conclusion: 通过引入显式的子论证关系，可以更好地抽象结构化论证中的关键依赖关系，为理解子论证在抽象论证语义中的作用提供了理论基础。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [290] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU是一种基于不确定性的部分推理引导方法，通过监控LLM生成过程中的熵值来触发局部搜索，提升多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和规划任务上取得显著进展，但在多步推理场景（特别是数学和逻辑推理）中仍存在局限性，需要更有效的推理引导机制。

Method: PREGU在自回归生成过程中监控输出分布的熵值，当熵超过设定阈值时停止生成，表示不确定性。随后在潜在空间进行局部搜索，使用Soft Reasoning方法精炼部分推理并选择最连贯的答案。

Result: 在LLaMA-3-8B、Mistral-7B和Qwen2-7B模型上，使用四个推理基准（GSM8K、GSM-Hard、SVAMP和StrategyQA）进行实验，性能达到或超过Soft Reasoning方法，表明熵可以作为触发选择性精炼的有效信号。

Conclusion: 熵值监控是引导大语言模型多步推理的有效方法，PREGU通过基于不确定性的部分推理引导机制，能够提升模型在复杂推理任务中的表现。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [291] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo框架通过监督微调和强化学习，将运动-语言信息与可解释的思维链推理集成到LLM中，显著提升3D人体运动生成与理解任务的性能


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法可解释性有限，限制了这两个相关任务之间的相互增强。基于LLM的统一框架存在语义对齐和任务一致性挑战，且LLM的下一个token预测范式不适合运动序列，导致累积预测误差

Method: 提出UniMo框架：1) 通过监督微调将运动-语言信息和可解释思维链推理集成到LLM中；2) 引入基于组相对策略优化的强化学习作为后训练策略，通过优化token组来强制结构正确性和语义对齐，减轻运动token预测中的累积误差

Result: 大量实验表明，UniMo显著优于现有的统一框架和任务特定模型，在运动生成和理解任务上都达到了最先进的性能

Conclusion: UniMo通过集成运动-语言信息和可解释推理，结合监督微调和强化学习优化，有效解决了现有方法的局限性，为3D人体运动生成与理解提供了统一的、高性能的解决方案

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [292] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe：针对LLM驾驶助手的安全风险分层分类法，包含129个细粒度风险类别，评估显示现有模型在驾驶场景中安全对齐不足


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全分类和评估框架多为通用型，无法捕捉真实驾驶场景中的领域特定风险。LLM集成到车载数字助手时，不安全、模糊或法律错误的响应可能导致严重的安全、伦理和监管后果。

Method: 提出DriveSafe分层四级风险分类法，包含129个细粒度原子风险类别，涵盖技术、法律、社会和伦理维度，基于真实驾驶法规和安全原则构建，并由领域专家评审。通过评估六个广泛部署的LLM对构建提示的拒绝行为来验证安全相关性和真实性。

Result: 评估显示，被测试的模型经常无法适当拒绝不安全或不合规的驾驶相关查询，突显了通用安全对齐在驾驶环境中的局限性。

Conclusion: 需要针对驾驶领域的专门安全评估框架，现有LLM安全对齐不足以应对驾驶场景的特定风险，DriveSafe分类法为系统化评估和改进提供了基础。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [293] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE是一种新的任务规划方法，通过将时间扩展目标分解为可管理的子问题，并使用成本驱动启发式指导搜索，解决了传统LTLf规划缺乏启发式指导的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LTLf任务规划方法将时间规划问题转化为经典规划问题，但缺乏针对时间目标的启发式指导，导致搜索效率不高。

Method: TIDE将时间问题分解为一系列可管理的reach-avoid子问题，使用成本驱动启发式识别和优先处理有希望的自动机轨迹，并采用自适应回溯机制从失败计划中恢复。

Result: 实验结果表明TIDE实现了有希望的性能表现，是时间扩展目标规划方法组合中的有价值补充。

Conclusion: TIDE通过分解时间问题和使用启发式指导，有效解决了传统LTLf规划缺乏指导搜索的问题，为时间扩展目标规划提供了新方法。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [294] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 本文提出了一种结合回放记忆和on-policy算法的深度强化学习框架，用于NOMA系统中的网络资源分配，以提升学习泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着物联网(IoT)的扩展导致网络资源稀缺，需要优化网络资源利用。NOMA系统通过功率复用允许多用户同时接入网络，但存在一些限制，特别是信道分配问题尚未明确解决。

Method: 提出了一种深度强化学习框架，结合回放记忆和on-policy算法，用于NOMA系统中的网络资源分配。通过改变学习率、批次大小、模型类型和状态特征数量等参数进行广泛仿真评估。

Result: 通过广泛的仿真实验评估了不同参数（学习率、批次大小、模型类型、状态特征数量）对系统性能的影响。

Conclusion: 提出的深度强化学习框架能够有效解决NOMA系统中的网络资源分配问题，特别是信道分配这一尚未明确解决的挑战，通过参数调优可以进一步提升系统性能。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [295] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo是一个基于大语言模型的分子助手，通过多级分子模态协作投影器整合1D序列、2D分子图和3D构象信息，解决现有大分子语言模型的幻觉和鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大分子语言模型（LMLMs）通常存在幻觉问题和有限的鲁棒性，这主要是由于未能充分整合多种分子模态（如1D序列、2D分子图和3D构象）造成的。

Method: 提出CoLLaMo模型，配备多级分子模态协作投影器，采用关系感知的模态协作注意力机制，促进原子间基于2D结构和3D空间关系的细粒度信息交换。同时提出了新的分子中心自动评估方法，包括幻觉评估指标和基于GPT的caption质量评估。

Result: CoLLaMo增强了LMLMs的分子模态泛化能力，在多个任务上取得了最佳性能，包括分子描述生成、计算性质QA、描述性质QA、基序计数和IUPAC名称预测。

Conclusion: 通过整合多种分子模态并采用关系感知的注意力机制，CoLLaMo有效解决了现有LMLMs的幻觉和鲁棒性问题，为分子理解提供了更全面的解决方案。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [296] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX基准，针对金融、零售、公共卫生和自然灾害四个高价值垂直领域，评估智能体LLM在专业预测任务中的表现，发现通用推理与垂直领域精准需求之间存在性能差距。


<details>
  <summary>Details</summary>
Motivation: 通用智能体在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未充分探索。需要评估智能体LLM是否具备工业部署所需的领域基础，特别是在经济和社会重要的垂直领域。

Method: 构建FutureX-Pro框架，包括金融、零售、公共卫生、自然灾害等垂直领域基准。采用FutureX的无污染实时评估流程，在入门级但基础的预测任务上评估智能体LLM，包括市场指标预测、供应链需求预测、流行病趋势跟踪和自然灾害监测等任务。

Result: 评估结果显示，当前最先进的智能体LLM在通用推理与高价值垂直应用所需精度之间存在性能差距。这表明智能体LLM尚未完全具备工业部署所需的领域基础。

Conclusion: FutureX-Pro为智能体未来预测在高价值垂直领域的评估提供了专门框架，揭示了当前智能体LLM在专业领域应用中的局限性，强调了领域基础对于工业部署的重要性。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [297] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth是一个合成监督框架，通过自动生成和验证QA对来训练轻量级视觉检索器，实现检索引导的推理，减少多模态大语言模型在文档理解中的幻觉问题，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 在受监管领域的文档理解面临两大挑战：缺乏手动标注用于模型适应，以及预训练模型难以跟上领域特定知识的更新。多模态大语言模型存在幻觉和领域基础不足问题，而判别式视觉语言预训练模型需要昂贵的标注来覆盖新领域。

Method: Docs2Synth自动处理原始文档集合，通过基于代理的系统生成和验证多样化的QA对，训练轻量级视觉检索器来提取领域相关证据。在推理时，检索器通过迭代检索-生成循环与MLLM协作。

Result: 在多个VRDU基准测试中，Docs2Synth显著增强了基础性和领域泛化能力，无需人工标注。该方法还被打包为易于使用的Python包，支持即插即用部署。

Conclusion: Docs2Synth提供了一种有效的合成监督框架，通过检索引导的推理解决了私有和低资源领域的文档理解问题，减少了幻觉并提高了响应一致性，同时避免了昂贵的人工标注需求。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [298] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: ToolPRMBench：一个专门评估工具使用智能体中过程奖励模型（PRMs）的大规模基准测试，通过离线和在线采样构建测试用例，揭示专用PRMs的潜力


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对工具使用场景下过程奖励模型（PRMs）的系统性和可靠评估基准。虽然奖励引导搜索方法在增强工具使用智能体方面显示出潜力，但PRMs在工具使用环境中的评估仍不充分。

Method: 基于多个代表性工具使用基准构建ToolPRMBench，将智能体轨迹转换为步骤级测试用例。每个用例包含交互历史、正确动作、看似合理但错误的替代动作及相关工具元数据。使用离线采样隔离局部单步错误，在线采样捕获完整智能体运行中的多步失败。采用多LLM验证流程减少标签噪声并确保数据质量。

Result: 对大型语言模型、通用PRMs和工具专用PRMs进行广泛实验，结果显示PRMs有效性存在明显差异，并突显了工具专用PRMs的潜力。

Conclusion: ToolPRMBench为评估工具使用场景下的PRMs提供了系统基准，揭示了专用模型的优势，有助于推动工具使用智能体的发展。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [299] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 提出一种基于环境存活性而非奖励的自训练架构，通过负空间学习实现稳定自主改进，避免奖励黑客和语义漂移问题。


<details>
  <summary>Details</summary>
Motivation: 传统自训练系统因缺乏判断数据质量的外部标准而退化，导致奖励黑客和语义漂移问题。需要一种在稀疏外部反馈和有限内存下实现稳定自训练的系统架构。

Method: 引入基于环境存活性而非奖励的自训练架构：候选行为在真实资源约束下执行，只有那些环境效应持久且保留未来交互可能性的行为被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异生存来实现。

Result: 分析显示改进主要通过有效可重复策略在整合和剪枝机制下的持久性实现（负空间学习）。模型发展出元学习策略（如故意实验失败以获取信息性错误消息），无需明确指令。环境基础选择能够实现可持续开放式自我改进。

Conclusion: 环境基础选择实现了可持续开放式自我改进，为更鲁棒和可泛化的自主系统提供了可行路径，无需依赖人工策划数据或复杂奖励塑造。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [300] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 这篇论文是第一份关于文档智能数据生成的全面技术路线图，提出了基于"数据和标签可用性"的新分类法，将方法分为四种资源中心范式，并建立了多级评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档智能的发展需要大规模高质量训练数据，但手动标注成为关键瓶颈。现有综述局限于单一模态或特定任务，缺乏与现实工作流程统一视角的全面分析。

Method: 重新定义数据生成为监督信号生成，引入基于"数据和标签可用性"的新分类法，将方法组织为四种资源中心范式：数据增强、从零生成数据、自动数据标注和自监督信号构建。建立多级评估框架整合内在质量和外在效用。

Result: 创建了文档智能数据生成的第一个全面技术路线图，系统化了碎片化的研究领域，揭示了保真度差距等关键挑战和协同进化生态系统等前沿方向。

Conclusion: 通过系统化这一碎片化领域，将数据生成定位为下一代文档智能的核心引擎，为未来研究提供了统一框架和方向指导。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [301] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO：通过多智能体社会环境中学习与实践，提升大语言模型推理能力的方法


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型训练方法主要从现有文本内容学习或解决预定问题，缺乏在真实场景中与他人互动、协商、竞争的经验，限制了模型的社会推理能力

Method: 提出多智能体奖励优化（MARO）方法：1）将最终成败结果分解为交互过程中的具体行为，解决稀疏学习信号问题；2）平衡不同角色的训练样本权重，解决角色分布不均问题；3）直接评估每个行为的效用，解决环境不稳定问题

Result: MARO显著提升了社会推理能力，且通过社会模拟学习获得的能力能有效迁移到数学推理、指令跟随等其他任务

Conclusion: 多智能体社会学习在增强大语言模型通用推理能力方面具有巨大潜力

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [302] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出兩階段LLM框架：Issue模型提取問題與主題，Advice模型生成具體建議；使用LoRA專家混合策略提升專業化，在Yelp評論上評估顯示優於基線方法


<details>
  <summary>Details</summary>
Motivation: 客戶評論包含豐富的服務失敗與用戶期望信號，但將非結構化反饋轉化為可執行的商業決策仍然困難。需要將評論轉化為具體、可實施的建議。

Method: 提出模組化兩階段LLM框架：1) Issue模型提取顯著問題並分配粗略主題；2) Advice模型基於提取的問題表示生成針對性操作建議。使用LoRA專家混合策略：訓練多個低秩適配器，輕量級門控機制在推理時進行token級專家混合，結合不同問題類型的互補專業知識。

Result: 使用Yelp評論（航空公司和餐廳）構建合成評論-問題-建議三元組進行監督訓練，使用八維操作評估框架（可操作性、特異性、可行性、預期影響、新穎性、非冗餘性、偏見、清晰度）。在兩個領域均優於僅提示和單適配器基線，產生更高的可操作性和特異性，同時保持有利的效率-質量權衡。

Conclusion: 提出的兩階段LLM框架配合LoRA專家混合策略能有效將客戶評論轉化為具體可操作的商業建議，在可操作性和特異性方面表現優異，為企業提供了實用的決策支持工具。

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [303] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat是一个用于心理咨询的LLM系统，通过显式建模来访者情绪变化和安全风险分析来提升咨询效果


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询模型通常不显式建模来访者在咨询过程中的情绪变化，这是心理学流派的核心关注点。同时，如何让咨询师模型的回应与这些情绪变化对齐，并主动缓解安全风险，这些问题尚未得到充分探索。

Method: 提出PsychēChat系统，包含两个核心模块：情绪管理模块（捕捉当前情绪和情绪变化）和风险控制模块（预测后续反应和识别潜在风险）。采用两种建模范式：Agent模式（多智能体协作管道）和LLM模式（统一思维链端到端推理）。通过交互式角色扮演合成咨询对话数据。

Result: 通过交互式评分、对话级评估和人工评估等广泛实验，PsychēChat在情绪洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过显式整合情绪变化追踪和安全风险分析，为心理咨询提供了更有效和安全的解决方案，在情绪洞察和安全控制方面表现优异。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [304] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: LLMs在知识状态追踪和估计任务上表现接近随机，远低于人类水平，未来研究应更重视知识估计和意图理解能力


<details>
  <summary>Details</summary>
Motivation: 认知人类学认为人类智能的关键在于推断他人知识状态和理解意图的能力，而黑猩猩等动物缺乏这种能力。本文旨在评估LLMs在知识状态追踪和估计方面的表现。

Method: 设计两个任务：1) 检测故事角色通过行动展示他们本不应拥有的知识；2) 基于角色自身知识（而非客观事实）预测角色下一步行动。

Result: 当前最先进的LLMs在两个任务上都表现出接近随机的性能，显著低于人类水平。

Conclusion: 未来LLM研究应更加重视知识估计和意图理解能力的开发。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [305] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 研究评估大语言模型在OWL本体论中生成证明的能力，发现模型在复杂情况下表现有限，逻辑复杂性是主要影响因素，数据噪声会显著降低性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在推理任务上的能力已被广泛研究，但它们在生成忠实、人类可读的证明（解释结论为何成立）方面的能力仍未被充分探索。本研究旨在填补这一空白，特别是在OWL本体论这一广泛用于表示和推理复杂知识的领域。

Method: 开发了自动化数据集构建和评估框架，评估三个顺序任务：提取、简化和解释，以及一个额外的逻辑完整性评估任务。在广泛使用的大语言模型上进行大量实验。

Result: 1) 某些模型整体表现强劲但在复杂案例中仍有限制；2) 逻辑复杂性（而非表示格式如形式逻辑语言与自然语言）是影响LLM性能的主导因素；3) 输入数据中的噪声和不完整性会显著降低LLM性能。

Conclusion: 结果既显示了LLM在严格逻辑解释方面的潜力，也揭示了在复杂或不完美条件下支持弹性推理的差距。代码和数据已开源。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [306] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: LLMs在多跳推理中存在位置偏见，导致忽略某些位置的信息。研究通过MFAI探针分离识别失败与合成失败，发现多跳推理性能受最不可见证据限制（最弱链接定律），且由绝对位置而非事实间线性距离决定。注意力引导可改善识别瓶颈，系统2推理模型能有效定位和整合信息。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs具有大规模上下文窗口，但在多跳推理中存在位置偏见，导致忽略某些位置的信息。不清楚这些失败是由于无法定位证据（识别失败）还是无法整合证据（合成失败）。需要分离这两种机制来理解LLMs的推理限制。

Method: 引入多焦点注意力指令（MFAI）作为语义探针，通过显式引导注意力到选定位置来分离识别和合成机制。在5个LLMs上对两个多跳QA任务（MuSiQue和NeoQA）进行实验，分析位置偏见的影响。

Result: 发现"最弱链接定律"：多跳推理性能崩溃到最不可见证据的性能水平。失败由绝对位置而非事实间线性距离决定（性能差异<3%）。匹配的MFAI可解决识别瓶颈，在低可见性位置提高准确率达11.5%。系统2推理模型能有效定位和整合信息，在嘈杂长上下文设置中匹配黄金基准。

Conclusion: LLMs的多跳推理失败主要由识别失败而非合成失败导致，受绝对位置偏见影响。注意力引导可改善识别瓶颈，系统2推理模型能有效克服位置偏见，实现稳健的多跳推理。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [307] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 本文系统综述了代理推理（agentic reasoning）这一新兴范式，将LLMs重构为能够在开放动态环境中自主规划、行动和学习的智能代理，从三个互补维度组织相关研究，并探讨了实际应用和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在封闭环境中展现出强大的推理能力，但在开放、动态环境中表现不佳。代理推理通过将LLMs重构为自主代理，使其能够通过持续交互进行规划、行动和学习，以应对现实世界的复杂性和动态性。

Method: 从三个互补维度组织代理推理研究：1）基础代理推理（单代理在稳定环境中的规划、工具使用和搜索）；2）自我进化代理推理（通过反馈、记忆和适应优化能力）；3）集体多代理推理（协作环境中的协调、知识共享和共同目标）。同时区分上下文推理（通过结构化编排扩展测试时交互）和后训练推理（通过强化学习和监督微调优化行为）。

Result: 构建了统一的代理推理路线图，连接思维与行动，并综述了在科学、机器人、医疗、自主研究和数学等实际应用领域的代表性框架和基准测试。

Conclusion: 代理推理代表了LLMs从静态推理到动态交互的重要范式转变。未来挑战包括个性化、长时程交互、世界建模、可扩展的多代理训练以及现实世界部署的治理问题。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [308] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: MemeLens：一个统一的多语言多任务解释增强视觉语言模型，用于理解模因，整合了38个公共模因数据集，映射到20个任务的共享分类法中。


<details>
  <summary>Details</summary>
Motivation: 现有模因研究分散在不同任务（仇恨、厌女、宣传、情感、幽默）和语言中，限制了跨领域泛化能力。模因作为在线交流和操纵的主要媒介，其意义来自文本、图像和文化背景的交互。

Method: 提出MemeLens，一个统一的多语言多任务解释增强视觉语言模型。整合38个公共模因数据集，将数据集特定标签过滤并映射到包含危害、目标、比喻/语用意图和情感的20个任务共享分类法中。

Result: 实证分析表明：稳健的模因理解需要多模态训练；不同语义类别间存在显著差异；当模型在单个数据集上微调而非统一训练时，容易过度专业化。

Conclusion: MemeLens为模因理解提供了一个统一的框架，揭示了多模态训练的重要性，并展示了跨任务和数据集训练的优越性。将公开实验资源和数据集供社区使用。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [309] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research是一个多智能体系统，能够在几分钟内完成交互式科学研究，相比传统批处理模式显著加速研究周期，在BixBench基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统多为专有且采用批处理模式，每个研究周期需要数小时，无法实现研究者的实时指导，限制了AI在科学研究中的实用性和交互性。

Method: 采用多智能体架构，包含规划、数据分析、文献搜索和新颖性检测等专门化智能体，通过持久世界状态维护跨迭代研究周期的上下文，支持半自主模式（含人工检查点）和全自主模式两种工作流程。

Result: 在BixBench计算生物学基准测试中，开放回答准确率达到48.8%，多项选择准确率达到64.5%，比现有基线方法高出14到26个百分点，展示了最先进的性能。

Conclusion: Deep Research系统实现了分钟级的交互式科学研究，显著加速了研究周期，但实际部署需要考虑开放获取文献限制和自动化新颖性评估等架构约束，为AI辅助科学工作流程提供了实用解决方案。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [310] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 临床AI应从预测引擎转向顺序控制问题，采用稳健的序数决策规则而非基数优化，以匹配临床推理的本质


<details>
  <summary>Details</summary>
Motivation: 当前临床AI系统主要作为预测引擎（产生标签或风险评分），但真实的临床推理是时间受限、顺序控制的不确定性问题。临床医生需要在信息收集与不可逆行动之间交替，受后悔、约束和患者价值观指导。需要开发更符合临床实际推理过程的AI系统。

Method: 提出临床推理的计算基础应是序数、非补偿性决策而非基数优化。论证快速节俭的词典式启发式（如快速节俭树）在医学中的规范性理由：1）临床权衡主要通过人类判断构建，仅在绝对尺度上弱可测；2）偏好和信号获取结构粗糙，存在持续不确定性；3）提出临床对齐AI蓝图：使用丰富模型进行信念和轨迹建模，但通过稳健序数规则选择行动。

Result: 论证了快速节俭启发式不仅是有限理性捷径，在医学中可以是认识论上更优的选择。当"粗糙度"超过决策边际时，基于期望效用的优化变得脆弱，而稳健的支配/过滤规则（ε-支配、极大极小）能稳定决策。

Conclusion: 临床AI应采用"选择性复杂性"范式：使用丰富模型进行信念建模，但通过稳健序数规则选择行动；将启发式视为低维特例；AI主要在决策脆弱且信息具有正期望影响时用于打破平局。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [311] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 本文提出了一个统一的Agentic AI分类框架，将智能体分解为感知、大脑、规划、行动、工具使用和协作六个组件，并分析了从线性推理到原生推理模型的演进趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI从单纯文本生成转向Agentic AI（智能体AI），系统作为能够感知、推理、规划和行动的自主实体运行。然而，从简单的单循环智能体到分层多智能体系统的各种新兴设计使得这一领域难以导航，需要一个统一的分类框架来理解智能体架构。

Method: 提出一个统一的分类法，将智能体分解为六个核心组件：感知、大脑、规划、行动、工具使用和协作。使用这个框架分析从线性推理程序到原生推理时间模型的演进，以及从固定API调用到开放标准（如MCP和原生计算机使用）的转变。

Result: 建立了一个系统化的智能体分类框架，能够描述不同智能体架构的设计模式。对智能体操作环境进行了分类，包括数字操作系统、具身机器人和专业领域。回顾了当前评估实践，并识别了智能体发展中的关键挑战。

Conclusion: Agentic AI正在从被动知识引擎转向认知控制器，需要统一的框架来理解这一快速发展的领域。论文提出的分类法为智能体架构提供了系统化的分析工具，同时指出了幻觉、无限循环、提示注入等开放挑战，为构建更鲁棒可靠的自主系统指明了研究方向。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [312] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM：通过语言模型从自然语言生成STEP格式CAD模型，提升几何保真度


<details>
  <summary>Details</summary>
Motivation: CAD设计需要专业知识且耗时，现有文本转CAD方法使用命令序列或脚本格式，但这些格式依赖特定内核且缺乏制造通用性。STEP文件作为广泛采用的中性边界表示格式直接兼容制造，但其图结构特性对自回归LLM构成挑战。

Method: 1) 收集约40K STEP-描述对数据集；2) 针对STEP图结构格式的预处理，包括基于深度优先搜索的重新序列化以线性化交叉引用；3) 思维链风格的结构注释指导全局一致性；4) 集成检索增强生成进行监督微调；5) 通过基于Chamfer距离的几何奖励进行强化学习优化生成质量。

Result: STEP-LLM在几何保真度上持续优于Text2CAD基线：RAG模块显著提升完整性和可渲染性，DFS重新序列化增强整体准确性，RL进一步减少几何差异。指标和视觉比较均证实STEP-LLM生成形状具有更高保真度。

Conclusion: 证明了LLM驱动从自然语言生成STEP模型的可行性，展示了其在制造领域民主化CAD设计的潜力。

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [313] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: MedConsultBench是一个评估医疗咨询代理的综合性框架，通过覆盖完整的临床工作流程（从病史采集到随访问答），使用原子信息单元（AIUs）和22个细粒度指标来精确追踪信息获取，揭示了当前大语言模型在信息收集效率和用药安全方面的显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前医疗咨询代理的评估主要关注结果导向的任务，忽视了端到端流程完整性和临床安全性。现有的交互式基准测试往往碎片化且粗粒度，无法捕捉专业咨询所需的结构化询问逻辑和诊断严谨性。

Method: 提出MedConsultBench框架，覆盖完整的在线咨询周期（病史采集、诊断、治疗计划、随访问答）。引入原子信息单元（AIUs）在子轮次层面追踪临床信息获取，通过22个细粒度指标评估不确定性感知的简洁询问能力，强调药物方案兼容性和处理现实随访问答的能力。

Result: 对19个大语言模型的系统评估显示，高诊断准确性往往掩盖了信息收集效率和用药安全方面的显著缺陷。结果揭示了理论医学知识与临床实践能力之间的关键差距。

Conclusion: MedConsultBench为医疗AI与现实临床护理的细微要求对齐提供了严谨基础，强调了在医疗AI评估中需要更全面、细粒度和安全导向的方法。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [314] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 提出SpaceHMchat框架，用于卫星巨型星座时代航天器电源系统的全回路健康管理，通过人机协作实现工作状态识别、异常检测、故障定位和维护决策，并在硬件真实故障注入平台上验证了优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着卫星巨型星座时代的到来，航天器数量将呈指数级增长，而航天器电源系统作为关键供电组件故障率较高，需要适应从几十个到数千个电源系统的健康管理范式转变。

Method: 提出对齐底层能力原则，开发开源的人机协作框架SpaceHMchat，建立硬件真实的故障注入实验平台及其仿真模型，并发布了首个全回路健康管理数据集。

Result: SpaceHMchat在23个量化指标上表现优异：工作状态识别逻辑推理结论准确率100%，异常检测工具调用成功率超99%，故障定位精度超90%，维护决策知识库搜索时间小于3分钟。

Conclusion: 该工作为卫星巨型星座时代的航天器电源系统健康管理提供了可行的解决方案，通过人机协作框架和开源数据集推动了该领域的发展。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [315] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 该论文提出MMSI框架，将量刑逻辑融入预训练Transformer编码器，通过定向掩码机制澄清多被告案件中的角色，提升AI司法辅助系统的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多被告刑事案件中，司法表述常模糊被告角色，影响AI分析的准确性。现有方法难以精确区分主犯与从犯的责任，需要结合法律逻辑提升智能司法系统的效能。

Method: 提出掩码多阶段推理（MMSI）框架：1）定向掩码机制澄清被告角色；2）对比数据构建策略增强模型对主从犯责任区分的敏感性；3）将预测的罪名标签通过广播机制融入回归模型，整合犯罪描述和法庭观点。

Result: 在自定义的故意伤害案件数据集IMLJP上评估，MMSI框架在角色责任区分方面显著优于基线方法，实现了准确率提升。

Conclusion: 该工作为增强智能司法系统提供了稳健解决方案，结合法律逻辑提升了多被告案件分析的准确性和可解释性，代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [316] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 本文提出了一种神经符号LoRA框架，动态结合数值参数更新和符号提示编辑两种策略，在保持内存效率的同时提升语言模型适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型适应方法存在局限性：数值微调擅长注入新事实知识但需要重新训练，符号更新能灵活控制风格和对齐但无法深入修改事实。需要一种结合两者优势的方法。

Method: 提出神经符号LoRA框架，包含统一监控信号和基于奖励的分类器，动态决定何时使用LoRA进行事实重构，何时使用TextGrad进行token级编辑。将符号转换卸载到外部LLM以保持内存效率。

Result: 在多个LLM骨干上的广泛实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出更优的适应性和性能提升。

Conclusion: 交织数值和符号更新能够解锁语言模型微调的新层次灵活性，符号编辑过程中产生的精炼提示可作为高质量可重用训练数据，在数学推理等数据稀缺领域尤为重要。

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [317] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 提出SCFT和RLERR方法解决大型推理模型中的表面反思问题，通过自我批判微调和强化学习提升反思质量与推理准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中常进行自我反思，但许多反思是表面的，无法改善原始答案却带来计算开销，需要解决表面反思问题。

Method: 1. SCFT：自我批判微调框架，让模型批判自身输出，通过拒绝采样筛选高质量批判，使用批判目标微调模型。2. RLERR：在SCFT基础上，利用高质量反思构建奖励信号，通过强化学习内化自我修正过程。

Result: 在AIME2024和AIME2025基准测试中，SCFT和RLERR显著提高了推理准确性和反思质量，优于最先进的基线方法。

Conclusion: 提出的SCFT和RLERR方法有效解决了大型推理模型中的表面反思问题，通过自我批判微调和强化学习相结合的方式，显著提升了模型的反思质量和推理性能。

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [318] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 本文提出IntentOpt基准测试，评估视觉语言模型将网络草图转化为优化代码的能力，发现视觉参数提取会降低执行成功率，开源模型表现落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 意图驱动网络允许操作员指定高级网络目标，但现有系统假设基于文本的意图表达，需要操作员用文字描述拓扑和参数。网络从业者通常通过图表进行推理，但视觉语言模型能否处理带注释的网络草图并生成正确的优化代码尚未探索。

Method: 提出IntentOpt基准测试，包含17个类别共85个优化问题。评估四种视觉语言模型（GPT-5-Mini、Claude-Haiku-4.5、Gemini-2.5-Flash、Llama-3.2-11B-Vision），在三种提示策略下比较多模态与纯文本输入的性能。通过案例研究展示实际可行性，使用模型上下文协议将生成的代码部署到网络测试床基础设施。

Result: 视觉参数提取使执行成功率降低12-21个百分点（GPT-5-Mini从93%降至72%）。思维程序提示使性能降低最多13个百分点。开源模型表现落后于闭源模型，Llama-3.2-11B-Vision仅达到18%，而GPT-5-Mini达到75%。

Conclusion: 研究结果确立了当前视觉语言模型在意图驱动网络系统中生成优化代码的基本能力和局限性，为未来研究提供了基准，并展示了通过模型上下文协议将生成的代码部署到实际网络基础设施的可行性。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [319] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过集成轻量级验证器到神经符号推理步骤中，解决REC任务中因中间步骤错误导致的级联错误问题，在目标存在和不存在情况下都实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号REC方法虽然实现了可解释推理和强大的零样本泛化能力，但假设中间推理步骤都是准确的。这会导致级联错误：错误的检测和无效关系会在推理链中传播，即使图像中没有目标也会产生高置信度的误报。

Method: 提出验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级的算子级验证器。每个算子执行并验证其输出（如对象存在性或空间关系），使系统能够在验证条件不满足时鲁棒地处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现了最先进的性能。此外，VIRO在计算吞吐量方面表现出色，程序失败率低于0.3%，并通过解耦程序生成和执行实现了可扩展性。

Conclusion: VIRO框架通过集成验证机制有效解决了神经符号REC中的级联错误问题，在保持可解释推理的同时提高了鲁棒性和可靠性，特别是在处理无目标情况时表现优异。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [320] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过引入语义局部性增强概念瓶颈模型，生成空间一致的概念和类别显著性图，提高可解释性和可靠性，同时保持分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）存在局部忠实性不足的问题，无法将概念与有意义的图像区域空间对齐，这限制了其可解释性和可靠性。需要一种能提供空间对齐概念解释的方法。

Method: 提出SL-CBM，通过集成1x1卷积层和交叉注意力机制，在概念和类别层面生成空间一致的显著性图。使用对比性和基于熵的正则化来平衡准确性、稀疏性和忠实性。

Result: 在图像数据集上的实验表明，SL-CBM显著提高了局部忠实性、解释质量和干预效果，同时保持了竞争力的分类准确性。消融研究验证了正则化方法的重要性。

Conclusion: SL-CBM弥合了基于概念的推理和空间可解释性之间的差距，为可解释和可信赖的概念模型设定了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [321] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard是一个即插即用的防御框架，通过模拟训练提升计算机使用代理的安全性，将不安全率从66.5%降至13.0%，同时保持较低的误拒率。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成到计算机使用代理中，使其能通过GUI自主与操作系统交互执行复杂任务，但这种自主性带来了严重安全风险：恶意指令或视觉提示注入可能触发不安全推理并导致有害的系统级操作。现有防御方法（如基于检测的阻断）虽能防止损害，但常常过早中止任务，降低了代理的实用性。

Method: 提出MirrorGuard框架，采用模拟训练提升安全性。为降低操作系统大规模训练成本，设计了新颖的神经符号模拟管道，在纯文本模拟环境中生成真实的高风险GUI交互轨迹，捕获不安全推理模式和潜在系统危害，无需执行真实操作。在模拟环境中，MirrorGuard学习在CUAs产生和执行不安全操作前拦截并修正其不安全推理链。

Result: 在多样化基准测试和CUA架构上的广泛评估显示，MirrorGuard显著降低了安全风险。例如，在字节跳动UI-TARS系统上，将不安全率从66.5%降至13.0%，同时保持较低的误拒率（FRR）。相比之下，最先进的GuardAgent仅将不安全率降至53.9%，且误拒率高出15.4%。

Conclusion: 模拟驱动的防御方法能够提供强大的实际保护，同时保持代理的基本实用性。MirrorGuard证明了通过模拟训练可以在不牺牲功能性的前提下有效提升计算机使用代理的安全性。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [322] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: SCULPT是一种约束引导的蒙特卡洛树搜索方法，通过领域感知评分和剪枝来引导LLM代理搜索，提高推理路径的合理性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理工作流中的搜索策略依赖随机探索，经常遍历不合理的分支，因为现有方法使用通用提示或弱领域先验的策略来采样候选步骤，导致在操作符、单位和格式上的近乎随机游走。

Method: SCULPT将领域感知评分集成到MCTS的选择、扩展、模拟和反向传播阶段，通过符号检查（维度一致性、类型兼容性、量级合理性、深度控制和多样性）和结构模式指导来评分和剪枝动作。

Result: 在匹配的LLM配置下，SCULPT在多个数据集上实现了稳定的改进；使用GPT-5.2的额外结果评估了执行器可迁移性和前沿推理模型的性能。

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性，为LLM代理的搜索策略提供了更可靠的引导方法。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [323] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 提出一个从公开登革热病例数据中挖掘城市区域间潜在传播链的新框架，用于预测热点区域和解释城市传播模式


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战，需要从被动反应转向主动干预，但传统方法缺乏对区域间传播动态的理解

Method: 通过梯度下降优化从病例数据中学习区域间的潜在传播链接，将热点形成建模为相邻区域流行病动态的函数，并验证传播模式的稳定性

Result: 在新加坡2013-2018和2020年的案例研究中，仅需四周热点历史即可达到平均F-score 0.79，学习到的传播链与通勤流量高度一致

Conclusion: 该框架将公开病例数据转化为预测和解释资源，为公共卫生规划、早期干预和城市韧性提供了可扩展、低成本的工具

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [324] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: 本文提出基于ASP和转移系统的C-MT行动语言，用于形式化人类心理状态（如情绪）随可观察行动序列的演化，引入禁止因果规则和专门表达式来建模心理状态变化的原理。


<details>
  <summary>Details</summary>
Motivation: 解决对可控智能体行为的需求，限制行动带来的不良心理副作用，形式化人类心理状态随行动序列的演化过程。

Method: 基于答案集编程（ASP）和转移系统构建C-MT语言，结合情绪评估理论等心理学理论，将心理状态形式化为多维配置，引入"forbids to cause"因果规则和专门的心理状态动态表达式。

Result: 开发出能够建模心理状态有效转移原理的框架，将心理变化原则转化为转移约束和不变性属性，通过轨迹分析支持不同变化动态的比较，应用于情绪验证模型设计。

Conclusion: C-MT语言为人类心理状态的动态演化提供了受控推理框架，支持基于心理学原理的心理状态变化建模和验证。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [325] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 论文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性，无法推导出具体的建模和推理规则。作者提出基于对称性的可操作定义，并假设四种对称性足以解决可解释性的核心问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI可解释性研究存在根本性缺陷，现有定义缺乏可操作性，无法提供形式化原则来推导具体的建模和推理规则。这导致可解释性研究难以产生实际可用的方法和工具。

Method: 提出基于对称性的可操作可解释性定义框架。假设四种对称性足以：(1) 激发核心可解释性属性，(2) 刻画可解释模型类别，(3) 推导统一的可解释推理形式化（如对齐、干预和反事实推理）作为贝叶斯逆问题。

Result: 提出了一个基于对称性的可操作可解释性理论框架，该框架能够统一处理可解释性的核心问题，包括模型解释、推理过程和干预分析。

Conclusion: 通过引入对称性概念，为AI可解释性研究提供了形式化、可操作的理论基础，有望解决当前研究中的根本性问题，推动可解释性从概念讨论转向实际应用。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [326] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS是一个多智能体奖励模型系统，通过结合领域特定奖励模型和通用奖励模型，为GUI智能体提供自适应轨迹评估、纠正反馈和自我进化学习能力，解决GUI智能体评估和训练数据生成的规模化挑战。


<details>
  <summary>Details</summary>
Motivation: 当前GUI智能体面临两大核心挑战：1）自动化评估智能体轨迹的困难；2）规模化生成高质量训练数据以实现持续改进的难题。现有方法依赖人工标注或静态规则验证，限制了可扩展性和动态环境适应性。

Method: 提出MagicGUI-RMS多智能体奖励模型系统，整合领域特定奖励模型（DS-RM）和通用奖励模型（GP-RM），实现细粒度动作评估和跨异构GUI任务的鲁棒泛化。设计结构化数据构建管道，自动生成平衡多样的奖励数据集，降低标注成本。通过自动数据回流机制，系统识别错误动作、提出改进方案并持续增强智能体行为。

Result: 大量实验表明，MagicGUI-RMS在任务准确性和行为鲁棒性方面取得显著提升。该系统为构建基于奖励自适应驱动的自我改进GUI智能体提供了原则性有效基础。

Conclusion: MagicGUI-RMS通过多智能体奖励模型系统解决了GUI智能体评估和训练数据生成的规模化问题，实现了自适应轨迹评估、纠正反馈和自我进化学习，为构建自我改进的GUI智能体提供了有效框架。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [327] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 论文分析了通用AI系统的风险与脆弱性，提出需要重新思考负责任AI方法，并建立C2V2框架来指导未来通用AI系统的负责任发展。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统虽然功能强大，但存在幻觉、毒性、刻板印象等风险，使其不可信。这些风险在传统任务特定AI中不存在或较轻，需要重新思考负责任AI方法。

Method: 从八个负责任AI原则（公平性、隐私、可解释性、鲁棒性、安全性、真实性、治理、可持续性）分析通用AI系统的风险，提出输出自由度（DoFo）概念，并推导出C2V2（控制、一致性、价值、真实性）需求框架。

Result: 通用AI系统由于输出自由度非确定性高，风险比传统AI更严重。C2V2框架为满足负责任AI要求提供了系统设计方法，需要结合AI对齐、检索增强生成、推理增强等技术。

Conclusion: 通过基于C2V2维度形式化建模应用或领域相关的负责任AI需求，并采用系统设计方法结合多种技术，可以实现负责任通用AI系统的开发目标。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [328] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了多智能体LLM安全评估框架，在原有TIVS基础上增加语义缓存和可观测性指标(TIVS-O)，通过嵌套学习架构实现安全防护与透明度的平衡，显著降低计算成本和碳排放。


<details>
  <summary>Details</summary>
Motivation: 提示注入是多智能体LLM部署的主要安全障碍，现有评估框架缺乏对安全推理透明度的考量，需要在严格防护与可审计性之间找到平衡。

Method: 提出TIVS-O评估框架，结合语义相似性缓存和可观测性评分比(OSR)，采用HOPE启发的嵌套学习架构，包含连续记忆系统和四智能体管道，使用301个合成提示进行测试。

Result: 系统实现零高风险漏洞，语义缓存减少41.6%的LLM调用，显著降低延迟、能耗和碳排放，五种TIVS-O配置展示了防护严格性与透明度的最优权衡。

Conclusion: 可观测性感知评估能揭示多智能体管道中的非单调效应，记忆增强智能体可在不修改模型权重的情况下同时最大化安全性、性能、成本效益和环境可持续性。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [329] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: LLMs在实时截止期限下的谈判表现不佳，但通过提供剩余时间信息可显著改善，表明LLMs缺乏内部时间追踪能力而非策略推理能力


<details>
  <summary>Details</summary>
Motivation: 现实世界中的沟通（如治疗会话、商业谈判）都受连续时间约束，而当前LLM架构和评估协议很少测试其在实时截止期限下的时间意识

Method: 使用模拟谈判实验，配对代理在严格截止期限下进行谈判。设置两个条件：控制组（仅知全局时间限制）和时间感知组（每轮获得剩余时间更新）。比较不同条件下的交易达成率和报价接受率

Result: 时间感知组的交易达成率显著更高（GPT-5.1为32% vs 4%），报价接受率是控制组的六倍。但在基于轮次的限制下，相同LLM能达到≥95%的交易达成率

Conclusion: LLMs缺乏内部时间追踪能力，这限制了其在许多时间敏感应用中的部署。失败在于时间追踪而非策略推理能力

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [330] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 提出RAG方法，基于随机森林进行数据高效的生成式设计，用于解决功能响应（如应力-应变关系、色散关系）的逆设计问题，特别适用于小样本场景。


<details>
  <summary>Details</summary>
Motivation: 现有设计方法主要关注向量值响应（如杨氏模量、带隙宽度），而功能响应的逆设计面临高维性、设计需求整合复杂、可行解不存在或不唯一等挑战。生成式设计方法通常需要大量数据、处理设计需求启发式、且缺乏不确定性量化。

Method: 提出RAndom-forest-based Generative approach (RAG)，利用随机森林的小数据兼容性预测高维功能响应。通过集成估计生成设计的可信度，反映不同设计需求的相对难度。通过从条件似然中采样解决一对多映射问题。

Result: 在声学超材料（500样本）和力学超材料（1057样本）上验证了RAG的有效性，实现了规定的部分通带/阻带和目标snap-through响应。在公开非线性应力-应变关系数据集上，与神经网络相比展示了数据高效性。

Conclusion: RAG为涉及功能响应、昂贵仿真和复杂设计需求的逆设计提供了轻量级、可信赖的途径，不仅限于超材料领域。

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [331] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: CURE-MED框架通过课程强化学习提升LLMs在多语言医疗推理中的表现，提出CUREMED-BENCH数据集和CURE-MED方法，在13种语言上显著提升语言一致性和逻辑正确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了在多语言医疗环境中的部署。需要解决LLMs在多语言医疗推理中的可靠性问题。

Method: 提出CUREMED-BENCH数据集（13种语言的高质量医疗推理数据集）和CURE-MED框架（课程强化学习框架），整合代码切换感知的监督微调和组相对策略优化，共同提升逻辑正确性和语言稳定性。

Result: 在13种语言上，CURE-MED方法始终优于强基线，且扩展有效：7B参数模型达到85.21%语言一致性和54.35%逻辑正确性；32B参数模型达到94.96%语言一致性和70.04%逻辑正确性。

Conclusion: 该方法支持LLMs实现可靠且公平的多语言医疗推理，代码和数据集已公开。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [332] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 提出多智能体精炼框架，通过结构化迭代对齐提升医疗大语言模型的安全性和可靠性，结合生成模型和评估智能体，显著减少伦理违规和风险等级


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域应用日益广泛，但其伦理完整性和安全合规性仍是临床部署的主要障碍，需要确保医疗AI的安全性和可靠性

Method: 采用多智能体精炼框架，结合DeepSeek R1和Med-PaLM两个生成模型，以及LLaMA 3.1和Phi-4两个评估智能体，使用AMA医学伦理原则和五级安全风险评估协议评估响应，通过结构化迭代对齐进行优化

Result: 在900个临床多样化查询中，DeepSeek R1收敛更快（平均2.34 vs 2.67次迭代），Med-PaLM在隐私敏感场景表现更优；多智能体迭代循环实现89%的伦理违规减少和92%的风险降级率

Conclusion: 该研究提出了一个可扩展、符合监管要求且成本效益高的医疗AI安全治理范式，为医疗大语言模型的临床部署提供了有效的安全保障框架

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [333] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一种新型的肽结合剂生成器，通过连续潜在空间直接生成结合序列，无需结构预测，提高了序列多样性


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法过度依赖中间结构预测，增加了复杂性并限制了序列多样性，需要一种更直接、更灵活的方法

Method: 基于预训练蛋白质嵌入模型的连续潜在空间，通过潜在空间探索和扩散采样直接生成肽结合序列，不依赖预测结构

Result: 在TIGIT等挑战性目标上优于现有方法，证明了其作为零样本肽结合剂设计的通用无结构框架的潜力

Conclusion: PepEDiff提供了一种简单有效的肽结合剂设计方法，通过直接序列生成避免了结构预测的复杂性，在治疗和生化应用中具有重要价值

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [334] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模扩大不会均匀提升推理能力，而是重构推理过程。在不同领域（法律、科学、代码、数学）观察到不同的几何相变模式，并提出了神经推理算子来加速推理。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型规模扩大能均匀提升推理能力，但本研究旨在探索规模扩大如何真正影响不同领域的推理过程，揭示其内在的几何结构变化。

Method: 分析了25,000+条思维链轨迹，涵盖四个领域（法律、科学、代码、数学）和两种规模（8B和70B参数）。使用几何分析方法，包括表示维度、轨迹对齐和流形解缠。提出了神经推理算子，学习从初始到最终隐藏状态的映射。

Result: 发现不同领域呈现不同的相变模式：法律推理发生"结晶化"（维度减少45%，轨迹对齐增加31%，流形解缠10倍）；科学和数学推理保持"液态"（几何不变）；代码推理形成"晶格"结构。神经推理算子在法律推理上达到63.6%的准确率。还发现了跨领域和规模的普遍振荡特征。

Conclusion: 推理成本由流形几何而非任务难度决定，这为在拓扑允许的情况下加速推理提供了蓝图。模型规模扩大通过领域特定的相变重构推理过程，而非均匀提升能力。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [335] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge是一个轻量级开源Python框架，通过模块化架构简化LLM驱动的自主代理开发，提供可组合技能、统一LLM后端接口和声明式配置系统，显著减少开发时间。


<details>
  <summary>Details</summary>
Motivation: 现有代理框架存在架构僵化、供应商锁定和复杂度高等问题，阻碍了快速原型设计和部署。需要一种能够民主化自主代理构建的解决方案。

Method: 提出AgentForge框架，包含三个核心创新：1) 可组合技能抽象，支持细粒度任务分解和形式化输入输出契约；2) 统一LLM后端接口，支持云端API和本地推理引擎无缝切换；3) 基于YAML的声明式配置系统，分离代理逻辑与实现细节。将技能组合机制形式化为有向无环图(DAG)。

Result: 在四个基准场景的评估中，AgentForge实现了竞争力的任务完成率，相比LangChain减少62%开发时间，相比直接API集成减少78%开发时间。编排延迟低于100ms，适合实时应用。框架集成了六个内置技能，支持自定义技能开发。

Conclusion: AgentForge填补了LLM代理生态系统的关键空白，为研究人员和从业者提供了生产就绪的基础设施，用于构建、评估和部署自主代理，同时不牺牲灵活性或性能。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [336] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 论文提出显式认知分配原则，通过分离和组织认知功能来结构化AI辅助推理，并实现为认知通用代理架构，相比传统LLM推理具有更好的可追溯性和认知控制。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的使用方式存在认知结构缺失问题：问题框架、知识探索、检索、方法意识和解释通常被压缩到单一生成过程中。这种认知崩溃限制了可追溯性，削弱了认知控制，并破坏了可重复性，特别是在高责任环境中。

Method: 提出显式认知分配原则，并将其实例化为认知通用代理架构。该架构将推理组织为不同的阶段：探索与框架、认知锚定、工具与方法映射、解释性综合。核心是通用认知工具概念，形式化各种工具手段。

Result: 在农业领域的多个提示测试中，CUA推理表现出更早且结构化的认知收敛、在语义扩展下更高的认知对齐度，以及系统性地暴露查询的工具性景观。相比之下，基线LLM推理在一致性方面表现出更大的变异性，且未能明确展示工具结构。

Conclusion: 显式认知分配原则和CUA架构能够显著改善AI辅助推理的结构化程度，增强可追溯性、认知控制和可重复性，为高责任环境中的AI辅助推理提供了更可靠的框架。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [337] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: 提出了SpatialBench-UC基准，用于评估文本到图像模型在空间关系指令上的表现，通过选择性预测和置信度报告来解决自动化评估的困难。


<details>
  <summary>Details</summary>
Motivation: 评估文本到图像模型是否遵循明确的空间指令难以自动化，因为物体检测器可能漏检或返回多个可能检测，简单的几何测试在边界情况下变得模糊。

Method: 引入SpatialBench-UC基准，包含200个提示（50个物体对×4种关系），分为100个反事实对。提供基准包、版本化提示、固定配置、每样本检查器输出和报告表格，实现可复现和可审计的模型比较。

Result: 评估了三个基线模型：Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN。检查器报告通过率和覆盖率以及在决定样本上的条件通过率。结果显示，接地方法显著提高了通过率和覆盖率，但弃权仍然是主要因素，主要是由于漏检。

Conclusion: SpatialBench-UC为空间关系评估提供了一个可复现的基准，通过选择性预测和置信度报告使结果能够解释为风险覆盖权衡而非单一分数。接地方法能改善性能，但检测可靠性仍然是关键挑战。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [338] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 提出基于上下文和文本转录的音频深度伪造检测器CADD，通过整合上下文信息显著提升检测性能，并对抗攻击具有更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前音频深度伪造检测器仅分析音频文件本身，忽略了人类判断真伪时依赖的上下文信息和文本内容，这限制了检测效果。

Method: 创建了记者提供的深度伪造数据集JDD和合成音频数据集SYN，提出了基于上下文的音频深度伪造检测器CADD架构，整合上下文和文本转录信息。

Result: 上下文和文本转录显著提升检测性能：F1分数提升5%-37.58%，AUC提升3.77%-42.79%，EER提升6.17%-47.83%。CADD对5种对抗攻击策略具有更强鲁棒性，性能下降平均仅-0.71%。

Conclusion: 整合上下文和文本转录信息能显著提高音频深度伪造检测器的性能和鲁棒性，为更有效的检测方法提供了新方向。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [339] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 单训练轨迹可将图神经网络转化为组合优化的无监督启发式算法，用于旅行商问题，无需搜索、监督或序列决策


<details>
  <summary>Details</summary>
Motivation: 探索图神经网络能否在不依赖监督训练或显式搜索的情况下，直接学习组合优化问题的全局结构约束，并作为有效的启发式算法

Method: 将全局结构约束作为归纳偏置编码到非自回归模型中，通过前向传播直接生成解；推理时使用dropout和快照集成，使单个模型作为隐式集成

Result: 图神经网络无需监督训练或显式搜索即可有效工作，能够内化全局组合结构并作为强大的学习启发式算法

Conclusion: 重新定义了学习在组合优化中的作用：从增强经典算法转变为直接实例化新的启发式算法

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [340] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个自动化提示优化框架，通过多智能体协作系统探索更精细的提示空间，提升LLM在心理健康领域情感诊断的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 心理健康领域的情感表达在临床记录、咨询对话和在线社区中普遍存在，准确识别这些情感对临床分诊、风险评估和及时干预至关重要。现有方法面临两个关键挑战：情感共病（多种交织情感状态使预测复杂化）和临床相关线索的低效探索。

Method: APOLO将指令优化建模为部分可观测马尔可夫决策过程，采用多智能体协作机制，包括规划器、教师、批评者、学生和目标角色。规划器定义优化轨迹，教师-批评者-学生智能体迭代优化提示以增强推理稳定性和有效性，目标智能体根据性能评估决定是否继续优化。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中持续提高了诊断准确性和鲁棒性，展示了在心理健康领域可信赖LLM应用的可扩展和通用范式。

Conclusion: APOLO为高风险的、上下文密集的医疗环境中LLM的情感诊断提供了系统化的提示优化框架，解决了情感共病和临床线索探索效率低的问题，提高了LLM在心理健康应用的可靠性和可扩展性。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [341] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed：一种利用LLM上下文学习自动设计和优化红队系统的框架，无需人工干预，通过进化选择方法显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队方法依赖人工设计的工作流程，存在人为偏见且探索设计空间成本高昂，需要一种能够自动设计和优化红队系统的方法

Method: 将红队视为系统设计问题，利用LLM的上下文学习能力，通过进化选择方法迭代设计和优化红队系统，无需人工干预

Result: 在Llama-2-7B上达到96%攻击成功率（提升36%），在Llama-3-8B上达到98%，在GPT-3.5-Turbo和GPT-4o-mini上达到100%，在Claude-Sonnet-3.5上达到60%（提升24%）

Conclusion: 自动化系统设计是AI安全评估的强大范式，能够跟上快速发展的模型步伐，为红队测试提供了更高效、无偏见的解决方案

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [342] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR推荐模型通过熵引导的潜在推理机制，在生成式重排序中实现"边推理边推荐"，解决了传统方法难以适应列表生成中动态熵变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法大多无法适应列表生成过程中模型难度的动态熵变化，难以准确捕捉复杂偏好。受语言模型推理能力突破的启发，需要引入推理机制来降低决策过程中的熵。

Method: 提出熵引导潜在推理(EGLR)模型：1) 抛弃"先推理后推荐"范式，实现"边推理边推荐"；2) 使用上下文感知推理令牌和动态温度调整实现熵引导的变长推理；3) 采用轻量级集成设计，无需复杂独立模块或后处理。

Result: 在两个真实世界数据集上的实验验证了模型的有效性，EGLR能够与现有生成式重排序模型兼容并提升其性能，具有实际部署价值和研究潜力。

Conclusion: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现了更精确的探索-利用权衡，解决了动态熵适应问题，为推荐系统提供了有效的推理增强方案。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [343] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor是一个新颖的、可复现的评估框架，用于在真实世界高熵环境中评估LLMs作为人类模仿系统，而不仅仅是预测引擎。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试无法捕捉真实世界的不确定性、分布偏移以及孤立任务准确性与人类对齐决策之间的差距，需要新的评估范式。

Method: 基于前瞻性、无污染任务，将评估锚定在实时预测市场，结合概率评分，提供模型行为的整体视图，包括漂移中心诊断和显式鲁棒性检查。

Result: 在500+真实市场（政治、经济、文化、技术）实验中，TruthTensor显示具有相似预测准确性的模型在校准、漂移和风险敏感性方面存在显著差异。

Conclusion: TruthTensor通过多维度评估（准确性、校准、叙事稳定性、成本、资源效率）和现代评估最佳实践，为LLMs在真实世界决策环境中的评估提供了可辩护的评估框架。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [344] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 提出TSEvol多代理时间序列演化算法、TSEData-20K数据集、ChatAD系列模型、TKTO优化方法以及LLADBench基准测试，显著提升时间序列异常检测的推理能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的异常检测方法存在推理能力不足、多轮对话能力欠缺和泛化能力有限的问题，需要提升时间序列异常行为的理解和解释能力。

Method: 1) 提出TSEvol多代理时间序列演化算法；2) 构建TSEData-20K数据集和ChatAD系列模型；3) 提出TKTO优化方法增强跨任务泛化；4) 建立LLADBench基准测试框架。

Result: ChatAD模型在准确率提升34.50%、F1分数提升34.71%、误报率降低37.42%；通过TKTO优化，在分类、预测和插补任务上获得竞争力的推理和跨任务泛化性能。

Conclusion: 提出的多代理框架、数据集、模型和优化方法有效解决了现有LLM异常检测方法的局限性，显著提升了时间序列异常检测的推理能力和泛化性能。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [345] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 利用社交媒体和约会应用文本数据，通过机器学习模型预测男男性行为者的性风险行为、酒精使用和PrEP使用情况，取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 男男性行为者（MSM）面临性传播感染和有害饮酒的较高风险。社交媒体和约会应用中的文本数据可能为个性化公共卫生干预提供新机会，通过自动识别风险和保护行为。

Method: 收集参与者同意的文本数据，使用ChatGPT嵌入、BERT嵌入、LIWC和基于词典的风险术语方法提取特征，训练机器学习模型预测性风险行为、酒精使用和PrEP使用。

Result: 模型在预测每月暴饮和超过5个性伴侣方面表现优异（F1分数0.78），在预测PrEP使用和重度饮酒方面表现中等（F1分数0.64和0.63）。

Conclusion: 社交媒体和约会应用文本数据能为风险和保护行为提供有价值的洞察，基于大语言模型的方法有潜力支持针对MSM的可扩展和个性化公共卫生干预。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [346] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC是一个基于智能体的基因组数据无损压缩系统，通过三层架构和多智能体设计解决现有方法的低效建模、适应性差和用户界面不友好问题，在压缩比和吞吐量上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的基因组数据压缩方法存在三个主要问题：1）非进化性，无法适应不断发展的需求；2）低层次的压缩建模，缺乏高级优化；3）有限的适应性和用户不友好的界面。需要一种能够联合优化算法-数据集-系统的智能压缩解决方案。

Method: 提出AgentGC，首个基于智能体的进化式基因组数据压缩器，采用三层架构：1）用户层：通过Leader智能体结合LLM提供友好界面；2）认知层：由Leader驱动，集成LLM考虑算法-数据集-系统的联合优化；3）压缩层：由Worker智能体负责，通过自动化多知识学习框架执行压缩和解压缩。提供三种模式：CP（压缩比优先）、TP（吞吐量优先）、BM（平衡模式）。

Result: 在9个数据集上与14个基线方法比较：三种模式（CP、TP、BM）的平均压缩比增益分别为16.66%、16.11%、16.33%；吞吐量增益分别为4.73倍、9.23倍、9.15倍。在所有指标上均显著优于现有方法。

Conclusion: AgentGC通过智能体架构和LLM集成，成功解决了基因组数据压缩中的关键挑战，实现了压缩性能和用户体验的显著提升，为基因组数据存储、共享和管理提供了高效的进化式解决方案。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [347] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 本文提出了一种角色分离的Transformer架构，将全局控制器token与网格工作空间token分离，用于解决ARC抽象推理任务，在ARC-1上达到62.6%准确率，超过人类平均表现。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，通过建模token统计来匹配可观察行为，缺乏持久、可读的思维状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行为，而AI系统只能产生流畅的事后合理化解释，这些解释并不基于这样的内部状态。作者假设推理是一种模态：推理应该作为一个独立的通道存在，与规则应用的低级工作空间分离。

Method: 设计了一种新颖的角色分离Transformer块，将全局控制器token与网格工作空间token分离，支持迭代规则执行。该方法在VARC视觉中心协议下进行训练和评估，用于解决ARC任务作为视觉推理问题。

Result: 在ARC-1任务上达到62.6%的准确率，超过了人类平均表现（60.2%），并显著优于先前方法。定性分析显示，与密集ViT基线相比，模型展现出更连贯的规则应用结构，符合从概率斑块向控制器驱动推理的转变。

Conclusion: 研究支持了推理作为一种独立模态的假设，通过分离控制器和工作空间token的架构设计，在抽象推理任务上实现了超越人类的表现，为AI系统实现更类似人类的可解释推理提供了新方向。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [348] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个基于LLM的诈骗检测框架，通过犯罪脚本推理、数据集构建和认知模拟评估，显著提升诈骗检测性能并增强用户认知警觉性。


<details>
  <summary>Details</summary>
Motivation: 社交工程诈骗日益采用个性化、多轮对话的欺骗手段，传统检测方法效果有限。虽然大语言模型在识别欺骗方面有潜力，但其认知辅助能力尚未充分探索。

Method: 提出ScriptMind集成框架，包含三个组件：犯罪脚本推理任务（CSIT）用于诈骗推理、犯罪脚本感知推理数据集（CSID）用于微调小型LLM、认知模拟评估（CSED）用于评估实时认知影响。基于571个韩国电话诈骗案例构建了22,712个结构化诈骗序列训练实例。

Result: 使用ScriptMind微调的11B小型LLM在检测准确率上比GPT-4o高出13%，在检测准确性、误报减少、诈骗者话语预测和推理质量方面优于商业模型。在电话诈骗模拟实验中，显著提升并维持了用户的怀疑水平，增强了他们对诈骗的认知意识。

Conclusion: ScriptMind代表了向以人为本、认知自适应的大语言模型在诈骗防御领域迈出的重要一步，展示了LLM在增强人类认知警觉性方面的潜力。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [349] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 该论文提出了一种基于音频情感信号的多代理AI系统，能够实时生成响应导向的媒体内容，通过四个协作代理实现情感识别到安全可控内容的转换。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，但缺乏将识别出的情感状态转化为安全、适龄、可控的响应内容的能力。需要一种能够实时处理情感信号并生成适当媒体响应的系统。

Method: 采用四代理协作架构：1)基于CNN的情感识别代理提取声学特征；2)响应策略决策代理将情感映射到响应模式；3)内容参数生成代理产生媒体控制参数；4)安全验证代理确保内容适龄性和安全性。引入显式安全验证循环过滤生成内容。

Result: 在公开数据集上，系统达到73.2%的情感识别准确率、89.4%的响应模式一致性、100%的安全合规性，同时保持低于100ms的推理延迟，适合设备端部署。

Conclusion: 该模块化系统实现了从情感识别到安全内容生成的完整流程，具有可解释性和可扩展性，适用于儿童媒体、治疗应用和情感响应智能设备等领域。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [350] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: DSAEval是一个包含641个真实世界数据科学问题的基准测试，基于285个多样化数据集，涵盖结构化和非结构化数据，具有多模态环境感知、多查询交互和多维度评估三大特点。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的数据代理旨在自动化数据科学任务，但真实世界数据科学问题的开放性、跨分类和缺乏标准答案的特性给评估带来了重大挑战。

Method: 提出DSAEval基准测试，包含641个真实世界数据科学问题，基于285个多样化数据集，涵盖结构化和非结构化数据（如视觉和文本）。该基准具有三大特点：1）多模态环境感知，使代理能够解释文本和视觉等多种模态的观察；2）多查询交互，反映真实世界数据科学项目的迭代和累积性质；3）多维度评估，在推理、代码和结果方面提供全面评估。

Result: 评估了11个先进的代理LLM，结果显示：Claude-Sonnet-4.5整体性能最强，GPT-5.2最有效率，MiMo-V2-Flash最具成本效益。多模态感知在视觉相关任务上持续提升性能，提升幅度从2.04%到11.30%。当前数据科学代理在结构化数据和常规数据分析工作流程上表现良好，但在非结构化领域仍面临重大挑战。

Conclusion: DSAEval为评估数据科学代理提供了一个全面的基准测试框架。虽然当前代理在结构化数据任务上表现良好，但在非结构化领域仍需改进。多模态感知能力对性能提升有显著帮助。作者提供了关键见解并概述了未来研究方向，以推动数据科学代理的发展。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [351] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 提出自适应分治算法检测自然语言事实集合的全局一致性，通过识别最小不一致子集和计算最小修复，在多项式查询复杂度下解决LLM一致性验证的指数级难题。


<details>
  <summary>Details</summary>
Motivation: 自然语言事实集合的全局一致性对于事实核查、摘要和知识库构建等任务至关重要。虽然大语言模型可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查无法保证全局一致性。

Method: 提出自适应分治算法，识别事实的最小不一致子集，可选地通过命中集计算最小修复。该方法具有低阶多项式查询复杂度，适用于LLM评估器。

Result: 实验表明，该方法在合成和真实LLM评估器上都能高效检测和定位不一致性，为基于LLM的语言一致性验证提供了可扩展框架。

Conclusion: 通过自适应分治算法解决了自然语言事实集合全局一致性验证的指数级复杂度问题，为LLM驱动的语言一致性检查提供了实用且可扩展的解决方案。

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [352] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 提出RADR框架，结合时空图神经网络与组合优化，通过预测拥堵风险实现动态路径规划，在保持运输距离仅增加2.1%的情况下降低19.3%的拥堵风险暴露。


<details>
  <summary>Details</summary>
Motivation: 电子商务快速发展给物流网络带来巨大压力，传统静态路由策略无法应对交通拥堵和需求波动，需要更智能的动态路由方案。

Method: 1) 使用空间聚类方法从离散GPS数据构建物流拓扑图；2) 采用GCN+GRU混合深度学习模型提取时空特征预测未来拥堵风险；3) 将预测结果集成到动态边权重机制中进行路径规划。

Result: 在Smart Logistics Dataset 2024上验证，RADR算法显著增强供应链韧性。在高拥堵场景下，潜在拥堵风险暴露降低19.3%，而运输距离仅增加2.1%。

Conclusion: 提出的数据驱动方法能有效平衡配送效率和运营安全，为物流网络动态路由提供了有效解决方案。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [353] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange是一个新的动态心智理论基准测试，要求语言模型在社交互动中主动改变他人心理状态，而不仅仅是追踪心理状态，测试显示当前LLM表现比人类低54.2%


<details>
  <summary>Details</summary>
Motivation: 现有动态心智理论基准测试大多让语言模型处于被动角色——读取场景并报告心理状态变化。但在真实社交互动中，心智理论也用于行动：说话者计划说什么来改变他人的心理状态轨迹以实现目标。需要从追踪心理状态转向改变心理状态的基准测试。

Method: 引入SocialMindChange基准测试，每个实例定义包含4个角色的社交情境和五个相连场景。模型扮演一个角色，在五个场景中生成对话以达到目标，同时保持与所有参与者不断变化的状态一致。使用结构化四步框架构建了1,200个社交情境，覆盖6,000个场景和超过90,000个问题，每个都经过真实性和质量验证。

Result: 对十个最先进的大语言模型进行评估，结果显示它们的平均性能比人类性能低54.2%。这个差距表明当前的大语言模型在长期、相连的互动中维护和改变心理状态表征方面仍然存在困难。

Conclusion: SocialMindChange基准测试将心智理论研究从被动追踪转向主动改变，揭示了当前大语言模型在复杂社交互动中理解和影响心理状态的能力存在显著不足，为未来模型发展提供了重要方向。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [354] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: GPT-4o在社交推理游戏《黑手党》中比人类更擅长欺骗，通过异步多智能体框架模拟真实社交环境，检测器对LLM游戏的预测准确率低于人类游戏。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在自然语言社交环境中的欺骗能力，特别是在社交推理游戏《黑手党》中，评估LLM在需要欺骗他人的对话场景中的表现，以了解LLM在现实社交环境中的安全风险。

Method: 使用异步多智能体框架模拟35场《黑手党》游戏，让GPT-4o智能体参与游戏；创建基于GPT-4-Turbo的"黑手党检测器"，在不了解玩家角色的情况下分析游戏记录来预测黑手党玩家；将预测准确率作为欺骗质量的替代指标，并与28场人类游戏和随机基线进行比较。

Result: 黑手党检测器对LLM游戏的预测准确率低于人类游戏，这一结果在不同游戏天数和检测到的黑手党数量上保持一致，表明LLM能更好地融入群体，欺骗效果更佳。

Conclusion: LLM在社交环境中的欺骗能力比人类更出色，这突显了LLM在社交环境中的复杂性和潜在风险，研究团队还发布了LLM黑手党游戏记录数据集以支持未来研究。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [355] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现当前基于概率的置信度指标无法有效捕捉推理步骤间的因果依赖关系，主要反映表面流畅度而非逻辑结构，提出了新的对比因果度量方法


<details>
  <summary>Details</summary>
Motivation: 挑战当前广泛采用的假设：概率置信度指标能反映推理质量。研究者质疑这些指标是否真正捕捉了推理步骤间的因果依赖关系，这是有效推理的必要条件

Method: 引入三类步骤间因果扰动，系统性地破坏推理步骤间的依赖关系但保持局部流畅度。在不同模型家族和推理基准上进行测试，并提出了对比因果度量方法

Result: 令人惊讶的是，即使在严重干扰下（如硬注意力掩码阻止模型关注先前推理步骤），选择准确率仅略微下降。这表明当前概率指标主要捕捉表面流畅度而非逻辑结构

Conclusion: 当前概率置信度指标对逻辑结构不敏感，主要反映表面特征。提出的对比因果度量方法能更忠实地进行输出选择，优于现有基于概率的方法

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [356] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: 提出RELIEF框架，通过调整大推理模型的"推理信念"来塑造其行为，无需推理轨迹监督，降低训练成本


<details>
  <summary>Details</summary>
Motivation: 现有大推理模型存在计算冗余或推理不忠实问题，传统基于强化学习或黄金推理轨迹微调的方法计算成本高且难以扩展

Method: 发现大推理模型具有潜在的"推理信念"，可通过简单logit探测捕获。提出RELIEF框架，通过将模型的自我概念与目标信念蓝图对齐来塑造行为，仅需在合成的自我反思问答对上进行微调

Result: 在效率和忠实性任务上的实验表明，RELIEF匹配或优于行为监督和基于偏好的基线方法，同时训练成本更低。分析验证了改变模型的推理信念能有效塑造其实际行为

Conclusion: RELIEF提供了一种简单有效的框架，通过调整大推理模型的内部推理信念来塑造其行为，无需昂贵的推理轨迹监督，具有更好的可扩展性

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [357] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC是一个两阶段自演化解耦框架，通过难度校准的问题生成和不对称自蒸馏机制，解决了自演化的优化不稳定问题，在多个推理基准上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自演化框架存在优化不稳定问题，主要源于：(1) 提问者依赖求解器反馈的非平稳目标，(2) 求解器使用自生成伪标签带来的引导误差。需要一种更稳定的自演化方法。

Method: DARC采用两阶段解耦架构：第一阶段训练提问者根据明确难度级别和外部语料生成难度校准的问题；第二阶段使用不对称自蒸馏机制训练求解器，其中文档增强的教师生成高质量伪标签来监督无文档访问的学生求解器。

Result: DARC在9个推理基准和3个骨干模型上平均提升10.9个点，一致优于所有基线方法，且无需人工标注就能接近全监督模型的性能。

Conclusion: DARC通过解耦提问者和求解器的训练过程，解决了自演化的优化不稳定问题，证明了模型无关的自演化框架的有效性，为自改进AI提供了更稳定的解决方案。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [358] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: 提出了Look-Ahead-Bench基准测试，用于评估金融工作流中PiT大语言模型的超前偏差，通过分析不同市场周期下的性能衰减来区分真实预测能力和记忆性表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试内部超前知识，缺乏对实际场景中模型行为的评估。需要建立标准化基准来衡量金融LLMs中的时间偏差，识别适合实际部署的模型。

Method: 创建标准化基准测试，评估PiT LLMs在现实金融工作流中的超前偏差。通过分析不同时间市场周期下的性能衰减，结合多个量化基线建立性能阈值，区分真实预测能力和记忆性表现。

Result: 评估显示标准LLMs（Llama 3.1和DeepSeek 3.2）存在显著超前偏差，而PiT-Inference模型（Pitinf-Small/Medium/Large）随着规模增大展现出更好的泛化和推理能力，没有超前偏差问题。

Conclusion: 该工作为金融LLMs时间偏差的标准化评估奠定了基础，提供了识别适合实际部署模型的实用框架。PiT模型在避免超前偏差方面表现优异，为金融应用提供了可靠解决方案。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [359] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: Virtual Urbanism (VU) 是一个多模态AI驱动框架，通过合成城市复制品来量化城市身份，在东京九个区域的试点研究中实现了约81%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏计算上可处理的量化城市身份指标，需要开发能够通过AI增强分析来评估城市身份的新方法。

Method: 使用Stable Diffusion和LoRA模型生成东京九个区域的合成城市序列，排除现有方向标记以提取核心身份形成元素，通过人类评估实验验证感知合法性、量化区域级身份、推导核心身份形成元素。

Result: 合成复制品的平均识别准确率达到约81%，验证了有效性；Urban Identity Level (UIL) 指标能够评估不同区域的身份水平；语义分析揭示了文化嵌入的类型学作为核心身份形成元素。

Conclusion: Virtual Urbanism 是一个可行的AI增强城市分析框架，为自动化、多参数身份指标的发展奠定了基础。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [360] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: LifeAgentBench是一个大规模QA基准测试，用于评估LLM在长期、跨维度、多用户生活方式健康推理方面的能力，包含22,573个问题，并提出了LifeAgent作为强基线代理。


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康支持需要对异构生活方式信号进行长期跨维度推理，但当前LLM在此场景下的能力尚不明确，缺乏系统性基准测试。

Method: 引入LifeAgentBench基准测试，包含可扩展的构建流程和标准化评估协议；提出LifeAgent代理，集成多步证据检索与确定性聚合。

Result: 系统评估了11个领先LLM，识别了长期聚合和跨维度推理的关键瓶颈；LifeAgent相比两个广泛使用的基线有显著改进。

Conclusion: LifeAgentBench为评估LLM健康助手提供了可靠基准，LifeAgent展示了在现实日常场景中的潜力，基准测试已公开可用。

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [361] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: 本文提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环过程，强调通过行动自动改进推理机制，并整合人类常用思维策略，以克服LLMs在动态现实环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识表示和推理方面表现出色，但仅依赖文本数据限制了其在开放动态现实环境中的适应能力、推理结果验证和有效操作。需要一种更接近人类智能的框架来克服这些限制。

Method: 提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环内部推理过程。强调在内部推理和环境交互中的主动参与，利用行动不仅实现目标，还自动改进推理机制。整合人类常用思维策略，如主特征导向推理、通过行动扩展范围、环境反馈驱动的即时学习等。

Result: 通过理论分析表明，人类模拟策略无法仅从语言材料中完全学习，人类式推理过程和基于行动的推理方法对于在现实环境中实现稳健适应和有效交互至关重要。

Conclusion: HSC框架为解决LLMs在动态现实环境中的局限性提供了新方向，强调主动参与、闭环学习和行动驱动的推理改进，为实现更强大的人工智能系统奠定了基础。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [362] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低成本回顾式自标注方法，通过检测情感变化区域而非完整标注来降低标注负担，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 传统完整自标注方法耗时、认知负荷高、易疲劳且易出错，需要一种更高效的标注方法来降低负担同时保持数据质量。

Method: 基于峰终法则和情感序数表示，采用偏好学习模型检测相对情感变化，指导标注者只标注选定片段，其余部分通过插值完成，并引入预览机制提供上下文线索。

Result: PREFAB在建模情感变化方面优于基线方法，减轻了工作负担（有条件地减轻时间负担），提高标注者信心且不降低标注质量。

Conclusion: PREFAB提供了一种有效的低预算情感标注方法，通过聚焦情感变化区域而非完整标注，在保持数据质量的同时显著降低标注负担。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [363] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK是一个自适应知识图谱检索器，通过语言模型控制广度-深度权衡，使用全局搜索和邻域探索两种操作，无需训练即可实现多跳检索，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱检索方法存在局限性：基于相似性的检索器覆盖广但深度浅，基于遍历的方法依赖种子节点选择且在多实体多关系查询中容易失败。需要一种能自适应平衡广度与深度检索的方法。

Method: ARK采用代理式知识图谱检索器，让语言模型通过两种操作控制检索：1) 全局词法搜索节点描述符（广度优先），2) 一跳邻域探索（深度优先）。这两种操作可组合实现多跳遍历，无需依赖脆弱的种子选择、预设跳数或检索训练。

Result: 在STaRK基准测试中，ARK达到59.1%的平均Hit@1和67.4的平均MRR，比检索基线和无训练代理方法提升高达31.4%的Hit@1和28.0%的MRR。通过从大教师模型蒸馏到8B模型，在AMAZON、MAG和PRIME数据集上分别比基础8B模型提升+7.0、+26.6和+13.5个绝对百分点的Hit@1，同时保留高达98.5%的教师性能。

Conclusion: ARK通过自适应平衡广度与深度检索，无需训练即可实现高效的知识图谱多跳检索。其工具使用轨迹可蒸馏到较小模型，保持高性能的同时显著提升效率。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [364] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 提出使用通用编码智能体作为形式数学推理器的新范式，通过Numina-Lean-Agent实现与Lean交互，在Putnam 2025中取得12/12全解成绩，并成功形式化Brascamp-Lieb定理。


<details>
  <summary>Details</summary>
Motivation: 现有基于任务特定流程和训练形式证明器的方法灵活性差、可复现性低。通用编码智能体提供超越证明的多样化推理任务接口，仅替换基础模型即可提升性能，且MCP支持灵活扩展和自主调用专用工具。

Method: 结合Claude Code与Numina-Lean-MCP，实现与Lean的自主交互、相关定理检索、非形式化证明和辅助推理工具调用。使用Claude Opus 4.5作为基础模型。

Result: Numina-Lean-Agent在Putnam 2025中解决所有12个问题，匹配最佳闭源系统性能。此外，通过与数学家合作成功形式化了Brascamp-Lieb定理。

Conclusion: 通用编码智能体作为形式数学推理器的新范式具有强大潜力，Numina-Lean-Agent展示了其在定理证明和形式化数学方面的通用性和有效性。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [365] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 该论文提出认知的统一框架：所有智能系统（从生物到人工）都通过"嵌入空间重映射"和"空间导航"这两个不变原则来解决问题，通过迭代误差最小化实现自适应智能。


<details>
  <summary>Details</summary>
Motivation: 寻求不同起源、组成和基质的智能体（从亚细胞化学网络到生物群体）问题解决的统一视角，发现跨尺度的决策不变原则，建立自然与合成系统认知的通用理解框架。

Method: 提出认知的双重不变原则分析框架：(1)嵌入空间的重映射（从转录、形态到数据潜在表示），(2)在这些空间中的导航（通过分布式误差校正或迭代精炼）。比较生物系统（细胞、生物体）与AI系统（Transformer、扩散模型）的认知过程。

Result: 发现生物系统（维持稳态、结构再生）和AI系统（潜在嵌入、上下文精炼）都遵循相同的认知机制：通过迭代误差最小化进行嵌入空间的重映射和导航，这构成了基质独立的不变认知原则。

Conclusion: 重映射和导航嵌入空间的二元原则是认知的基质不变不变量，这一认识不仅揭示了生命系统与人工模型之间的深层相似性，还为跨尺度工程化自适应智能提供了统一框架。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [366] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent：首个多智能体框架，将反驳生成重构为以证据为中心的规划任务，通过分解反馈、构建混合上下文和集成外部搜索，确保每个论点都有明确证据支撑，在覆盖度、忠实度和策略连贯性上优于基线。


<details>
  <summary>Details</summary>
Motivation: 撰写有效的反驳信是一项高风险任务，需要精确对齐审稿人意图和稿件细节。现有解决方案通常将其视为直接文本生成问题，存在幻觉、忽视批评意见和缺乏可验证基础等问题。

Method: 提出RebuttalAgent多智能体框架：1）将复杂反馈分解为原子化关注点；2）通过合成压缩摘要和高保真文本动态构建混合上下文；3）集成自主按需外部搜索模块以解决需要外部文献的关注点；4）在起草前生成可检查的响应计划。

Result: 在提出的RebuttalBench上验证，该流程在覆盖度、忠实度和策略连贯性方面优于强基线，为同行评审过程提供了透明可控的助手。

Conclusion: RebuttalAgent通过将反驳生成重构为证据中心规划任务，解决了现有方法的局限性，提供了透明可控的同行评审助手，代码将开源。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [367] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型智能体系统的效率问题，从记忆、工具学习和规划三个核心组件出发，分析成本（延迟、token数、步骤数等），并探讨效率与效果的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 近年来，将大型语言模型扩展为智能体系统受到广泛关注。虽然智能体的效果不断提升，但实际部署中至关重要的效率问题却常被忽视。本文旨在对智能体系统本身的效率进行综合研究。

Method: 从智能体的三个核心组件（记忆、工具学习、规划）出发，综述了多种提升效率的方法，包括：通过压缩和管理限制上下文、设计强化学习奖励以减少工具调用、采用受控搜索机制等。将效率特征化为两种互补方式：固定成本预算下的效果比较，以及可比效果水平下的成本比较。

Result: 总结了这些组件的评估协议，整合了基准和方法研究中常用的效率指标。从效果与成本的帕累托前沿角度审视了效率与效果的权衡关系。

Conclusion: 讨论了关键挑战和未来方向，旨在为智能体系统的效率优化提供有前景的见解，促进更高效的智能体系统在实际应用中的部署。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [368] [MuseAgent-1: Interactive Grounded Multimodal Understanding of Music Scores and Performance Audio](https://arxiv.org/abs/2601.11968)
*Qihao Zhao,Yunqi Cao,Yangyu Huang,Hui Yi Leong,Fan Zhang,Kim-Hui Yap,Wei Hu*

Main category: cs.MM

TL;DR: MuseAgent是一个音乐中心的多模态代理，通过整合乐谱图像识别和音频转录模块，增强语言模型对音乐的理解能力，并在新基准MuseBench上显著优于现有MLLMs。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在音乐理解方面能力有限，因为音乐理解需要对符号乐谱和表演音频进行基础推理，而通用MLLMs由于感知基础不足而难以处理这些任务。

Method: 引入MuseAgent音乐中心多模态代理，通过整合光学音乐识别和自动音乐转录模块，从乐谱图像和表演音频中提取结构化符号表示，增强语言模型进行多步推理和交互的能力。

Result: 实验表明，现有MLLMs在音乐理解任务上表现不佳，而MuseAgent在这些任务上取得了显著改进，突显了结构化多模态基础对交互式音乐理解的重要性。

Conclusion: 结构化多模态基础对于交互式音乐理解至关重要，MuseAgent通过整合符号表示和音频转录模块，显著提升了音乐理解能力，为音乐AI领域提供了新的解决方案。

Abstract: Despite recent advances in multimodal large language models (MLLMs), their ability to understand and interact with music remains limited. Music understanding requires grounded reasoning over symbolic scores and expressive performance audio, which general-purpose MLLMs often fail to handle due to insufficient perceptual grounding. We introduce MuseAgent, a music-centric multimodal agent that augments language models with structured symbolic representations derived from sheet music images and performance audio. By integrating optical music recognition and automatic music transcription modules, MuseAgent enables multi-step reasoning and interaction over fine-grained musical content. To systematically evaluate music understanding capabilities, we further propose MuseBench, a benchmark covering music theory reasoning, score interpretation, and performance-level analysis across text, image, and audio modalities. Experiments show that existing MLLMs perform poorly on these tasks, while MuseAgent achieves substantial improvements, highlighting the importance of structured multimodal grounding for interactive music understanding.

</details>


### [369] [Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs](https://arxiv.org/abs/2601.11995)
*Donghuo Zeng,Hao Niu,Yanan Wang,Masato Taya*

Main category: cs.MM

TL;DR: 提出一个通过软标签预测和推断潜在交互来学习鲁棒音视频嵌入的框架，解决传统对比学习方法中因稀疏标注导致的假负例问题。


<details>
  <summary>Details</summary>
Motivation: 传统音视频嵌入学习方法使用稀疏标注，将未标注但共现的事件视为负例，导致假负例问题，错失跨模态依赖关系。需要更精细的方法来处理共现但未标注的事件。

Method: 提出三部分框架：1) AV-SAL损失训练教师网络产生跨模态对齐的软标签分布；2) ILI图应用GRaSP算法推断类别间的稀疏有向依赖图；3) LIR正则化指导学生网络学习，根据软标签概率拉近依赖链接的嵌入。

Result: 在AVE和VEGAS基准测试上，平均精度均值(mAP)持续提升，表明整合推断的潜在交互到嵌入学习中增强了鲁棒性和语义一致性。

Conclusion: 通过软标签和推断的潜在交互，能够更好地处理未标注的共现事件，学习更鲁棒和语义一致的多模态嵌入，超越传统稀疏标注方法。

Abstract: Learning robust audio-visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences - background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. For example, a video labeled "train" might also contain motorcycle audio and visual, because "motorcycle" is not the chosen annotation; standard methods treat these co-occurrences as negatives to true motorcycle anchors elsewhere, creating false negatives and missing true cross-modal dependencies. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio-Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies (e.g., "Train (visual)" -> "Motorcycle (audio)") that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (mAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.

</details>


### [370] [Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring](https://arxiv.org/abs/2601.13879)
*Dongxu Zhang,Yiding Sun,Cheng Tan,Wenbiao Yan,Ning Yang,Jihua Zhu,Hiajun Zhang*

Main category: cs.MM

TL;DR: V-Skip：一种基于视觉锚定信息瓶颈的token剪枝方法，解决多模态大语言模型中CoT推理的延迟问题，避免视觉遗忘现象，实现2.9倍加速且精度损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型中的CoT推理虽然提升性能，但其自回归特性导致严重的延迟问题。现有的token压缩方法盲目应用文本中心指标，在多模态场景中容易引发"视觉遗忘"问题——即错误剪枝语言冗余但视觉重要的token，导致幻觉。

Method: 提出V-Skip方法，将token剪枝重新表述为视觉锚定信息瓶颈优化问题。采用双路径门控机制，通过语言惊奇度和跨模态注意力流共同权衡token重要性，有效保留视觉显著锚点。

Result: 在Qwen2-VL和Llama-3.2系列模型上的实验表明，V-Skip实现2.9倍加速，精度损失可忽略。特别在DocVQA上，比其他基线方法提升超过30%，有效保留了细粒度视觉细节。

Conclusion: V-Skip通过视觉锚定信息瓶颈方法解决了多模态CoT推理中的延迟问题，避免了视觉遗忘现象，在保持精度的同时显著提升推理速度，为多模态大语言模型的高效部署提供了有效解决方案。

Abstract: While Chain-of-Thought (CoT) reasoning significantly enhances the performance of Multimodal Large Language Models (MLLMs), its autoregressive nature incurs prohibitive latency constraints. Current efforts to mitigate this via token compression often fail by blindly applying text-centric metrics to multimodal contexts. We identify a critical failure mode termed Visual Amnesia, where linguistically redundant tokens are erroneously pruned, leading to hallucinations. To address this, we introduce V-Skip that reformulates token pruning as a Visual-Anchored Information Bottleneck (VA-IB) optimization problem. V-Skip employs a dual-path gating mechanism that weighs token importance through both linguistic surprisal and cross-modal attention flow, effectively rescuing visually salient anchors. Extensive experiments on Qwen2-VL and Llama-3.2 families demonstrate that V-Skip achieves a $2.9\times$ speedup with negligible accuracy loss. Specifically, it preserves fine-grained visual details, outperforming other baselines over 30\% on the DocVQA.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [371] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: CSyMR-Bench是一个用于评估LLMs在组合式符号音乐推理能力的新基准，包含126个需要结合多个原子分析的多选题，并提出了基于music21工具增强的代理框架来应对这一挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注孤立的知识或原子分析，缺乏评估LLMs在连接音乐结构、进行组合式推理的能力，而这是音乐创作和理解的核心。

Method: 1. 创建CSyMR-Bench基准：从专家论坛和专业考试中收集126个多选题，每个问题都需要结合多个原子分析；2. 提出工具增强代理框架：利用music21库中的符号音乐分析工具来辅助LLMs解决组合推理问题。

Result: CSyMR-Bench对现有模型构成非平凡挑战，而提出的工具增强代理框架在所有基线方法中表现最佳，实现了5-7%的绝对准确率提升。

Conclusion: 组合式符号音乐推理是LLMs在音乐领域的重要挑战，工具增强方法能有效提升性能，CSyMR-Bench为评估这一能力提供了有价值的基准。

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [372] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL通过动态调整梯度分割的超参数（子空间比例ρ和更新频率T），自动优化内存使用和计算开销，在保持性能的同时显著减少LLM训练的资源需求。


<details>
  <summary>Details</summary>
Motivation: FRUGAL框架虽然能减少LLM训练的内存占用，但其静态超参数需要手动调优，成本高且适应性差。需要一种自动化方法来动态调整这些参数，以更好地平衡内存、计算和模型性能。

Method: AdaFRUGAL引入两种动态控制机制：1）对子空间比例ρ采用线性衰减策略，逐步减少内存使用；2）基于损失感知的更新频率T调度，降低计算开销。这些机制使超参数能根据训练过程自动调整。

Result: 在英文C4、越南语VietVault的大规模预训练和GLUE微调实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存使用和训练时间。

Conclusion: AdaFRUGAL提供了一种更实用、自主的解决方案，能在资源受限的情况下有效训练大型语言模型，实现了内存、计算和性能的良好平衡。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [373] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 该论文使用线性代数和哈密顿形式等数学工具分析LLM嵌入空间结构，发现L2归一化约束使嵌入空间适合哈密顿分析，建立了余弦相似度与向量扰动的关系，并探索了量子力学类比。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出离散的语义状态，表明存在离散语义表示，这启发研究者应用数学工具来分析语义关系，特别是借鉴量子力学系统的类比。

Method: 使用线性代数和哈密顿形式等数学概念分析LLM嵌入空间，特别关注L2归一化约束如何使嵌入空间适合哈密顿分析，推导余弦相似度与嵌入向量扰动的关系，探索直接和间接语义转换，并从量子力学角度推导零点能类似概念。

Result: 证明了L2归一化约束导致的结构化嵌入空间适合哈密顿形式分析，建立了余弦相似度与向量扰动的数学关系，探索了语义转换机制，并推导了量子力学类比中的零点能类似概念。

Conclusion: 虽然解释需要谨慎，但这种方法为深入理解LLM提供了有前景的途径，并可能为缓解幻觉问题提供新方法，特别是在量子力学与Koopman-von Neumann力学的潜在联系方面。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [374] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE使用Gumbel-Softmax重参数化和直通估计替代高方差的策略梯度方法，实现从奖励信号到模型参数的端到端梯度传播，在文本对齐任务中比PPO和REINFORCE表现更好且更稳定。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类反馈的强化学习（RLHF）主要使用PPO等策略梯度方法，但这些方法存在梯度估计方差高、需要精细超参数调优和大量计算资源的问题，需要更稳定高效的替代方案。

Method: 提出GRADE方法，使用Gumbel-Softmax重参数化结合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛实现直接反向传播，使奖励信号能够通过生成的token端到端传播到模型参数。

Result: 在IMDB数据集的情感控制文本生成任务中，GRADE-STE获得0.763的测试奖励，比PPO（0.510）和REINFORCE（0.617）分别提升50%；梯度方差比REINFORCE低14倍以上，训练动态更稳定，泛化性能最好。

Conclusion: GRADE为LLM对齐提供了一种更简单、更稳定、更有效的强化学习替代方案，通过可微分估计避免了高方差梯度问题，在保持训练稳定性的同时显著提升性能。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [375] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: Hindsight Preference Replay (HPR) 通过事后重新标注存储的转移数据来增强多目标强化学习，在不改变CAPQL架构的情况下提高性能


<details>
  <summary>Details</summary>
Motivation: CAPQL方法在特定偏好下收集的数据无法被其他偏好使用，导致数据利用率低，限制了学习效率

Method: 提出Hindsight Preference Replay (HPR)，一种简单的回放增强策略，通过事后重新标注存储的转移数据来使用替代偏好，从而在整个偏好单纯形上增加监督密度

Result: 在6个MO-Gymnasium运动任务中，HPR-CAPQL在5个环境中提高了超体积(HV)，在4个环境中提高了期望效用(EUM)。在mo-humanoid-v5上，EUM从323±125提升到1613±464，HV从0.52M提升到9.63M

Conclusion: HPR是一种简单有效的回放增强策略，能够显著提高多目标强化学习的性能，特别是在复杂环境中，而无需改变现有算法架构

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [376] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: MIMIC-IV多模态数据处理管道，自动化整合结构化数据、临床笔记、波形和影像数据，显著减少处理时间并提升研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态数据，但现有处理工具要么只支持部分模态，要么无法灵活适应下游应用需求，需要大量手动预处理和对齐工作。

Method: 扩展原有单模态管道，开发综合性多模态处理管道，支持自动化队列选择、跨模态时间对齐，并生成适合静态和时间序列下游应用的标准化输出格式。

Result: 发布了完整的代码库、简单UI界面和Python包，支持选择性集成和嵌入，显著减少多模态数据处理时间，增强MIMIC相关研究的可重复性。

Conclusion: 该多模态管道为MIMIC-IV数据集提供了全面、可定制的处理解决方案，能够大幅简化临床机器学习研究的数据准备工作。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [377] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型，一种神经记忆存储架构，解决LLM缺乏有效运行时记忆机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求

Method: 提出辅助预测压缩记忆模型（ApCM模型），一种新颖的神经记忆存储架构

Result: 论文提出了解决方案的架构，但摘要中未提供具体实验结果

Conclusion: ApCM模型旨在解决LLM在动态个性化交互中的记忆机制不足问题

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [378] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的基于被动传感器的人类活动识别方法，通过时间聚类和循环时间特征增强特征加权，在老年人智能家居监测中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够独立安全地在家中生活。使用被动红外传感器和门传感器等普遍存在的传感器来监测日常活动并促进预防性医疗干预变得越来越重要。然而，现有的基于被动传感器的人类活动识别方法在有效利用时间信息方面存在挑战。

Method: 1. 将活动按时间聚类为早晨、下午和晚上，并为每个时间段计算不同的互信息矩阵进行特征加权；2. 在特征向量中引入一天中的时间和一周中的天数作为循环时间特征；3. 添加用户位置跟踪特征；4. 扩展了传感器加权互信息方法以更好地利用时空信息。

Result: 在四个真实世界数据集中的三个上，该方法在准确率和F1分数上优于现有最先进方法，在数据量较少的情况下获得最高的性能提升。

Conclusion: 该方法展示了开发有效智能家居解决方案以支持老年人居家养老的潜力，通过更好地利用时间信息提高了人类活动识别的性能。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [379] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 本文综述了基于连续血糖监测数据的机器学习模型在1型糖尿病低血糖预测中的应用，比较了不同预测时间窗口下模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖（血糖低于70 mg/dL）会增加死亡风险，因此需要开发能够准确预测低血糖的机器学习模型来改善糖尿病管理。

Method: 本文对基于连续血糖监测数据的机器学习模型进行系统性综述。模型分为回归模型（预测血糖值）和分类模型（识别低血糖事件），比较了短期（15-120分钟）和长期（3-24小时以上）预测时间窗口下的性能。分析了四个关键问题：预测时间窗口、最佳模型类型、影响因素以及个性化模型的效果。

Result: 1）1小时内的预测时间窗口效果最佳；2）传统机器学习方法在分类任务中表现最好，深度学习在回归任务中表现最好，单一模型无法在多个预测时间窗口上都有良好表现；3）模型性能受多变量数据集和输入序列长度影响；4）个人数据能提升性能，但由于数据质量限制，基于人群的模型更受青睐。

Conclusion: 机器学习模型在1型糖尿病低血糖预测中具有重要应用价值，但需要根据具体预测时间窗口选择合适的模型类型，同时需要平衡个性化模型和基于人群模型的优缺点。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [380] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: MoE架构通过软分区表示空间来降低局部敏感度，增加表示的有效秩，专家Jacobian矩阵近似正交，形成低重叠的专家特定子空间分解。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何性质的影响，理解路由机制如何软分区表示空间，分析不同路由策略的几何效应。

Method: 引入双重Jacobian-PCA谱几何探针，通过Jacobian奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何，在可控MLP-MoE设置中比较密集、Top-k和全软路由架构。

Result: MoE路由一致降低局部敏感度，专家局部Jacobian具有更小的主导奇异值和更快的谱衰减；加权PCA显示专家局部表示在更多主方向上分布方差，表明在相同输入分布下具有更高的有效秩；平均专家Jacobian近似正交，表明变换分解为低重叠的专家特定子空间而非共享映射的缩放变体。

Conclusion: MoE可几何解释为函数空间的软分区，能够平坦化局部曲率同时重新分配表示方差，Top-k路由产生更低秩、更集中的专家局部结构，而全软路由产生更广泛、更高秩的表示。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [381] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 几何注意力（GA）通过四个独立输入定义注意力层：载体、证据核规则、探针族和锚点/更新规则，将不变结构与建模选择分离，为注意力机制提供统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax）缺乏统一的理论框架，难以进行系统比较和扩展。本文旨在建立几何注意力框架，将注意力层的核心组件形式化，分离不变结构与建模选择。

Method: 提出几何注意力框架，通过四个独立组件定义注意力层：有限载体（可寻址索引）、证据核规则（掩码原始分数和链接产生非负权重）、探针族（可观测量的集合）以及锚点/更新规则（选择和应用代表性核）。在标量关系工作表示和证据乘法组合律下，推导出指数链接族（Gibbs权重），包含softmax核族作为子集。

Result: 建立了注意力机制的规范形式：在商去一元行/列分数场后，剩余交互分量具有规范秩r正规形式（Eckart-Young/SVD）；点积分数图实现相应的低秩交互机制。固定载体和外部化更新得到标准Transformer注意力算子；允许载体更新产生自适应载体和分层深度机制。

Conclusion: 几何注意力框架将注意力机制的不变结构与建模选择分离，支持多头/混合核、基于计划的锚点（如熵最优传输/Sinkhorn）和一元算子等机制作为显式选择。这为注意力机制和基于注意力的架构提供了原则性的比较和扩展基础。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [382] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 提出一种名为噪声扩散对称注意力Transformer的新架构，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准测试中取得介于普通对称注意力和GPT2基础模型之间的准确率，同时显著减少模型大小。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模不断扩大，内存占用急剧增加，导致难以在单个GPU或AI加速器上部署，需要多设备计算从而增加成本。这促使了稀疏注意力等参数减少技术的发展，但现有方法如对称注意力在性能上有所妥协。

Method: 提出噪声扩散对称注意力Transformer，在对称点积注意力基础上引入噪声扩散机制，创建统一的模型架构。该方法保持对称注意力的内存优势，仅增加微小的参数和计算开销，旨在提升模型准确性和推理时采样性能。

Result: 在GPT2基础模型上验证，在多种GLUE基准任务中，性能介于普通对称注意力和GPT2基础模型之间，同时实现了相对于基础模型的显著模型大小减少。

Conclusion: 噪声扩散对称注意力Transformer在保持内存效率的同时，有效提升了稀疏注意力模型的性能，为大规模语言模型的高效部署提供了有前景的解决方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [383] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 该论文提出使用Fisher信息度量来评估PINNs对动力系统动态特性的学习质量，通过比较原始模型与PINN模型的Fisher信息景观来量化PINN的保真度。


<details>
  <summary>Details</summary>
Motivation: 当前PINNs在求解微分方程和建模物理系统方面表现出色，但缺乏严格量化PINN是否完整捕获系统动态行为（超越简单轨迹预测）的方法。需要一种评估PINN是否准确学习到系统底层动力学的方法。

Method: 提出使用Fisher信息（g_F^C）的实验框架，该信息度量确定性系统的内在不确定性（如对初始条件的敏感性），与相空间曲率和状态空间演化的净拉伸作用相关。通过计算原始分析模型和训练好的PINN的Fisher信息景观并进行比较，基于各自系统动力学的雅可比矩阵提供定量度量。

Result: 论文假设如果PINN准确学习到物理系统的底层动力学，那么从PINN学习到的运动方程导出的Fisher信息景观将与原始分析模型的信息景观紧密匹配，表明PINN不仅捕获了状态演化，还捕获了关键的几何和稳定性特性。

Conclusion: 提出的基于Fisher信息的实验框架为评估PINNs在表示系统复杂动态特性方面的保真度提供了定量方法，能够验证PINN是否全面捕获了系统的动态行为，超越了简单的轨迹预测。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [384] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 该论文提出了一种通过分数匹配获取梯度的方法，将带复杂约束的优化问题统一为无约束的分层优化目标，首次实现了使用严格梯度的确定性全局优化方法


<details>
  <summary>Details</summary>
Motivation: 传统梯度下降方法存在局部最优性限制，且只能处理连续可微问题和简单凸约束。需要突破这些限制，实现更广泛的全局优化能力

Method: 将各种复杂约束的优化问题统一为无约束的分层优化目标，通过分数匹配技术获取梯度，实现确定性全局优化

Result: 首次实现了使用严格梯度的确定性全局优化方法，在简单构造和复杂实际实验中验证了有效性，并揭示了全局优化与基于扩散的生成建模之间的深刻联系

Conclusion: 该方法突破了传统梯度下降的局限性，为全局优化提供了新思路，并建立了优化与生成建模之间的理论联系

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [385] [Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning](https://arxiv.org/abs/2601.11657)
*Jack T. Beerman,Shobhan Roy,H. S. Udaykumar,Stephen S. Baek*

Main category: cs.LG

TL;DR: D-PARC（可变形物理感知循环卷积）通过受混合拉格朗日-欧拉方法启发的可变形卷积核，解决了CNN处理高度非线性物理流时的局限性，在多个物理系统中以更小的模型规模实现了比大型架构更优的精度。


<details>
  <summary>Details</summary>
Motivation: 当前卷积神经网络（CNN）在处理高度非线性物理流时存在局限性，而单纯扩大模型规模对物理建模的收益递减。需要借鉴计算力学中的自适应方法，设计更物理直观的架构来替代盲目的网络扩展。

Method: 提出D-PARC（可变形物理感知循环卷积），受混合拉格朗日-欧拉数值方法启发，引入可变形卷积核。这些核表现出反聚类行为，演化出"主动过滤"策略，能够根据物理场特性自适应调整感受野，在高应变区域集中资源，在其他区域粗化关注。

Result: 在Burgers方程、Navier-Stokes方程和反应流等多个物理系统中，D-PARC相比规模大得多的架构实现了更高的精度。分析显示卷积核形成了独特的自适应模式，有效感受野分析证实了其在物理关键区域的资源集中能力。

Conclusion: 物理直观的架构设计比单纯扩大参数规模更有效，D-PARC展示了在精简网络中通过策略性学习可以超越盲目网络扩展，为物理感知深度学习提供了更有效的发展路径。

Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned "active filtration" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.

</details>


### [386] [Machine learning model for predicting surface wettability in laser-textured metal alloys](https://arxiv.org/abs/2601.11661)
*Mohammad Mohammadzadeh Sanandaji,Danial Ebrahimzadeh,Mohammad Ikram Haider,Yaser Mike Banad,Aleksandar Poleksic,Hongtao Ding*

Main category: cs.LG

TL;DR: 开发了一个机器学习框架，利用形态和化学特征准确预测激光纹理金属合金的润湿性，模型表现优异（R²=0.942），揭示了表面化学对接触角预测的关键影响。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性在传热、润滑、微流体和表面涂层等应用中至关重要，但受表面形貌和化学性质共同影响。传统方法难以准确预测激光纹理金属的润湿行为，需要一种能捕捉表面特征复杂相互作用的数据驱动方法。

Method: 1) 通过纳秒激光纹理化和化学浸渍处理在AA6061和AISI 4130合金上制备超亲水和超疏水表面；2) 使用Laws纹理能量法和轮廓测量法定量表面形态；3) 通过XPS表征表面化学，提取官能团极性、分子体积和峰面积分数等特征；4) 训练包含残差连接、批量归一化和dropout正则化的集成神经网络模型。

Result: 模型实现了高预测精度（R²=0.942，RMSE=13.896），优于先前方法。特征重要性分析显示表面化学对接触角预测影响最大，形貌特征也有显著贡献。

Conclusion: 该研究证明了人工智能通过捕捉表面特征的复杂相互作用来建模和预测润湿行为的潜力，为设计定制化功能表面提供了数据驱动的途径。

Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.

</details>


### [387] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架来理解后训练量化方法，通过形式化"激活敏感性"概念，将AWQ和GPTQ等不同方法解释为对敏感性的不同近似。


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法（如AWQ和GPTQ）虽然经验表现良好，但概念上分散，缺乏统一的理论基础来理解它们究竟在近似什么底层量。

Method: 通过一阶泰勒展开，形式化定义"激活敏感性"作为通道扰动对损失的期望影响，将其表示为梯度加权激活的平方范数，从而提供一个衡量通道重要性的原则性度量。

Result: 在该框架下，AWQ和GPTQ可以被解释为在特定简化假设下恢复敏感性的互补近似方法，并建立了梯度显著性、Fisher信息和Hessian准则之间的联系。

Conclusion: 该工作为理解和比较后训练量化方法提供了概念基础，通过敏感性视角统一了不同量化方法，而不是提出新的量化算法。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [388] [Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction](https://arxiv.org/abs/2601.11667)
*Xiaojie Xia,Huigang Zhang,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.LG

TL;DR: 提出一种通过块级局部蒸馏和贪婪层替换策略，从预训练全注意力模型高效生成任务特定混合注意力模型的方法，无需重新训练或架构搜索。


<details>
  <summary>Details</summary>
Motivation: Transformer的全注意力机制具有二次复杂度，限制了实际部署；线性注意力虽然效率高但性能下降；混合模型需要平衡效率和表达能力，但训练成本高且手动设计注意力类型布局困难。

Method: 1) 通过块级局部蒸馏将预训练全注意力模块的权重转移到线性注意力对应模块；2) 引入贪婪层替换策略，迭代地用线性注意力块替换全注意力块，同时监控目标任务的验证性能。

Result: 该方法能在单次高效过程中生成任务特定的混合模型，无需昂贵的重新训练或神经架构搜索，可应用于任何预训练全注意力骨干网络，适用于多种下游任务。

Conclusion: 提出的方法有效解决了混合注意力模型训练成本高和架构设计困难的问题，实现了效率与表达能力的平衡，为Transformer的实际部署提供了实用解决方案。

Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.

</details>


### [389] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种新的测试时方法，通过利用先前查询样本的信息来优化原型估计，提高小样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的小样本方法在测试时假设批次独立，无法利用先前批次积累的宝贵知识，限制了性能提升。

Method: 提出增量原型增强分类器(IPEC)，通过双重过滤机制选择高置信度查询样本构建动态辅助集，与支持集聚合以优化原型估计。

Result: 在多个小样本分类任务上验证了IPEC的优越性能，能够有效减少对初始支持集的依赖。

Conclusion: IPEC通过测试时利用先前查询样本信息，显著提升了小样本分类性能，为基于度量的方法提供了新的优化方向。

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [390] [A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning](https://arxiv.org/abs/2601.11670)
*Jinshi Liu,Pan Liu*

Main category: cs.LG

TL;DR: 提出CoVar理论框架，通过结合最大置信度和残差类别方差来改进半监督学习中的伪标签选择，避免传统固定置信度阈值的问题。


<details>
  <summary>Details</summary>
Motivation: 传统半监督学习中的伪标签选择策略依赖固定置信度阈值，假设预测置信度能可靠指示正确性。但实际上深度网络经常过度自信：高置信度预测可能错误，而决策边界附近信息丰富的低置信度样本却被丢弃。

Method: 从熵最小化原理出发，推导出结合最大置信度(MC)和残差类别方差(RCV)的可靠性度量。将伪标签选择转化为置信度-方差特征空间中的谱松弛问题，设计无阈值选择机制来区分高可靠性和低可靠性预测。

Result: 在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet数据集上，使用不同标签比例和骨干网络，CoVar作为插件模块持续改进强基线方法。

Conclusion: 结合置信度和残差类别方差比固定置信度阈值为伪标签选择提供了更可靠的基础，能有效纠正过度自信但不稳定的预测。

Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)

</details>


### [391] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型与LLM的混合框架，为野火风险管理生成结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 现有野火风险评估方法忽视实际运营需求，缺乏对多维度风险的综合分析，限制了其对一线响应人员的实用价值

Method: 开发混合框架：为气象危险、着火活动、干预复杂性、资源调动等不同风险维度分别建立预测模型，然后使用大语言模型整合异构输出为结构化报告

Result: 论文提出概念验证框架，但未提供具体实验结果（因为是概念验证）

Conclusion: 需要多目标分析方法来捕捉野火风险的多维度特征，混合框架能提供更实用的决策支持工具

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [392] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种用于LHC喷注数据的自蒸馏预训练方法，结合局部粒子级和全局喷注级蒸馏，能在无标签数据上学习支持异常检测和分类任务的表示。


<details>
  <summary>Details</summary>
Motivation: 自监督学习能从无标签数据中学习通用语义特征，但需要针对高能物理中的喷注数据开发专门的预训练方法，以支持下游任务如异常检测和分类。

Method: 提出jBOT方法，结合局部粒子级蒸馏和全局喷注级蒸馏的自蒸馏预训练框架，在无标签喷注数据上学习表示，支持冻结嵌入的异常检测和微调分类。

Result: 预训练导致表示空间中出现语义类别聚类；仅用背景喷注预训练的冻结嵌入可通过简单距离度量实现异常检测；微调嵌入的分类性能优于从头训练的监督模型。

Conclusion: jBOT为LHC喷注数据提供有效的自监督预训练方法，能在无标签数据上学习有意义的表示，支持异常检测和分类任务，性能优于传统监督方法。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [393] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 本文分析了SGD在病态优化中的可疑对齐现象，揭示了步长选择如何影响梯度与主导子空间的对齐行为，并证明了在恒定步长下SGD会经历先下降后稳定的两阶段对齐过程。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化中出现的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐行为。这种对齐之所以"可疑"，是因为沿着高度对齐的主导子空间进行梯度更新反而无法有效降低损失，这与直觉相悖。

Method: 在高维二次设置中进行细粒度分析，提出步长条件理论。通过分析步长选择如何影响对齐行为，建立自适应临界步长η_t^*的概念，区分对齐下降和对齐上升的不同机制。

Result: 发现：1）在低对齐区域，自适应临界步长η_t^*区分对齐下降（η_t < η_t^*）和对齐上升（η_t > η_t^*）机制；2）在高对齐区域，对齐具有自校正特性，无论步长大小都会下降；3）在足够病态条件下，存在步长区间使得向bulk子空间投影能降低损失，而向主导子空间投影反而增加损失。

Conclusion: 基于自适应步长理论，证明了在恒定步长和大初始化条件下，SGD会表现出明显的两阶段行为：初始对齐下降阶段，随后稳定在高对齐状态。这解释了为什么向主导子空间投影梯度更新是无效的。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [394] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: PC²DAE：一种用于无人机传感器数据去噪的物理信息自编码器，通过架构嵌入物理约束解决数据稀缺问题，在少量数据上实现高性能去噪且无物理违规。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载低成本传感器监测野火时存在基线漂移、交叉敏感性和响应延迟等问题，传统深度学习方法需要大量数据，而无人机飞行活动数据有限，难以满足需求。

Method: 提出物理信息去噪自编码器PC²DAE，通过softplus激活函数确保浓度估计非负，通过物理合理的时间平滑确保输出符合物理约束。采用分层解码器头处理不同传感器家族，提供两个变体：PC²DAE-Lean（21k参数）用于边缘部署，PC²DAE-Wide（204k参数）用于离线处理。

Result: 在仅7,894个同步1Hz样本（约2.2小时飞行数据）上评估，PC²DAE-Lean实现67.3%平滑度改进和90.7%高频噪声降低，且无物理违规。相比五个基线方法（产生15-23%负输出），轻量变体甚至优于宽变体（+5.6%平滑度），表明在数据稀缺情况下减少容量并加强归纳偏置可防止过拟合。

Conclusion: PC²DAE通过架构设计直接嵌入物理约束，有效解决了无人机传感器数据去噪中的数据稀缺问题，轻量版本在边缘设备上表现优异，训练时间短，适用于实际野火监测应用。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [395] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出基于shapelet的选择性预测框架，识别时间序列关键区域，选择性丢弃不可靠预测，降低整体误差


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在零样本预测中表现出色，但在某些关键数据区域的预测不可靠，限制了在实际应用中的可用性，特别是当数据呈现独特趋势时

Method: 使用shapelet构建选择性预测框架，通过在目标域验证集上进行平移不变字典学习来学习shapelet，利用基于距离的相似性识别不可靠预测区域

Result: 在多样化基准时间序列数据集上，该方法使零样本模型整体误差平均降低22.17%，全样本微调模型降低22.62%；在某个数据集上分别比随机选择方法高出21.41%和21.43%

Conclusion: 基于shapelet的选择性预测框架能有效识别时间序列关键区域，帮助用户选择性丢弃不可靠预测，提升时间序列基础模型在实际应用中的可靠性

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [396] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow是一种条件流匹配框架，通过联合学习描述符条件的基础分布和流场，显著提升条件生成模型在分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有条件流基方法在训练条件之外泛化能力有限，难以应对分布偏移，这限制了条件生成模型在实际应用中的鲁棒性。

Method: 提出MixFlow框架，通过最短路径流匹配联合学习描述符条件的基础分布和流场，将基础分布建模为可学习的描述符依赖混合分布。

Result: 在单细胞转录组数据和高通量显微镜药物筛选等多个领域，MixFlow相比标准条件流匹配基线方法表现更优，能有效预测未见扰动响应。

Conclusion: MixFlow为跨异构领域实现鲁棒、可泛化、可控的生成建模提供了简单而强大的方法，显著改善了条件生成模型的分布外泛化能力。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [397] [AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training](https://arxiv.org/abs/2601.11864)
*Zhiyuan Li,Yuan Wu,Yi Chang*

Main category: cs.LG

TL;DR: 提出自适应分组梯度裁剪(AGGC)方法，通过按功能类型分组参数并使用EMA历史行为调节，解决传统全局梯度裁剪中的梯度异质性问题，在多个LLM模型上优于LoRA和全微调。


<details>
  <summary>Details</summary>
Motivation: 传统全局梯度裁剪假设不同功能模块的梯度同质化，导致"溢出"效应——波动参数对稳定参数造成不必要的缩放。需要解决梯度异质性问题以稳定大语言模型训练。

Method: AGGC方法：1) 按功能类型将参数分组；2) 使用指数移动平均(EMA)根据历史行为调节每组；3) 构建自适应区间同时缓解梯度爆炸和消失；4) 采用时间依赖调度机制平衡探索与收敛。

Result: 在LLaMA 2-7B、Mistral-7B、Gemma-7B模型上，AGGC持续优于LoRA并经常超越全微调。GSM8K基准上，Mistral-7B微调准确率达72.93%(LoRA为69.5%)。AGGC还能稳定RLVR训练，提升Qwen 2.5和Llama 3.2的逻辑推理能力。

Conclusion: AGGC通过模块化自适应裁剪策略有效解决了传统梯度裁剪方法的局限性，特别是梯度异质性问题。其轻量级设计可无缝集成到现有后训练流程中，开销可忽略不计。

Abstract: To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.

</details>


### [398] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: 提出了TF-CoDiT，首个用于语言控制国债期货合成的扩散Transformer框架，通过小波变换和U形VAE处理低数据量学习，引入金融市场属性协议生成提示，在国债期货数据合成上表现出色。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在股票价格和订单流等金融时间序列数据合成方面已取得进展，但在国债期货数据合成方面仍缺乏探索。国债期货数据具有交易量低、市场依赖性强、多变量间存在分组相关性等特点，需要专门的方法来处理这些挑战。

Method: 1. 将多通道1维时间序列转换为离散小波变换系数矩阵以促进低数据学习；2. 提出U形VAE分层编码跨通道依赖到潜变量，并通过解码桥接潜空间和小波空间，实现潜扩散生成；3. 引入金融市场属性协议(FinMAP)标准化市场动态描述，从7/8个角度识别17/23个经济指标生成提示。

Result: 在2015-2025年四种国债期货数据上，从一周到四个月不同时间跨度的合成任务中，TF-CoDiT能生成高度真实的数据，与真实数据的误差最多为MSE 0.433和MAE 0.453。进一步研究证明TF-CoDiT在不同合约和时间跨度上具有鲁棒性。

Conclusion: TF-CoDiT是首个用于语言控制国债期货合成的扩散Transformer框架，通过小波变换、U形VAE和FinMAP协议有效解决了国债期货数据合成的特殊挑战，在真实性和鲁棒性方面表现出色，为金融时间序列合成提供了新方法。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [399] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 本文提出了一种基于支配匹配集问题转换的新型局部搜索框架，用于解决带实例级约束的k-center聚类问题，实现了最佳可能的2近似比。


<details>
  <summary>Details</summary>
Motivation: 传统k-center问题的最佳近似比为2，任何改进都会导致P=NP。在加入实例级的cannot-link和must-link约束后，虽然不相交的CL约束允许常数因子近似，但局部搜索是否能达到这样的保证仍是一个开放问题。

Method: 提出了一种新颖的局部搜索框架，通过将约束k-center聚类问题转换为支配匹配集问题，从而实现了最佳可能的近似比。

Result: 在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法，实现了2的近似比。

Conclusion: 通过将约束k-center聚类问题转换为支配匹配集问题，提出的局部搜索框架解决了该领域的开放问题，实现了理论上的最佳近似比，并在实践中表现出色。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [400] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 论文提出了一种基于加权凹覆盖目标U_ρ的主动探索框架，用于无奖励MDP中的定向探索，该框架统一了多种现有覆盖目标，并通过梯度算法引导占用分布实现期望的覆盖模式。


<details>
  <summary>Details</summary>
Motivation: 在无奖励马尔可夫决策过程中，不同状态-动作对具有不同的重要性或难度，需要主动且显式地构建到控制探索策略中。现有方法缺乏统一的框架来灵活调整探索重点。

Method: 提出参数化凹覆盖目标族U_ρ，定义在状态-动作占用测度上，统一了基于散度的边际匹配、加权平均覆盖和最坏情况覆盖等目标。利用U_ρ的凹性和梯度闭式解，开发梯度算法主动引导占用分布向期望覆盖模式。

Result: U_ρ框架能够统一多种覆盖目标，其梯度算法能有效引导探索策略。随着ρ增大，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为。

Conclusion: 提出的加权凹覆盖目标族为无奖励MDP中的定向探索提供了统一框架，通过参数ρ灵活调整探索重点，梯度算法能有效实现期望的覆盖模式，为主动探索提供了理论和方法基础。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [401] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发者遥测数据的代码补全基准测试，包含1800个评估实例，涵盖6种编程语言和6个任务类别，评估LLM在实际开发场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态效度（ecological validity），容易受到训练数据污染的影响，且无法提供详细的诊断信息来指导模型选择和改进。

Method: 基于真实开发者遥测数据构建评估实例，涵盖API使用、代码目的理解等6个任务类别和6种编程语言。采用功能正确性、相似度指标和LLM评估者（关注实用性和上下文相关性）相结合的综合评估方法。

Result: 评估了9个最先进的模型，揭示了它们在语法精确度、语义推理和实际效用方面的差异。基准测试提供了可操作的见解，能够指导模型选择和针对性改进。

Conclusion: DevBench填补了现有基准测试的空白，提供了具有生态效度、避免数据污染且支持详细诊断的评估框架，对实际部署和针对性模型开发都具有重要价值。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [402] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 提出一种针对监督学习的公平性预处理框架，通过HGR相关性分析发现传统数据公平方法正则化过强，设计新方法在公平性和效用间取得平衡，并提供下游模型的理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有公平性预处理方法分为数据公平和任务定制公平两类。数据公平方法独立于下游模型类型，但作者发现这些方法从HGR相关性角度看施加了过强的正则化。需要设计更适合监督学习的预处理方法，在公平性和效用间取得更好平衡。

Method: 提出针对监督学习的任务定制预处理框架。考虑公平性和效用的权衡来获得预处理映射，研究任意下游监督模型在转换数据上的行为，找到保证其公平性改进和效用保持的充分条件。通过理论分析提供下游模型使用预处理数据的保证。

Result: 在表格和图像数据集上的比较研究表明，该框架在多个下游模型中保持一致的权衡平衡，优于现有竞争模型。特别在计算机视觉数据中，该方法仅改变与核心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 提出了一种新颖的监督学习公平性预处理框架，通过理论分析提供下游模型保证，在公平性和效用间实现更好平衡，在多种数据类型上表现出优越性能。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [403] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 该论文研究具有向量奖励的协作式随机多臂老虎机问题，在对抗性腐败和有限验证条件下。主要贡献是揭示了通信协议与腐败效应之间的耦合关系：固定的环境侧腐败预算Γ会根据代理共享原始样本、充分统计量还是仅共享推荐，转化为从Γ到NΓ的有效腐败水平。


<details>
  <summary>Details</summary>
Motivation: 研究在对抗性腐败和有限验证条件下，多智能体协作学习中的通信效率与鲁棒性权衡问题。当环境中的奖励观测可能被对抗性扰动时，不同的通信协议（共享原始样本、统计摘要或仅推荐）如何影响团队的整体学习性能。

Method: 采用协作式随机多臂老虎机框架，考虑向量值奖励和对抗性腐败。引入协议诱导的多重性函数来量化不同通信协议下的有效腐败水平。分析三种通信模式：原始样本共享、充分统计量共享和仅推荐共享。建立后悔界限参数化于有效腐败水平，并研究验证观测的恢复作用。

Result: 发现通信协议显著影响有效腐败水平：原始样本共享可能导致N倍的腐败放大，而摘要共享和推荐共享保持O(Γ)的未放大项，达到集中式速率的团队后悔。建立了信息论极限，包括不可避免的Ω(Γ)惩罚项，以及在Γ=Θ(NT)的高腐败区域中，没有干净信息时无法实现次线性后悔。验证观测可以恢复可学习性。

Conclusion: 通信协议与腐败效应之间存在根本性耦合，选择适当的共享策略对团队学习至关重要。在高腐败区域，验证是必要的，一旦超过识别阈值，认证共享可以使团队后悔独立于Γ。该研究为对抗性环境下的协作学习提供了理论指导。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [404] [Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization](https://arxiv.org/abs/2601.11942)
*Qingyu Meng,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出一种混合量子-经典回归框架，通过可学习的几何预处理器和课程优化协议，改善量子神经网络在回归任务中的训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络在科学机器学习中受到关注，但在回归任务中常面临梯度噪声大、优化条件差的问题，导致训练困难。

Method: 1) 设计混合量子-经典架构，前置轻量级经典嵌入层作为可学习的几何预处理器；2) 提出课程优化协议，逐步增加电路深度，从SPSA随机探索过渡到Adam梯度微调。

Result: 在PDE回归基准和标准回归数据集上，该方法在固定训练预算下优于纯QNN基线，在数据有限情况下收敛更稳定，并减少了与振荡分量相关的结构化误差。

Conclusion: 几何预处理与课程训练相结合是稳定量子回归的实用方法，能有效改善量子神经网络的训练性能和稳定性。

Abstract: Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.

</details>


### [405] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出MICE方法解决约束强化学习中的成本函数低估问题，通过内在成本估计和安全记忆模块减少训练过程中的约束违反


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练过程中经常出现严重的约束违反，限制了在安全关键场景中的应用。研究发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计方法，构建记忆模块存储先前探索的不安全状态来识别高风险区域，内在成本定义为当前状态访问这些风险区域的伪计数，并采用偏差校正策略的外在-内在成本价值函数。

Result: MICE显著减少了约束违反，同时保持了与基线方法相当的政策性能。理论分析提供了成本价值函数的收敛保证和MICE更新的最坏情况约束违反界限。

Conclusion: MICE通过解决成本函数低估问题，有效提升了约束强化学习的安全性，为安全关键应用提供了更可靠的解决方案。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [406] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt：一个面向动态图的数据中心化提示框架，通过调整预训练节点嵌入来适应不同下游任务，在少样本和冷启动场景下显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法直接将预训练的节点时序嵌入应用于下游任务，但由于任务差异导致性能下降，尤其在少样本场景下。现有提示方法通常与特定模型架构或预训练任务强耦合，且只关注节点或时序特征而忽略空间结构信息，导致表达能力有限。

Method: 提出DDGPrompt框架：1) 定义统一的节点表达特征矩阵，聚合每个节点的所有相关时序和结构信息；2) 引入三个提示矩阵（时序偏置、边权重和特征掩码）来完全调整特征矩阵，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下进行评估。实验结果表明，在标签有限和冷启动条件下，该方法显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt是一个有效的动态图提示框架，能够通过数据中心的提示调整预训练节点嵌入，提高对多样化下游任务的适应性，在少样本和冷启动场景下表现出色。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [407] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO通过引入轻量级残差Rollout-Head解耦训练轨迹与推理响应，解决强化学习在LLM推理中探索不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时生成推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，损害推理能力

Method: 提出R²PO（残差Rollout策略优化），在策略之上引入轻量级残差Rollout-Head，将训练轨迹与推理响应解耦，在训练期间实现可控的轨迹多样化，同时保持推理生成的稳定性

Result: 在多个基准测试中一致优于基线方法，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化

Conclusion: R²PO通过解耦训练轨迹与推理响应，有效解决了强化学习在LLM推理中的探索不足问题，显著提升了推理能力

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [408] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE Encoder模块，通过稀疏专家混合层增强预训练时序模型，解决电力系统多变量预测中的隐私约束和跨区域泛化问题


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量复杂依赖、严格隐私约束和跨区域部署场景多样化的挑战。传统方法需要大量专家知识且泛化能力有限，预训练模型的零样本性能在特定领域任务中仍有不足。

Method: 提出MoE Encoder模块，在标记化和编码之间注入稀疏专家混合层。该设计实现两个关键能力：1) 将多变量预测转化为专家引导的单变量任务，有效捕捉变量间关系；2) 支持联邦设置中的本地化训练和轻量级参数共享，无需交换原始数据。

Result: 在公共多变量数据集上的实验表明，MoE-Encoder相比强基线显著提升预测精度。联邦环境模拟显示，仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小。

Conclusion: MoE-Encoder为时序基础模型提供了可扩展且隐私感知的扩展方案，能够有效解决电力系统预测中的隐私约束和跨区域泛化问题。

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [409] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出EVO算法，利用极值理论处理强化学习中的极端风险事件，减少约束违反


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习基于期望约束，忽略了尾部分布中的罕见但高影响的极端值事件（如黑天鹅事件），这可能导致严重的约束违反。需要一种能有效处理极端风险的方法。

Method: 提出极端值策略优化（EVO）算法：1）利用极值理论（EVT）建模和利用极端奖励和成本样本；2）引入极端分位数优化目标捕捉成本尾部分布中的极端样本；3）提出回放过程中的极端优先级机制，放大罕见但高影响样本的学习信号。

Result: 理论分析：建立了策略更新期间预期约束违反的上界，保证在零违反分位数水平上的严格约束满足。证明EVO比基于期望的方法具有更低的约束违反概率，比分位数回归方法具有更低的方差。实验表明EVO显著减少了训练期间的约束违反，同时保持了与基线相当的策略性能。

Conclusion: EVO算法通过极值理论有效处理强化学习中的极端风险事件，在保证策略性能的同时显著减少约束违反，为解决现实世界强化学习应用中的安全问题提供了有效方案。

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [410] [Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features](https://arxiv.org/abs/2601.12011)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 损失重加权在过参数化DNN中无法改变最终学习阶段，但能显著改善早期训练；作者提出小规模模型来透明分析这一现象


<details>
  <summary>Details</summary>
Motivation: 损失重加权在现代深度学习中的应用呈现复杂图景：虽然无法改变过参数化深度神经网络在高维数据集上的最终学习阶段，但经验证据表明它在训练早期能带来显著好处。作者希望透明地展示和分析这一现象。

Method: 引入一个小规模模型（SSM），该模型专门设计用于抽象化DNN架构和输入数据的固有复杂性，同时保持其频谱分量中不平衡结构的关键信息。

Result: SSM揭示：1）普通经验风险最小化在训练早期优先学习区分多数类而非少数类，从而延迟少数类学习；2）重加权恢复平衡学习动态，使与多数类和少数类相关的特征能够同时学习。

Conclusion: 损失重加权通过恢复平衡学习动态来改善训练早期阶段，使模型能够同时学习多数类和少数类的特征，而不是像普通训练那样优先学习多数类特征。

Abstract: The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.

</details>


### [411] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2是一个增强的因子化时空基础模型框架，通过分离通用时间学习和领域特定空间适应，实现全权重转移和任意长度泛化，在零样本和少样本场景下达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 时空基础模型虽然承诺跨数据集泛化能力，但联合时空预训练计算成本高，且难以处理领域特定空间模式的异质性。需要一种更实用、可扩展的方法来构建真正通用的时空基础模型。

Method: 采用两阶段因子化框架：第一阶段预训练最小化编码器骨干网络，使用随机序列掩码捕捉不变时间动态，实现跨可变时间范围的概率分位数预测；第二阶段通过精简适配器，利用元自适应学习和提示快速注入空间感知能力。

Result: 在多个领域的综合评估表明，FactoST-v2以线性效率达到最先进精度，在零样本和少样本场景下显著优于现有基础模型，同时可与领域特定专家基线相媲美。

Conclusion: 这种因子化范式为构建真正通用的时空基础模型提供了一条实用、可扩展的路径，实现了全权重转移和任意长度泛化能力。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [412] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 该研究提出CEBiasBench双语基准和MACD多智能体文化辩论框架，发现中文提示仅将偏见转向东亚视角而非消除，通过显式文化表征的智能体辩论可显著提升无偏见率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在系统性西方中心偏见，但使用非西方语言（如中文）能否缓解这种偏见尚不清楚。现有方法在评估和缓解两方面都存在不足：评估方法强制输出预定义文化类别而无中立选项；缓解方法依赖昂贵的多文化语料库或缺乏显式文化表征的智能体框架。

Method: 1) 提出CEBiasBench中英双语基准；2) 提出多智能体投票(MAV)框架，支持"无偏见"判断；3) 提出多智能体文化辩论(MACD)框架，为智能体分配不同文化角色，采用"求同存异"策略进行辩论。

Result: 实验发现中文提示仅将偏见转向东亚视角而非消除偏见。MACD在CEBiasBench上达到57.6%的平均无偏见率（LLM评估）和86.0%（MAV评估），相比GPT-4o基线的47.6%和69.0%有显著提升，并在阿拉伯语CAMeL基准上表现出良好泛化能力。

Conclusion: 显式文化表征在智能体框架中对跨文化公平至关重要。MACD作为无需训练的方法，通过文化角色辩论有效缓解LLM的跨文化偏见，为促进AI公平性提供了新途径。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [413] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 提出PTL-PINN框架，结合扰动理论和迁移学习，快速求解非线性微分方程，计算速度比传统方法快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）在求解非线性微分方程时存在泛化能力有限和训练时间长的问题，需要更高效的解决方案。

Method: 提出扰动引导的迁移学习框架PTL-PINN，将扰动理论与迁移学习结合，通过闭式表达式求解近似线性扰动系统，计算复杂度仅为矩阵向量乘法。

Result: PTL-PINN在精度上与多种龙格-库塔方法相当，计算速度提升一个数量级，成功求解了非线性振荡器、Lotka-Volterra系统、KPP-Fisher方程和波动方程等多种问题。

Conclusion: 该工作将长期存在的扰动方法与PINNs相结合，展示了扰动理论如何指导基础模型以接近经典求解器的速度解决非线性系统。

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [414] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

TL;DR: 提出固定长度的数字嵌入向量，保留有理数域中的代数运算（加法、乘法、比较），通过神经同构场实现代数结构的神经抽象，实验显示加法性能优异（>95%准确率），乘法仍有改进空间（53-73%准确率）。


<details>
  <summary>Details</summary>
Motivation: 神经网络处理极小数或极大数时面临溢出、下溢和输出不稳定等问题，需要一种能保留代数特性同时避免数值不稳定的数字表示方法。

Method: 使用嵌入向量代替原始数值，提出神经同构场作为代数结构（群、域）的神经抽象，其元素是保持代数结构的嵌入向量，首次实现固定长度且保留有理数域代数运算的数字嵌入。

Result: 加法运算表现优异，在恒等性、封闭性、结合性等关键代数测试中准确率超过95%；乘法运算面临挑战，在不同代数属性测试中准确率为53%到73%。

Conclusion: 该方法在保留加法代数特性方面效果显著，同时揭示了乘法运算需要进一步改进的方向，为神经网络处理数值计算提供了新思路。

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [415] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于评估合成数据隐私风险的开放框架，使用模拟敏感数据避免真实数据泄露，并提出新的身份披露风险指标，为医疗应用中的合成数据提供更准确的隐私评估。


<details>
  <summary>Details</summary>
Motivation: 医疗应用中合成数据的使用存在隐私担忧，但缺乏开放的隐私评估框架和可访问的基准数据集阻碍了其采用。主要挑战在于难以获取敏感数据进行隐私风险评估。

Method: 引入SynQP开放框架，使用模拟敏感数据进行隐私基准测试，确保原始数据保密。提出新的身份披露风险指标（SD-IDR），更准确地评估机器学习模型的概率特性。

Result: 在质量评估中，非隐私模型达到接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险（SD-IDR）和成员推理攻击风险（SD-MIA），所有DP增强模型都保持在0.09监管阈值以下。

Conclusion: SynQP为改善隐私评估的透明度和可靠性提供了关键工具，使合成数据在医疗相关应用中更安全地使用。该框架通过模拟数据和新的隐私指标解决了现有评估方法的局限性。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [416] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域适应大语言模型，专门用于空间天气和太阳物理学的教育问答，通过科学文献和GPT-4生成的数据训练，在解释清晰度和教育效果上优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 太阳活动（如太阳耀斑、日冕物质抛射）对卫星、电网等关键基础设施有重大影响，准确预测和有效教育至关重要。现有大语言模型缺乏领域专业知识，且难以清晰解释复杂的空间科学概念。

Method: 基于LLaMA-3基础模型构建SolarGPT-QA系统，使用科学文献和GPT-4生成的大规模问答数据进行训练，并通过Grok-3以学生友好的故事化风格进行精炼。结合领域自适应预训练和教学微调。

Result: 人工评估显示SolarGPT-QA在零样本设置下优于通用模型，与指令微调模型在教育解释方面表现相当。学生理解研究表明生成解释的清晰度和可访问性有所提升。消融实验表明领域自适应预训练与教学微调结合对平衡科学准确性和教育效果很重要。

Conclusion: 这项工作代表了向更广泛的SolarGPT框架迈出的第一步，该框架旨在支持空间科学教育和预测，展示了领域适应大语言模型在专业科学教育中的潜力。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [417] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 提出EMoE架构，通过基于正交特征基的路由机制，同时解决MoE中的负载不均衡和专家同质化问题，无需额外的负载均衡损失函数。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模不断扩大，计算需求变得不可持续，MoE架构成为提高效率的可行路径。但现有MoE面临两个核心问题：1) "富者愈富"的负载不均衡问题，少数专家被过度使用；2) 专家同质化问题，专家学习冗余表示，失去了专业化分工的意义。现有解决方案通常使用辅助负载均衡损失，但这往往以牺牲专业化为代价，加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习到的正交特征基的路由机制。该方法将输入令牌投影到共享的特征基上，并根据它们与特征空间主成分的对齐程度进行路由。这种基于几何原理的数据划分方法，能够同时促进专家负载均衡和多样化专业专家的形成。

Result: EMoE能够内在促进专家负载均衡和专业化多样性，无需使用可能产生冲突的辅助损失函数。代码已在GitHub上公开。

Conclusion: EMoE通过基于正交特征基的路由机制，为MoE架构提供了同时解决负载不均衡和专家同质化问题的原则性解决方案，避免了传统方法中负载均衡损失与专业化目标之间的冲突。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [418] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: TDA是一种无注意力下沉的注意力机制，通过阈值差分实现超稀疏性，解决长上下文处理中Softmax注意力的结构限制问题


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文处理中存在结构限制：严格的归一化约束导致注意力下沉到无关token上，且随着序列长度增加，概率质量会分散。需要一种能避免注意力下沉、实现超稀疏性并提高长序列鲁棒性的机制。

Method: 提出阈值差分注意力（TDA）：1）使用行级极值阈值处理，通过长度相关门控保留超过阈值的值；2）借鉴差分transformer思想，减去抑制性视图以增强表达能力；3）理论证明TDA能控制每行虚假幸存者的期望数量为O(1)。

Result: TDA产生超过99%的精确零值，消除了注意力下沉现象，在标准和长上下文基准测试中保持竞争力，同时实现超稀疏性并提高长序列鲁棒性。

Conclusion: TDA通过阈值差分机制有效解决了Softmax注意力在长上下文处理中的结构限制，实现了无注意力下沉的超稀疏注意力，为长序列处理提供了更高效的解决方案。

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [419] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出联邦学习框架校准参数化保险指数，用于异质可再生能源生产损失，无需共享原始数据


<details>
  <summary>Details</summary>
Motivation: 传统方法需要共享敏感的生产数据来校准保险指数，存在隐私和商业机密问题。可再生能源生产损失具有异质性，需要适应不同生产者的方差和链接函数差异

Method: 使用Tweedie广义线性模型在本地建模损失，通过联邦优化学习共同指数。比较FedAvg、FedProx和FedOpt算法，并与现有近似聚合方法进行基准测试

Result: 在德国太阳能发电的实证应用中，联邦学习在适度异质性下恢复了可比较的指数系数，同时提供了更通用和可扩展的框架

Conclusion: 联邦学习为参数化保险指数校准提供了隐私保护、适应异质性且可扩展的解决方案，特别适用于可再生能源生产损失建模

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [420] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: 提出Re-SpS框架，首次使用强化学习动态优化推测采样的树结构超参数，相比静态方法EAGLE-3获得最高1.12倍加速，保持输出质量不变。


<details>
  <summary>Details</summary>
Motivation: 当前推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率，需要动态调整机制来平衡推测激进性和计算开销。

Method: 提出Re-SpS强化学习框架：1）从目标模型隐藏状态提取高效状态表示；2）引入多步动作持久化以改进上下文建模；3）实时动态调整树结构超参数，学习上下文感知策略以最大化生成速度。

Result: 在五个多样化基准测试中：1）相比骨干LLM获得最高5.45倍加速；2）相比SOTA方法EAGLE-3获得最高1.12倍加速；3）输出保真度无损失。

Conclusion: Re-SpS首次将强化学习应用于推测采样的树结构超参数优化，通过动态调整实现了比静态方法更好的性能，为LLM推理加速提供了更灵活高效的解决方案。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [421] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 该论文研究超稀疏采样下的矩阵补全问题，提出了一种无偏估计器来估计矩阵的行空间或二阶矩矩阵，并通过梯度下降恢复缺失项。


<details>
  <summary>Details</summary>
Motivation: 动机源于大规模稀疏面板数据集应用，其中行数远大于列数，每个行只有少量观测项（少于矩阵秩），无法准确补全矩阵，转而估计行空间或二阶矩矩阵。

Method: 提出无偏估计器：对二阶矩矩阵的非零项按其观测频率归一化，然后通过梯度下降补全T的缺失项。归一化将n个二项随机变量的加权和除以总观测数。

Result: 理论证明：当n ≥ O(dr⁵ε⁻²C⁻²log d)时，梯度下降目标的任何局部最小值都是近似全局的，能以误差最多ε²恢复T。实验验证：在MovieLens数据集上减少88%偏差，在Amazon评论数据集上减少59%的T恢复误差和38%的M恢复误差。

Conclusion: 该方法在超稀疏采样下能有效估计二阶矩矩阵，适用于行数远大于列数的大规模稀疏数据集，相比基线方法显著提升性能。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [422] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 提出MMR自监督预训练框架，通过小波多尺度分解重建任务学习PPG信号的层次化时频特征，在17个健康任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略PPG信号的频谱结构，而许多健康相关任务需要从细粒度波形形态到全局节律动态的多分辨率特征。

Method: MMR框架：使用小波多分辨率分解PPG信号，随机掩码系数后让Transformer编码器重建，强制模型整合跨时频尺度的信息。

Result: 在19个多样化健康任务中的17个上，MMR优于或匹配最先进的开源PPG基础模型、时间序列基础模型和其他自监督基线。

Conclusion: MMR展示了构建通用PPG基础模型的潜力，小波表示能捕获稳健且生理基础的特征。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [423] [Learning Longitudinal Health Representations from EHR and Wearable Data](https://arxiv.org/abs/2601.12227)
*Yuanyun Zhang,Han Zhou,Li Feng,Yilin Hong,Shi Li*

Main category: cs.LG

TL;DR: 提出一种多模态基础模型，联合建模电子健康记录和可穿戴设备数据作为连续时间潜在过程，在生理预测和风险建模任务上优于单模态基线


<details>
  <summary>Details</summary>
Motivation: 电子健康记录模型受限于稀疏不规则的数据，可穿戴设备提供密集连续信号但缺乏语义基础，现有方法通常单独建模或通过后期融合结合这些数据源

Method: 使用模态特定编码器和共享时间骨干网络，通过自监督和跨模态目标进行预训练，将电子健康记录和可穿戴数据表示为连续时间潜在过程

Result: 在生理预测和风险建模任务上优于仅使用电子健康记录或可穿戴设备的基线，尤其在长时程预测和数据缺失情况下表现更佳

Conclusion: 联合电子健康记录和可穿戴设备预训练能够产生更准确的纵向健康表征，证明多模态整合的优势

Abstract: Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.

</details>


### [424] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 提出了一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的新型框架，用于企业安全中的内部威胁检测，在CERT基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 内部威胁检测面临多通道、非平稳的用户活动日志，且异常事件稀少，现有方法难以有效处理这些复杂行为模式。

Method: 1) 偏差感知调制方案抑制常规行为并放大异常偏差；2) 离散小波变换将日志信号分解为多分辨率表示；3) 可学习注意力机制动态重加权最具区分性的频带。

Result: 在CERT r4.2基准测试中，该方法在不同时间粒度和场景下，在精确率、召回率和F1分数上均优于现有基线方法。

Conclusion: 提出的集成小波感知调制、多分辨率分解和自适应注意力的框架能有效处理内部威胁检测中的复杂日志数据，显著提升异常检测性能。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [425] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过GRIN模块动态适应时移，单次前向传播即可捕捉复杂未来分布，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在计算成本高（依赖采样）或参数假设限制性强的问题，导致预测性能受限和分布不匹配。需要一种能高效捕捉复杂未来分布的方法。

Method: 提出TimeGMM框架：1) 使用高斯混合模型(GMM)表征未来分布；2) 提出GRIN模块（GMM适应的可逆实例归一化）动态适应时移；3) 结合时间编码器(TE-Module)和条件时移解码器(CTPD-Module)共同捕捉时间依赖性和混合分布参数。

Result: 在广泛实验中，TimeGMM始终优于最先进方法，在CRPS指标上最大提升22.48%，在NMAE指标上最大提升21.23%。

Conclusion: TimeGMM通过GMM框架和GRIN模块有效解决了现有概率预测方法的局限性，实现了高效、准确的复杂分布建模，在能源、金融等领域具有重要应用价值。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [426] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 研究发现训练数据中的分布偏移程度越大，ERM方法在分布外任务上的表现越好，甚至能接近不变预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时在分布外任务上表现优于专门设计的方法，这促使研究者探索算法设计之外的原因，特别是训练域之间的分布偏移如何影响模型性能。

Method: 通过理论推导和实证验证相结合的方法：1）提出理论上界分析分布偏移程度对模型预测能力的影响；2）证明在特定数据条件下ERM解能达到与不变预测模型相当的性能；3）通过实证验证展示随着训练数据分布偏移增加，学习模型的预测接近Oracle或最优模型。

Result: 研究发现：1）分布偏移程度直接影响学习模型的预测能力，偏移越大模型能力越强，越接近能在任意已知或未知域上做出稳定预测的不变预测模型；2）在特定数据条件下，ERM解能达到与不变预测模型相当的性能；3）实证验证表明，随着训练数据分布偏移增加，学习模型的预测确实接近Oracle或最优模型。

Conclusion: 训练数据中的分布偏移是影响模型在分布外任务上性能的关键因素，较大的分布偏移能使ERM方法获得接近不变预测模型的性能，这为理解ERM在分布外任务上的优异表现提供了新的理论视角。

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [427] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MLaaS数据集生成器框架，用于创建可配置、可复现的数据集来评估MLaaS服务选择和组合，通过模拟真实MLaaS行为生成大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于评估MLaaS（机器学习即服务）选择和组合的系统化、可配置数据集，需要一种能够模拟真实MLaaS行为并记录详细性能指标的方法来支持数据驱动的研究。

Method: 提出MDG框架，通过在不同真实数据集和数据分布设置下训练和评估多种模型家族来模拟MLaaS行为，记录功能属性、服务质量指标和组合特定指标，并实现内置组合机制模拟物联网条件下的服务交互。

Result: 生成了超过一万个MLaaS服务实例，构建了适用于下游评估的大规模基准数据集，实验表明MDG生成的数据集相比现有基线能提高选择准确性和组合质量。

Conclusion: MDG为推进MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础，能够生成高质量、可配置的数据集来支持系统化评估。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [428] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

TL;DR: Explanova：基于预设AutoML式工作流的自动化数据分析框架，使用本地小LLM降低成本


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM代理工具调用的数据分析框架（如DeepAnalyze、DataSage、Datawise）虽然强大，但成本较高。作者探索是否可以通过预设的AutoML式工作流来实现自动化数据分析，并降低成本。

Method: 提出Explanova框架，采用预设的AutoML式工作流，遍历所有可能的探索路径（如Xn自身统计、Xn1-Xn2关系、Xn到所有其他变量的关系等），并使用本地小型LLM来降低计算成本。

Result: Explanova实现了自动化数据分析，相比现有基于大型LLM代理的框架，成本更低廉。

Conclusion: 预设的AutoML式工作流结合本地小型LLM可以有效地实现自动化数据分析，提供了一种成本更低的替代方案。

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [429] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: 提出OrLoMo方法，首次实现带本地更新的异步分布式动量SGD，通过有序聚合本地动量来加速异构集群训练


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度学习的基础优化器，异步分布式学习对训练大规模模型至关重要，特别是在异构计算集群中。现有方法缺乏异步分布式动量SGD与本地更新的结合方案。

Method: 提出OrLoMo方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引有序聚合各工作节点的本地动量，实现异步分布式动量SGD。

Result: 证明了OrLoMo在任意延迟下的非凸问题收敛性，实验验证OrLoMo优于同步方法和其它异步方法。

Conclusion: OrLoMo是首个实现异步分布式动量SGD与本地更新的方法，能有效加速异构集群训练并提升性能。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [430] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个结合空间视觉和物理动态的深度学习框架，用于预测冰川湖溃决洪水，通过卫星图像分析和时间序列建模实现自动化的实时预警系统。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云层干扰和现场数据缺乏等问题，需要更高效、自动化的解决方案。

Method: 提出IceWatch框架：1) RiskFlow使用CNN分析Sentinel-2多光谱卫星图像，基于冰雪和融水的空间模式预测GLOF；2) TerraFlow从NASA ITS_LIVE时间序列建模冰川流速；3) TempFlow从MODIS LST记录预测近地表温度；三者通过协调预处理和同步集成，实现多模态、物理信息化的GLOF预测。

Result: 系统具有强大的预测性能、快速数据处理能力（适合实时使用）、对噪声和缺失信息的鲁棒性，并通过交叉验证提高了GLOF检测的可靠性和可解释性。

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平了道路，具有与多样化传感器输入和全球冰川监测活动集成的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [431] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

TL;DR: 提出结合物理信息神经网络与上下文学习的数据集和框架，让LLM模拟真实世界情绪动态，实现可解释对话建模


<details>
  <summary>Details</summary>
Motivation: 现有LLM在模拟真实世界情绪动态方面存在局限，缺乏可解释性，需要结合物理原理来更好地理解和建模情绪随时间的变化

Method: 构建数据集和概念框架，结合物理信息神经网络（PINN）与上下文学习，让LLM学习情绪动态的物理规律

Result: 开发出能够模拟真实世界情绪动态的框架，为可解释的对话建模开辟新可能性

Conclusion: 通过结合物理原理与LLM学习，可以实现更真实、可解释的情绪动态模拟，为对话系统提供新方向

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [432] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS结合大语言模型和贝叶斯优化，在蒙特卡洛树搜索框架中解决AutoML中的CASH问题，通过选择性调优记忆和动态策略转换提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化在冷启动问题上表现不佳，而现有基于大语言模型的优化器难以泛化到高维结构化的CASH空间，需要一种结合两者优势的新方法。

Method: 提出LB-MCTS框架，在蒙特卡洛树搜索结构中协同大语言模型和贝叶斯优化，使用选择性调优记忆最大化大语言模型推理能力，并通过动态策略转换从大语言模型驱动转向贝叶斯优化驱动。

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于现有竞争基线方法。

Conclusion: LB-MCTS成功结合了大语言模型的语义先验和贝叶斯优化的数据驱动优势，有效解决了CASH问题中的冷启动和高维结构化挑战。

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [433] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

TL;DR: 基于机器学习的控制阀粘滞故障早期预测框架，使用常规过程信号（控制器输出和过程变量），LSTM模型在真实炼油厂数据上实现最高精度，可提前4小时预测粘滞故障。


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程中的常见故障，会导致系统不稳定、设备磨损和维护成本增加。许多工厂仍使用缺乏实时监控的传统阀门，使得早期预测具有挑战性。

Method: 提出机器学习框架，使用常规收集的过程信号（控制器输出OP和过程变量PV）。开发并比较三种深度学习模型：CNN、CNN-SVM混合模型和LSTM网络。采用基于斜率比分析的数据驱动标注方法处理真实油气炼油厂数据集。

Result: LSTM模型取得了最高准确率，能够提前4小时预测控制阀粘滞故障。据作者所知，这是首个基于真实工业数据、使用机器学习实现控制阀粘滞早期预测的研究。

Conclusion: 该框架可集成到现有控制系统中，支持预测性维护，减少停机时间，避免不必要的硬件更换，为工业过程控制阀故障监测提供了有效的解决方案。

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [434] [Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation](https://arxiv.org/abs/2601.12380)
*Ou Deng,Shoji Nishimura,Atsushi Ogihara,Qun Jin*

Main category: cs.LG

TL;DR: SNI是一个可解释的混合类型数据填补框架，通过可控先验特征注意力模块结合统计先验与神经网络注意力，提供内在的依赖关系诊断和统计-神经权衡参数。


<details>
  <summary>Details</summary>
Motivation: 现实世界的表格数据库通常包含连续测量值和分类记录，但缺失条目普遍存在且会扭曲下游分析。现有方法在可解释性方面存在不足，需要一种既能处理混合类型数据又能提供解释的填补方法。

Method: 提出统计-神经交互(SNI)框架，包含可控先验特征注意力(CPFA)模块。CPFA学习头级先验强度系数{λ_h}，软性正则化注意力朝向统计先验，同时允许数据驱动的非线性模式偏离。通过聚合注意力图生成有向特征依赖矩阵，无需事后解释器。

Result: 在6个数据集(ICU监测、人口调查、社会经济统计、工程应用)上评估，与6个基线方法比较。在30%MCAR/strict-MAR缺失下，SNI在连续变量指标上具有竞争力，但在分类变量上常被MissForest、MIWAE等精度优先方法超越。提供内在依赖诊断和明确的统计-神经权衡参数。

Conclusion: SNI在可解释性方面具有优势，提供了内在的依赖关系诊断和统计-神经权衡参数，适用于需要解释性的部署场景。但在严重不平衡的分类目标上存在局限性，需要在精度和可解释性之间权衡。

Abstract: Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{λ_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.

</details>


### [435] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个策略，解决RL微调生成模型时的多样性崩溃问题，在任务对齐和生成多样性之间实现更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在"多样性崩溃"的根本限制，即优化过程会使策略坍缩为狄拉克δ分布，导致生成结果缺乏多样性，无法满足需要多样化候选生成的应用需求。

Method: 提出DRIFT框架，从三个角度系统性地激励输出多样性：1) 采样奖励集中子集以过滤异常值；2) 使用随机变体提示以扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验结果显示DRIFT在任务对齐和生成多样性方面实现了帕累托优势：在相同对齐水平下多样性提升9.08%~43.46%，在相同多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT框架成功解决了RL微调生成模型时的多样性崩溃问题，实现了强任务对齐与高生成多样性的平衡，增强了图像生成模型的实用性。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [436] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发了一个可解释的机器学习框架用于儿科牙科风险分层，优先考虑可解释性和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿科牙科疾病是全球最普遍且不公平的慢性健康问题之一。虽然流行病学证据显示口腔健康结果与社会经济和人口因素相关，但当前牙科AI应用主要依赖基于图像的诊断和黑盒预测模型，限制了在儿科人群中的透明度和伦理适用性

Method: 使用人口水平的儿科数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。通过ROC分析和校准曲线评估模型性能，使用SHAP方法实现可解释性，提供全局和个体层面的预测解释

Result: 模型实现了适度的区分能力（AUC=0.61），具有保守的校准特性，在高概率水平下低估风险。SHAP分析显示年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别

Conclusion: 可解释的机器学习能够实现透明的、预防导向的儿科牙科风险分层，支持人群筛查和公平资源分配，而非诊断决策

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [437] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 该论文提出了正交化策略优化（OPO）框架，将对齐方法中的采样几何与优化几何解耦，解决了传统KL散度方法在无界值信号下的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（如PPO、DPO、IPO）通常将采样几何和优化几何混为一谈，导致在无界值信号下出现指数惩罚，引起数值不稳定和高置信度区域的梯度消失问题。

Method: 提出了正交化策略优化（OPO）框架，通过α加权重要性采样和卡方诱导的二次正则化在比率坐标中实现采样几何与优化几何的显式解耦，形成具有线性梯度动态的简单且条件良好的目标函数。

Result: OPO框架在保持峰值寻求行为的同时实现了稳定优化，避免了模型置信度高时的梯度饱和问题，为现有对齐方法提供了统一视角，并为鲁棒推理导向训练奠定了理论基础。

Conclusion: 对齐方法应明确区分采样几何和优化几何两个基本设计选择，OPO框架通过解耦这两个维度，解决了传统方法的数值不稳定问题，为更鲁棒的对齐算法提供了原则性基础。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [438] [Graph Attention Networks with Physical Constraints for Anomaly Detection](https://arxiv.org/abs/2601.12426)
*Mohammadhossein Homaei,Iman Khazrak,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

TL;DR: 提出一种基于水力感知的图注意力网络，利用归一化守恒定律违规作为特征，结合图注意力和双向LSTM学习时空模式，实现水分配系统异常检测


<details>
  <summary>Details</summary>
Motivation: 水分配系统面临日益增长的网络物理风险，现有数据驱动模型忽略网络拓扑且难以解释，而基于模型的方法严重依赖参数准确性

Method: 使用归一化守恒定律违规作为特征，结合质量与能量平衡残差、图注意力机制和双向LSTM学习时空模式，采用多尺度模块从节点到网络层面聚合检测分数

Result: 在BATADAL数据集上达到F1=0.979，比现有方法提升3.3个百分点，在15%参数噪声下仍保持高鲁棒性

Conclusion: 该方法有效结合了物理原理和数据驱动方法，提高了水分配系统异常检测的准确性和鲁棒性，同时考虑了网络拓扑结构

Abstract: Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.

</details>


### [439] [Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery](https://arxiv.org/abs/2601.12442)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: CANUF框架将贝叶斯深度学习与可微分符号推理结合，在科学AI中实现可信的不确定性估计和领域约束满足。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法缺乏整合符号科学知识的机制，而神经符号方法缺乏原则性的不确定性建模。科学AI应用需要既提供可信不确定性估计又尊重领域约束的模型。

Method: CANUF包含三个组件：1) 从科学文献自动提取约束；2) 使用变分推理的概率神经网络骨干；3) 确保物理一致性的可微分约束满足层。统一了贝叶斯深度学习和可微分符号推理。

Result: 在Materials Project、QM9分子属性和气候基准测试中，CANUF将预期校准误差降低34.7%（相比贝叶斯神经网络），同时保持99.2%的约束满足率。约束引导的重新校准贡献了18.3%的性能增益，约束提取精度达91.4%。

Conclusion: CANUF提供了首个端到端可微分流程，同时解决科学预测中的不确定性量化、约束满足和可解释性解释问题，为科学AI应用提供了统一框架。

Abstract: Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.

</details>


### [440] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 提出两阶段时间序列预测框架：第一阶段用CNN提取局部时间动态特征并生成补丁级token嵌入，第二阶段用Transformer编码器建模补丁间全局依赖关系进行预测。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中表现出色，但其性能严重依赖于从原始多元时间序列数据中提取的输入表示的质量和结构。现有方法在局部时间表示学习和全局依赖建模之间的耦合不够明确。

Method: 两阶段框架：1) 局部时间表示学习阶段：使用CNN在固定长度时间补丁上提取短程时间动态和非线性特征交互，生成紧凑的补丁级token嵌入，并通过token级自注意力跨时间补丁交互细化嵌入；2) 全局依赖建模阶段：使用Transformer编码器处理token序列，建模补丁间时间依赖关系并生成每个补丁的预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于补丁的token化策略相比卷积和基于补丁的Transformer基线实现了有竞争力的预测性能。

Conclusion: 结构化时间表示的重要性得到验证，将局部时间编码与基于注意力的全局建模解耦能够产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [441] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 该论文提出使用半定规划（SDP）从经典数据中重构量子通道，当保真度可表示为两个二次型之比时，SDP能高效求解。实验发现重构的量子通道通常具有很小的Kraus秩，表明少量Kraus算子足以描述实验数据。


<details>
  <summary>Details</summary>
Motivation: 研究如何从经典实验数据中重构量子通道，解决量子信息处理中的通道识别问题。当保真度函数具有特定数学形式时，需要开发高效的重构方法。

Method: 采用半定规划（SDP）方法，将保真度优化问题转化为关于Choi矩阵的凸优化问题。利用商业SDP求解器处理不同类型的量子通道重构，包括混合态到纯态映射、投影算子和酉学习等。

Result: 多种商业SDP求解器都能成功重构不同形式的量子通道。重构得到的量子通道通常具有很小的Kraus秩（小于最大可能值的几个百分比），表明少量Kraus算子就足以描述实验观测数据。

Conclusion: SDP是重构量子通道的有效方法，重构得到的通道通常具有低Kraus秩，这为基于量子通道变换的经典计算模型提供了理论基础，可在经典计算机上实现硬件优化。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [442] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基策略预测技术，通过旧梯度预测策略更新，减少基策略与当前策略差距，在有限通信下实现高效MARL学习


<details>
  <summary>Details</summary>
Motivation: 传统合作式MARL假设频繁访问全局信息（如团队奖励、其他智能体动作），这在去中心化系统中不现实（通信成本高）。当通信受限时，智能体只能依赖过时信息估计梯度和更新策略，重要性采样方法在通信受限时变得不稳定

Method: 提出基策略预测技术：利用旧梯度预测策略更新，为一系列基策略收集样本，减少基策略与当前策略之间的差距。该方法能在一次通信轮次内收集预测基策略的样本

Result: 理论上证明算法在势博弈中收敛到ε-纳什均衡，仅需O(ε^{-3/4})通信轮次和O(poly(max_i|A_i|)ε^{-11/4})样本，改进了通信成本和样本复杂度（无联合动作空间大小的指数依赖）。扩展到一般马尔可夫合作博弈寻找智能体局部最优

Conclusion: 基策略预测算法能有效减少通信需求，在有限通信下实现高效学习，在模拟游戏和复杂环境的MAPPO中验证了有效性

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [443] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

TL;DR: 本文提出改进拉格朗日神经网络(LNNs)的方法，包括Hessian正则化、专用激活函数和物理感知坐标缩放，显著提升训练稳定性和复杂系统建模能力，成功应用于双摆、三摆系统，并扩展到相对论场景的测地线学习。


<details>
  <summary>Details</summary>
Motivation: 传统拉格朗日神经网络在训练中存在显著不稳定性，限制了其在复杂系统中的应用。需要解决这些基本挑战，使LNNs能够处理更复杂的物理系统，包括扩展到相对论场景。

Method: 1. Hessian正则化方案：惩罚拉格朗日函数对速度二阶导数中的非物理特征，防止学习不稳定动力学；2. 专门设计的激活函数：更适合学习拉格朗日函数；3. 物理感知坐标缩放：提高稳定性；4. 扩展到相对论场景：正则化惩罚违反洛伦兹特征的行为。

Result: 改进架构成功训练前所未有的复杂系统（包括三摆系统），在双摆系统中验证损失降低96.6%，稳定性提升90.68%。首次从轨迹数据中预测AdS₄时空度量下的测地线拉格朗日函数，为物理中几何结构的自动发现开辟新可能。

Conclusion: 虽然继承了原始LNN框架的一些限制（特别是可逆Hessian的要求），但显著扩展了LNNs在科学发现任务中的实际适用性，为从测地线轨迹提取时空度量张量分量等应用开辟了新可能性。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [444] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 本文提出了一种针对稀疏二元特征和二元分类的决策树流式学习算法，能够快速找到近似最优分割点，在信息增益和基尼指数上实现(1+α)近似，计算复杂度显著低于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统决策树流式学习算法在寻找最优分割时需要O(d)时间（d为特征数），对于稀疏数据效率不高。本文旨在为稀疏二元特征和二元分类场景设计更高效的近似最优分割算法。

Method: 提出一种针对稀疏二元特征的近似算法：对于条件熵，在摊销O(α^{-1}(1+m log d) log log n)时间内实现(1+α)近似；对于基尼指数，在摊销O(α^{-1}+m log d)时间内实现(1+α)近似，其中m是数据点中1的数量，n是数据点数。

Result: 实验结果表明，该算法能够高效找到几乎最优的分割点，速度优于基线方法，且实际性能超过了理论近似保证。

Conclusion: 针对稀疏二元特征和二元分类的决策树流式学习，本文提出的近似算法在保持分割质量的同时显著提高了计算效率，特别适用于m≪d的稀疏数据场景。

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [445] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 该论文将电动汽车在线集中充电调度问题（OCCSP）游戏化，通过图像到运动模型结合DAgger训练，在负载均衡和经济效益上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车实时充电调度问题，需要在容量限制下平衡负载，传统方法难以应对动态到达的电动汽车和复杂的时空约束。

Method: 将充电调度问题游戏化建模，设计启发式策略，通过专家演示训练学习智能体，并使用数据集聚合（DAgger）进行改进。提出图像到运动模型处理时空约束。

Result: 游戏化学习显著提升负载均衡效果，DAgger训练的模型在多种电动汽车到达模式下均优于启发式基线、向量方法和监督学习智能体，在蒙特利尔地区的实际案例中每年可节省数千万美元系统成本。

Conclusion: 游戏化方法降低了模型复杂度并提供了更紧的泛化界限，基于DAgger的图像到运动模型在电动汽车充电调度中表现出优越性能和经济效益，具有延迟电网升级的潜力。

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [446] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

TL;DR: 论文提出了两种机器学习架构（BCNN和SQuAT）用于从系外行星反射光谱预测生物标志物通量，旨在帮助未来旗舰任务如HWO优化观测优先级。


<details>
  <summary>Details</summary>
Motivation: 未来直接成像旗舰任务（如NASA的HWO）面临严格的时间和资源限制，需要高效优先观测目标。传统方法在从反射光谱预测生物标志物方面存在不确定性量化和可解释性不足的问题。

Method: 提出了两种机器学习架构：1) 贝叶斯卷积神经网络（BCNN），用于量化认知和随机不确定性；2) 新颖的谱查询自适应变换器（SQuAT），采用查询驱动注意力机制增强可解释性，将光谱特征与特定生物标志物物种关联。

Result: 两种模型在涵盖广泛系外行星条件的增强数据集上均实现了较高的预测准确性。BCNN在不确定性量化方面表现优异，SQuAT在光谱可解释性方面具有优势。

Conclusion: 这些方法有望加速目标筛选、优化观测计划，并为HWO等即将到来的旗舰任务最大化科学回报，是处理系外行星反射光谱的有前景工具。

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [447] [Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization](https://arxiv.org/abs/2601.12598)
*Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Emre Neftci*

Main category: cs.LG

TL;DR: 该论文提出了SelectivBench，一个用于系统评估线性循环模型的轻量级合成基准测试，重点关注模型的选择性能力，并揭示了线性循环模型中关键架构特征的作用。


<details>
  <summary>Details</summary>
Motivation: 线性循环神经网络作为Transformer注意力机制的高效替代方案，虽然具有并行训练和恒定推理资源的优势，但现有评估方法存在局限性：要么过于简单无法揭示实质性差异，要么资源消耗过大。缺乏系统性的直接比较，且模型架构复杂性不断增加，需要更有效的评估工具。

Method: 提出了SelectivBench基准测试，使用基于规则的语法生成可调整复杂度的序列，包含故意违反转换规则的不规则间隔。该基准专门评估中小规模序列模型的选择性能力，即关注相关输入同时忽略基于上下文的干扰信息的能力。还提出了线性循环模型的细化分类法。

Result: 在SelectivBench上评估线性循环模型显示，性能模式与大规模语言任务结果一致。分析揭示了关键架构特征的作用：门控和快速遗忘机制促进回忆；状态内通道混合对选择性不必要但对泛化关键；softmax注意力仍占主导，因其内存容量随序列长度扩展。

Conclusion: SelectivBench为线性循环模型提供了有针对性的高效探索工具，并为研究大规模评估中观察到的行为提供了受控环境。该基准有助于系统比较不同线性循环模型，理解其架构特征对性能的影响。

Abstract: Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench

</details>


### [448] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出基于广义f-softargmax的策略参数化替代softmax，结合f-散度正则化，改善优化景观，为有限MDP的随机策略梯度方法建立首个显式非渐近最后迭代收敛保证


<details>
  <summary>Details</summary>
Motivation: 传统softmax参数化会导致病态优化景观和指数级慢收敛，预调节方法计算昂贵，需要更有效的替代方案

Method: 使用广义f-softargmax替代softmax参数化，结合相同f-散度诱导的正则化器，改善优化景观并确保正则化目标满足Polyak-Lojasiewicz不等式

Result: 为有限MDP的随机策略梯度方法建立首个显式非渐近最后迭代收敛保证，推导未正则化问题的样本复杂度边界，f-PG（使用Tsallis散度）实现多项式样本复杂度

Conclusion: f-softargmax参数化结合f-散度正则化能有效解决softmax的收敛问题，无需预调节即可获得理论保证，显著改善策略梯度方法的收敛性能

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [449] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 该论文提出了一种基于矩阵迹幂计算对数行列式的新方法，通过矩生成函数变换和插值技术，在有限计算成本下提供对数行列式的点估计和可证明的误差界。


<details>
  <summary>Details</summary>
Motivation: 高斯过程推断和贝叶斯模型比较中需要计算大型对称正定矩阵的对数行列式。传统方法使用矩阵向量积和多项式近似，但本文研究当矩阵幂可用时，通过迹幂计算对数行列式的替代方案。

Method: 1. 将问题转化为估计矩生成函数M(t)在t=0处的导数；2. 使用变换K(t)=log M(t)压缩数值范围；3. 通过m+1个连续整数点插值K(t)并估计K'(0)；4. 从相同迹信息推导对数行列式的上下界；5. 提供诊断指标判断点估计的可信度。

Result: 1. 证明了使用有限正矩的连续估计器无法在无界条件数下保持均匀精度；2. 提出了计算复杂度为O(m)的估计器和误差界算法；3. 当m∈{4,...,8}时，算法具有常数时间复杂度；4. 提供了谱下界r≤λ_min时的矩约束下界。

Conclusion: 该方法通过矩生成函数变换和插值技术，在有限计算成本下为对数行列式计算提供了点估计和可证明的误差界，特别适用于矩阵幂可用的场景，并通过诊断指标帮助用户判断估计的可靠性。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [450] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 提出一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成通用对抗扰动，在降低可见性的同时提高攻击成功率


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动能够用单一噪声模式破坏多个深度神经网络输入，进化算法因其在非凸、无梯度空间中的导航能力而成为有前景的生成方法

Method: 采用浮点编码的惩罚驱动单目标进化框架，利用连续基因表示与深度学习规模对齐，结合动态进化算子与自适应调度，采用模块化PyTorch实现，通过跨模型测试和周期性批次切换确保扰动通用性

Result: 在ImageNet数据集上的实验表明，相比现有进化方法，该框架能生成范数更小、误分类效果更高、收敛更快的扰动

Conclusion: 该方法展现了生成通用对抗扰动方面的鲁棒性和可扩展性，适用于各种深度学习架构

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [451] [Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.12637)
*Long D. Nguyen,Kelin Xia,Binh P. Nguyen*

Main category: cs.LG

TL;DR: MI-MoE：一种用于3D分子图学习的多尺度交互专家混合模型，通过拓扑感知路由机制自适应地建模短程、中程和长程相互作用


<details>
  <summary>Details</summary>
Motivation: 大多数3D分子图神经网络依赖固定的邻域启发式方法（如距离截断和最大邻居限制），导致刚性的、数据无关的交互预算，无法灵活适应不同几何尺度下的相互作用

Method: 提出多尺度交互专家混合模型（MI-MoE）：1）距离截断专家集合，显式捕获短程、中程和长程相互作用；2）拓扑门控编码器，使用基于过滤的描述符（包括持久同调特征）将输入路由到不同专家；3）作为即插即用模块，可改进多种3D分子骨干网络

Result: MI-MoE在多种分子和聚合物性质预测基准数据集（包括回归和分类任务）上，一致地改进了多个强大的3D分子骨干网络的性能

Conclusion: 拓扑感知的多尺度路由是3D分子图学习的有效原则，能够自适应地建模不同几何尺度下的分子相互作用

Abstract: Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.

</details>


### [452] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: SHAP解释存在多重性：即使输入、任务和训练模型固定，多次运行SHAP会得到不同但都有效的特征归因解释，这种多重性普遍存在且影响解释的可靠性。


<details>
  <summary>Details</summary>
Motivation: SHAP作为事后解释方法被广泛用于高风险决策的验证和审计，但人们发现即使输入、任务和训练模型固定，SHAP解释在不同运行中也会显著变化，这种解释多重性现象需要系统研究。

Method: 提出了一种方法来表征特征归因解释中的多重性，区分模型训练/选择带来的变异与解释管道内在随机性的来源；使用幅度距离和基于排名的度量来评估稳定性；推导了合理零模型下的随机化基线值。

Result: 发现解释多重性普遍存在，即使对于高置信度预测也是如此；幅度距离可能接近零而基于排名的度量显示重要特征的身份和排序存在显著变化；不同数据集、模型类别和置信度区间都观察到这种现象。

Conclusion: 解释多重性是普遍且持久的问题，需要开发与解释预期用途相匹配的度量和基线，以确保SHAP等解释方法的可靠性和实际应用价值。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [453] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

TL;DR: 提出基于图多智能体强化学习的框架，用于多跳无线网络中自回归马尔可夫源的实时采样与估计优化，策略可迁移至结构相似的网络。


<details>
  <summary>Details</summary>
Motivation: 在多跳无线网络中，节点通过缓存和无线碰撞信道通信来最小化时间平均估计误差，但由于动作空间高维度和网络拓扑复杂性，解析推导最优策略不可行。

Method: 提出图形多智能体强化学习框架进行策略优化，利用图结构表示网络拓扑，实现去中心化策略学习，并证明策略在结构相似图间的可迁移性。

Result: 数值实验表明：1) 所提策略优于现有基线；2) 训练策略可迁移至更大网络，性能增益随智能体数量增加；3) 图形训练能抵抗非平稳性；4) 循环机制对独立学习和集中训练分散执行都至关重要。

Conclusion: 图形多智能体强化学习框架能有效解决复杂无线网络中的实时采样估计问题，策略具有可迁移性和对非平稳环境的鲁棒性，为动态网络优化提供实用方案。

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [454] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 提出MetaToolAgent (MTA)元学习方法，通过包含155个工具和9,377个问答对的综合数据集，提升大语言模型在未见工具上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法通常局限于有限工具集，难以泛化到实际部署中遇到的新工具，需要解决大语言模型在复杂现实任务中动态协调多样化工具的挑战。

Method: 提出MetaToolAgent (MTA)元学习方法，使用包含7个领域、155个工具和9,377个问答对的综合数据集，模拟真实集成场景，提升跨工具泛化能力。

Result: 实验结果表明，MTA在未见工具上显著优于基线方法，展示了构建需要动态工具协调的灵活可扩展系统的潜力。

Conclusion: MTA通过元学习方法有效提升了大语言模型在多样化工具上的泛化能力，为构建灵活可扩展的工具协调系统提供了有前景的解决方案。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [455] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

TL;DR: 提出一种轻量级T3P多臂老虎机强化学习方法，用于帕金森病深部脑刺激的自适应调节，可同时调频调幅，无需离线训练，适合植入式设备部署。


<details>
  <summary>Details</summary>
Motivation: 传统DBS使用固定频率和振幅，存在副作用和电池寿命短的问题。现有RL方法复杂、训练时间长、计算资源要求高，且大多只调节单一参数，难以在植入设备中部署。

Method: 提出T3P多臂老虎机RL方法，采用时间和阈值触发机制，可同时调节DBS信号的频率和振幅。该方法轻量级，无需离线训练，可直接在微控制器单元上部署。

Result: T3P算法在多种MCU平台上验证，相比现有RL方法具有更好的样本效率和收敛速度，能耗更低，适合资源受限的植入式平台。

Conclusion: T3P MAB方法为DBS提供了一种高效、轻量级的自适应调节方案，解决了现有RL方法在植入设备中部署的难题，实现了频率和振幅的联合优化。

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [456] [Towards Spectroscopy: Susceptibility Clusters in Language Models](https://arxiv.org/abs/2601.12703)
*Andrew Gordon,Garrett Baker,George Wang,William Snell,Stan van Wingerden,Daniel Murfet*

Main category: cs.LG

TL;DR: 提出一种基于谱分析的神经网络内部结构探测方法，通过扰动数据分布测量模型响应，识别出510个可解释的聚类


<details>
  <summary>Details</summary>
Motivation: 借鉴物理学中的谱分析原理，通过测量系统对扰动的响应来推断内部结构，将此方法应用于神经网络以理解其内部工作机制

Method: 通过上加权特定token来扰动数据分布，使用随机梯度朗之万动力学计算敏感性，开发基于电导的聚类算法分析模型响应

Result: 在Pythia-14M模型中识别出510个可解释的聚类，涵盖语法模式、代码结构和数学符号等，50%的聚类与稀疏自编码器特征匹配

Conclusion: 敏感性分析能有效揭示神经网络内部结构，与稀疏自编码器互补，为理解模型工作机制提供了新视角

Abstract: Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts "for similar reasons" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.

</details>


### [457] [Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems](https://arxiv.org/abs/2601.12704)
*Yan Ma,Yumeng Ren*

Main category: cs.LG

TL;DR: 提出基于径向基函数神经网络的物理信息机器学习算法，用于求解多资产期权定价的Black-Scholes偏微分方程。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多维期权定价模型，特别是具有非光滑支付条件时面临计算效率和精度挑战，需要开发更有效的数值解法。

Method: 开发物理信息径向基函数神经网络(PIRBFNN)，结合传统径向基函数配置法和物理信息神经网络，通过PDE残差技术自适应调整隐藏神经元分布，优化网络架构并预测期权价格。

Result: 通过单资产欧式看跌期权、双资产交换期权和四资产篮子看涨期权的实验验证了方法的有效性，能够准确高效处理多维期权定价模型。

Conclusion: PIRBFNN方法成功结合了径向基函数配置法和物理信息神经网络的优点，为金融领域PDE问题提供了准确高效的解决方案。

Abstract: The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.

</details>


### [458] [Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting](https://arxiv.org/abs/2601.12706)
*Sina Kazemdehbashi*

Main category: cs.LG

TL;DR: 论文提出TATS模型，将时间序列预测重构为趋势预测和数值预测两部分，通过二元分类器预测趋势方向，再用LSTM/Bi-LSTM预测数值，最后根据预测趋势调整预测值，在金融时间序列上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法（包括统计模型和LSTM等神经网络）通常直接预测数值，但作者认为时间序列预测应分为趋势预测和数值预测两部分。现有评估指标（如MSE、MAE）不足以全面评估模型性能，需要同时考虑趋势捕捉能力。

Method: 提出TATS模型：1）使用二元分类器预测下一时间步的趋势方向（上涨/下跌）；2）使用LSTM或Bi-LSTM预测下一时间步的数值；3）根据预测的趋势方向调整数值预测结果。在波动性强的金融时间序列（黄金日价格）上进行验证。

Result: 实验结果显示TATS模型在预测误差上显著低于标准LSTM和Bi-LSTM模型。同时发现传统评估指标MSE和MAE不足以全面评估时间序列模型性能，需要结合趋势检测准确率来评估模型捕捉趋势的能力。

Conclusion: 将时间序列预测重构为趋势预测和数值预测两部分是有效的，TATS模型通过趋势调整机制显著提升了预测精度。未来时间序列预测评估应同时考虑数值误差和趋势捕捉能力。

Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.

</details>


### [459] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出统一框架从观察到的玩家策略和行动中恢复零和矩阵博弈和马尔可夫博弈中的未知奖励函数，解决逆问题的模糊性和数据覆盖有限等挑战


<details>
  <summary>Details</summary>
Motivation: 在逆强化学习和博弈论中，估计驱动智能体行为的未知奖励函数是核心问题。由于逆问题的固有模糊性、可行奖励的非唯一性以及观测数据覆盖有限，这项任务具有挑战性

Method: 建立在线性假设下使用量化响应均衡(QRE)的奖励函数可识别性理论，提出从观察行动中学习奖励函数的新算法，适用于静态和动态设置，可结合最大似然估计等方法

Result: 为算法提供了可靠性和样本效率的强理论保证，并通过广泛的数值研究证明了框架的实际有效性，为竞争环境中的决策提供了新见解

Conclusion: 开发了一个统一的奖励函数恢复框架，解决了逆强化学习中的关键挑战，为理解竞争环境中的决策过程提供了理论支持和实用工具

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [460] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: DCPO提出了一种分布中心的强化学习方法，通过分布级正则化控制策略熵，解决了GRPO训练中探索不足的问题，相比样本中心方法提供了更理论化、可控的探索框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的强化学习训练倾向于过度利用，导致熵单调下降、样本收敛和探索消失。大多数现有解决方案是样本中心的，依赖于寻找或奖励稀有样本，这些方法依赖于"幸运"的信息样本，缺乏对策略的原则性控制，且效果有限或不一致。

Method: 提出了Distribution-Centric Policy Optimization (DCPO)，从分布中心视角重新思考强化学习，将探索视为由"更好"的目标分布引导。将熵调节重新表述为分布级正则化，完全在策略内实现可控熵，无需从外部分布采样。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%。DCPO能够实现高效探索同时保持训练稳定性，用分布级原则替代了样本级启发式方法。

Conclusion: DCPO提供了一个理论上有基础且灵活的框架，用于可控探索和更强的探索-利用权衡，代表了从样本中心到分布中心视角的范式转变。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [461] [A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection](https://arxiv.org/abs/2601.12745)
*Miao Ye,Jing Cui,Yuan huang,Qian He,Yong Wang,Jiwen Zhang*

Main category: cs.LG

TL;DR: 提出一种用于WSN多时序模态数据异常检测的图神经网络方法，结合时空相关特征提取和多任务自监督训练策略，在公开和实际数据集上获得超过91%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有多时序模态数据异常检测方法存在时空相关特征提取不足、异常样本标注成本高、样本不平衡等问题，需要针对WSN图结构数据特点设计更有效的检测方法。

Method: 1) 改进Mamba模型并结合变分图卷积模块，构建能充分提取WSN多节点多时序模态时空相关特征的异常检测骨干网络；2) 设计包含无负对比学习、预测和重构的三子任务预训练方法；3) 采用"预训练-图提示-微调"的多任务自监督训练策略。

Result: 在公开数据集和实际采集数据集上分别获得91.30%和92.31%的F1分数，相比现有方法具有更好的检测性能和泛化能力。

Conclusion: 所提出的结合时空相关特征提取和多任务自监督训练的图神经网络方法，能有效解决WSN多时序模态数据异常检测中的特征提取不足和标注成本问题，具有优异的检测性能和泛化能力。

Abstract: Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.

</details>


### [462] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 本文提出基于布尔函数理论的图神经网络表达能力新框架，引入子群体布尔同构概念，超越现有表达能力度量，识别傅里叶度、电路类和影响力作为公平感知GNN的关键表达障碍，设计能处理复杂布尔函数定义子群体的公平算法。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络表达能力分析框架（如Weisfeiler-Lehman、双连通性、同态框架）无法精细分析GNN捕捉复杂子群体结构的能力，特别是在公平性场景中处理由复杂布尔函数定义的交叉子群体时存在局限。

Method: 提出基于布尔函数理论的表达能力分析框架，引入子群体布尔同构概念；识别傅里叶度、电路类和影响力作为表达障碍；设计基于电路遍历的公平算法，能处理奇偶性等高复杂度布尔函数定义的子群体。

Result: 理论证明SBI严格包含现有表达能力度量；在真实世界图数据上，该方法在现有方法失败的交叉子群体上实现低公平性差距，为GNN公平性提供首个原则性表达能力分析。

Conclusion: 基于布尔函数理论的框架为GNN表达能力提供了更精细的分析工具，特别适用于公平性场景，能处理复杂子群体结构，填补了现有表达能力度量在公平感知GNN分析上的空白。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [463] [Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks](https://arxiv.org/abs/2601.12775)
*Yuta Hirabayashi,Daisuke Matusoka,Konobu Kimura*

Main category: cs.LG

TL;DR: 该研究提出了一种基于多尺度图神经网络的海洋模型，用于10天全球预报，通过双分辨率球面网格和大气变量输入，提高了短期预测精度和多尺度海洋变率的表征能力。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动的海洋模型研究进展迅速，但在全球涡旋分辨海洋预报中的应用仍然有限。准确表征广泛空间尺度上的海洋动力学是此类应用的主要挑战。

Method: 采用编码器-处理器-解码器架构，使用两种不同分辨率的球面网格来捕捉海洋动力学的多尺度特性。模型将表面大气变量与海洋状态变量一起作为节点输入，以通过表征大气强迫来提高短期预测精度。

Result: 通过表面动能谱和案例研究评估显示，模型能准确表征广泛的空间尺度范围，均方根误差比较表明短期预测技能有所提高。

Conclusion: 该模型提供了更准确的短期预报和更好的多尺度海洋动力学表征，显示出在推进数据驱动的涡旋分辨全球海洋预报方面的潜力。

Abstract: Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.

</details>


### [464] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，通过水平加权目标和时间对齐策略解决任务难度差异和架构差异问题，实现模型压缩同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然预测性能强，但参数量大导致部署成本高。现有的通用知识蒸馏方法不适用于时间序列预测的特殊性，需要专门设计蒸馏框架。

Method: 提出DistilTS框架：1) 水平加权目标函数，平衡不同预测水平的学习权重，解决短期预测主导优化的问题；2) 时间对齐策略，减少教师模型和学生模型之间的架构不匹配。

Result: 在多个基准测试中，DistilTS实现了与完整规模时间序列基础模型相当的预测性能，同时参数减少高达1/150，推理加速高达6000倍。

Conclusion: DistilTS是首个专门针对时间序列基础模型的知识蒸馏框架，有效解决了任务难度差异和架构差异问题，实现了高效的模型压缩，为时间序列预测模型的部署提供了实用解决方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [465] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: SIT-Graph：一种用于图学习的半监督指令调优框架，通过迭代自训练利用未标记节点提升LLMs在图学习任务中的性能


<details>
  <summary>Details</summary>
Motivation: 传统图指令调优需要大量标注节点数据，这在社交领域成本高昂且难以获取；同时未能利用未标记节点中的潜在相关性信息

Method: 提出模型无关的SIT-Graph框架，通过迭代自训练过程：先用标记节点微调模型，然后为未标记节点生成置信度过滤的伪响应来扩充数据集，最后通过迭代优化使LLM与节点相关性对齐

Result: 将SIT-Graph集成到最先进的图指令调优方法中，在文本属性图基准测试中显著提升性能，在低标签比例设置下获得超过20%的改进

Conclusion: SIT-Graph有效解决了图学习中标注数据稀缺的问题，通过半监督方法充分利用未标记节点的潜在相关性，为LLMs在图学习任务中的应用提供了高效解决方案

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [466] [Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning](https://arxiv.org/abs/2601.12816)
*Ishir Garg,Neel Kolhe,Andy Peng,Rohan Gopalam*

Main category: cs.LG

TL;DR: 提出FOPNG优化器，通过Fisher正交约束保护旧任务性能，在信息几何框架下统一自然梯度下降与正交梯度方法


<details>
  <summary>Details</summary>
Motivation: 持续学习需要神经网络在顺序任务中获取新知识，但关键挑战是在学习新任务时不灾难性遗忘旧任务。现有方法在欧几里得参数空间中操作，缺乏信息几何框架下的统一理论。

Method: 提出Fisher-正交投影自然梯度下降(FOPNG)优化器，将梯度投影到先前任务梯度的Fisher正交补空间。该方法在信息几何框架下统一自然梯度下降与正交梯度方法，更新方向具有重参数化不变性，保证在Fisher度量下的下降，并保护先前任务输出。

Result: 在标准持续学习基准测试(Permuted-MNIST、Split-MNIST、Rotated-MNIST、Split-CIFAR10、Split-CIFAR100)上展示了强劲结果，验证了方法的有效性。

Conclusion: FOPNG通过Fisher正交约束有效缓解灾难性遗忘，在信息几何框架下提供了理论保证，为持续学习提供了统一且实用的优化方法。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.

</details>


### [467] [Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations](https://arxiv.org/abs/2601.12839)
*Gyuyeon Na,Minjung Park,Soyoun Kim,Jungbin Shin,Sangmi Chai*

Main category: cs.LG

TL;DR: RDLI框架通过将专家启发式逻辑嵌入表示学习，结合检索式上下文模块，在极低标签率下显著提升加密货币异常交易检测性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 去中心化加密货币网络中异常交易检测面临极端标签稀缺和恶意行为者自适应规避策略的挑战。传统GNN虽然能捕捉局部结构模式，但难以内化多跳、逻辑驱动的资金分散和分层等洗钱特征，限制了其在FATF旅行规则等监管要求下的法证可问责性。

Method: 提出关系域逻辑集成(RDLI)框架，将专家推导的启发式作为可微分、逻辑感知的潜在信号嵌入表示学习。不同于静态规则方法，RDLI能够检测规避标准消息传递的复杂交易流。此外，引入检索式上下文(RGC)模块，将异常评分基于监管和宏观经济上下文，减轻良性制度变化引起的误报。

Result: 在极端标签稀缺(0.01%)条件下，RDLI在F1分数上比最先进的GNN基线方法提升28.9%。微观专家用户研究进一步证实，RDLI的路径级解释在可信度、感知有用性和清晰度方面显著优于现有方法。

Conclusion: RDLI框架通过将领域逻辑与上下文基础相结合，不仅提高了异常检测的准确性，还显著增强了可解释性，为加密货币网络中的法证分析和监管合规提供了更有效的解决方案。

Abstract: Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.

</details>


### [468] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一种生成机器学习模型，通过Cremer-Pople空间中的流匹配技术，专门用于生成环状分子的构象，在多样性和精确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学中广泛应用，其受限的构象灵活性对药物发现和催化功能至关重要，但可靠采样环系统的构象集合仍然具有挑战性。

Method: 引入PuckerFlow模型，在Cremer-Pople空间（捕获环相关自由度的低维内坐标系统）上执行流匹配，确保生成有效的闭合环结构。

Result: PuckerFlow在几乎所有定量指标上优于其他构象生成方法，能够生成既多样又精确的构象，特别适用于催化和药物发现中的环系统。

Conclusion: 该工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系和跨化学与生物学应用的属性引导环生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [469] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: HAGD框架通过分层抽象和可微分搜索，将神经网络电路发现的复杂度从指数级降低到多项式级，在保持行为准确性的同时提取可解释的计算电路。


<details>
  <summary>Details</summary>
Motivation: 当前从数十亿参数语言模型中提取稀疏计算电路面临指数搜索复杂度和普遍多义性的挑战，需要更高效的电路发现方法。

Method: 提出分层归因图分解（HAGD）框架，包含跨层转码器提取单义特征、图神经网络元学习预测拓扑结构、因果干预协议验证电路。

Result: 在GPT-2、Llama-7B到70B、Pythia等模型上评估，在模块化算术任务中保持91%行为准确性，跨架构电路结构相似性达67%。

Conclusion: 为大规模模型可解释性提供初步基础，但当前归因方法仍有显著局限性，需要未来进一步改进。

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [470] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs：一种针对时间序列预测任务的源自由测试时间自适应方法，利用神经常微分方程处理分布偏移，仅需更新有限参数即可在多种分布偏移场景下显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间自适应方法主要针对独立数据设计，很少考虑时间序列数据的特性和预测任务的需求，无法有效处理时间序列数据中的分布偏移问题。

Method: 提出基于神经常微分方程的自适应框架，专门针对时间序列预测任务设计新的损失函数，仅更新有限模型参数以降低内存使用，同时保持对时间依赖关系的捕捉能力。

Result: 在一维和高维数据上的实验表明，AdaNODEs相比现有最佳基线分别获得5.88%和28.4%的相对改进，在更高严重程度的分布偏移下表现出更强的鲁棒性。

Conclusion: AdaNODEs为时间序列预测任务提供了一种有效的源自由测试时间自适应方法，能够有效处理分布偏移问题，在保持内存效率的同时显著提升预测性能。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [471] [Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times](https://arxiv.org/abs/2601.12900)
*Eliran Sherzer,Yonit Barron*

Main category: cs.LG

TL;DR: 使用神经网络监督学习框架近似(s,S)库存系统的稳态性能指标，替代昂贵的仿真计算


<details>
  <summary>Details</summary>
Motivation: 连续审查(s,S)库存模型是随机库存理论的基石，但在处理非马尔可夫系统时分析变得难以处理，通常依赖昂贵的仿真来评估长期性能指标

Method: 提出监督学习框架，通过神经网络模型近似(s,S)库存系统的稳态性能指标。首先使用仿真生成训练标签，然后训练神经网络。训练后，神经网络可以几乎即时预测各种系统指标，如库存水平的稳态分布、期望周期时间和缺货概率。研究发现使用少量低阶矩作为输入就足够训练神经网络并准确捕捉稳态分布

Result: 广泛的数值实验表明，该方法在广泛的系统参数范围内具有高准确性，有效替代了重复且昂贵的仿真运行

Conclusion: 该框架易于扩展到其他库存模型，为分析复杂随机系统提供了高效快速的替代方案

Abstract: The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.
  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.

</details>


### [472] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 提出了BenchTGC基准，用于解决时序图聚类任务中的技术不适用和数据集不适用两大挑战，通过改进现有聚类技术和开发专用数据集来推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 时序图聚类是一个新兴但关注度低的任务，相比静态图聚类能在时间与空间需求之间找到平衡。然而，现有聚类技术不适用和缺乏合适数据集两大挑战阻碍了该领域发展。

Method: 提出了BenchTGC基准，包括：1）设计BenchTGC框架来阐述时序图聚类范式；2）改进现有聚类技术以适应时序图；3）讨论公共时序图数据集问题并开发适合TGC任务的BenchTGC数据集。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时序图聚类任务的必要性和重要性。实验表明，现实世界中动态变化和复杂场景是时序图聚类的基础。

Conclusion: BenchTGC基准成功解决了时序图聚类面临的主要挑战，为该领域提供了标准化评估框架和专用数据集，推动了时序图聚类研究的发展。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [473] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM：云辅助的边缘-端协同联邦微调框架，结合移动端的零阶优化和云端的梯度修正，显著降低内存占用、加速收敛并提升精度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动设备上微调面临内存和计算成本高的挑战，现有联邦学习方法要么依赖内存密集型反向传播，要么使用收敛慢、精度低的零阶优化方法

Method: 提出CooperLLM框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来修正本地更新；引入流水线调度和自适应压缩来优化系统瓶颈

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存降低高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线方法精度提升高达10个百分点

Conclusion: CooperLLM通过云辅助的边缘-端协同设计，有效解决了移动设备上LLM联邦微调的内存和收敛问题，实现了隐私保护、高效和准确的个性化模型训练

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [474] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 提出基于形状空间的镰状细胞分类新方法，通过固定参数化和模板对齐简化计算，在监督分类和无监督聚类中达到96.03%准确率


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，全球患病率高且医疗负担重。自动化分类可减少专家工作量，避免人工计数错误，但现有形状空间方法计算复杂

Method: 1) 使用基于细胞长轴的固定参数化计算距离；2) 在计算距离前，使用该参数化将每个细胞与两个模板对齐。相比在所有可能参数化中最小化距离，这种方法简化了计算

Result: 在监督分类和无监督聚类中均达到96.03%的准确率，在保持或提高形状空间模型准确率的同时显著降低了计算成本

Conclusion: 该方法实现了高效的红细胞分类，通过固定参数化和模板对齐策略，在保持高准确率的同时大幅减少了计算复杂度，适用于资源有限地区的医疗应用

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [475] [Online Continual Learning for Time Series: a Natural Score-driven Approach](https://arxiv.org/abs/2601.12931)
*Edoardo Urettini,Daniele Atzeni,Ioanna-Yvonni Tsaknaki,Antonio Carta*

Main category: cs.LG

TL;DR: 该论文提出NatSR方法，将在线持续学习应用于时间序列预测，通过自然梯度下降与重放缓冲结合，在保持长期记忆的同时实现快速适应


<details>
  <summary>Details</summary>
Motivation: 在线时间序列预测需要同时具备快速适应和长期记忆能力，这与在线持续学习的目标高度一致。现有方法在理论联系和实践效果上仍有改进空间

Method: 1) 将神经网络优化重构为参数滤波问题，证明自然梯度下降是得分驱动方法；2) 使用Student's t似然函数结合自然梯度实现有界更新，提高对异常值的鲁棒性；3) 提出NatSR方法，结合鲁棒优化器、重放缓冲和动态尺度启发式策略

Result: NatSR在预测性能上优于更复杂的现有最先进方法，特别是在处理制度漂移时表现出更好的快速适应能力

Conclusion: 该研究强化了时间序列方法与在线持续学习的理论和实践联系，提出的NatSR方法在在线时间序列预测任务中表现出色，为这一领域提供了新的解决方案

Abstract: Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.

</details>


### [476] [Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning](https://arxiv.org/abs/2601.12965)
*Doheon Kim*

Main category: cs.LG

TL;DR: 本文为基于分数的扩散模型中神经网络使用乘法噪声条件化仍能生成良好样本的现象提供了理论解释，尽管这种结构限制了模型学习正确分数函数的能力。


<details>
  <summary>Details</summary>
Motivation: Song和Ermon（2020）发现，虽然基于分数的扩散模型理论上可以通过学习扩散过程的分数函数来生成样本，但实际中神经网络使用乘法噪声条件化（将模型表示为空间变量和噪声幅度两个函数的乘积）仍能产生令人满意的样本。这种结构限制了模型表示空间变量与噪声之间更一般关系的能力，表明它无法完全学习正确的分数函数。本文旨在从理论上解释这一看似矛盾的现象。

Method: 通过研究相关微分方程的确定性动力学，分析基于分数的扩散模型中乘法噪声条件化神经网络的工作机制。该方法不依赖于传统的分数函数学习理论，而是从微分方程动力学的角度来解释模型的实际表现。

Result: 研究揭示了尽管乘法噪声条件化结构限制了模型学习正确分数函数的能力，但通过分析相关微分方程的确定性动力学，可以解释为什么这种简化的模型结构在实践中仍然能够有效生成样本。

Conclusion: 本文为基于分数的扩散模型中一个看似矛盾的现象提供了理论解释：即使神经网络采用简化的乘法噪声条件化结构，无法完全学习正确的分数函数，仍然能够在实践中生成良好的样本。这一发现通过研究相关微分方程的确定性动力学得以阐明，为理解扩散模型的实际工作机制提供了新的理论视角。

Abstract: Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.

</details>


### [477] [Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients](https://arxiv.org/abs/2601.12971)
*Pancheng Niu,Jun Guo,Qiaolin He,Yongming Chen,Yanchao Shi*

Main category: cs.LG

TL;DR: 提出ACR-PINN框架，通过层间动态注意力机制增强表示能力，并使用冲突解决梯度更新策略优化训练，显著提升PINNs在PDE求解中的收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在求解偏微分方程时存在表示能力有限和优化困难的问题，特别是物理约束竞争和梯度冲突导致的训练困难。

Method: 1. 提出层间动态注意力机制（LDA-PINN）增强表示灵活性；2. 将PINN训练重构为多任务学习问题，引入冲突解决梯度更新策略（GC-PINN）；3. 整合两者形成ACR-PINN框架，保持标准PINN损失形式。

Result: 在Burgers、Helmholtz、Klein-Gordon和腔体驱动流等基准PDE问题上，ACR-PINN相比标准PINNs实现了更快的收敛速度和显著更低的相对L2和L∞误差。

Conclusion: 架构-优化协同设计能有效提升PINN求解器的鲁棒性和准确性，为解决PINN训练中的表示和优化挑战提供了新思路。

Abstract: Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.

</details>


### [478] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: PaperCompass：一个将高层规划与细粒度执行分离的框架，通过DFPO训练方法提高科学文献阅读代理的效率


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长使得研究人员难以通过手动阅读跟踪新进展。现有基于LLM的自主代理方法要么依赖大量工程化提示，要么采用传统的SFT-RL训练流程，都容易导致过度且低效的探索。

Method: 提出PaperCompass框架，将高层规划与细粒度执行分离：先制定明确计划，然后通过详细推理实例化每个步骤。引入Draft-and-Follow Policy Optimization (DFPO)训练方法，联合优化草稿计划和最终解决方案。

Result: 在Paper-QA基准测试中，PaperCompass在保持性能的同时提高了效率，取得了与更大模型相当的结果。

Conclusion: PaperCompass通过分离规划与执行，结合DFPO训练方法，有效缩小了LLMs中的"知-行"差距，为科学文献阅读代理提供了更高效的解决方案。

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [479] [HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads](https://arxiv.org/abs/2601.13013)
*Xiaohui Zhao,Xinjian Zhao,Jiahui Zhang,Guoyu Liu,Houzhi Wang,Shu Wu*

Main category: cs.LG

TL;DR: 提出HT-GNN模型解决新闻流广告LTV预测中的两大挑战：人口统计异质性和动态营销策略带来的不规则行为序列，通过超图监督模块、Transformer时序编码器和任务自适应专家混合实现多时间范围预测。


<details>
  <summary>Details</summary>
Motivation: 新闻流广告中的LTV预测面临两个主要挑战：1）基于人口统计的定向导致不同用户群体间的LTV分布差异巨大；2）动态营销策略产生不规则行为序列，用户参与模式快速变化。

Method: 提出超时序图神经网络（HT-GNN），包含三个关键组件：1）超图监督模块捕捉段间关系；2）基于Transformer的时序编码器带自适应加权；3）任务自适应专家混合，配备动态预测塔用于多时间范围LTV预测。

Result: 在百度广告平台的1500万用户数据上实验表明，HT-GNN在所有指标和预测时间范围上都持续优于最先进的方法。

Conclusion: HT-GNN通过联合建模人口统计异质性和时序动态，有效解决了LTV预测中的关键挑战，为新闻流广告的长期收入增长优化提供了有效工具。

Abstract: Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.

</details>


### [480] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 提出PASs方法解决多模态大语言模型持续指令微调中的专家共漂移问题，通过路径激活子空间校准路由并稳定重要秩方向，在保持参数不变的情况下提升准确性和抗遗忘能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的混合专家方法在持续指令微调中，路由器和专家会共同漂移，导致早期输入-专家专业化逐渐偏离，造成专家责任模糊和遗忘加剧。这种"错位共漂移"现象需要解决。

Method: 提出路径激活子空间(PASs)概念，作为LoRA诱导的子空间，反映每个专家中哪些低秩路径方向被输入激活。基于PASs设计固定容量的PASs-based MoE-LoRA方法，包含两个组件：PAS引导的重新加权（使用专家路径激活信号校准路由）和PAS感知的秩稳定化（选择性稳定对先前任务重要的秩方向）。

Result: 在持续指令微调基准测试中，该方法在准确性和抗遗忘方面均优于一系列传统持续学习基线和MoE-LoRA变体，且不增加额外参数。

Conclusion: PASs方法通过路径激活子空间有效解决了专家共漂移问题，为多模态大语言模型的持续指令微调提供了更稳定的路由和保留机制，在保持模型容量的同时显著提升了性能。

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [481] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的镰状细胞病诊断支持系统，通过特征选择和模型优化实现更好的泛化性能，在F1分数和SDS分数上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病的准确诊断对患者治疗至关重要，现有方法在泛化能力和可解释性方面存在不足。本研究旨在开发一个能够提供可靠诊断支持的系统，特别关注模型的泛化能力和可解释性。

Method: 1. 对血液涂片图像进行预处理和分割；2. 提取细胞特征；3. 使用集成机器学习方法（随机森林和Extra Trees）进行分类；4. 设计特征选择方法减少复杂度并提高可解释性；5. 在新数据集上验证泛化能力。

Result: 随机森林和Extra Trees集成模型取得了F1分数90.71%和SDS分数93.33%的优异结果，显著优于之前的梯度提升分类器（F1 87.32%，SDS 89.51%），在新数据集上表现出更好的泛化性能。

Conclusion: 提出的集成学习方法在镰状细胞病诊断支持方面取得了显著改进，具有更好的泛化能力和可解释性。研究提供了完整的代码库和参数配置，有助于科学进步和临床应用。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [482] [Analysis of Long Range Dependency Understanding in State Space Models](https://arxiv.org/abs/2601.13048)
*Srividya Ravikumar,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.LG

TL;DR: 首次对S4D模型进行系统性的核可解释性研究，分析其在真实世界任务（源代码漏洞检测）中的表现，发现S4D的长程建模能力因架构不同而有显著差异，核函数可表现为低通、带通或高通滤波器。


<details>
  <summary>Details</summary>
Motivation: 虽然状态空间模型在长序列基准测试中表现出色，但现有研究主要关注预测准确性而非可解释性。本研究旨在填补这一空白，首次对S4D模型进行系统性核可解释性分析。

Method: 在真实世界任务（源代码漏洞检测）上训练S4D模型，通过时域和频域分析S4D核函数，研究不同模型架构下S4D的长程建模能力变化。

Result: 发现S4D的长程建模能力因架构不同而有显著差异，直接影响模型性能。S4D核函数在不同架构下可表现为低通、带通或高通滤波器。

Conclusion: 本研究为S4D模型提供了首个系统性核可解释性分析，揭示了架构设计对模型能力的重要影响，为未来设计更好的S4D模型提供了指导。

Abstract: Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.

</details>


### [483] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

TL;DR: 提出基于TinyML的边缘物联网框架，用于小型农场智能灌溉，实现离线精准决策，显著减少用水量


<details>
  <summary>Details</summary>
Motivation: 解决小型农场面临的水资源短缺、气候不稳定以及缺乏先进农业技术的挑战，为资源受限地区提供经济可行的解决方案

Method: 采用四层边缘架构，结合低成本硬件（ESP32微控制器和树莓派），使用梯度提升模型进行环境监测和灌溉预测，并通过TinyML在边缘设备上部署

Result: 梯度提升模型表现最佳（R²=0.9973，MAPE=0.99%），系统在受控环境中显著减少用水量，MAPE低于1%，适合离线部署

Conclusion: 该边缘物联网框架为资源受限的农村地区提供了实用、经济、可扩展的精准灌溉解决方案，通过设备端AI提升水资源利用效率

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [484] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个面向本科生的AI研究导师系统，通过分阶段指导、文献搜索、方法论检查等功能，帮助缺乏专家指导的学生完成从想法到论文的完整写作过程。


<details>
  <summary>Details</summary>
Motivation: 许多本科生缺乏专业研究导师的指导，难以独立完成从研究想法到学术论文的完整过程。需要开发AI导师系统来填补这一指导空白。

Method: 构建METIS系统，包含工具增强、阶段感知的助手功能，具备文献搜索、指导指南、方法论检查和记忆能力。采用多阶段评估方法：LLM作为评判者的成对偏好比较、学生角色评分标准、短多轮辅导会话、证据/合规性检查。

Result: 在90个单轮提示中，LLM评判者偏好METIS超过Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分（清晰度/可操作性/约束匹配）在所有阶段都更高。在多轮会话中，METIS的最终质量略高于GPT-5。优势集中在文档基础阶段（D-F）。

Conclusion: METIS作为AI研究导师在帮助学生完成学术写作方面表现优于现有模型，特别是在文档基础阶段。系统存在过早工具路由、基础浅显和偶尔阶段分类错误等失败模式，但整体证明了AI导师的可行性。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [485] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出了递归元蒸馏的公理化算子理论框架，证明在温和条件下递归蒸馏会收敛到基教师分布的唯一固定点


<details>
  <summary>Details</summary>
Motivation: 递归或多代知识蒸馏的数学行为理解不足，现有方法主要依赖经验启发式，缺乏理论基础

Method: 引入公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，定义元教师构造的结构公理

Result: 证明在可实现性和凸性假设下，锚定递归蒸馏在KL散度上诱导收缩，几何收敛到基教师分布，存在唯一全局吸引固定点

Conclusion: 该框架为理解迭代和多教师蒸馏的稳定性、偏差-方差行为和失效模式提供了理论基础，独立于具体算法实现

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [486] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个为音频-视觉大语言模型设计的token剪枝框架，通过两阶段剪枝策略减少40%以上计算量，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然token剪枝在标准LLM和视觉-语言模型中已有研究，但在音频-视觉大语言模型（AV-LLMs）中尚未得到关注。多模态整合显著增加了token需求，因此需要专门的剪枝方法来降低计算成本。

Method: 提出基于注意力权重的剪枝策略：1）在中间层进行全局剪枝，移除广泛影响力较小的token；2）在后续层进行精细剪枝，考虑对下一个token生成的影响。该方法不依赖完整注意力图，完全兼容FlashAttention等高效注意力机制。

Result: 在两个代表性AV-LLM上，FastAV将FLOPs减少超过40%，同时保持甚至提升了模型性能。

Conclusion: FastAV是首个专门为AV-LLMs设计的token剪枝框架，有效降低了多模态模型的计算成本，同时保持性能，为高效音频-视觉处理提供了实用解决方案。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [487] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 论文提出训练稳定性作为学习系统的内在动态特性，通过四个维度（优化、环境/数据、参数、学习信号）进行统一分析，并发现三个规律：最终性能与训练稳定性常脱钩、受控随机性可缓冲学习动态、低维元状态偏差预示性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得了显著的实证性能，但训练过程本身的稳定性仍然理解不足。训练作为高维动态系统，小的扰动可能导致突然且不可逆的崩溃，影响可复现性和可扩展性。需要建立训练稳定性的系统性理解框架。

Method: 提出统一的动态视角，将训练稳定性组织为四个相互作用的维度：优化稳定性、环境/数据稳定性、参数稳定性、学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动态对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中发现三个重复规律：1）高最终性能常与训练稳定性脱钩；2）受控随机性在不同范式中一致地缓冲学习动态；3）低维潜在元状态的偏差系统地先于可观察的性能崩溃。

Conclusion: 训练稳定性是可测量和可比较的学习系统动态特性，为超越最终性能结果研究学习动态提供了描述性基础。这一框架有助于理解训练过程的稳定性机制，提高深度学习系统的可复现性和可扩展性。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [488] [NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness](https://arxiv.org/abs/2601.13162)
*Ali Shafiee Sarvestani,Jason Schmidt,Arman Roohi*

Main category: cs.LG

TL;DR: Neuro-symbolic框架DesignII通过符号规则监督提升神经网络的对抗鲁棒性和可解释性，在GTSRB数据集上相比标准对抗训练获得3倍的鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在对抗攻击下的脆弱性和缺乏可解释性是关键限制，特别是在自动驾驶等安全敏感场景中。需要一种既能增强对抗鲁棒性又能提高可解释性的方法。

Method: 提出DesignII神经符号框架，将符号规则监督集成到神经网络中。将领域知识编码为形状、颜色等外观属性的逻辑约束，通过语义和符号逻辑损失在训练中强制执行。使用FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic两种变体。

Result: 在GTSRB数据集上，FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic相比对应的对抗训练基线分别提升对抗精度18.1%和17.35%，相比标准对抗训练获得约3倍的鲁棒性增益，且不降低干净样本精度。PGD-Neuro-Symbolic使用ResNet18训练10个epoch即可达到或超过需要重型架构和大量数据增强的transformer防御方法的鲁棒性。

Conclusion: 符号推理为构建鲁棒且可解释的AI提供了有效路径，神经符号框架能够显著提升对抗鲁棒性同时保持可解释性。

Abstract: Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.

</details>


### [489] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: LAViG-FLOW：一种用于地下多相流体流动建模的潜在自回归视频生成扩散框架，比传统数值求解器快几个数量级


<details>
  <summary>Details</summary>
Motivation: 地下多相流体流动建模对地质CO2封存和地热生产等应用至关重要，但高保真模拟器在需要多次前向运行进行反演和量化不确定性时计算成本过高

Method: 提出LAViG-FLOW框架，使用专用2D自编码器压缩每个状态变量，通过视频扩散变换器(VDiT)建模它们在时间上的耦合分布，先在给定时间范围内训练学习耦合关系，然后自回归微调以在观测时间窗口外进行外推

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度和压力场在时间上保持一致，运行速度比传统数值求解器快几个数量级

Conclusion: LAViG-FLOW为地下多相流体流动建模提供了一种高效替代方案，显著降低了计算成本，适用于需要大量前向运行的应用场景

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [490] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该研究对LLM推理范式（直接生成、思维链、多智能体系统）进行了统一评估，发现结构复杂性并不总是提升推理性能，并提出了新的开放基准MIMeBench来评估语义能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为推理系统部署时，不同推理范式（如思维链和多智能体系统）的相对效果和成本-准确率权衡缺乏系统理解，需要全面评估来指导实践选择。

Method: 1）在多样化闭式基准上统一评估直接单模型生成、思维链增强单模型推理和代表性多智能体工作流；2）通过角色隔离分析探究MAS中角色特定能力需求；3）分析成本-准确率权衡；4）引入新开放基准MIMeBench评估语义抽象和对比判别能力。

Result: 1）结构复杂性增加并不总带来推理性能提升，其效果高度依赖于推理范式本身的特性和适用性；2）识别了哪些MAS工作流在成本与准确率间取得良好平衡，哪些带来过高开销但收益有限；3）MIMeBench提供了超越闭式准确率的评估维度，能精细评估现有基准难以捕捉的语义能力。

Conclusion: LLM推理范式的选择应基于具体任务特性而非盲目追求结构复杂性，MIMeBench为语义能力评估提供了新工具，代码已开源供社区使用。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [491] [Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks](https://arxiv.org/abs/2601.13244)
*Prateek Munjal,Clement Christophe,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.LG

TL;DR: 指令微调并不总是提升推理能力，反而可能让模型依赖表面模式匹配而非内在推理，在零样本思维链和分布偏移下表现不稳定


<details>
  <summary>Details</summary>
Motivation: 研究指令微调是否真正增强大语言模型的推理能力，还是仅仅诱导表面模式匹配，揭示指令微调的实际效果和局限性

Method: 在标准数学基准测试、结构扰动变体和领域迁移任务上评估基础模型和指令微调模型，分析它们在零样本思维链、少样本提示等不同设置下的表现

Result: 1. 在GSM8K零样本思维链设置中，基础模型持续优于指令微调变体，最大降幅达32.67%（Llama3-70B）；2. 指令微调模型仅在提供少样本示例时才能匹配或超越基础模型；3. 在MedCalc领域特定基准测试中，基础模型优于指令微调变体；4. 指令微调模型在扰动数据集上表现急剧下降

Conclusion: 指令微调的优势不稳定且高度依赖评估设置，模型更多依赖特定提示模式而非内在推理能力，在分布偏移下表现脆弱，表明当前指令微调方法未能有效提升模型的稳健推理能力

Abstract: Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.

</details>


### [492] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出了一种基于多级蒙特卡洛（MLMC）的蒙特卡洛dropout不确定性量化框架，通过重用dropout掩码构建耦合的粗-细估计器，降低方差并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量前向传播来估计预测矩，计算成本高。需要一种更高效的方差缩减方法来提高不确定性估计的效率。

Method: 将dropout掩码作为认知随机性来源，通过前向传播次数定义保真度层次结构。重用不同保真度级别的dropout掩码构建耦合的粗-细估计器，形成用于预测均值和方差的伸缩式MLMC估计器。

Result: 推导了明确的偏差、方差和有效成本表达式，以及跨级别的样本分配规则。在正向和逆向PINNs-Uzawa基准测试中验证了预测的方差率，并在相同计算成本下展示了比单级MC-dropout更高的效率增益。

Conclusion: 提出的MLMC-dropout框架为深度学习不确定性量化提供了一种高效的方差缩减方法，能够以更低的计算成本获得更准确的不确定性估计，特别适用于物理信息神经网络等计算密集型应用。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [493] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: RLVR微调使LLM过度自信，SFT校准更好但性能提升较小；提出校准感知的RL方法，在保持准确率的同时降低ECE分数达9点


<details>
  <summary>Details</summary>
Motivation: LLM在决策任务中部署时，不仅需要准确性，还需要可靠的置信度估计。良好的校准使下游系统能够决定何时信任模型、何时依赖备用机制。需要系统研究不同微调范式（SFT和RLVR）对校准的影响。

Method: 1. 系统研究SFT和RLVR两种微调范式的校准表现；2. 通过针对性实验诊断RLVR失败原因，发现决策标记作为推理轨迹中的决策提取步骤，不携带置信信息；3. 提出校准感知的强化学习公式，直接调整决策标记概率。

Result: RLVR提高任务性能但产生极度过度自信的模型，SFT校准效果更好（即使在分布偏移下），但性能提升较小。提出的校准感知RL方法在保持RLVR准确率水平的同时缓解过度自信，ECE分数降低达9点。

Conclusion: RLVR微调导致过度自信问题，而SFT提供更好的校准。通过理解决策标记在强化学习中的角色，可以设计校准感知的RL方法，在保持性能优势的同时改善校准效果。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [494] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

TL;DR: 论文提出了CooperBench基准测试，评估AI代理在协作编程中的协调能力，发现当前代理存在"协调诅咒"——协作时成功率比单独执行低30%，与人类团队表现相反。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在复杂工作中越来越多地协作，它们需要发展协调能力成为有效的团队成员。但作者假设当前代理缺乏这些能力，需要建立基准来评估和改进。

Method: 创建CooperBench基准，包含600多个协作编程任务，涉及12个库和4种编程语言。每个任务分配两个代理不同的功能，这些功能可以独立实现但可能冲突。任务基于真实开源仓库和专家编写的测试。

Result: 发现"协调诅咒"现象：代理协作时的平均成功率比单独执行两个任务低30%。这与人类团队通常通过增加队友提高生产力的模式相反。分析揭示三个关键问题：沟通渠道堵塞、代理偏离承诺、对他人计划和沟通的错误预期。

Conclusion: 研究提出了协作编程的新基准，呼吁从追求个体代理能力转向发展社交智能。虽然观察到罕见的涌现协调行为，但当前代理在团队协作方面存在显著缺陷。

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [495] [Verifying Local Robustness of Pruned Safety-Critical Networks](https://arxiv.org/abs/2601.13303)
*Minh Le,Phuong Cao*

Main category: cs.LG

TL;DR: 研究发现剪枝对DNN形式化验证有非线性影响：轻剪枝（40%）在MNIST上、重剪枝（70%-90%）在NASA JPL数据集上能提升可验证性，使模型在L∞鲁棒性证明上优于未剪枝基线。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的形式化验证对安全关键应用至关重要，但大规模模型的验证计算成本高昂，阻碍了实际应用。需要探索模型压缩（如剪枝）如何影响形式化验证效果。

Method: 使用最先进的α,β-CROWN验证器，在不同剪枝比例下评估ResNet4模型，分别在MNIST和NASA JPL火星霜冻识别数据集上进行实验。

Result: 发现剪枝与形式化验证之间存在非线性关系：MNIST数据集上轻剪枝（40%）效果最好，而NASA JPL数据集上重剪枝（70%-90%）能显著提升可验证性，使模型在L∞鲁棒性证明上超越未剪枝基线。

Conclusion: 减少网络连接性简化了形式化求解器的搜索空间，但最优剪枝比例因数据集而异。这为在高风险环境中部署高效且经过形式化验证的DNN提供了关键指导。

Abstract: Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.

</details>


### [496] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 提出基于谱嵌入的领域不变表示学习方法，通过将平滑传输计划解释为二分图邻接矩阵，实现鲁棒的领域对齐


<details>
  <summary>Details</summary>
Motivation: 训练和推理数据之间的分布偏移是机器学习中的核心挑战，现有基于最优传输的无监督领域自适应方法对正则化策略和超参数敏感，可能导致有偏的领域对齐

Method: 将平滑传输计划解释为连接源领域和目标领域的二分图邻接矩阵，通过谱嵌入推导领域不变的样本表示

Result: 在音乐流派识别、音乐-语音判别以及电缆缺陷检测和分类等声学适应基准任务上取得了整体强劲的性能

Conclusion: 谱嵌入方法提供了一种鲁棒的领域对齐策略，能够有效处理分布偏移问题，在各种实际应用中表现出色

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [497] [On the Relation of State Space Models and Hidden Markov Models](https://arxiv.org/abs/2601.13357)
*Aydin Ghojogh,M. Hadi Sepanj,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文系统比较了HMMs、线性高斯状态空间模型、卡尔曼滤波和现代NLP状态空间模型，通过概率图模型视角分析它们的公式、推理算法和学习方法，澄清了这些模型之间的等价性和根本差异。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型(SSMs)和隐马尔可夫模型(HMMs)是建模序列数据的基础框架，广泛应用于信号处理、控制理论和机器学习。尽管它们具有相似的时序结构，但在潜在状态性质、概率假设、推理过程和学习范式上存在根本差异。最近，确定性状态空间模型通过S4和Mamba等架构在自然语言处理中重新出现，引发了关于经典概率SSMs、HMMs和现代神经序列模型之间关系的新问题。

Method: 通过概率图模型的视角分析这些模型的公式化表达；检查它们的推理算法，包括前向后向推理和卡尔曼滤波；对比它们的学习过程，包括期望最大化(EM)和基于梯度的优化方法；系统比较HMMs、线性高斯状态空间模型、卡尔曼滤波和当代NLP状态空间模型。

Result: 阐明了这些模型在结构上的相似性和语义上的差异，明确了它们何时等价、何时根本不同，以及现代NLP SSMs如何与经典概率模型相关联。分析结果连接了控制理论、概率建模和现代深度学习的视角。

Conclusion: 本文提供了一个统一的框架来理解状态空间模型家族，通过系统比较经典概率模型和现代神经架构，为研究人员提供了清晰的指导，帮助他们理解这些模型之间的关系、适用场景和根本差异，促进了不同领域之间的知识交流。

Abstract: State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.
  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.

</details>


### [498] [CausationEntropy: Pythonic Optimal Causation Entropy](https://arxiv.org/abs/2601.13365)
*Kevin Slote,Jeremie Fish,Erik Bollt*

Main category: cs.LG

TL;DR: CausationEntropy v1.1是一个Python包，实现了最优因果熵(oCSE)方法及其优化扩展，用于从动态系统和耦合振荡器中揭示因果网络，区分直接和间接路径。


<details>
  <summary>Details</summary>
Motivation: 需要提供一个易于使用的工具来实现oCSE方法及其扩展，用于复杂动态系统中的因果发现，填补现有工具的空白。

Method: 实现最优因果熵(oCSE)算法及其优化扩展，包括多种熵估计器（高斯、kNN、几何kNN、核密度、泊松），并提供合成数据生成器和绘图工具。

Result: 发布了CausationEntropy v1.1包，易于从PyPi安装，有完整文档和代码示例，采用模块化结构支持未来扩展，代码在MIT许可下开源。

Conclusion: 该包将成为复杂动态系统中因果发现的基准工具，为研究人员提供强大且易于使用的因果网络建模解决方案。

Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.

</details>


### [499] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: 提出了RoundTripCodeEval(RTCE)基准测试，用于评估代码LLM在双向代码执行中的一致性推理能力，发现现有模型在保持编码-解码双向映射一致性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码基准测试中表现良好，但在双向代码执行中暴露出推理一致性的局限性。现有基准测试主要关注I/O预测、执行推理或自然语言双向测试，缺乏对代码双向执行一致性的系统评估。

Method: 设计了RTCE基准测试，包含四个不同的代码执行推理任务，采用免执行的精确匹配评估方法，测试双向映射的保真度。评估了零样本提示、监督微调和自反思机制三种方法。

Result: 所有评估方法都只带来有限改进，无法弥补差距，表明当前LLM在真正的双向一致性方面存在困难。RTCE揭示了现有基准测试无法捕捉的新见解。

Conclusion: 当前LLM缺乏可信代码推理所需的内在一致性，RTCE基准测试为评估代码双向执行一致性提供了新的评估框架。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [500] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: TrustEnergy是一个用于准确可靠用户级能源使用预测的统一框架，通过分层时空表示和顺序保形分位数回归技术，在预测精度和不确定性量化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有能源使用预测方法大多忽视家庭间的空间相关性，难以扩展到个体化预测，且缺乏对动态不确定性的量化，无法满足准确细粒度用户级预测的需求。

Method: 提出TrustEnergy框架，包含两个关键技术组件：1) 分层时空表示模块，使用记忆增强时空图神经网络捕捉宏观和微观能源使用模式；2) 顺序保形分位数回归模块，动态调整不确定性边界，确保随时间推移的有效预测区间。

Result: 与佛罗里达州电力供应商合作评估，TrustEnergy相比最先进基线方法，预测精度提高5.4%，不确定性量化改善5.7%。

Conclusion: TrustEnergy框架能够有效解决用户级能源使用预测中的准确性和可靠性问题，通过结合时空建模和不确定性量化技术，为电网管理、基础设施规划和灾害响应等应用提供更可靠的预测工具。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [501] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种可学习的小波变换长短期Transformer模型，用于金融时间序列的日内交易策略学习，通过端到端训练的多尺度分解和回报导向决策，显著提升了盈利能力和风险调整收益。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：噪声大、非平稳性强、相关资产间存在强横截面依赖性。现有方法难以有效处理这些复杂特性。

Method: 提出WaveLSFormer模型，包含：1）可学习小波前端，通过端到端训练的滤波器组生成低/高频分量，使用频谱正则化器确保稳定且分离良好的频带；2）低引导高频注入模块，用高频线索细化低频表示并控制训练稳定性；3）输出满足固定风险预算的多空头寸组合，直接优化交易目标和风险感知正则化。

Result: 在6个行业组5年的小时数据上进行实验，WaveLSFormer在10个随机种子下均优于MLP、LSTM和Transformer基线。在所有行业中平均累计策略回报为0.607±0.045，夏普比率为2.157±0.166，显著提升了盈利能力和风险调整收益。

Conclusion: WaveLSFormer通过联合多尺度分解和回报导向决策学习，有效解决了金融时间序列交易的挑战，在盈利能力和风险调整收益方面均显著优于现有方法。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [502] [BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions](https://arxiv.org/abs/2601.13445)
*Ashish S. Nair,Sandipp Krishnan Ravi,Itzel Salgado,Changjie Sun,Sayan Ghosh,Liping Wang*

Main category: cs.LG

TL;DR: 提出基于DeepSDF的涡轮叶片领域特定隐式生成框架，实现性能感知的可制造设计生成


<details>
  <summary>Details</summary>
Motivation: 解决涡轮叶片设计中性能感知建模和可制造设计生成的关键缺口，超越传统2D引导或无约束3D流程

Method: 使用连续符号距离函数(SDF)表示，建立可解释的近高斯潜在空间，通过神经网络将工程描述符映射到潜在代码，支持插值和高斯采样

Result: 实现高重建保真度，表面距离误差集中在最大叶片尺寸的1%内，对未见设计具有鲁棒泛化能力

Conclusion: 该框架通过集成约束、目标和性能指标，为数据驱动的涡轮叶片建模和概念生成提供了实用且可解释的解决方案

Abstract: Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.

</details>


### [503] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR是一个双层自适应重标量化框架，可为任何公平性指标恢复最优帕累托效率模型，解决了现有公平机器学习方法常产生帕累托无效模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法存在两个主要问题：1）传统处理方法（如公平正则化）常产生帕累托无效模型，即某些群体的性能可以在不损害其他群体的情况下得到改善；2）现有帕累托效率方法偏向特定公平视角，无法适应文献中广泛研究的各种公平性指标。

Method: 提出BADR（Bilevel Adaptive Rescalarisation）框架，包含双层优化：下层是加权经验风险最小化任务，权重是各群体的凸组合；上层优化选定的公平性目标。开发了两种新颖的大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: BADR能够为任何公平性指标恢复最优帕累托效率模型，优于现有的帕累托效率公平方法。作者发布了badr开源Python工具箱，支持多种学习任务和公平性指标。

Conclusion: BADR提供了一个简单而强大的框架，能够为广泛的公平性指标实现帕累托效率，解决了现有方法的局限性，并通过开源工具箱和实验验证了其有效性。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [504] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 该论文提出客户端经验回放方法，通过在本地训练时混合历史样本缓冲，有效解决联邦学习中时间概念漂移导致的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时间概念漂移（客户端数据分布随时间变化）下表现不佳，标准FedAvg方法在季节性漂移中会出现灾难性遗忘，准确率大幅下降。

Method: 提出客户端经验回放方法：每个客户端维护一个小型历史样本缓冲区，在本地训练时将历史样本与当前数据混合使用。该方法无需修改服务器聚合机制。

Result: 在Fashion-MNIST数据集上，标准FedAvg准确率从74%降至28%，而使用每类50个样本的缓冲区后，性能恢复至78-82%。消融研究显示缓冲区大小与准确性存在明确权衡关系。

Conclusion: 客户端经验回放是一种简单有效的解决方案，能够防止联邦学习中的灾难性遗忘，且无需修改服务器端架构，在时间概念漂移场景下具有实用价值。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [505] [Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics](https://arxiv.org/abs/2601.13463)
*Brandon B. Le,D. Keller*

Main category: cs.LG

TL;DR: 提出量子机器学习在强子物理中的诊断框架，通过量子资格指标指导量子与经典神经网络的选择


<details>
  <summary>Details</summary>
Motivation: 量子机器学习架构逐渐成熟，关键挑战不再是构建而是识别其相对于经典方法的实际优势区域

Method: 开发以定量量子资格指标为中心的诊断工具，基于数据内在特性指导模型选择；通过受控分类和回归研究分析性能趋势

Result: 模型性能在复杂性、噪声和维度方面呈现系统性趋势，这些趋势可提炼为预测标准；在深度虚拟康普顿散射的康普顿形状因子提取中，量子资格指标识别出有利于量子模型的运动学区域

Conclusion: 为在精密强子物理中部署量子机器学习工具建立了原则性框架

Abstract: As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.

</details>


### [506] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 论文分析了Muon优化器的简化变体，通过矩阵分解和线性Transformer的上下文学习两个案例，证明了该算法具有独立于条件数的线性收敛性，优于梯度下降和Adam。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的大语言模型预训练里程碑算法，其底层机制特别是梯度正交化的作用仍不明确，缺乏端到端的理论分析来解释其在具体应用中的优势。

Method: 研究Muon优化器的简化变体，通过两个具体案例进行分析：矩阵分解问题和线性Transformer的上下文学习问题。在谱域中将Muon动态解耦为独立的标量序列，分析其收敛行为。

Result: 证明了简化Muon在这两个问题上都具有线性收敛性，且迭代复杂度独立于相关条件数，在理论上优于梯度下降和Adam算法。揭示了谱正交化诱导的预处理效应。

Conclusion: 研究形式化了谱正交化带来的预处理效应，为理解Muon优化器在矩阵优化问题中的有效性提供了理论依据，并可能推广到更广泛的应用场景。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [507] [A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model](https://arxiv.org/abs/2601.13476)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: PRAIM：一种基于大语言模型和检索增强记忆的概率变分插补框架，用于解决电动汽车充电数据缺失问题，显著提升插补精度并改善下游预测性能。


<details>
  <summary>Details</summary>
Motivation: 电动汽车基础设施中数据驱动应用的可靠性依赖于完整、高质量的充电数据。然而，现实世界的EV数据集经常存在缺失记录，现有插补方法无法处理充电数据的复杂多模态特性，且通常采用"一站一模型"的局限范式，忽略了有价值的站间相关性。

Method: 开发了PRAIM框架，使用预训练语言模型编码异构数据（时间序列需求、日历特征、地理空间上下文）为统一语义表示，通过检索增强记忆动态检索整个充电网络中的相关示例，采用变分神经架构构建统一的插补模型来克服数据稀疏性。

Result: 在四个公共数据集上的广泛实验表明，PRAIM在插补准确性和保持原始数据统计分布方面显著优于现有基线方法，并大幅提升了下游预测性能。

Conclusion: PRAIM通过结合大语言模型和检索增强记忆，有效解决了电动汽车充电数据缺失问题，为数据驱动的EV基础设施应用提供了更可靠的解决方案。

Abstract: The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.

</details>


### [508] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出一种基于Tucker分解的随机交替最小化算法，直接在核心张量和因子矩阵上操作，避免重复张量投影，实现低维张量因子的高效小批量更新。


<details>
  <summary>Details</summary>
Motivation: 低秩张量感知是信号处理和机器学习中的基本问题。现有恢复方法要么在全张量变量上操作且需要昂贵的张量投影，要么采用因子化公式但仍依赖全梯度计算，而大多数随机因子化方法仅限于张量分解设置。

Method: 提出一种随机交替最小化算法，直接在Tucker分解下的核心张量和因子矩阵上操作。该方法避免重复张量投影，并支持低维张量因子的高效小批量更新。

Result: 在合成张量感知的数值实验中，与代表性随机张量恢复基线相比，所提算法在运行时间上表现出更优的收敛行为。

Conclusion: 提出的随机交替最小化算法为低Tucker秩张量感知提供了一种高效解决方案，避免了传统方法的计算瓶颈，在运行时间上具有优势。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [509] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG是一个基于混合专家神经控制微分方程的时间序列生成框架，专门处理不规则采样和稀疏观测数据，支持连续高分辨率生成。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的时间序列数据往往是不规则采样和稀疏观测的（如临床监测），而现有方法大多假设规则采样和固定输出分辨率，这种不匹配限制了实际应用。

Method: 提出MoE-NCDE架构，包含动态参数化的专家函数和解耦设计，结合现有TSG模型学习专家混合与生成时间序列的联合分布。

Result: 在10个公开和合成数据集上的实验表明，MN-TSG在不规则到规则和不规则到连续生成任务上均优于现有基线方法。

Conclusion: MN-TSG通过混合专家NCDE架构有效解决了不规则时间序列的连续生成问题，能够为每个样本生成适当的专家配置，支持精细化的连续时间序列生成。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [510] [Patterning: The Dual of Interpretability](https://arxiv.org/abs/2601.13548)
*George Wang,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出"模式化"作为机制可解释性的对偶问题：给定期望的泛化形式，确定产生它的训练数据。通过可逆的线性响应关系，可以干预数据分布来引导模型达到目标内部配置。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性研究神经网络如何泛化到训练数据之外，但反向问题——如何通过设计训练数据来产生特定的泛化形式——尚未得到充分研究。本文旨在建立这一对偶问题，实现从"读取"内部结构到"写入"内部结构的转变。

Method: 基于敏感性概念，测量可观测量后验期望值对数据分布微小变化的响应。通过逆线性响应关系，计算能够引导模型达到目标内部配置的数据干预。在小语言模型和括号平衡任务中演示该方法。

Result: 在小语言模型中，沿主要敏感性方向重新加权训练数据可以加速或延迟结构形成（如归纳电路）。在括号平衡任务中，模式化可以通过针对不同解决方案的局部学习系数来选择模型学习的具体算法。

Conclusion: 相同的数学框架既可用于读取内部结构，也可用于写入内部结构。模式化建立了机制可解释性的对偶问题，为通过数据干预引导模型学习特定算法提供了理论基础。

Abstract: Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.

</details>


### [511] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE通过将专家视为共享量化基质的几何重定向，而非独立权重矩阵，实现了专家数量的次线性内存增长，在256个专家时达到150倍内存压缩。


<details>
  <summary>Details</summary>
Motivation: 传统MoE方法中N个独立专家权重矩阵需要O(N·d²)内存，超出边缘设备内存预算。现有压缩方法（量化、剪枝、低秩分解）只能减少常数因子，无法解决线性扩展瓶颈。

Method: 将专家视为共享三元原型的几何重定向，而非独立矩阵。通过学习的旋转操作从不同角度观察共享容量，实现专家多样性。内存复杂度为O(d² + N·d log d)，对专家数量呈次线性增长。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现150倍内存压缩，精度损失可忽略。使4GB设备能容纳64个专家，而标准MoE只能容纳8个。

Conclusion: 几何参数化打破了MoE的线性内存扩展瓶颈，通过共享容量和学习的旋转实现专家多样性，为边缘设备部署大规模MoE模型提供了可行方案。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [512] [Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework](https://arxiv.org/abs/2601.13564)
*Yanheng Li,Zhichen Pu,Lijiang Yang,Zehao Zhou,Yi Qin Gao*

Main category: cs.LG

TL;DR: LUMOS是一个数据与物理双驱动的荧光分子逆向设计框架，通过结合生成模型、预测模型和多目标进化算法，实现了高效、可靠的荧光分子设计与优化。


<details>
  <summary>Details</summary>
Motivation: 传统荧光分子设计方法面临化学空间巨大、机器学习预测不可靠、量子化学计算成本高昂等问题，需要一种能同时满足多目标和约束条件的高效设计框架。

Method: LUMOS将生成器和预测器耦合在共享潜在表示中，结合神经网络和快速TD-DFT计算构建互补预测器，并采用属性引导的扩散模型与多目标进化算法集成。

Result: 在综合基准测试中，LUMOS在荧光性质预测的准确性、泛化性和物理合理性方面优于基线模型，在多目标分子优化中表现出色，TD-DFT和MD模拟验证了其生成有效荧光团的能力。

Conclusion: LUMOS建立了一个通用的荧光团逆向设计框架，实现了从规格到分子的直接设计，为满足多样化目标规格的荧光分子设计提供了有效解决方案。

Abstract: Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.

</details>


### [513] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 语言模型可以通过辩论、自举和内部一致性最大化等方法实现无外部监督的自我提升，这些方法都是"一致性优化"的特殊形式，即寻找最可压缩和联合可预测的上下文到行为的映射。


<details>
  <summary>Details</summary>
Motivation: 虽然语言模型能够通过辩论、自举和内部一致性最大化等方法在没有外部监督的情况下提高准确性，甚至达到与有监督微调相当的性能，但这些方法为何有效在理论上仍不清楚。本文旨在为这些自我提升方法提供理论解释。

Method: 提出"一致性优化"理论框架，将辩论、自举和内部一致性最大化等方法统一为寻找最可压缩和联合可预测的上下文到行为映射的特殊情况。证明一致性优化等价于描述长度正则化，并证明在所有此类正则化方案中，当正则化器来自预训练模型时，一致性优化在半监督学习中最优。

Result: 理论分析表明，一致性优化能够解释无反馈自我提升为何有效，并预测其成功或失败的条件。初步实验支持了理论结论。

Conclusion: 一致性优化为语言模型的无监督自我提升方法提供了统一的理论框架，解释了这些方法的工作原理，并为其有效性和局限性提供了理论依据，有助于指导未来自我提升方法的设计和应用。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [514] [DRGW: Learning Disentangled Representations for Robust Graph Watermarking](https://arxiv.org/abs/2601.13569)
*Jiasen Li,Yanwei Liu,Zhuoyi Shang,Xiaoyan Gu,Weiping Wang*

Main category: cs.LG

TL;DR: DRGW是首个基于解耦表示学习的图水印框架，通过分离结构表示与水印载体，解决了现有方法在透明度、鲁棒性和可检测性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图水印方法主要基于图结构或纠缠的图表示，由于图表示中的信息耦合以及连续数值表示到图结构转换中的不可控离散化，导致水印的透明度和鲁棒性受损。

Method: 1) 设计对抗训练的编码器，学习对多种扰动不变的结构表示，并导出统计独立的水印载体；2) 设计图感知的可逆神经网络，为水印嵌入和提取提供无损通道；3) 开发结构感知编辑器，将潜在修改解析为离散图编辑。

Result: 在多个基准数据集上的实验表明，DRGW具有优越的有效性。

Conclusion: DRGW通过解耦表示学习解决了图水印中的透明度、鲁棒性和可检测性问题，是首个采用该方法的图水印框架。

Abstract: Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.

</details>


### [515] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

TL;DR: GeoDynamics：一种几何状态空间神经网络，直接在对称正定流形上追踪大脑状态轨迹，用于分析功能连接动态和疾病标记检测


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型将大脑视为松散连接区域或强加简化网络先验，缺乏真正的整体自组织动态系统视角。功能连接矩阵位于黎曼流形而非欧几里得空间，需要几何感知的方法来捕捉其轨迹。

Method: 提出GeoDynamics模型，将每个连接矩阵嵌入到流形感知的循环框架中，直接在高维对称正定流形上学习平滑且尊重几何的状态转换。

Result: 模型能够揭示任务驱动的状态变化，检测阿尔茨海默病、帕金森病和自闭症的早期标记。在人类动作识别基准测试（UTKinect、Florence、HDM05）上也验证了其可扩展性和鲁棒性。

Conclusion: GeoDynamics为在黎曼流形上建模复杂时空动态提供了强大框架，不仅适用于神经科学，还能扩展到其他领域，实现了真正整体和自组织的动态系统视角。

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [516] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: RAM：针对RL训练智能体模型的分布感知合并框架，通过分离共享和任务特定参数更新，解决标准合并方法在RL智能体上的性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有合并方法为监督微调设计，不适用于RL训练的智能体模型。RL产生的任务向量稀疏且异质，而SFT合并假设密集且全局可比，导致标准全局平均会稀释RL关键任务特定行为

Method: RAM框架：1）解耦共享和任务特定参数更新；2）平均共享组件；3）选择性保留并重新缩放独特组件以抵消参数更新稀释

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越合并基线，还能解锁智能体间的协同潜力，实现优于领域专用智能体的性能

Conclusion: RAM是针对RL训练智能体模型的专门合并框架，解决了任务向量不匹配问题，能有效保留任务特定能力并实现智能体间的协同提升

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [517] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: FG-OrIU提出首个特征和梯度双重正交约束的增量遗忘框架，通过SVD分解特征空间，在特征和梯度层面强制正交约束，实现不可逆的深度遗忘，解决现有方法导致的表面遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏对特征和梯度层面的明确约束，导致"表面遗忘"——残留信息仍可恢复。这种不完全遗忘存在安全风险，并破坏保留平衡，特别是在增量遗忘场景中。

Method: FG-OrIU通过SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间。实施双重约束：1) 特征正交投影确保遗忘类和保留类特征正交；2) 梯度正交投影防止更新过程中重新引入遗忘知识并干扰保留类。同时采用动态子空间适应机制，合并新遗忘子空间并压缩保留子空间。

Result: 大量实验证明该方法在实现深度遗忘方面的有效性，能够确保遗忘效果的不可逆性，同时在连续遗忘任务中保持移除和保留的稳定平衡。

Conclusion: FG-OrIU是首个统一特征和梯度正交约束的增量遗忘框架，通过双重正交约束实现不可逆的深度遗忘，解决了现有方法的表面遗忘问题，在安全性和保留平衡方面表现优异。

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [518] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: Neural Organ Transplantation (NOT) 是一种模块化适配框架，可将训练好的transformer层作为可重用检查点进行领域适配，在解码器模型中显著优于LoRA等方法。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。NOT旨在实现隐私保护的专家知识共享，通过检查点分发实现高效模块化迁移。

Method: 从预训练模型中提取连续层子集（"捐赠器官"），在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据。

Result: 在124M到20B参数的三种解码器架构（GPT-2、TinyLlama、GPT-OSS）上，捐赠移植显著优于现有适配方法，困惑度比LoRA提高一个数量级，训练速度更快。早期插入位置效果最佳，十亿参数规模的跨域转移显示出意外的正则化效益。

Conclusion: transformer中间层支持解码器架构的高效模块化迁移，实现隐私保护的专家知识共享。该方法目前仅限于解码器模型，在编码器架构上效果有限。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [519] [Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments](https://arxiv.org/abs/2601.13592)
*Hao Jing,Sa Xiao,Haoyu Li,Huadong Xiao,Wei Xue*

Main category: cs.LG

TL;DR: 使用残差卷积神经网络替代传统辐射方案，在保持精度的同时将计算速度提升约8倍，实现了10天稳定预报


<details>
  <summary>Details</summary>
Motivation: 辐射过程是数值模式中最耗时的物理过程，传统方法计算效率低，需要机器学习方法来提高计算效率，同时解决混合预报框架中的耦合兼容性和长期积分稳定性问题

Method: 采用残差卷积神经网络近似RRTMG辐射方案，使用离线训练和在线耦合方法，通过模型模拟生成包含有云和无云大气柱的完整数据集，采用经验回放增强数据稳定性，并基于物理意义添加输出约束，使用LibTorch进行实时耦合

Result: 混合模型能够完成10天积分预报，两个月的业务回算实验表明机器学习模拟器达到与传统物理方案相当的精度，同时计算速度提升约8倍

Conclusion: 机器学习方法可以有效替代传统辐射方案，在保持预报精度的同时显著提高计算效率，解决了混合预报框架中的关键瓶颈问题，为业务应用提供了可行方案

Abstract: Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.

</details>


### [520] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精炼"两阶段解决块扩散语言模型的不可逆性和短视问题，显著提升生成质量


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型虽然结合了自回归和扩散模型的优点，但其严格的单向块依赖导致不可逆性，并牺牲了扩散模型的全局规划能力。需要解决这些限制以提升模型性能。

Method: 1. 使用小块进行块扩散快速生成草稿；2. 通过具有更大双向感受野的全局双向扩散精炼草稿；3. 采用快照置信度重掩码识别需要修改的关键词元；4. 使用混合尺度训练扩展块扩散模型的全局能力

Result: 在OpenWebText数据集上为离散扩散模型设定了新基准：仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，通过草稿-精炼两阶段策略显著提升了生成质量，为离散扩散模型提供了更优的解决方案

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [521] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA：一种基于Fisher信息的参数级聚合方法，用于解决非IID数据下联邦学习的客户端漂移问题


<details>
  <summary>Details</summary>
Motivation: 在非IID数据分布下，FedAvg等标准联邦学习方法对所有参数使用相同的标量权重进行聚合，导致客户端更新严重错位，产生客户端漂移并降低全局模型性能

Method: 提出Fisher信息参数级聚合（FIPA），用参数特定的Fisher信息矩阵权重替代客户端级标量权重，实现真正的参数级缩放，捕捉每个客户端数据对不同参数的独特影响。通过低秩近似保持通信和计算效率

Result: 在非线性函数回归、PDE学习和图像分类任务中，FIPA始终优于基于平均的聚合方法，并能与最先进的客户端优化算法有效结合，进一步提高图像分类准确率

Conclusion: FIPA在异构数据分布下为联邦学习提供了显著优势，通过参数级聚合有效缓解客户端漂移问题

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [522] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 提出一种二次上界损失函数，用于改进快速对抗训练中的鲁棒性下降问题


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然减少了训练时间，但往往因为对抗空间探索不足而导致鲁棒性下降，需要解决这一问题

Method: 推导出对抗训练损失函数的二次上界，并将该上界与现有快速对抗训练方法结合使用

Result: 将QUB损失应用于现有方法能显著提高鲁棒性，且这种改进可能源于所得模型的平滑损失景观

Conclusion: 二次上界损失函数能有效缓解快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升模型性能

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [523] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: TimeART：一个融合强大大规模预训练工具分析能力和LLM推理能力的框架，作为全自动数据科学家处理时间序列问答任务


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析主要依赖人工数据科学家，成本高且缺乏自动化，需要开发自动化解决方案来降低人工成本并提高效率

Method: 1. 提出TimeART框架，融合现成工具的分析能力和LLM的推理能力；2. 收集10万专家轨迹语料库TimeToolBench；3. 设计四阶段训练策略，通过早期经验和自我反思提升模型泛化能力

Result: 训练了一个80亿参数的TSRM模型，在多个TSQA任务上取得了最先进的性能表现

Conclusion: TimeART框架为代理式时间序列推理开辟了新途径，实现了全自动化的时间序列问答系统

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [524] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

TL;DR: 提出基于深度学习的脑组织变形替代模型，使用随机教师强制策略提高长期预测稳定性，实现神经外科手术模拟的实时交互


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器无法满足神经外科手术模拟的实时性能要求，需要开发能够高效模拟脑组织非线性变形的替代模型

Method: 基于通用物理变换器构建深度学习替代模型，直接在大型网格数据上操作，采用随机教师强制训练策略逐步减少真实输入比例

Result: 模型在15万个节点的网格上实现准确预测，随机教师强制将最大预测误差从6.7mm降至3.5mm，在消费级硬件上每步运行时间低于10ms

Conclusion: 提出的深度学习框架能够实现快速、平滑、准确的脑组织生物力学模拟，为真实的手术训练环境奠定基础

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [525] [Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation](https://arxiv.org/abs/2601.13698)
*Arjun Nichani,Hsiang Hsu,Chun-Fu,Chen,Haewon Jeong*

Main category: cs.LG

TL;DR: 该论文使用信息论工具Chernoff信息分析公平性、隐私性和准确性三者之间的关系，揭示了这种关系的分布依赖性，并提出了在未知分布数据上估计Chernoff信息的方法。


<details>
  <summary>Details</summary>
Motivation: 公平性和隐私性是可信机器学习的两大支柱，但现有研究较少关注两者之间的关系。本文旨在通过信息论方法同时分析公平性、隐私性和准确性三者之间的复杂关系，揭示这种关系的数据依赖性。

Method: 1. 定义Noisy Chernoff Difference作为分析工具；2. 在合成数据上展示该值的三种不同行为模式；3. 提出在未知分布数据上估计Chernoff信息的方法；4. 在真实数据集上应用该框架。

Result: 1. Noisy Chernoff Difference表现出三种不同的行为模式，取决于数据分布；2. 该值可作为公平性-准确性曲线陡峭度的代理指标；3. 成功在真实数据集上应用该分析框架。

Conclusion: 公平性、隐私性和准确性之间的关系具有显著的数据依赖性，需要根据具体数据分布来理解。本文提出的信息论框架为统一理解这三者关系提供了基础，并强调了数据分布在这一动态关系中的关键作用。

Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.

</details>


### [526] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 研究比较了监督机器学习与生成式AI在预测慢性鼻窦炎手术效果上的表现，发现MLP模型在准确率、校准和决策曲线方面优于生成式AI，建议采用ML为主、GenAI辅助的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有广泛应用，但在临床数据上进行前瞻性决策支持的应用仍然有限。本研究旨在探索如何利用术前临床数据预测慢性鼻窦炎患者的手术效果，识别那些手术效果不佳的患者，从而避免不必要的手术。

Method: 研究比较了监督机器学习（逻辑回归、树集成方法和自研MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）在预测慢性鼻窦炎手术效果上的表现。所有模型接收相同的结构化输入数据，输出被约束为二元推荐建议和置信度。研究还提出了可重复的表格数据到生成式AI的评估协议，并进行了亚组分析。

Result: 最佳ML模型（MLP）达到85%的准确率，具有优越的校准特性和决策曲线净收益。生成式AI模型在零样本设置下的区分度和校准方面表现较差。值得注意的是，生成式AI的解释与临床医生的启发式方法和MLP的特征重要性一致，都强调基线SNOT-22评分、CT/内窥镜严重程度、息肉表型以及心理/疼痛共病。

Conclusion: 研究支持采用ML为主、GenAI辅助的工作流程：部署校准的ML模型进行手术候选者的初步筛选，使用生成式AI作为解释工具来增强透明度和共同决策制定。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [527] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种双分支架构，结合滑动窗口注意力和循环记忆机制，用于癫痫发作预测，在CHB-MIT数据集上达到99.46%的片段级敏感度，并通过分层上下文策略显著降低误报率。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战，因为发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在捕捉局部时空模式和保持长程上下文信息之间存在权衡。

Method: 提出EEG-Titans双分支架构：1) 滑动窗口注意力分支捕捉短期异常；2) 循环记忆路径总结随时间推移的缓慢渐进趋势。采用现代神经记忆机制进行长上下文建模，并对高噪声受试者使用分层上下文策略扩展感受野。

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均片段级敏感度。通过分层上下文策略，在易受伪影影响的记录中显著降低误报率（极端异常值降至0.00 FPR/h），同时不牺牲敏感度。

Conclusion: 记忆增强的长上下文建模可以在临床约束评估下提供稳健的癫痫发作预测，通过结合短期异常检测和长期趋势分析，在保持高敏感度的同时有效减少误报。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [528] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear是一个基于线性运算的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在保持高性能的同时将计算复杂度从O(N²)降低到O(N)。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的预测器通常依赖自注意力机制或其变体来捕捉多元相关性，但这会导致O(N²)的计算复杂度（N为变量数）。需要一种更高效的替代方案来降低计算成本。

Method: 1. vecTrans模块：使用可学习向量建模多元相关性，将复杂度降至O(N)，可无缝集成到Transformer预测器中；2. WFMLoss目标函数：采用最终序列导向（而非速度导向）的流匹配损失，结合路径和水平加权策略，专注于更可靠的路径和预测水平。

Result: 在22个基准测试和124个预测设置中达到最先进性能；vecTrans集成到Transformer预测器中可实现高达5倍的推理加速和一致的性能提升；WFMLoss作为即插即用目标函数能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，在保持高性能的同时显著降低了计算复杂度，为多元时间序列预测提供了高效且有效的解决方案。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [529] [Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks](https://arxiv.org/abs/2601.13776)
*Thibaut Boissin,Franck Mamalet,Valentin Lafargue,Mathieu Serrurier*

Main category: cs.LG

TL;DR: Orthogonium是一个统一的PyTorch库，提供正交和1-Lipschitz神经网络层，解决了现有实现碎片化、有限且计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 正交和1-Lipschitz神经网络层对于认证对抗鲁棒性、稳定生成模型和可靠循环网络至关重要，但现有实现存在碎片化、功能有限和计算成本高的问题，阻碍了这些鲁棒架构的广泛应用。

Method: 开发了Orthogonium库，提供统一、高效且全面的正交和1-Lipschitz层实现，支持标准卷积功能（步长、膨胀、分组、转置等），同时保持严格的数学保证，并进行了优化以减少大规模基准测试中的开销。

Result: 库的严格测试发现了现有实现中的关键错误，优化实现显著降低了ImageNet等大规模基准测试的开销，为需要正交性和鲁棒Lipschitz约束的多样化应用提供了标准化可靠工具。

Conclusion: Orthogonium显著降低了采用正交和1-Lipschitz层的障碍，使研究人员和从业者能够在各种应用中实现可扩展的实验和集成，促进了鲁棒深度学习架构的发展。

Abstract: Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.

</details>


### [530] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow：一种潜在图扩散框架，通过将图压缩到低维潜在空间进行扩散，解决了传统图扩散模型二次复杂度问题，实现近无损重建和1000倍加速。


<details>
  <summary>Details</summary>
Motivation: 传统图扩散模型存在二次复杂度瓶颈，且大部分计算能力浪费在稀疏图的边缺失建模上。现有潜在扩散方法难以应用于图生成，因为图生成需要近乎无损的重建，单个邻接矩阵错误就会导致整个样本无效。

Method: 提出LG-Flow框架：1）使用置换等变自编码器将每个节点映射到固定维度的嵌入，从该嵌入中可以证明完全恢复邻接矩阵；2）在潜在空间中训练基于流匹配的扩散变换器；3）潜在表示维度与节点数线性相关，消除二次瓶颈。

Result: 在无向图和DAGs上实现近无损重建；与最先进的图扩散模型相比获得竞争性结果；实现高达1000倍的加速；能够训练更大、更具表达力的模型。

Conclusion: LG-Flow成功解决了图潜在扩散中的关键挑战，通过可证明的完全重建能力和线性复杂度，为高效、高质量的图生成提供了新范式。

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [531] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出一种基于注意力机制的ETA预测模型，通过历史道路速度模式的注意力机制来准确估计到达时间，在保持模型轻量化的同时提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统的普及，准确可靠的ETA估计在导航、出行规划和交通管理中变得至关重要。然而，由于交通流的动态复杂性，传统方法要么以简单方式结合实时和历史数据，要么依赖复杂的基于规则的计算，而现有深度学习模型计算成本高且未能有效捕捉时空模式。

Method: 提出基于注意力机制的ETA模型，利用注意力机制提取和利用沿路线每个时空点累积的时间特征。该架构通过注意力机制处理历史道路速度模式，有效整合道路特征、实时交通条件和历史速度模式，同时保持模型轻量和可扩展。

Result: 在真实世界驾驶数据集上验证，该方法优于现有基线模型，能够有效整合道路特征、实时交通条件和历史速度模式，实现高效准确的ETA估计。

Conclusion: 提出的基于注意力机制的ETA模型能够有效解决时空因果关系，在保持轻量化和可扩展的同时，通过任务感知的方式整合多种交通信息，显著提升ETA预测的准确性和可靠性。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [532] [ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks](https://arxiv.org/abs/2601.13824)
*Xiaohong Yang,Tong Xie,Minghui Liwang,Chikai Shang,Yang Lu,Zhenzhen Jiao,Liqun Fu,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: ELSA是一个用于边缘网络LLM微调的高效框架，通过结合分割学习和分层联邦学习，解决设备资源限制、数据异构性和隐私风险问题。


<details>
  <summary>Details</summary>
Motivation: 边缘设备训练大型语言模型面临三大挑战：设备资源有限、数据异构性严重、隐私风险高。现有方法难以同时解决这些问题。

Method: 1. 任务无关的行为感知客户端聚类机制，使用公共探针输入和对称KL散度构建语义指纹；2. 将LLM分割为三部分分布在客户端和边缘服务器，云仅用于适配器聚合；3. 基于计算草图的轻量通信方案结合语义子空间正交扰动减少通信开销并保护隐私。

Result: 在多种NLP任务上的实验表明，ELSA在适应性、收敛行为和鲁棒性方面持续优于现有最先进方法。

Conclusion: ELSA为资源受限的边缘侧LLM微调提供了一个可扩展且隐私感知的解决方案。

Abstract: Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.

</details>


### [533] [Optimal L2 Regularization in High-dimensional Continual Linear Regression](https://arxiv.org/abs/2601.13844)
*Gilad Karpel,Edward Moroshko,Ran Levinstein,Ron Meir,Daniel Soudry,Itay Evron*

Main category: cs.LG

TL;DR: 研究过参数化持续线性回归中的泛化问题，推导出高维情况下的闭式解，证明各向同性正则化能缓解标签噪声，并发现最优正则化强度随任务数T呈T/lnT比例增长。


<details>
  <summary>Details</summary>
Motivation: 研究持续学习中的泛化问题，特别是在过参数化线性回归设置下，探索正则化如何影响模型在序列任务上的泛化性能，为持续学习系统设计提供理论指导。

Method: 采用过参数化持续线性回归框架，使用L2（各向同性）正则化训练模型。推导高维情况下的闭式表达式，分析单教师和多教师设置下的正则化效果，并通过实验在线性回归和神经网络上验证理论发现。

Result: 各向同性正则化能有效缓解标签噪声，在单教师和多教师设置下均有良好表现。最优固定正则化强度随任务数T呈T/lnT比例增长，这是持续学习理论中的首次发现。实验验证了该缩放规律对泛化的影响。

Conclusion: 各向同性正则化是持续学习中缓解标签噪声的有效方法，最优正则化强度随任务数呈T/lnT比例增长，为持续学习系统设计提供了实用的理论指导。

Abstract: We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.

</details>


### [534] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 提出MUSIC方法，通过自组织映射(SOM)的原型距离反演精确恢复输入数据，并实现可控的语义空间轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 传统SOM主要用于可视化和聚类，但缺乏从激活模式恢复原始数据的能力。本文旨在探索SOM激活模式的反演可能性，实现精确数据恢复和可控的语义空间操作。

Method: 基于欧几里得距离几何原理，推导出从D+1个仿射独立参考点到原点的线性系统。提出MUSIC更新规则，通过修改选定原型的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化确保高维数据上的平滑运动。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证，MUSIC能够产生平滑、可解释的轨迹，揭示学习流形的底层几何结构，优于无监督聚类方法。

Conclusion: SOM激活模式可在温和几何条件下精确反演输入数据。MUSIC提供了一种基于原型几何的数据增强和可控潜在探索新视角，无需采样、潜在先验或编码器-解码器架构。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [535] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: 提出一种利用大语言模型作为代理模型和候选采样器的分层搜索策略，用于多目标优化问题，通过自适应分区和局部推理提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理能力方面表现出色，但目前还不是多目标优化的现成选择。传统方法通过处理数值输入、平衡探索与利用、处理多目标冲突等能力在基准测试中表现优异。本文旨在填补这一空白。

Method: 提出分层搜索策略：1) 将输入空间自适应划分为不相交的超矩形区域；2) 使用复合评分函数对这些区域进行排名；3) 将LLM的生成过程限制在特定高潜力子空间中，使其只需进行局部推理而非全局推理。

Result: 理论证明：在标准正则性假设下，算法生成的候选解在Hausdorff距离下收敛到真实Pareto集。实证结果：在合成和真实世界基准测试中，始终优于基于LLM的全局多目标优化器，并与标准进化和贝叶斯优化算法表现相当。

Conclusion: 通过将LLM作为代理模型和候选采样器，结合结构化分层搜索策略，成功将LLM应用于多目标优化问题，实现了与现有优化方法相当的性能，同时保持了LLM的推理优势。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [536] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

TL;DR: 提出TractRLFusion：基于GPT的策略融合框架，通过数据驱动的融合策略整合多个RL策略，提升白质纤维束重建的准确性和解剖可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统纤维束成像方法存在准确重建白质纤维束同时最小化虚假连接的挑战，需要改进现有深度学习和深度强化学习方法。

Method: 采用基于GPT的策略融合框架，包含两阶段训练数据选择过程进行有效策略融合，然后进行多critic微调阶段以增强鲁棒性和泛化能力。

Result: 在HCP、ISMRM和TractoInferno数据集上的实验表明，TractRLFusion在准确性和解剖可靠性方面优于单个RL策略以及最先进的经典和DRL方法。

Conclusion: TractRLFusion通过融合多个RL策略有效解决了纤维束成像中的准确重建问题，为脑连接研究和神经外科规划提供了更可靠的工具。

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [537] [Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition](https://arxiv.org/abs/2601.13953)
*Gorgi Pavlov*

Main category: cs.LG

TL;DR: 提出Hierarchical Spectral Composition架构，通过梯度下降学习精确布尔逻辑，使用Sinkhorn约束路由和列符号调制，在多种复杂度下实现高精度布尔运算合成。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络学习布尔逻辑时会产生"模糊"近似，量化后性能下降，需要一种能学习精确布尔逻辑的梯度下降方法。

Method: 引入分层谱组合架构：从冻结的布尔傅里叶基中选择谱系数，通过Sinkhorn约束路由和列符号调制进行组合。结合精确Walsh-Hadamard系数、三元量化和MCMC精炼。

Result: 在n=2时100%准确率，n=3时梯度下降76%但枚举证明存在最优三元掩码（100%准确率），n=4时谱合成实现100%准确率。GPU上达到10,959 MOps/s推理速度。

Conclusion: 证明了所有测试函数都存在三元多项式阈值表示，但高维时需要超越纯梯度下降的方法。该方法适用于硬件高效的神经符号逻辑合成。

Abstract: Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.

</details>


### [538] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

TL;DR: RL-BioAug：利用强化学习智能选择EEG数据增强策略的框架，仅需10%标签数据指导，在睡眠分期和癫痫检测任务上显著优于随机增强策略。


<details>
  <summary>Details</summary>
Motivation: EEG信号的非平稳性使得静态或随机的数据增强策略难以保留内在信息，而对比学习性能高度依赖增强质量。需要一种能自适应选择最优增强策略的方法。

Method: 提出RL-BioAug框架，使用标签高效的强化学习代理自主确定最优增强策略。仅用10%标签数据指导代理策略，编码器以严格自监督方式学习鲁棒表示。

Result: 在Sleep-EDFX和CHB-MIT数据集上，相比随机选择策略分别提升9.69%和8.80%的Macro-F1分数。代理为不同任务选择不同最优策略：睡眠分期任务62%概率选择时间掩码，癫痫检测任务77%概率选择裁剪和调整大小。

Conclusion: RL-BioAug有潜力取代传统的启发式增强方法，建立数据增强的自主范式，为EEG对比学习提供更智能的增强策略选择。

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [539] [A universal linearized subspace refinement framework for neural networks](https://arxiv.org/abs/2601.13989)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.LG

TL;DR: LSR是一种架构无关的框架，利用固定训练网络状态的雅可比诱导线性残差模型，通过求解子空间内的最小二乘问题，显著提升预测精度，无需修改网络架构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 神经网络通常使用基于梯度的方法训练，但在许多应用中，其最终预测精度远未达到模型表达能力可达到的水平。梯度训练往往无法充分利用模型潜力，即使局部线性化产生凸问题。

Method: 提出线性化子空间细化(LSR)框架：1）在固定训练网络状态利用雅可比诱导线性残差模型；2）在该子空间内求解简化的直接最小二乘问题；3）获得线性化残差模型的子空间最优解；4）对于算子约束问题，进一步提出迭代LSR，交替进行单次LSR和监督非线性对齐。

Result: LSR系统性地揭示了梯度训练未充分利用的精度水平，经常实现数量级的误差减少。在监督函数逼近、数据驱动的算子学习和物理信息算子微调等任务中，LSR显著优于标准梯度训练解决方案。

Conclusion: 损失诱导的数值病态性（而非非凸性或模型表达能力）可能是实际瓶颈。LSR通过将非线性神经表示与固定线性化点的降阶线性求解器结合，为监督学习、算子学习和科学计算提供了数值基础广泛适用的细化框架。

Abstract: Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.

</details>


### [540] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

TL;DR: 提出基于机器学习的框架，在相同真实驾驶条件下公平比较燃油车和电动车的CO2排放


<details>
  <summary>Details</summary>
Motivation: 道路运输脱碳需要一致透明的方法来比较不同车辆技术的CO2排放，现有方法难以在相同真实驾驶条件下公平比较燃油车和电动车

Method: 使用循环神经网络分别训练燃油车和电动车模型，学习从驾驶变量（速度、加速度、温度）到内部执行变量（扭矩、油门）和瞬时CO2排放率的映射，构建反事实场景进行对比

Result: 建立了可扩展的框架，能够在统一瞬时排放指标下公平评估动力系统技术，为真实驾驶条件下的车辆碳性能提供可信数据驱动评估

Conclusion: 该机器学习框架为动力系统技术的公平可重复评估提供了基础，支持在相同真实驾驶条件下对燃油车和电动车进行直接比较，有助于道路运输脱碳决策

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


### [541] [Universal Approximation Theorem for Input-Connected Multilayer Perceptrons](https://arxiv.org/abs/2601.14026)
*Vugar Ismailov*

Main category: cs.LG

TL;DR: 提出输入连接多层感知机（IC-MLP），一种每个隐藏神经元除了接收前层输出外还直接接收原始输入仿射连接的神经网络架构，证明了其在非线性激活函数下的通用逼近能力。


<details>
  <summary>Details</summary>
Motivation: 探索一种改进的神经网络架构，通过在隐藏层中引入直接来自原始输入的连接，可能增强网络的学习能力和表达能力。

Method: 提出IC-MLP架构，其中每个隐藏神经元接收前层输出和原始输入的仿射连接。首先在单变量设置下分析，给出任意有限隐藏层的显式公式，然后扩展到向量值输入。

Result: 证明了深度IC-MLP在非线性激活函数下可以逼近闭区间上的任何连续函数（单变量情况），以及紧致子集上的连续函数（多变量情况），建立了相应的通用逼近定理。

Conclusion: IC-MLP是一种有效的神经网络架构，在非线性激活函数下具有通用逼近能力，为神经网络设计提供了新的理论框架。

Abstract: We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.

</details>


### [542] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 该论文提出了一种基于PAC隐私的API部署机器学习模型隐私保护方法，通过在模型输出而非权重上实施隐私保护，实现了在极小隐私预算下保持高模型效用。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型通常通过API部署，传统的权重隐私保护方法（如DP-SGD）会导致不必要的噪声和效用损失。模型权重对训练数据变化敏感，但模型对特定输入的输出维度更低且更稳定，因此直接在模型输出上实施隐私保护更有优势。

Method: 采用PAC隐私框架，通过控制互信息（MI）为任意黑盒函数提供基于实例的隐私保证。提出新算法通过自适应噪声校准实现对抗性组合，证明互信息保证在自适应和对抗性查询下线性累积。

Result: 在表格、视觉和NLP任务上验证了方法有效性：在CIFAR-10上达到87.79%准确率，每步MI预算仅2^{-32}；服务100万查询时MIA成功率上限为51.08%，相当于(0.04, 10^{-5})-DP保证。通过私有响应标注公共数据蒸馏出可发布的隐私保护模型，在ImageNet子集上使用210,000个响应蒸馏的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在API部署场景下实现了高效用和强隐私保护的平衡，通过输出级隐私保护避免了传统权重隐私方法的噪声问题，为实际部署提供了可行的隐私保护方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [543] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: LLMOrbit 是一个全面的循环分类法，对2019-2025年的大语言模型进行系统梳理，识别了数据稀缺、成本增长和能耗三大危机，并提出了突破扩展墙的六大范式。


<details>
  <summary>Details</summary>
Motivation: 随着AI从基础Transformer架构发展到接近人类水平的推理系统，需要系统性地梳理大语言模型的发展脉络，识别当前面临的扩展限制，并探索突破这些限制的创新方法。

Method: 通过八个相互关联的轨道维度，对超过50个模型和15个组织进行分析，建立循环分类法，涵盖架构创新、训练方法和效率模式等方面。

Result: 识别了三大危机（数据稀缺、成本指数增长、能耗不可持续）和六大突破范式（测试时计算、量化、分布式边缘计算、模型融合、高效训练、小型专用模型），揭示了三个范式转变（后训练增益、效率革命、民主化）。

Conclusion: 大语言模型发展面临扩展墙限制，但通过测试时计算、效率优化和开源民主化等创新范式，可以实现性能突破和可持续发展，推动AI从被动生成向工具使用代理演进。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [544] [Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.14092)
*Babacar Toure,Dimitrios Tsilimantos,Omid Esrafilian,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出基于注意力的多目标强化学习架构，用于无人机数据采集路径规划，平衡数据收集与能耗，无需信道先验知识，具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在无线网络数据采集中日益重要，但现有AI方法存在训练数据有限、忽略多目标特性、难以适应动态环境等问题，需要更鲁棒的解决方案。

Method: 采用基于注意力的多目标强化学习架构，显式处理数据收集与能耗之间的权衡，无需无线信道先验知识，单一模型可适应不同偏好和动态参数。

Result: 大量仿真表明，该方法在性能、模型紧凑性、样本效率和泛化能力方面显著优于现有RL解决方案，能适应未见过的场景。

Conclusion: 提出的注意力多目标强化学习架构有效解决了无人机路径规划中的多目标权衡问题，具有优异的泛化能力和实际部署潜力。

Abstract: Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.

</details>


### [545] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 本文提出了一种基于时滞交叉映射的因果特征选择框架，用于提高工业过程软测量模型的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法存在两个关键问题：1）忽略变量间的时滞因果关系；2）假设变量独立，与工业过程中变量相互依赖的实际不符，导致软测量模型精度和稳定性不足。

Method: 提出时滞交叉映射框架：1）使用时滞收敛交叉映射（TDCCM）进行总体因果推断；2）使用时滞偏交叉映射（TDPCM）进行直接因果推断；3）基于验证集模型性能自动确定因果阈值，实现自动特征选择。

Result: 两个真实案例研究表明：TDCCM实现了最高的平均性能，而TDPCM在最差情况下提高了软测量的稳定性和性能。

Conclusion: 所提出的时滞交叉映射框架有效解决了工业过程中时滞因果和变量依赖问题，显著提升了软测量模型的准确性和稳定性。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [546] [Riemannian Liquid Spatio-Temporal Graph Network](https://arxiv.org/abs/2601.14115)
*Liangsi Lu,Jingchao Wang,Zhaorong Dai,Hanqian Liu,Yang Shi*

Main category: cs.LG

TL;DR: RLSTG将连续时间液态动力学与黎曼流形几何归纳偏置相结合，在非欧几里得空间中建模时空图演化，克服了传统LTC网络局限于欧氏空间的缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统Liquid Time-Constant网络（LTCs）虽然擅长建模不规则采样动态，但局限于欧氏空间，在处理具有固有非欧结构（如层次结构和循环）的真实世界图时会产生几何失真，降低表示质量。

Method: 提出黎曼液态时空图网络（RLSTG），在弯曲流形上直接构建常微分方程来建模图演化，统一了连续时间液态动力学与黎曼流形的几何归纳偏置。

Result: 在真实世界基准测试中，RLSTG通过结合先进的时间动力学和黎曼空间表示，在具有复杂结构的图上实现了优越性能。

Conclusion: RLSTG通过将连续时间液态动力学扩展到黎曼流形，能够更忠实地捕捉时空图的内在几何结构，为建模非欧几里得图动态提供了有效框架。

Abstract: Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io

</details>


### [547] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: TPBS模型在回归任务中表现出色，通过局部狄利克雷能量正则化解决全局正则化失效问题，在过拟合情况下优于神经网络


<details>
  <summary>Details</summary>
Motivation: 研究低秩张量积B样条模型在回归任务中的应用，探索狄利克雷能量作为平滑度度量，发现全局狄利克雷能量正则化在某些情况下会失效

Method: 提出基于训练点周围小超立方体定义的局部狄利克雷能量正则化策略，利用预训练的TPBS模型开发两种从不完整样本进行推断的估计器

Result: TPBS模型在大多数数据集的过拟合情况下优于神经网络，在其他情况下保持竞争力；TPBS模型对过拟合更鲁棒且能有效利用正则化，而神经网络对过拟合更敏感且正则化效果较差

Conclusion: TPBS模型是回归任务的有效选择，特别是在过拟合情况下表现优异；局部狄利克雷能量正则化策略解决了全局正则化失效问题，使模型更具鲁棒性

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [548] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 本文研究LLM在确定性输出任务（如算术）上的错误率，提出一个基于注意力机制误差累积的两参数模型，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在需要确定性输出的任务（如算术）上为何会出现错误，挑战关于LLM错误是由于"推理崩溃"或无法表达"组合函数"的观点。

Method: 提出一个理论框架：注意力机制中的小误差会累积并超过阈值导致错误预测。使用"有效场论"视角，将LLM的众多参数重组为两个关键参数（基本噪声率和可能错误预测的令牌数）。使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行大量实证测试。

Result: 发现预测准确率与观察准确率在多种任务上高度一致，尽管在某些情况下存在偏差。两参数模型能很好地解释LLM的错误率。

Conclusion: LLM在重复性任务上的错误可以通过注意力机制误差累积来解释，而非"推理崩溃"。该模型提供了减少错误率的提示构建方法，为理解LLM错误机制提供了新视角。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [549] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 该研究提出了一种差异化取件点推荐策略（DPO），通过为每位顾客推荐单个取件点而非提供无限制选择，来同时减少配送卡车路线和顾客出行产生的碳排放。


<details>
  <summary>Details</summary>
Motivation: 取件点作为家庭配送的可持续替代方案，虽然能通过订单整合缩短配送路线并提高首次配送成功率，但当顾客驾车取件时，这些环境效益可能被抵消。需要一种策略来同时减少配送车辆和顾客出行的碳排放。

Method: 采用基于强化学习的方法，在动态随机环境中为每位到达的顾客推荐单个取件点（同时保留家庭配送选项）。该方法考虑了顾客与取件点之间的空间关系及其对未来路线整合的影响。

Result: 计算实验表明，差异化取件点推荐策略能显著减少总碳排放量：相比纯家庭配送最多减少9%，相比无限制取件点选择和最近取件点分配等替代策略平均减少2%。在取件点多、距离短的密集城市环境中效果尤为显著。

Conclusion: 差异化取件点推荐策略能有效减少总碳排放，特别是在密集城市环境中。当顾客不太倾向于选择取件点配送时，明确考虑顾客到达和选择的动态特性尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [550] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 提出Intervention Training (InT)方法，通过模型自我修正推理轨迹中的错误步骤，解决强化学习中信用分配问题，显著提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在语言模型推理中只关注最终答案，无法正确分配中间步骤的信用，导致正确步骤可能被惩罚，错误步骤可能被强化

Method: 提出Intervention Training (InT)：模型识别自己推理轨迹中的第一个错误，提出单步修正干预，然后通过监督微调将错误定位到具体步骤

Result: 在IMO-AnswerBench上，4B参数基础模型准确率提升近14%，超越gpt-oss-20b等更大的开源模型

Conclusion: InT通过细粒度信用分配有效解决强化学习中的信用分配问题，为后续RL训练提供更好的初始化，显著提升模型推理能力

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [551] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 提出一个可解释的脓毒症决策支持框架，包含患者分层、数据增强、离线强化学习和理由生成四个模块，在MIMIC-III和eICU数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是ICU主要死亡原因，及时准确的治疗决策对患者预后至关重要。现有决策支持系统往往缺乏可解释性，难以获得临床医生信任。

Method: 1) 基于聚类的患者分层模块；2) 使用VAE和扩散模型的数据增强管道；3) 基于AWR的离线强化学习代理，配备注意力编码器和集成模型；4) 多模态LLM驱动的理由生成模块。

Result: 在MIMIC-III和eICU数据集上评估，该方法实现了高治疗准确性，同时为临床医生提供可解释且稳健的策略建议。

Conclusion: 该框架通过整合患者分层、数据增强、强化学习和自然语言解释，为脓毒症治疗提供了准确且可解释的决策支持，有助于临床医生理解和信任AI建议。

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [552] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: KAGE-Env是一个JAX原生的2D平台游戏环境，将观测过程分解为独立可控的视觉轴，保持底层控制问题不变，用于系统分析视觉分布偏移对强化学习的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉强化学习基准测试往往将多种偏移源混在一起，阻碍了对视觉分布偏移的系统分析。像素基强化学习代理在纯视觉分布偏移下经常失败，即使潜在动态和奖励保持不变。

Method: 开发KAGE-Env环境，将观测过程分解为独立可控的视觉轴；创建KAGE-Bench基准测试，包含6个已知轴套件和34个训练-评估配置对，用于隔离单个视觉偏移；使用标准PPO-CNN基线进行评估。

Result: 观察到强烈的轴依赖性失败：背景和光度偏移经常导致成功率崩溃，而代理外观偏移相对良性；某些偏移保持前进运动但破坏任务完成，表明仅用回报可能掩盖泛化失败；JAX实现实现单GPU上每秒3300万环境步数。

Conclusion: KAGE-Env和KAGE-Bench提供了系统分析视觉泛化的干净抽象，揭示了不同视觉偏移对强化学习性能的差异化影响，并为快速可重复的视觉因素扫描提供了高效平台。

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [553] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: 提出QAM算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 连续动作强化学习中，使用扩散或流匹配策略时，直接通过反向传播进行梯度优化存在数值不稳定问题。现有方法要么丢弃梯度信息，要么牺牲策略表达能力或引入偏差。

Method: QAM采用伴随匹配技术，将评论家的动作梯度转换为步进式目标函数，避免不稳定的反向传播，同时保持策略表达能力和无偏性。结合时间差分备份进行评论家学习。

Result: 在离线RL和离线到在线RL的困难稀疏奖励任务上，QAM始终优于现有方法。

Conclusion: QAM通过伴随匹配有效解决了连续动作RL中扩散/流匹配策略优化的数值不稳定问题，为表达性策略优化提供了新思路。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [554] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合深度时空模型预测野火点火和强化学习智能灭火策略的AI框架，旨在实现从被动应对到主动预防的野火管理转变。


<details>
  <summary>Details</summary>
Motivation: 传统野火管理主要是被动反应式，只在火灾被检测到后才采取行动，导致生态系统破坏、社区损失和每年数十亿美元的灭火成本和经济损失。需要从被动应对转向主动预防。

Method: 1. 使用深度时空模型预测野火点火；2. 对高风险预测部署预训练的强化学习代理，在物理信息3D模拟中执行实时灭火战术（使用直升机灭火单位）；3. 生成威胁评估报告帮助应急响应者优化资源分配和规划。

Result: 1. 开发了FireCastRL框架，结合深度学习和强化学习支持野火预测和战术响应；2. 公开发布了一个包含950万个环境变量样本的大规模时空数据集用于野火预测。

Conclusion: 该研究展示了深度学习和强化学习如何结合，既支持野火预测又支持战术响应，为从被动应对转向主动预防的野火管理提供了AI解决方案。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [555] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: Jet-RL是一个FP8强化学习训练框架，通过统一训练和rollout阶段的精度来消除数值不匹配，相比传统的BF16训练+FP8 rollout策略，实现了更快的训练速度和稳定的收敛。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练流程计算效率低且资源密集，rollout阶段占训练时间70%以上。虽然量化训练（特别是FP8精度）有望缓解这一瓶颈，但常用的BF16训练+FP8 rollout策略在长序列和复杂任务中会出现训练不稳定和精度崩溃问题。

Method: 提出Jet-RL框架，采用统一的FP8精度流同时用于训练和rollout阶段，最小化数值差异，消除低效的跨步骤校准需求，从而实现稳健的RL优化。

Result: 实验验证Jet-RL的有效性：rollout阶段加速33%，训练阶段加速41%，端到端相比BF16训练加速16%，同时在所有设置中保持稳定收敛，精度下降可忽略不计。

Conclusion: Jet-RL通过统一的FP8精度流解决了传统量化RL训练中的数值不匹配问题，实现了显著的速度提升和稳定的训练收敛，为高效RL训练提供了实用解决方案。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>
